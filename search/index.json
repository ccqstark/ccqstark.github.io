[{"content":"什么是布隆过滤器 简介 布隆过滤器（Bloom Filter）是 1970 年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。\n具体实现原理 如上图所示，布隆过滤器的原理就是通过几个哈希函数把要存储的数据映射到一个二进制的数组里，映射到的对应位标为1，如上图就为（2，5，9）。后续有元素加入时，若该位本就为1，则不对该位再做处理。\n当要判断一个元素是否在过滤器中，也是先进行Hash计算出对应的位，判断二进制数组中所有对应的位是否都为1，是的话表示元素在其中；反之不在。\n存在的问题 布隆过滤器存在误判率，也是可能会把一个不存在的元素判定为存在的。因为在加入大量元素后，二进制数组中可能大部分位都被置为1了，所以一个新的数据Hash出来对应的位就很可能也都置为1了。\n解决办法就是增加二进制数组的长度，使得二进制数组不那么快饱和，就可以容纳更多的元素，降低误判概率；或者增加Hash次数，使得数据更加分散。\n所以但布隆过滤器判断一个元素存在时，可能不一定真的存在；但假如它判断一个元素不存在，那这个元素一定不存在，这种情况不存在误判。\n还有一个问题是删除困难，因为在元素较多的情况下它们对应的位总有交叉，如果你把其中一个元素对应的位都置0了，那很可能也会影响到其他的元素，很难仅仅删除一个元素。\n应用场景  网页爬虫对 URL 去重，避免爬取相同的 URL 地址； 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱； Google Chrome 使用布隆过滤器识别恶意 URL； Medium 使用布隆过滤器避免推荐给用户已经读过的文章； Google BigTable，Apache HBbase 和 Apache Cassandra 使用布隆过滤器减少对不存在的行和列的查找。  除了上述的应用场景之外，布隆过滤器还有一个应用场景就是解决缓存穿透的问题。所谓的缓存穿透就是服务调用方每次都是查询不在缓存中的数据，这样每次服务调用都会到数据库中进行查询，如果这类请求比较多的话，就会导致数据库压力增大，这样缓存就失去了意义。\n所以当有黑客生成大量随机的不存在的值请求服务器导致查询数据库，造成大量缓存穿透的情况时。我们可以用布隆过滤器进行拦截，被布隆过滤器判断为不存在的值就不需要查询数据库了，直接返回，大大减低了数据库压力。(少量判断为存在的值因为有误判率所以可以进行下一步查询)\n在redis中安装布隆过滤器 redis本身是不自带布隆过滤器功能的，要么基于bitmap自己实现，要么安装插件\n（布隆过滤器在guava包中也有实现）\n安装redis插件 非docker安装的redis可以采用安装插件的方式来\n# 去这个github仓库看看最新版本 wget https://github.com/RedisLabsModules/rebloom/archive/v2.2.4.tar.gz # 解压 tar zxvf v2.2.4.tar.gz # 编译 cd RedisBloom-2.2.4 make 以上执行完之后在目录下多了一个rebloom.so文件，将其移动到一个合适的位置\n然后在redis的配置文件里增加以下一行（最好添加在MODULES区域，规范点，redis配置文件所在路径可以在redis-cli中用info 命令查看）\n# 后面为rebloom.so文件所在的目录 loadmodule /xxx/xxx/xxx/[rebloom.so](http://rebloom.so/) 重启redis后进入redis-cli尝试以下命令\nbf.add test 1 bf.add test 2 bf.exists test 1 bf.exists test 222 Docker镜像 拉取镜像并运行容器\ndocker run -d -p 6379:6379 --name redis-redisbloom redislabs/rebloom:latest 进入容器测试命令\n# 进入容器 docker exec -it redis-redisbloom bash # 启动客户端 redis-cli 同样去测试bf.add和bf.exists命令即可\n使用Redisson的API进行操作 Redisson是著名的redis客户端，有很多强大的功能，其中就包括了布隆过滤器的实现，而且是直接基于redis的bitmap的，所以也不需要去在redis安装布隆过滤器的插件，原生的redis即可。\n引入依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 如果只为了使用redisson的布隆过滤器api，则不需要配置其他东西，只需要在项目配置文件中配好redis地址密码等，用redistemplate原来那些配置就行。\n简单使用demo @Test public void TestRedissonBloomFilter() { // 先根据key获取一个布隆过滤器（不管存不存在）  RBloomFilter\u0026lt;Integer\u0026gt; bloomFilter = redissonClient.getBloomFilter(\u0026#34;phoneList\u0026#34;); //初始化布隆过滤器：预计元素为100000000L,误差率为3%  bloomFilter.tryInit(100000000L, 0.03); //将号码10086插入到布隆过滤器中  bloomFilter.add(666); //判断下面号码是否在布隆过滤器中  System.out.println(bloomFilter.contains(666));//false  System.out.println(bloomFilter.contains(66666));//true } 封装进RedisUtil /** * 初始化一个布隆过滤器 * * @param expectedInsertions 预期元素数量 * @param falseProbability 误判率 * @return 是否创建成功 */ public \u0026lt;T\u0026gt; boolean initBloomFilter(RBloomFilter\u0026lt;T\u0026gt; bloomFilter, long expectedInsertions, double falseProbability) { return bloomFilter.tryInit(expectedInsertions, falseProbability); } /** * 获取布隆过滤器 */ public \u0026lt;T\u0026gt; RBloomFilter\u0026lt;T\u0026gt; getBloomFilter(String key) { return redissonClient.getBloomFilter(key); } /** * 在布隆过滤器中增加一个值 */ public \u0026lt;T\u0026gt; boolean addInBloomFilter(RBloomFilter\u0026lt;T\u0026gt; bloomFilter, T value) { try { bloomFilter.add(value); } catch (IllegalStateException e) { initBloomFilter(bloomFilter, 50000L, 0.01); } return bloomFilter.add(value); } /** * 判断某值是否存在于过滤器中 */ public \u0026lt;T\u0026gt; boolean containsInBloomFilter(RBloomFilter\u0026lt;T\u0026gt; bloomFilter, T value) { try { bloomFilter.contains(value); } catch (IllegalStateException e) { initBloomFilter(bloomFilter, 50000L, 0.01); } return bloomFilter.contains(value); } 为了方便使用这些API，这里我自己封装了一些工具类。\n因为BloomFilter不像redis其他数据结构，不用初始化就可以直接set和get，如果getBloomFilter 方法获取了一个未初始化的过滤器，并进行了add和contains操作，就会报错。因此我在这两个操作的方法中捕获了未初始化的异常，假如检测到了异常就自动进行初始化（默认值），简化了使用。\n点赞功能的设计与思考 点赞，一个看起来很简单的功能实现，在数据量大，并发量大情况下就不是这么回事了。\n可以代入微博的场景来思考，假如明星发一条微博，瞬间几十万点赞，这波流量要顶住也不是那么容易，尽管只是一个点赞功能而已。最近在做公司那个项目的点赞功能，为了设计得更加高可用，也是去好好地思考了。\n功能拆解 点赞，说到底就两个方面需要实现\n 对应帖子的点赞数 用户与点赞帖子的关联关系  第一个本质就是一个计数器，我们需要对每一个帖子被点赞的次数进行计数\n第二个主要是用来判断此用户是否已经点赞过文章，从而避免二次点赞或者进行取消点赞的操作，需要维护的是一个类似二元组的关系结构（用户id，帖子id）\n方案主要也是从两个数据库入手，即MySQL和Redis，也就是怎么处理好存储层和缓存层之间的关系、怎么最合理地配合使用它们来达到最佳的实现效果，这也是这个问题的本质。\n看透问题的本质再思考方案与动手实践，才是正确的解决问题的方式。教父曾经说过：”花半秒钟就看透事物本质的人，和花一辈子都看不清事物本质的人，注定是截然不同的命运。”（doge）\n方案一 这个方案是我最开始在翻阅查询了晚上的一些资料后想出来的，看起来好像有模有样，其实问题还是挺多的，主要也是和公司的同事讨论后被指出很多不合理的地方。\n方案介绍\n 这个流程主要是在点赞时前端直接在本地将点赞数+1并改变样式，然后再去请求后端， 然后就是请求的接口是把点赞的这个消息或者说任务，放到了消息队列里，之后等待被消费。每次消费是先直接在redis对计数器incr。 接着用户是否点赞是存在布隆过滤器中的，一篇文章一个bloom filter，里面存的就是点过赞的用户的id。 最后是定期将redis中的数据持久化到mysql。  反思\n前端本地先+1主要是为了用户直观感觉到点赞可以立马得到反馈，而不是因为到等待后端返回而带来的延迟感，影响用户体验。\n消息队列，加入它的本意是为了让消息可以被准确消费从未保证点赞数较为精确，后来发现这样失去了实时性同时增加了开销，而且我还得去保证消息的可靠消费，就为了其实压根不需要很准确的点赞数，实在没有必要，所以后续删了。\n之前在学redis的应用场景的时候好像就听过可以用incr来做点赞，所以这次要做点赞就直接先到了incr。得益于redis单线程，这样没有并发修改问题，速度也快，但同步到mysql是个大问题。\n没错，我直接用一个布隆过滤器当做存储用了，还在想之后持久化到mysql可以用binary类型来存，完全没有意识到人家是一个过滤器，不是一个存储器，我直接忽略了误判率。导致这些错误的使用也是当时对它认识还不够深刻。\n对于持久化到mysql，当时还没仔细往下查具体的方案，感觉业内应该会有一个成熟的机制或者什么插件中间件之类的可以方便快捷稳定地完成这个任务，后来发现并没有，需要自己业务代码做定时任务定期写入库，感觉就比较麻烦不好非常优雅完美地实现，如果缓存中的数据越来越多，这个同步任务岂不是越来越庞大？这个暂时不知道如何解决。\n总结就是方案十分不成熟，漏洞百出，是一个孬方案。\n方案二 在与同事讨论后对方案一进行改良后的方案，也是最后确定使用的方案。\n方案介绍\n 首先前端还是和方案一一样，不再赘述。 如何采用了MyBatis的二级缓存，将每次查询到的结果缓存到redis中，有变更就清除，查不到再回库查。点赞数就在查的时候缓存到了redis中，但是每次更新点赞数都是直接到库中操作的，而且附带一个清缓存的操作。 用户是否点赞用一个布隆过滤器先做过滤，一个redis的set来存储点赞和帖子的关系，直接用redis的持久化机制，不入MySQL。  反思\n这个方案对比方案一明显有了改进，首先是去掉了意义不大的消息队列，很好。\n然后是二级缓存，虽然每次点赞都会直接操作库，对性能有影响而且同时还清缓存，导致下一次查询也要进库才能再设缓存，但是考虑到项目一开始用户应该不多，点赞行为的发生次数相对来说不会非常多，至少要比普通的查询少上一些，这样一来hit到缓存的几率还是不小的，缓存还是能起到一定的作用的，而且二级缓存也不仅仅只是用在点赞功能上，而是全线使用。\n接着夸一下这次布隆过滤器用的不错，真当一个过滤器用了，用来过滤掉很多元素不存在的情况，对性能提升作用还是不小的；然后就是点赞关系的存储，有人说既然是一个类似二元组的关系为啥不一个Hash结构搞定呢？考虑到目前直接用redis持久化的，如果慢慢积累下来，这个Hash变得硕大无比，也是会影响性能的。所以我是通过树形的key来使得一篇帖子有一个set集合（同时也有一个布隆），集合里放点赞过的userID。\n最后说一下redis和mysql同步的问题，在讨论过程中搜了一下，发现很多同步方案都是针对于mysql的改动同步到redis的（而不是redis同步到mysql），常见的有两种：\n 触发器+用户自定义函数UDF 中间件canal（binlog）  后来在学习redis当MyBatis的二级缓存中发现其实没有必要搞这个了，二级缓存本质已经解决了数据需要更新的问题（清除再设置）\n总结就是改进不少，但是仍有不足，或许是现阶段现情景下最好的选择。\n方案三 这个是在我对着搜索引擎直接输入关键字“redis实现点赞功能”后查出来的常见方案，大同小异，这里简答讲下就行。和之前的方案主要的不同是数据修改都是直接缓存中操作，然后再在业务代码中用定时任务例如Quartz每隔一段时间写入到mysql中；还有一个是存储点赞关系用redis的Hash。\n我这于两个不同点的看法上面也提到过了，在这里只能这样说也不失为一种方案吧。\n总结 方案很多，但是哪种最优，哪种更好，可能脱离场景的情况下不会有一个标准答案，对于好方案的追求与优化我也将不断追寻。。。（升华了doge）\n参考链接 https://juejin.cn/post/6844904007790673933\nhttps://zhuanlan.zhihu.com/p/346651831\nhttps://blog.csdn.net/ChenMMo/article/details/93615438\n","date":"2021-08-26T03:57:56+08:00","image":"https://ccqstark.github.io/p/bloom_filter/cover_hu4ee9ebaa10fc0f0205471a9a6145c894_228532_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/bloom_filter/","title":"Redis布隆过滤器与点赞功能设计"},{"content":"缓存的分类 本地缓存(local cache)：存在应用服务器内存中的数据称为本地缓存\n分布式缓存(dustribute cache)：存储在当前应用服务器之外的数据称为分布式缓存\n这里顺带提及集群和分布式的区别\n集群(cluster)：将同一种服务的多个节点放在一起共同对系统提供服务，称为集群\n分布式(distribute system)：有多个不同服务集群功能对系统提供服务，这个系统称之为分布式系统\n所以两者虽然都是多个服务器节点，区别就在多个节点中，集群侧重的是同一种服务，而分布式侧重的是不同的服务，而且分布式还是建立在集群的基础之上的。\n缓存发挥的作用 由图中可以看出，缓存是作为存储层和客户端之间的中间层，当客户端的请求过来时，首先请求缓存中的内容，如果查到（hit）则直接返回，不再去查找存储层；如果没有（miss），则去存储层中查找并将结果写入缓存（write cache）再返回，以便之后相同的请求可以去缓存中获取。\n之所以加入缓存层是因为存储层一般是需要读写磁盘的，而缓存层在内存中，两者的读写速度完全不是一个量级，内存快的多。而大部分应用的请求都有一个特点——读多写少，所以将总是需要查到的数据放在缓存层中可以大大提高应用的响应速度，减少存储层的压力。\n一般Web应用中，存储层就是我们用的关系型数据库，MySQL、Oracle、SQLServer等，而缓存层分类上面已经提到，常用的有Redis，Memcached等。\nMyBatis开启二级缓存 MyBatis一级缓存中，其最大的共享范围就是一个SqlSession内部，如果多个SqlSession之间需要共享缓存，则需要使用到二级缓存。\n开启方法：\n在业务的mapper.xml文件中添加\n\u0026lt;cache/\u0026gt; 二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。\n当开启缓存后，数据的查询执行的流程就是 二级缓存 -\u0026gt; 一级缓存 -\u0026gt; 数据库。\n这样开启的是本地二级缓存，这样有个缺点就是应用重新启动后，JVM重新分配内存，这样的话之前的缓存就都没了，所以我们得用分布式缓存来解决。\n使用Redis作为Mybatis的二级缓存 MyBatis的缓存实现类默认是PerpetualCache，它继承类Cache接口，除此之外还有其他实现类。\n原理就是维护一个HashMap，将查询的SQL以及Mapper的namespace作为Key，然后查询的结果作为Value，通过键值对的方式来实现缓存查询过的sql语句的结果，所以要用redis替换也还是十分合适的。\nCache接口 public interface Cache { String getId(); void putObject(Object var1, Object var2); Object getObject(Object var1); Object removeObject(Object var1); void clear(); int getSize(); ReadWriteLock getReadWriteLock(); } 解析\ngetId ：这个方法其实是获取了执行的sql对应的namespace，可以用来组成缓存的key\nputObject ：此方法就是用来将数据放入缓存的\ngetObject ：用以根据key获取缓存的值\nremoveObject ：删除某一缓存项目，MyBatis暂未实现与启用此方法，所以暂时无用\nclear ：每次执行update/delete/insert语句都会调用此方法进行清除原有的缓存\ngetSize ：获取缓存大小，暂时用处不大\ngetReadWriteLock ：获取读写锁，这是用来拿到互斥锁解决缓存击穿问题的\n所以我们只要恰当地实现以上方法，对接上redis，就可以使用redis作为mybatis的二级缓存了。\nMyBatisRedisCache实现类 这里在网上找了一个博主实现地比较好的，链接在文章最后，作者为Leven\nSpringBoot配置 mybatis:configuration:cache-enabled:trueRedisConfig中配置RedisTemplate /** * Redis缓存配置 * @author Leven * @date 2019-09-07 */ @Configuration public class RedisConfig { /** * 配置自定义redisTemplate * @return redisTemplate */ @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); template.setConnectionFactory(redisConnectionFactory); // 使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值  Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); ObjectMapper mapper = new ObjectMapper(); mapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(mapper); template.setKeySerializer(stringRedisSerializer); template.setValueSerializer(jackson2JsonRedisSerializer); template.setHashKeySerializer(stringRedisSerializer); template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; } } RedisService接口 /** * redis基础服务接口 * @author Leven * @date 2019-09-07 */ public interface RedisService { // =============================common============================  /** * 指定缓存失效时间 * @param key 键 * @param time 时间(秒) */ void expire(String key, long time); /** * 指定缓存失效时间 * @param key 键 * @param expireAt 失效时间点 * @return 处理结果 */ void expireAt(String key, Date expireAt); /** * 根据key 获取过期时间 * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ Long getExpire(String key); /** * 判断key是否存在 * @param key 键 * @return true 存在 false不存在 */ Boolean hasKey(String key); /** * 删除缓存 * @param key 可以传一个值 或多个 */ void delete(String... key); /** * 删除缓存 * @param keys 可以传一个值 或多个 */ void delete(Collection\u0026lt;String\u0026gt; keys); // ============================String=============================  /** * 普通缓存获取 * @param key 键 * @return 值 */ Object get(String key); /** * 普通缓存放入 * @param key 键 * @param value 值 */ void set(String key, Object value); /** * 普通缓存放入并设置时间 * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 */ void set(String key, Object value, long time); /** * 普通缓存放入并设置时间 * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 */ void set(String key, Object value, long time, TimeUnit timeUnit); /** * 递增 * @param key 键 * @param value 要增加几(大于0) * @return 递增后结果 */ Long incr(String key, long value); /** * 递减 * @param key 键 * @param value 要减少几(大于0) * @return 递减后结果 */ Long decr(String key, long value); // ================================Map=================================  /** * HashGet * @param key 键 不能为null * @param item 项 不能为null * @return 值 */ Object hashGet(String key, String item); /** * 获取hashKey对应的所有键值 * @param key 键 * @return 对应的多个键值 */ Map\u0026lt;Object, Object\u0026gt; hashEntries(String key); /** * HashSet * @param key 键 * @param map 对应多个键值 */ void hashSet(String key, Map\u0026lt;String, Object\u0026gt; map); /** * HashSet 并设置时间 * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) */ void hashSet(String key, Map\u0026lt;String, Object\u0026gt; map, long time); /** * 向一张hash表中放入数据,如果不存在将创建 * @param key 键 * @param item 项 * @param value 值 */ void hashSet(String key, String item, Object value); /** * 向一张hash表中放入数据,如果不存在将创建 * @param key 键 * @param item 项 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 */ void hashSet(String key, String item, Object value, long time); /** * 删除hash表中的值 * @param key 键 不能为null * @param item 项 可以使多个 不能为null */ void hashDelete(String key, Object... item); /** * 删除hash表中的值 * @param key 键 不能为null * @param items 项 可以使多个 不能为null */ void hashDelete(String key, Collection items); /** * 判断hash表中是否有该项的值 * @param key 键 不能为null * @param item 项 不能为null * @return true 存在 false不存在 */ Boolean hashHasKey(String key, String item); /** * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * @param key 键 * @param item 项 * @param value 要增加几(大于0) * @return 递增后结果 */ Double hashIncr(String key, String item, double value); /** * hash递减 * @param key 键 * @param item 项 * @param value 要减少记(小于0) * @return 递减后结果 */ Double hashDecr(String key, String item, double value); // ============================set=============================  /** * 根据key获取Set中的所有值 * @param key 键 * @return set集合 */ Set\u0026lt;Object\u0026gt; setGet(String key); /** * 根据value从一个set中查询,是否存在 * @param key 键 * @param value 值 * @return true 存在 false不存在 */ Boolean setIsMember(String key, Object value); /** * 将数据放入set缓存 * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ Long setAdd(String key, Object... values); /** * 将数据放入set缓存 * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ Long setAdd(String key, Collection values); /** * 将set数据放入缓存 * @param key 键 * @param time 时间(秒) * @param values 值 可以是多个 * @return 成功个数 */ Long setAdd(String key, long time, Object... values); /** * 获取set缓存的长度 * @param key 键 * @return set长度 */ Long setSize(String key); /** * 移除值为value的 * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ Long setRemove(String key, Object... values); // ===============================list=================================  /** * 获取list缓存的内容 * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return 缓存列表 */ List\u0026lt;Object\u0026gt; listRange(String key, long start, long end); /** * 获取list缓存的长度 * @param key 键 * @return 长度 */ Long listSize(String key); /** * 通过索引 获取list中的值 * @param key 键 * @param index 索引 index\u0026gt;=0时， 0 表头，1 第二个元素，依次类推；index\u0026lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * @return 值 */ Object listIndex(String key, long index); /** * 将list放入缓存 * @param key 键 * @param value 值 */ void listRightPush(String key, Object value); /** * 将list放入缓存 * @param key 键 * @param value 值 * @param time 时间(秒) */ void listRightPush(String key, Object value, long time); /** * 将list放入缓存 * @param key 键 * @param value 值 */ void listRightPushAll(String key, List\u0026lt;Object\u0026gt; value); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) */ void listRightPushAll(String key, List\u0026lt;Object\u0026gt; value, long time); /** * 根据索引修改list中的某条数据 * @param key 键 * @param index 索引 * @param value 值 */ void listSet(String key, long index, Object value); /** * 移除N个值为value * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ Long listRemove(String key, long count, Object value); } RedisServiceImpl实现 /** * redis基础服务接口实现 * * @author Leven * @date 2019-09-07 */ @Slf4j @Service public class RedisServiceImpl implements RedisService { private static final String PREFIX = \u0026#34;应用名\u0026#34;; @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; // =============================common============================  /** * 指定缓存失效时间 * * @param key 键 * @param time 时间(秒) */ @Override public void expire(String key, long time) { redisTemplate.expire(getKey(key), time, TimeUnit.SECONDS); } /** * 指定缓存失效时间 * * @param key 键 * @param expireAt 失效时间点 * @return 处理结果 */ @Override public void expireAt(String key, Date expireAt) { redisTemplate.expireAt(getKey(key), expireAt); } /** * 根据key 获取过期时间 * * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ @Override public Long getExpire(String key) { return redisTemplate.getExpire(getKey(key), TimeUnit.SECONDS); } /** * 判断key是否存在 * * @param key 键 * @return true 存在 false不存在 */ @Override public Boolean hasKey(String key) { return redisTemplate.hasKey(getKey(key)); } /** * 删除缓存 * * @param keys 可以传一个值 或多个 */ @Override public void delete(String... keys) { if (keys != null \u0026amp;\u0026amp; keys.length \u0026gt; 0) { if (keys.length == 1) { redisTemplate.delete(getKey(keys[0])); } else { List\u0026lt;String\u0026gt; keyList = new ArrayList\u0026lt;\u0026gt;(keys.length); for (String key : keys) { keyList.add(getKey(key)); } redisTemplate.delete(keyList); } } } /** * 删除缓存 * * @param keys 可以传一个值 或多个 */ @Override public void delete(Collection\u0026lt;String\u0026gt; keys) { if (keys != null \u0026amp;\u0026amp; !keys.isEmpty()) { List\u0026lt;String\u0026gt; keyList = new ArrayList\u0026lt;\u0026gt;(keys.size()); for (String key : keys) { keyList.add(getKey(key)); } redisTemplate.delete(keyList); } } // ============================String=============================  /** * 普通缓存获取 * * @param key 键 * @return 值 */ @Override public Object get(String key) { return key == null ? null : redisTemplate.opsForValue().get(getKey(key)); } /** * 普通缓存放入 * * @param key 键 * @param value 值 */ @Override public void set(String key, Object value) { redisTemplate.opsForValue().set(getKey(key), value); } /** * 普通缓存放入并设置时间 * * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 */ @Override public void set(String key, Object value, long time) { set(key, value, time, TimeUnit.SECONDS); } /** * 普通缓存放入并设置时间 * * @param key 键 * @param value 值 * @param time 时间 time要大于0 如果time小于等于0 将设置无限期 * @param timeUnit 时间单位 */ @Override public void set(String key, Object value, long time, TimeUnit timeUnit) { if (time \u0026gt; 0) { redisTemplate.opsForValue().set(getKey(key), value, time, timeUnit); } else { set(getKey(key), value); } } /** * 递增 * * @param key 键 * @param value 要增加几(大于0) * @return 递增后结果 */ @Override public Long incr(String key, long value) { if (value \u0026lt; 1) { throw new BizException(\u0026#34;递增因子必须大于0\u0026#34;); } return redisTemplate.opsForValue().increment(getKey(key), value); } /** * 递减 * * @param key 键 * @param value 要减少几(大于0) * @return 递减后结果 */ @Override public Long decr(String key, long value) { if (value \u0026lt; 1) { throw new BizException(\u0026#34;递减因子必须大于0\u0026#34;); } return redisTemplate.opsForValue().decrement(getKey(key), value); } // ================================Map=================================  /** * HashGet * * @param key 键 不能为null * @param item 项 不能为null * @return 值 */ @Override public Object hashGet(String key, String item) { return redisTemplate.opsForHash().get(getKey(key), item); } /** * 获取hashKey对应的所有键值 * * @param key 键 * @return 对应的多个键值 */ @Override public Map\u0026lt;Object, Object\u0026gt; hashEntries(String key) { return redisTemplate.opsForHash().entries(getKey(key)); } /** * HashSet * * @param key 键 * @param map 对应多个键值 */ @Override public void hashSet(String key, Map\u0026lt;String, Object\u0026gt; map) { redisTemplate.opsForHash().putAll(getKey(key), map); } /** * HashSet 并设置时间 * * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) */ @Override public void hashSet(String key, Map\u0026lt;String, Object\u0026gt; map, long time) { String k = getKey(key); redisTemplate.opsForHash().putAll(k, map); if (time \u0026gt; 0) { expire(k, time); } } /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 */ @Override public void hashSet(String key, String item, Object value) { redisTemplate.opsForHash().putIfAbsent(getKey(key), item, value); } /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 */ @Override public void hashSet(String key, String item, Object value, long time) { String k = getKey(key); redisTemplate.opsForHash().putIfAbsent(k, item, value); if (time \u0026gt; 0) { expire(k, time); } } /** * 删除hash表中的值 * * @param key 键 不能为null * @param item 项 可以使多个 不能为null */ @Override public void hashDelete(String key, Object... item) { redisTemplate.opsForHash().delete(getKey(key), item); } /** * 删除hash表中的值 * * @param key 键 不能为null * @param items 项 可以使多个 不能为null */ @Override public void hashDelete(String key, Collection items) { redisTemplate.opsForHash().delete(getKey(key), items.toArray()); } /** * 判断hash表中是否有该项的值 * * @param key 键 不能为null * @param item 项 不能为null * @return true 存在 false不存在 */ @Override public Boolean hashHasKey(String key, String item) { return redisTemplate.opsForHash().hasKey(getKey(key), item); } /** * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * * @param key 键 * @param item 项 * @param value 要增加几(大于0) * @return 递增后结果 */ @Override public Double hashIncr(String key, String item, double value) { if (value \u0026lt; 1) { throw new BizException(\u0026#34;递增因子必须大于0\u0026#34;); } return redisTemplate.opsForHash().increment(getKey(key), item, value); } /** * hash递减 * * @param key 键 * @param item 项 * @param value 要减少记(小于0) * @return 递减后结果 */ @Override public Double hashDecr(String key, String item, double value) { if (value \u0026lt; 1) { throw new BizException(\u0026#34;递减因子必须大于0\u0026#34;); } return redisTemplate.opsForHash().increment(getKey(key), item, -value); } // ============================set=============================  /** * 根据key获取Set中的所有值 * * @param key 键 * @return set集合 */ @Override public Set\u0026lt;Object\u0026gt; setGet(String key) { return redisTemplate.opsForSet().members(getKey(key)); } /** * 根据value从一个set中查询,是否存在 * * @param key 键 * @param value 值 * @return true 存在 false不存在 */ @Override public Boolean setIsMember(String key, Object value) { return redisTemplate.opsForSet().isMember(getKey(key), value); } /** * 将数据放入set缓存 * * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ @Override public Long setAdd(String key, Object... values) { return redisTemplate.opsForSet().add(getKey(key), values); } /** * 将数据放入set缓存 * * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ @Override public Long setAdd(String key, Collection values) { return redisTemplate.opsForSet().add(getKey(key), values.toArray()); } /** * 将set数据放入缓存 * * @param key 键 * @param time 时间(秒) * @param values 值 可以是多个 * @return 成功个数 */ @Override public Long setAdd(String key, long time, Object... values) { String k = getKey(key); Long count = redisTemplate.opsForSet().add(k, values); if (time \u0026gt; 0) { expire(k, time); } return count; } /** * 获取set缓存的长度 * * @param key 键 * @return set长度 */ @Override public Long setSize(String key) { return redisTemplate.opsForSet().size(getKey(key)); } /** * 移除值为value的 * * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ @Override public Long setRemove(String key, Object... values) { return redisTemplate.opsForSet().remove(getKey(key), values); } // ===============================list=================================  /** * 获取list缓存的内容 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return 缓存列表 */ @Override public List\u0026lt;Object\u0026gt; listRange(String key, long start, long end) { return redisTemplate.opsForList().range(getKey(key), start, end); } /** * 获取list缓存的长度 * * @param key 键 * @return 长度 */ @Override public Long listSize(String key) { return redisTemplate.opsForList().size(getKey(key)); } /** * 通过索引 获取list中的值 * * @param key 键 * @param index 索引 index\u0026gt;=0时， 0 表头，1 第二个元素，依次类推；index\u0026lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * @return 值 */ @Override public Object listIndex(String key, long index) { return redisTemplate.opsForList().index(getKey(key), index); } /** * 将list放入缓存 * * @param key 键 * @param value 值 */ @Override public void listRightPush(String key, Object value) { redisTemplate.opsForList().rightPush(getKey(key), value); } /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) */ @Override public void listRightPush(String key, Object value, long time) { String k = getKey(key); redisTemplate.opsForList().rightPush(k, value); if (time \u0026gt; 0) { expire(k, time); } } /** * 将list放入缓存 * * @param key 键 * @param value 值 */ @Override public void listRightPushAll(String key, List\u0026lt;Object\u0026gt; value) { redisTemplate.opsForList().rightPushAll(getKey(key), value); } /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) */ @Override public void listRightPushAll(String key, List\u0026lt;Object\u0026gt; value, long time) { String k = getKey(key); redisTemplate.opsForList().rightPushAll(k, value); if (time \u0026gt; 0) { expire(k, time); } } /** * 根据索引修改list中的某条数据 * * @param key 键 * @param index 索引 * @param value 值 */ @Override public void listSet(String key, long index, Object value) { redisTemplate.opsForList().set(getKey(key), index, value); } /** * 移除N个值为value * * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ @Override public Long listRemove(String key, long count, Object value) { return redisTemplate.opsForList().remove(getKey(key), count, value); } private String getKey(String key) { return PREFIX + \u0026#34;:\u0026#34; + key; } } 实现Cache接口的MybatisRedisCache /** * MyBatis二级缓存Redis实现 * 重点处理以下几个问题 * 1、缓存穿透：存储空值解决，MyBatis框架实现 * 2、缓存击穿：使用互斥锁，我们自己实现 * 3、缓存雪崩：缓存有效期设置为一个随机范围，我们自己实现 * 4、读写性能：redis key不能过长，会影响性能，这里使用SHA-256计算摘要当成key * @author Leven * @date 2019-09-07 */ @Slf4j public class MybatisRedisCache implements Cache { /** * 统一字符集 */ private static final String CHARSET = \u0026#34;utf-8\u0026#34;; /** * key摘要算法 */ private static final String ALGORITHM = \u0026#34;SHA-256\u0026#34;; /** * 统一缓存头 */ private static final String CACHE_NAME = \u0026#34;MyBatis:\u0026#34;; /** * 读写锁：解决缓存击穿 */ private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); /** * 表空间ID：方便后面的缓存清理 */ private final String id; /** * redis服务接口：提供基本的读写和清理 */ private static volatile RedisService redisService; /** * 信息摘要 */ private volatile MessageDigest messageDigest; /////////////////////// 解决缓存雪崩，具体范围根据业务需要设置合理值 //////////////////////////  /** * 缓存最小有效期 */ private static final int MIN_EXPIRE_MINUTES = 60; /** * 缓存最大有效期 */ private static final int MAX_EXPIRE_MINUTES = 120; /** * MyBatis给每个表空间初始化的时候要用到 * @param id 其实就是namespace的值 */ public MybatisRedisCache(String id) { if (id == null) { throw new IllegalArgumentException(\u0026#34;Cache instances require an ID\u0026#34;); } this.id = id; } /** * 获取ID * @return 真实值 */ @Override public String getId() { return id; } /** * 创建缓存 * @param key 其实就是sql语句 * @param value sql语句查询结果 */ @Override public void putObject(Object key, Object value) { try { String strKey = getKey(key); // 有效期为1~2小时之间随机，防止雪崩  int expireMinutes = RandomUtils.nextInt(MIN_EXPIRE_MINUTES, MAX_EXPIRE_MINUTES); getRedisService().set(strKey, value, expireMinutes, TimeUnit.MINUTES); log.debug(\u0026#34;Put cache to redis, id={}\u0026#34;, id); } catch (Exception e) { log.error(\u0026#34;Redis put failed, id=\u0026#34; + id, e); } } /** * 读取缓存 * @param key 其实就是sql语句 * @return 缓存结果 */ @Override public Object getObject(Object key) { try { String strKey = getKey(key); log.debug(\u0026#34;Get cache from redis, id={}\u0026#34;, id); return getRedisService().get(strKey); } catch (Exception e) { log.error(\u0026#34;Redis get failed, fail over to db\u0026#34;, e); return null; } } /** * 删除缓存 * @param key 其实就是sql语句 * @return 结果 */ @Override public Object removeObject(Object key) { try { String strKey = getKey(key); getRedisService().delete(strKey); log.debug(\u0026#34;Remove cache from redis, id={}\u0026#34;, id); } catch (Exception e) { log.error(\u0026#34;Redis remove failed\u0026#34;, e); } return null; } /** * 缓存清理 * 网上好多博客这里用了flushDb甚至是flushAll，感觉好坑鸭！ * 应该是根据表空间进行清理 */ @Override public void clear() { try { log.debug(\u0026#34;clear cache, id={}\u0026#34;, id); String hsKey = CACHE_NAME + id; // 获取CacheNamespace所有缓存key  Map\u0026lt;Object, Object\u0026gt; idMap = getRedisService().hashEntries(hsKey); if (!idMap.isEmpty()) { Set\u0026lt;Object\u0026gt; keySet = idMap.keySet(); Set\u0026lt;String\u0026gt; keys = new HashSet\u0026lt;\u0026gt;(keySet.size()); keySet.forEach(item -\u0026gt; keys.add(item.toString())); // 清空CacheNamespace所有缓存  getRedisService().delete(keys); // 清空CacheNamespace  getRedisService().delete(hsKey); } } catch (Exception e) { log.error(\u0026#34;clear cache failed\u0026#34;, e); } } /** * 获取缓存大小，暂时没用上 * @return 长度 */ @Override public int getSize() { return 0; } /** * 获取读写锁：为了解决缓存击穿 * @return 锁 */ @Override public ReadWriteLock getReadWriteLock() { return readWriteLock; } /** * 计算出key的摘要 * @param cacheKey CacheKey * @return 字符串key */ private String getKey(Object cacheKey) { String cacheKeyStr = cacheKey.toString(); log.debug(\u0026#34;count hash key, cache key origin string:{}\u0026#34;, cacheKeyStr); String strKey = byte2hex(getSHADigest(cacheKeyStr)); log.debug(\u0026#34;hash key:{}\u0026#34;, strKey); String key = CACHE_NAME + strKey; // 在redis额外维护CacheNamespace创建的key，clear的时候只清理当前CacheNamespace的数据  getRedisService().hashSet(CACHE_NAME + id, key, \u0026#34;1\u0026#34;); return key; } /** * 获取信息摘要 * @param data 待计算字符串 * @return 字节数组 */ private byte[] getSHADigest(String data) { try { if (messageDigest == null) { synchronized (MessageDigest.class) { if (messageDigest == null) { messageDigest = MessageDigest.getInstance(ALGORITHM); } } } return messageDigest.digest(data.getBytes(CHARSET)); } catch (Exception e) { log.error(\u0026#34;SHA-256 digest error: \u0026#34;, e); throw new SPIException(ExceptionCode.RUNTIME_UNITE_EXP,\u0026#34;SHA-256 digest error, id=\u0026#34; + id + \u0026#34;.\u0026#34;); } } /** * 字节数组转16进制字符串 * @param bytes 待转换数组 * @return 16进制字符串 */ private String byte2hex(byte[] bytes) { StringBuilder sign = new StringBuilder(); for (byte aByte : bytes) { String hex = Integer.toHexString(aByte \u0026amp; 0xFF); if (hex.length() == 1) { sign.append(\u0026#34;0\u0026#34;); } sign.append(hex.toUpperCase()); } return sign.toString(); } /** * 获取Redis服务接口 * 使用双重检查保证线程安全 * @return 服务实例 */ private RedisService getRedisService() { if (redisService == null) { synchronized (RedisService.class) { if (redisService == null) { redisService = ApplicationContextUtils.getBeanByClass(RedisService.class); } } } return redisService; } } 配置实现类 有两种方式配置二级缓存实现类到mapper上，二选一\n Java代码（注解）  @CacheNamespace(implementation=com.leven.mybatis.core.cache.MybatisRedisCache.class) public interface UserMapper extends OracleMapper\u0026lt;UserDO\u0026gt; { } XML  \u0026lt;cache type=\u0026#34;com.leven.mybatis.core.cache.MybatisRedisCache\u0026#34;/\u0026gt; 实现类解析与缓存三大问题的解决 通过阅读以上实现类源码可以看出其中一些设计的精巧，下面一一来分析。\n Key的命名  key的命名可以看到使用了一些前缀，比如最终对某一sql运行结果缓存的key实际上是\n应用名:MyBatis:SQL转为的HEX\n可以看出是用冒号隔开的，一层一层的，类似命名空间一样的方式，这种key命名方式的好处是可以很好地区分不同业务的key，使得缓存的存储更有条理更加规范，同时也可以使得在RDM等redis可视化界面中呈现树形的结构。\nkey的摘要处理  MyBatis原始的key里是直接包含了被执行的sql语句，但是这样会导致key的长度太大，对redis性能有一定的影响，所以这里的处理是用SHA-256算法计算出原本为string的key的摘要，最后将其转换为十六进制的表示形式。\n这样做的优点是可以缩短key的长度，提升redis性能，同时也保证了sql与key的唯一对应性，只是需要一点开销去计算这个过程。\nCacheNamespace  网上很多其他的clear方法的实现类都是flushdb的，这样做不好，因为很多情况下不同namespace下的数据并无关联，这边的修改不会影响那边，所以只需要清除本SQL所在的namespace即可，不需要全部清除，被清除的之后还要去数据库中取也是增加了开销。（如果有关联的缓存则用另一种方法处理，文章下面有介绍）\n上面的实现类就是通过redis维护一个hash结构，key为namespace，里面的每个field就是其下的执行过的SQL的摘要，value只是标志位。而SQL对应的查询结果缓存则是单独用普通的string的key-value进行存储，只是我们制定了序列化用json而已。在clear时，查询到此namespace下的所有摘要，想删除了对应的所有的string的key-value，再去把hash结构删了。\n那有人可能会说，为啥不直接在hash中field对应的value里存储SQL的查询结果，要在外面另外的用key-value结构去存呢，这样我clear的时候直接删除整个namespace对应的hash就行了呗。这其实也是一种方案，但是缺点有两个：（一）无法对每一个SQL摘要进行单独设置过期时间，最多只能对hash结构的大key设置；（二）hash中的filed不宜过多\n随机过期时间——应对缓存雪崩  缓存雪崩，简单来说就是当我们有一组key因为过期时间点相近，在那一小段时间内这组key集体失效，而此时又有很多请求过来要获取这组key的内容，那就全部打在MySQL上，可能就会造成数据库压力过大而崩溃。\n解决方法是在设置key的过期时间时加上随机数，使得他们的过期时间尽量分散，避免在同一时间内集体失效。\n存储空值——应对缓存穿透  缓存穿透 ，当客户端请求一个数据库中没有的值得时候，缓存中自然也不会有，那就穿过缓存直接来到数据库进行查询，如果这样的请求多了的话对数据库也不利。\n解决方法是对查询不存在的结果也在缓存中存储空值来解决，这个由MyBatis实现，下次再来请求这个不存在的值得时候就可以拦截在缓存中了。\n如果遇到那种黑客攻击，生成了一堆随机的，不存在的值来穿透，来打到我们的数据库怎么办？那就要用大名鼎鼎的布隆过滤器（bloom filter）了，这里不展开。\n使用互斥锁——应对缓存击穿  缓存击穿 ，这个跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是一个热点的key失效，经常有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。\n解决方案是互斥锁，当这个热点key失效时先加把互斥锁，拿到锁的线程去数据库中查找，其它线程只能等到重试，等load db完成后再写到缓存中，拿到锁的线程才释放锁，这时其他线程就可以去缓存中取了，这样就减少了数据库的压力。当然，用了锁就会影响系统一定的性能。\n关联缓存 当遇到不同namespace之间的数据有关联，也就是在清除一个namespace时，也需要清除另一个与之相关联的避免读到脏数据，这个时候我们可以使用关联缓存。\n开启方法：在对应的mapper下加上以下标签：\n\u0026lt;cache-ref namespace=\u0026#34;xxxxxxx\u0026#34;/\u0026gt; 设置之后本mapper的缓存会放到cache-ref制定的namespace下，也就是不再自己一个namespace，共用了指向的namespace，那到时清除的时候就会一块清除。\n参考链接 MyBatis整合Redis实现二级缓存\n聊聊MyBatis缓存机制\n【编程不良人】适合后端编程人员的Redis实战教程、redis应用场景、分布式缓存、Session管理、面试相关等已完结!\n","date":"2021-08-25T16:07:15+08:00","image":"https://ccqstark.github.io/p/redis_mybatis_cache/cover_hu98723c96db4cad61d3193fddfb3126c4_90918_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/redis_mybatis_cache/","title":"Redis分布式缓存实现"},{"content":"前言 最近在看周志明老师的经典《深入理解Java虚拟机》，第1章最后是一个自己编译JDK的实战，想到羊哥之前也出过这样一期视频，觉得做一做也蛮有成就感的，还可以加深下对Java的理解，所以边做边写下此篇博文。\n环境准备 系统环境 我的环境是macOS10.14.6(黑苹果)，问题相对Windows应该会少很多，推荐大家也是用Linux或者macOS来进行编译。\nXcode下载 一些C/C++相关的工具链一般是用Xcode带的，所以去官网下载就行。但是如果像我一样是黑苹果，系统不是最新的，官网的版本很可能不适配（目前最新Xcode 13要求macOS 11以上），所以只能翻到以前百度云里存的Xcode11.xip下载解压并安装就可以了。\nxip文件在解压时需要用系统自带的解压工具，不要用第三方的，不然解压出来不是一个.app文件。\n还有就是解压时可能会遇到系统验证问题，通过以下两步解决：\n 运行以下命令行  # 最后是xip文件的位置 xattr -d com.apple.quarantine Xcode_11.xip 在系统设置中修改系统的时间约为2018年7月，然后允许任何来源的软件安装。  所有软件环境基础 以下都是编译中需要用到的软件环境，确保都已经安装\n# 有一个已经可用的jdk，版本至少是要编译的版本-1 java -version # 输出 openjdk version \u0026#34;11.0.9\u0026#34; 2020-10-20 OpenJDK Runtime Environment (build 11.0.9+11) OpenJDK 64-Bit Server VM (build 11.0.9+11, mixed mode) # C的编译器 clang --version # 输出 Apple clang version 11.0.0 (clang-1100.0.33.8) Target: x86_64-apple-darwin18.7.0 Thread model: posix InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin # C++的编译器 clang++ --version # 输出 Apple clang version 11.0.0 (clang-1100.0.33.8) Target: x86_64-apple-darwin18.7.0 Thread model: posix InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin # 自动配置工具autoconf # 下载方式：brew install autoconf autoconf --version # 输出 autoconf (GNU Autoconf) 2.69 # 编译构建工具 make --version # 输出 GNU Make 3.81 # 渲染库freetype freetype-config --ftversion # 输出 2.10.4 源码下载 这次要编译的目标版本是jdk11，所以下载jdk11的源码\n方式一：通过Mercurial JDK是通过这个叫Mercurial的版本管理工具来进行代码管理的，这个和git是一类工具，只不过过于小众。而且这种方式慢，不推荐。\n 安装Mercurial  brew install mercurial   去网址hg.openjdk.java.net上复制地址\n  使用命令clone源码包\n  hg clone https://hg.openjdk.java.net/jdk/jdk11/ 方式二：官网下载压缩包 这种方式速度快，推荐这种方式\n前往地址：\nJava Platform, Standard Edition 11 Reference Implementations\n点击下载zip压缩包即可\n新建一个专门的文件夹存放源码包，解压后就可以看到目录结构\nsrc就是源码部分，看到里面基本都是C和C++的代码，说明Java就是用C和C++写的。\n自动配置工作 这一步进行编译前的自动编译工作\n# 首先cd进源码目录，也就是上图的openjdk11 cd openjdk11 # 运行脚本 sh configure 这个过程较快，最后会输出一些概览信息。\n正式编译工作 第一次编译直接进行全量编译，执行：\nmake all 这个过程比较久，耐心等待，会生成可执行文件，JDK成品镜像等很多东西\n过程中的警告可以忽略，只要不出现错误导致整个过程停止即可\n可以看到这个过程中我的mac的活动监视器，CPU快要炸了\n直到控制台最后几行输出一下信息就证明成功了\nCreating support/demos/image/jfc/SampleTree/SampleTree.jar Creating support/demos/image/jfc/TableExample/TableExample.jar Creating support/demos/image/jfc/TransparentRuler/TransparentRuler.jar Creating jdk image Finished building target \u0026#39;all\u0026#39; in configuration \u0026#39;macosx-x86_64-normal-server-release\u0026#39; 成品验收 完成上一步后就可以发现目录下多了一个build目录，进入build/macosx-x86_64-normal-server-release/目录可以看到如下文件\n命令行验证下\n# 进入编译后的jdk的bin目录 cd build/macosx-x86_64-normal-server-release/jdk/bin # 执行java命令查看版本 ./java -version # 输出 openjdk version \u0026#34;11-internal\u0026#34; 2018-09-25 OpenJDK Runtime Environment (build 11-internal+0-adhoc.ccqstark.openjdk11) OpenJDK 64-Bit Server VM (build 11-internal+0-adhoc.ccqstark.openjdk11, mixed mode) 最终的JDK成品就在images/jdk目录下，这个就和我们平时在官网上下载的JDK基本是一样的\nIDEA中使用新JDK 新建一个Hello World项目\n添加自己编译的JDK的路径\n切换项目所用的JDK为刚刚新增的\n运行之后可以看到我们使用的JDK已经换成自己编译得到的了\n定制JDK 当我们需要自己定制一套属于自己的JDK的时候就需要我们去修改源码中的一些实现，修改之后要生效的话必须重新编译一次，这次的编译就可以用增量编译了。\n修改Sourcepath 删除原来全部路径\n重新添加我们一开始下载的压缩包中解压出来的src目录下的源码，并让IDEA重新索引\n修改源码 我们Ctrl加鼠标点击进入println源码，并做点修改意思意思\n增量编译 再次cd到解压出来的大目录下，执行\nmake images 进行增量编译，速度会比全量编译快\n再次运行代码发现之前对源码的修改已经生效\n参考资料  《深入理解Java虚拟机》 周志明 JDK都没手动编译过，敢说自己是Java程序员吗？实战编译Java源码（JDK源码,JVM）视频教程 CodeSheep  ","date":"2021-07-27T03:44:28+08:00","image":"https://ccqstark.github.io/p/compile_jdk/cover_hucf54841c06fdf75c53fe986b35c09dc3_55691_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/compile_jdk/","title":"[实战]自己动手编译JDK实录"},{"content":"题目 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\n示例 1： 输入：nums = [-1,0,1,2,-1,-4] 输出：[[-1,-1,2],[-1,0,1]] 示例 2： 输入：nums = [] 输出：[] 示例 3： 输入：nums = [0] 输出：[] 分析 这里本可以借鉴两数之和的哈希法，通过判断0-(a+b)是否存在数组中来解答，但是由于题目要求的不能包含重复的三元组用这个方法实在很难去处理，所以这里就不推荐用哈希法了。\n这里推荐排序+双指针法 来解决。先对数组进行排序，然后用一个指针i对所有元素进行遍历，每一次遍历我们都有两个指针叫left和right，left一开始指向i+1，right一开始指向数组最后一位，然后开始判断此时三个指针之和sum是否为0。\n如果不是又分为两种情况，sum大于0，则让right左移一位，让sum减小；如果sum小于0，则让left右移一位，让sum增加。如果是找到了的话，就两边同时收缩。整个过程就是通过调整left和right指针来毕竟让sum逼近0，再注意一下去除重复情况即可。\n动画如下：\n代码 // 排序+双指针法（较优） public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; threeSum(int[] nums) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); // 排序  Arrays.sort(nums); for (int i = 0; i \u0026lt; nums.length; i++) { // 首位大于0的直接返回  if (nums[i] \u0026gt; 0) { return result; } // i的去重  if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } int left = i + 1; int right = nums.length - 1; // 循环  while (right \u0026gt; left) { // 计算此时的三数之和  int sum = nums[i] + nums[left] + nums[right]; // 三种情况  if (sum \u0026gt; 0) { right--; } else if (sum \u0026lt; 0) { left++; } else { // 找到一种答案添加到结果集  result.add(Arrays.asList(nums[i], nums[left], nums[right])); // 去重  while (right \u0026gt; left \u0026amp;\u0026amp; nums[right] == nums[right - 1]) right--; while (right \u0026gt; left \u0026amp;\u0026amp; nums[left] == nums[left + 1]) left++; // 找到一个答案后两边指针都收缩  right--; left++; } } } return result; } 时间复杂度：O(n^2)\n延伸 这里顺便把四数之和也说了，思路也是差不多的，多了一个数其实就多加一层循环再去使用left和right算sum罢了，时间复杂度就变成O(n^3)，如果有五数之和、六数之和也是一样的道理。\n直接上代码：\npublic List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; fourSum(int[] nums, int target) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); Arrays.sort(nums); // 四数之和实际上是在三数之和上多加了一层循环  for (int i = 0; i \u0026lt; nums.length; i++) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } for (int j = i + 1; j \u0026lt; nums.length; j++) { if (j \u0026gt; i + 1 \u0026amp;\u0026amp; nums[j] == nums[j - 1]) { continue; } int left = j + 1; int right = nums.length - 1; while (left \u0026lt; right) { int sum = nums[i] + nums[j] + nums[left] + nums[right]; if (sum \u0026gt; target) { right--; } else if (sum \u0026lt; target) { left ++; } else { result.add(Arrays.asList(nums[i], nums[j], nums[left], nums[right])); // 去重  while (left \u0026lt; right \u0026amp;\u0026amp; nums[right] == nums[right - 1]) right--; while (left \u0026lt; right \u0026amp;\u0026amp; nums[left + 1] == nums[left]) left++; // 找到后左右指针各收缩一下  right--; left++; } } } } return result; } ","date":"2021-07-23T16:55:26+08:00","image":"https://ccqstark.github.io/p/three_sum/cover_huf957eb7cc0803733802fcc4099cfd7cb_35766_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/three_sum/","title":"[leetcode]15.三数之和"},{"content":"注解 概述 不是程序本身，可以对程序作出解释，可以被其他程序（如编译器等）读取\n可以附加在package、class、method、field等上面，可以通过反射机制编程实现对这些元数据对访问\n内置注解 @Override\n只用修饰方法，表示一个方法声明打算重写超类中的另一个方法声明\n@Deprecated\n可以用于修饰方法，属性，类，表示不鼓励程序猿使用，但是还是可以使用的，只是使用它可能有危险或者存在更好的选择。\n@SuppressWarnings\n用来抑制编译时的警告信息，需要添加一个参数\n元注解 @Target\n用于描述注解的使用范围\n@Target(value = {ElementType.METHOD, ElementType.TYPE}) @Retention\n表示需要在什么级别保存该注释信息（SOURCE \u0026gt; CLASS \u0026gt; RUNTIME）\n@Retention(value = RetentionPolicy.RUNTIME) @Document 说明该注解将被包含在javadoc中\n@Inherited\n说明子类可以继承父类中的该注解\n自定义注解 使用@interface自定义注解时,自动继承了java. lang.annotation Annotation接口\n@interface用来声明一个注解，格式: public @interface 注解名 { 定义内容 }\n其中的每一个方法实际上是声明了一个配置参数，方法的名称就是参数的名称 返回值类型就是参数的类型(返回值只能是基本类型, Class, String, enum)\n可以通过 default来声明参数的默认值\n如果只有一个参数成员,一般参数名为 value 注解元素必须要有值，我们定义注解元素时，经常使用空字符串和0作为默认值\n@Target({ElementType.TYPE, ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) @interface MyAnnotation2 { // 方法名为参数名  String name() default \u0026#34;\u0026#34;; int age() default 0; int id() default -1; // 如果默认值为-1, 代表不存在  String[] schools() default {\u0026#34;西部开源\u0026#34;, \u0026#34;东部闭源\u0026#34;}; } 反射 概述 Java不是动态语言，但是可以通过反射机制获得类似动态语言的特性。\nReflection（反射）允许程序在执行期间借助 Reflection API 取得任何类的内部信息，并能直接操作任意对象的内部属性及方法。\n加载完类之后，在堆内存的方法区中就产生了一个Class类型的对象（一个类只有一个Class对象），这个对象就包含了完整的类的结构信息。我们可以通过这个对象看到类的结构。\nJava反射机制提供的功能  在运行时判断任意一个对象所属的类 在运行时构造任意一个类的对象 在运行时判断一个类所具有的成员变量和方法 在运行时获取泛型信息 在运行时调用任意一个对象的成员变量和方法 在运行时处理注解 生成动态代理 \u0026hellip;  优点：可以实现动态创建对象和编译，体现出很大的灵活性\n缺点：对性能有影响。使用反射是让JVM执行我们命令的操作，这类操作总是慢于直接执行相同的操作。\nClass类  Class本身也是一个类 Class对象只能由系统创建对象 一个加载的类在JVM中只会有一个Class实例 一个Class对象对应的是一个加载到JVM的一个.class文件 每个类的实例都会记得自己是由哪个Class实例所生成的 通过Class可以完整的得到一个类中所有被加载的结构 Class类是Reflection的根源，针对任何想动态加载、运行的类，唯有先获得相应的Class对象  得到Class的几种办法 // 方式一：通过对象获得 Class c1 = person.getClass(); System.out.println(c1.hashCode()); // 方式二：通过forName获得 Class c2 = Class.forName(\u0026#34;com.ccqstark.reflection.Person\u0026#34;); System.out.println(c2.hashCode()); // 方法三：通过类名.class获得 Class c3 = Student.class; System.out.println(c3.hashCode()); // 方法四：基本内置类型的包装类都有一个Type属性 Class c4 = Integer.TYPE; System.out.println(c4); // 获得父类类型 Class c5 = c1.getSuperclass(); System.out.println(c5); 有Class对象的类型  class 外部类，成员（成员内部类，静态内部类），局部内部类，匿名内部类 interface 接口 数组 enum 枚举 annotation 注解 primitive type 基本数据类型 void  类加载器的作用 类加载的作用：将class文件字节码内容加载到内存中，并将这些静态数据转换成方法区的运行时数据结构，然后在堆中生成一个代表这个类的java.lang.Class对象，作为方法区中类数据的访问入口。\n类缓存：标准的JavaSE类加载器可以按要求查找类，但一旦某个类被加载到类加载器中，它将维持加载（缓存）一段时间。不过JVM垃圾回收机制可以回收这些Class对象。\n三种类加载器：\n 引导类加载器：用C++编写的，是JVM自带的类加载器，负责Java平台核心库(rt.jar)，用来转载核心类库。该加载器无法直接获取 扩展类加载器：负责jre/lib/ext目录下的jar包或者-D java.ext.dirs指定目录下的jar包装入工作库 系统类加载器：负责 java -classpath 或 -D java.class.path 所指目录下的类与jar包装入工作，是常用的加载器  示例代码：\n// 获取系统的类加载器 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader); // 获取系统的类加载器的父类加载器--\u0026gt;扩展类加载器 ClassLoader parent = systemClassLoader.getParent(); System.out.println(parent); // 获取扩展类加载器的父类加载器--\u0026gt;根加载器(c/c++) ClassLoader parent1 = parent.getParent(); System.out.println(parent1); // 测试当前的类是哪个加载器加载的 ClassLoader classLoader = Class.forName(\u0026#34;com.ccqstark.reflection.Test07\u0026#34;).getClassLoader(); System.out.println(classLoader); // 测试JDK内置的类是谁加载的 classLoader = Class.forName(\u0026#34;java.lang.Object\u0026#34;).getClassLoader(); System.out.println(classLoader); // 获得系统类加载器可以加载的路径 System.out.println(System.getProperty(\u0026#34;java.class.path\u0026#34;)); 获得运行时类的完整结构 上代码：\nClass c1 = Class.forName(\u0026#34;com.ccqstark.reflection.User\u0026#34;); // 获得类的名字 System.out.println(c1.getName()); System.out.println(c1.getSimpleName()); // 获得类的属性 System.out.println(\u0026#34;========================\u0026#34;); Field[] fields = c1.getFields(); // 只能找到public属性  fields = c1.getDeclaredFields(); // 找到全部的属性 for (Field field : fields) { System.out.println(field); } // 获得指定属性的值 Field name = c1.getDeclaredField(\u0026#34;name\u0026#34;); System.out.println(name); // 获得方法 System.out.println(\u0026#34;=========================\u0026#34;); Method[] methods = c1.getMethods(); // 获得本类及其父类的全部public方法 for (Method method : methods) { System.out.println(\u0026#34;父类以及公有的：\u0026#34; + method); } methods = c1.getDeclaredMethods(); // 获得本类的所有方法 for (Method method : methods) { System.out.println(\u0026#34;本类所有的方法：\u0026#34; + method); } // 获得指定的方法 Method getName = c1.getMethod(\u0026#34;getName\u0026#34;, null); Method setName = c1.getMethod(\u0026#34;setName\u0026#34;, String.class); System.out.println(getName); System.out.println(setName); // 获得指定的构造器 System.out.println(\u0026#34;==========================\u0026#34;); Constructor[] constructors = c1.getConstructors(); // 获得公有的 for (Constructor constructor : constructors) { System.out.println(constructor); } constructors = c1.getDeclaredConstructors(); // 获取全部 for (Constructor constructor : constructors) { System.out.println(\u0026#34;#\u0026#34; + constructor); } // 获得指定的构造器 Constructor declaredConstructor = c1.getDeclaredConstructor(String.class, int.class, int.class); System.out.println(\u0026#34;指定：\u0026#34; + declaredConstructor); 通过反射动态创建对象 创建类的对象：调用Class对象的newInstance()方法：\n 类必须有一个无参构造器 类的构造器的访问权限需要足够  也可以通过调用有参构造器：\n 通过Class类的getDeclaredConstructor(Class ... parameterTypes)取得本类的指定参数类型的构造器 向构造器的形参中传递一个对象数组进去，里面包含了构造器中所需的各个参数 通过Constructor实例化对象（newInstance()方法）  示例代码：\n// 获得Class对象 Class c1 = Class.forName(\u0026#34;com.ccqstark.reflection.User\u0026#34;); // 构造一个对象 User user = (User) c1.newInstance(); System.out.println(user); // 通过构造器创建对象 Constructor constructor = c1.getConstructor(String.class, int.class, int.class); User user2 = (User) constructor.newInstance(\u0026#34;ccq\u0026#34;, 1, 2); System.out.println(user2); 通过反射调用指定的方法 通过反射，调用类中的方法，通过Method类完成\n 通过Class类的getMethod(String name, Class...parameterTypes)方法取得一个Method对象，并设置此方法操作时所需的参类型。 之后使用Object invoke(Object obj, Object[] args)进行调用，并向方法中传递要调用此方法的obj对象以及方法的参数  示例代码：\n// 通过反射调用普通方法 User user3 = (User) c1.newInstance(); // 通过反射获取一个方法 Method setName = c1.getDeclaredMethod(\u0026#34;setName\u0026#34;, String.class); // invoke(对象, \u0026#34;方法的参数\u0026#34;) setName.invoke(user3, \u0026#34;ccq\u0026#34;); System.out.println(user3.getName()); Object invoke(Object obj, Object\u0026hellip; args)\n Object对应原方法的返回值，若原方法无返回值，此时返回null 若原方法若为静态方法，此时形参Object obj可为null 若原方法的形参列表为空，则Object[] args为null 若原方法声明为private，则需要在调用此invoke()方法前，显示调用方法对象的setAccessible(true)方法，将可访问private的方法。  setAccessible\n Method和 Field、 Constructor 对象都有 setaccessible()方法 setAccessible作用是启动和禁用访问安全检查的开关。 参数值为true则指示反射的对象在使用时应该取消Java语言访问检查。  提高反射的效率。如果代码中必须用反射，而该句代码需要频繁的被调用，最好设置为true 使得原本无法访问的私有成员也可以访问   参数值为false则指示反射的对象应该实施Java语言访问检查  反射操作泛型 public void test01(Map\u0026lt;String, User\u0026gt; map, List\u0026lt;User\u0026gt; list) { System.out.println(\u0026#34;test01\u0026#34;); } public Map\u0026lt;String, User\u0026gt; test02() { System.out.println(\u0026#34;test02\u0026#34;); return null; } public static void main(String[] args) throws NoSuchMethodException { Method method = Test11.class.getMethod(\u0026#34;test01\u0026#34;, Map.class, List.class); // 获得范型参数类型  Type[] genericParameterTypes = method.getGenericParameterTypes(); for (Type genericParameterType : genericParameterTypes) { System.out.println(genericParameterType); // 如果是参数化类型  if (genericParameterType instanceof ParameterizedType) { // 强转为参数化类型，并且获得真实类型  Type[] actualTypeArguments = ((ParameterizedType) genericParameterType).getActualTypeArguments(); for (Type actualTypeArgument : actualTypeArguments) { System.out.println(actualTypeArgument); } } } method = Test11.class.getMethod(\u0026#34;test02\u0026#34;, null); // 获得泛型返回类型  Type genericReturnType = method.getGenericReturnType(); if (genericReturnType instanceof ParameterizedType) { Type[] actualTypeArguments = ((ParameterizedType) genericReturnType).getActualTypeArguments(); for (Type actualTypeArgument : actualTypeArguments) { System.out.println(actualTypeArgument); } } } 通过反射操作注解 通过反射操作注解来实现一些功能就是很多框架的原理了，像Spring、MyBatis中的注解底层就是通过反射来获得一些信息并进行一些操作来达成某些功能的。\n例如下面的实现ORM的示例，通过自定义注解让用户使用，让用户定义类名对应的表名，属性名对应的字段名，然后通过反射获取这些信息，就可以生成对应的SQL了。\n// 反射操作注解 public class Test12 { public static void main(String[] args) throws ClassNotFoundException, NoSuchFieldException { Class c1 = Class.forName(\u0026#34;com.ccqstark.reflection.Student2\u0026#34;); // 通过反射获得注解  Annotation[] annotations = c1.getAnnotations(); for (Annotation annotation : annotations) { System.out.println(annotation); } // 获得注解的value值，这里通过反射获得了映射表名的注解的值，也就是获得了表名  TableCcq tableCcq = (TableCcq) c1.getAnnotation(TableCcq.class); String value = tableCcq.value(); System.out.println(value); // 通过反射操作field的注解，获得了属性映射的表字段的信息，如字段名、类型、长度  Field f = c1.getDeclaredField(\u0026#34;name\u0026#34;); FieldCcq annotation = f.getAnnotation(FieldCcq.class); System.out.println(annotation.columnName()); System.out.println(annotation.type()); System.out.println(annotation.length()); } } @TableCcq(\u0026#34;db_ccq\u0026#34;) class Student2 { @FieldCcq(columnName = \u0026#34;db_id\u0026#34;, type = \u0026#34;int\u0026#34;, length = 10) private int id; @FieldCcq(columnName = \u0026#34;db_age\u0026#34;, type = \u0026#34;int\u0026#34;, length = 10) private int age; @FieldCcq(columnName = \u0026#34;db_name\u0026#34;, type = \u0026#34;varchar\u0026#34;, length = 3) private String name; } // 类名-\u0026gt;表名 的注解 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @interface TableCcq { String value(); } // 属性-\u0026gt;字段 的注解 @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @interface FieldCcq { String columnName(); String type(); int length(); } 总结 注解是给程序做的注释、标记，让程序可以读取一些额外信息并做出一些行为\n反射让Java程序在运行时可以获取到类和对象的信息（类名、属性、方法\u0026hellip;）\n注解和反射与Java很多流行框架息息相关，两者的搭配使用是它们的底层原理，所以非常重要。\n参考自：\n【狂神说Java】注解和反射\n","date":"2021-07-22T23:43:42+08:00","image":"https://ccqstark.github.io/p/java_annotaion_reflection/cover_hud3682ca23d8f51585d79a941911fa5ce_24013_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/java_annotaion_reflection/","title":"Java注解和反射"},{"content":"RESTful 与 RPC 的区别 在微服务定义中提道，每个小服务运行在自己的进程中，并以轻量级的机制进行通信。这里并没有明确给出具体的通信方式，只是要求以轻量级的机制进行通信，虽然作者推荐使用 RESTful 作为首选方案，但微服务间通信本身还有另一个轻量级的选择：以 Dubbo 为代表的 RPC通信方式。\nRPC 是远程过程调用（Remote Procedure Call）的缩写形式，RPC 与 RESTful 最大的不同是，RPC 采用客户端（Client) - 服务端（Server） 的架构方式实现跨进程通信，实现的通信协议也没有统一的标准，具体实现依托于研发厂商的设计。\n目前开源市场上 RPC 框架有很多，例如 GoogleRPC、Alibaba Dubbo、Facebook Thrift，每一种产品都有自己的设计与实现方案。\n那 RESTful 与 RPC 有什么区别呢？通过一个表格进行说明：\nApache Dubbo Dubbo 是阿里巴巴开源的高性能、轻量级的开源 Java 框架，目前被 Apache收录，官网是： http://dubbo.apache.org/\nDubbo 是典型的 RPC 框架的代表，通过客户端/服务端结构实现跨进程应用的高效二进制通信。\nApache Dubbo 提供了六大核心能力：\n面向接口代理的高性能 RPC 调用；\n智能容错和负载均衡；\n服务自动注册和发现；\n高度可扩展能力；\n运行期流量调度；\n可视化的服务治理与运维。\n下图引用 Dubbo 的官方架构图，讲解 ApacheDubbo 的组成。\nDubbo 架构中，包含 5 种角色。\n Provider：RPC服务提供者，Provider 是消息的最终处理者。 Container：容器，用于启动、停止 Provider 服务。这里的容器并非 Tomcat、Jetty 等 Web 容器，Dubbo 也并不强制要求 Provider 必须具备 Web 能力。Dubbo 的容器是指对象容器，例如 Dubbo 内置的 SpringContainer 容器就提供了利用 Spring IOC 容器管理 Provider 对象的职能。 Consumer：消费者，调用的发起者。Consumer 需要在客户端持有 Provider 的通信接口才能完成通信过程。 Registry：注册中心，Dubbo 架构中注册中心与微服务架构中的注册中心职责类似，提供了 Dubbo Provider 的注册与发现职能，Consumer通过 Registry 可以获取Provider 可用的节点实例的 IP、端口等，并产生直接通信。需要注意的是，前面我们讲解的 Alibaba Nacos 除了可以作为微服务架构中的注册中心外，同样对自家的 Dubbo 提供了 RPC 调用注册发现的职责，这是其他 Spring Cloud 注册中心所不具备的功能。 Monitor：监控器，监控器提供了Dubbo的监控职责。在 Dubbo 产生通信时，Monitor 进行收集、统计，并通过可视化 UI 界面帮助运维人员了解系统进程间的通信状况。Dubbo Monitor 主流产品有 Dubbo Admin、Dubbo Ops 等。  项目整合 服务提供者Provider  引入依赖  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.dubbo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dubbo-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 相比标准微服务，需要额外依赖 dubbo-spring-boot-starter 与 spring-boot-starter-actuator。其中 dubbo-spring-boot-starter 是 Dubbo 与 Spring Boot 整合最关键的组件，为 Spring Boot 提供了 Dubbo 的默认支持。而 spring-boot-starter-actuator则为微服务提供了监控指标接口，便于监控系统从应用收集各项运行指标。\n 配置文件  server:port:8000#服务端口spring:application:name:warehouse-service#微服务idcloud:nacos:#nacos注册地址discovery:server-addr:192.168.31.101:8848username:nacospassword:nacosdubbo:#dubbo与nacos的通信配置application:name:warehouse-dubbo#provider在Nacos中的应用idregistry:#Provider与Nacos通信地址，与spring.cloud.nacos地址一致address:nacos://192.168.31.101:8848protocol:name:dubbo#通信协议名port:20880#配置通信端口，默认为20880scan:base-packages:com.lagou.warehouseservice.dubboDubbo 需要依托 Container（容器）对外暴露服务，而这个容器配置与微服务配置是分开的，需要额外占用一个网络端口20880提供服务。\ndubbo.scan.base-packages 代表在 Dubbo 容器启动时自动扫描 com.lagou.warehouseservice.dubbo 包下的接口与实现类，并将这些接口信息在Nacos 进行登记，因此 Dubbo 对外暴露的接口必须放在该包下。\n 开发服务  实体类dto这里不做示例了\n下面是com.lagou.warehouseservice.dubbo包下创建的服务接口，包名要与 dubbo.scan.base-packages 保持一致\n//Provider接口 public interface WarehouseService { //查询库存  public Stock getStock(Long skuId); } 在 com.lagou.warehouseservice.dubbo.impl包下创建实现类\n@DubboService public class WarehouseServiceImpl implements WarehouseService { public Stock getStock(Long skuId){ /* code */ return stock; } } 需要额外增加 @DubboService注解。@DubboService 是 Provider 注解，说明该类所有方法都是服务提供者，加入该注解会自动将类与方法的信息在 Nacos中注册为 Provider。\n服务消费者Consumer  引入依赖和服务提供者一样 配置文件  spring:application:name:order-servicecloud:nacos:discovery:server-addr:192.168.31.101:8848username:nacospassword:nacosserver:port:9000dubbo:application:name:order-service-dubboregistry:address:nacos://192.168.31.101:8848 将处于服务提供方的服务接口和相关实体类复制到调用方  接口就行，接口的实现类不用。相当于声明了通信接口，注意要求包名、类名及代码保持完全一致。上面是在与原项目同级目录新建了一个和服务提供方一样的包路径。\n 消费者调用服务  @RestController public class OrderController { @DubboReference private WarehouseService warehouseService; @GetMapping(\u0026#34;/create_order\u0026#34;) public Map createOrder(Long skuId , Long salesQuantity){ // 查询商品库存，像调用本地方法一样完成业务逻辑。  Stock stock = warehouseService.getStock(skuId); // code\t return result; } } 关键点是 @DubboReference 注解。该注解用在 Consumer 端，Spring 会自动生成远程服务的接口的代理实现类，并隐藏远程通信细节。\n微服务启动后，在nacos的服务列表界面可以看到微服务和Dubbo的服务，表示注册成功了。\n小坑\n引入了spring-boot-starter-actuator 会与ShardingSphere检查数据库连接时产生冲突，抛出错误\norg.springframework.dao.InvalidDataAccessApiUsageException: ConnectionCallback; isValid; nested exception is java.sql.SQLFeatureNotSupportedException: isValid 解决办法：\n配置文件加上\nmanagement:health:db:enabled:false","date":"2021-07-22T02:26:29+08:00","image":"https://ccqstark.github.io/p/dubbo_nacos_rpc/cover_hu148189a32dd9592e6629114cd574d267_71263_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/dubbo_nacos_rpc/","title":"Dubbo+Nacos实现RPC"},{"content":"理论知识 RocketMQ 天然采用集群模式，常见的 RocketMQ 集群有三种形式：多 Master 模式、多 Master 多 Slave- 异步复制模式、多 Master 多 Slave- 同步双写模式，这三种模式各自的优缺点如下。\n 多 Master 模式是配置最简单的模式，同时也是使用最多的形式。优点是单个 Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复情况下，由于 RAID10 磁盘非常可靠，同步刷盘消息也不会丢失，性能也是最高的；缺点是单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。 多 Master 多 Slave 异步复制模式。每个 Master 配置一个 Slave，有多对 Master-Slave，HA 采用异步复制方式，主备有短暂消息毫秒级延迟，即使磁盘损坏只会丢失少量消息，且消息实时性不会受影响。同时 Master 宕机后，消费者仍然可以从 Slave 消费，而且此过程对应用透明，不需要人工干预，性能同多 Master 模式几乎一样；缺点是 Master 宕机，磁盘损坏情况下会丢失少量消息。 多 Master 多 Slave 同步双写模式，HA 采用同步双写方式，即只有主备都写成功，才向应用返回成功，该模式数据与服务都无单点故障，Master 宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；缺点是性能比异步复制模式低 10% 左右，发送单个消息的执行时间会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。  部署 部署 NameServer 集群 直接wget下载\nwget https://mirror-hk.koddos.net/apache/rocketmq/4.8.0/rocketmq-all-4.8.0-bin-release.zip unzip 解压后，我们进入bin目录修改runserver.sh文件的虚拟机内存配置（因为默认的太大了吃不消），根据自己服务器实际情况更改\nJAVA_OPT=\u0026#34;${JAVA_OPT}-server -Xms128m -Xmx128m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\u0026#34; 后台启动一下NameServer服务\nnohup sh mqnamesrv \u0026amp; NameServer 将占用 9876 端口提供服务，不要忘记在防火墙设置放行，另一台服务器也同样方式操作一波。\n部署 Broker 集群 同样改小JVM内存，这次改bin下的runbroker.sh文件\nJAVA_OPT=\u0026#34;${JAVA_OPT}-server -Xms128m -Xmx128m -Xmn128m\u0026#34; 然后我们要配置一下Broker，在 conf 目录下，RocketMQ 已经给我们贴心的准备好三组集群配置模板：\n 2m-2s-async 代表双主双从异步复制模式； 2m-2s-sync 代表双主双从同步双写模式； 2m-noslave 代表双主模式。  这里配置的是双主模式 ，所以去2m-noslave目录下，发现有broker-a.properties和broker-b.properties两个配置文件。\n第一台主机修改broker-a.properties作为broker-a，第二台修改broker-b.properties作为broker-b，都添加上NameServer集群的地址并配上自己的公网IP：\n#集群名称，同一个集群下的 broker 要求统一 brokerClusterName=DefaultCluster #broker 名称 brokerName=broker-a #broker 公网IP brokerIP1=49.234.82.226 #brokerId=0 代表主节点，大于零代表从节点 brokerId=0 #删除日志文件时间点，默认凌晨 4 点 deleteWhen=04 #日志文件保留时间，默认 48 小时 fileReservedTime=48 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master brokerRole=ASYNC_MASTER #刷盘方式 #- ASYNC_FLUSH 异步刷盘，性能好宕机会丢数 #- SYNC_FLUSH 同步刷盘，性能较差不会丢数 flushDiskType=ASYNC_FLUSH #末尾追加，NameServer 节点列表，使用分号分割 namesrvAddr=192.168.31.200:9876;192.168.31.201:9876 broker配置文件里一定要配个公网IP，否则默认是用内网的！\nbroker-b就只有brokerName和brokerIP1不同\n之后就可以运行了，到bin目录下\nnohup sh mqbroker -c ../conf/2m-noslave/broker-a.properties \u0026amp; broker-a就用broker-a.properties启动，broker-b就用broker-b.properties启动\nBroker 将占用 10911 端口提供服务，记得设置防火墙放行\n测试部署结果  修改bin下tools.sh的Djava.ext.dirs，添加jvm的ext绝对路径：  JAVA_OPT=\u0026#34;${JAVA_OPT}-Djava.ext.dirs=${BASE_DIR}/lib:${JAVA_HOME}/jre/lib/ext:${JAVA_HOME}/lib/ext:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64/jre/lib/ext\u0026#34; 如上，在最后用冒号隔开加上自己的jre/lib/ext 绝对路径\n 使用 mqadmin 命令查看集群状态  sh mqadmin clusterList -n [NameServer服务器的IP]:9876 可以看到broker-a和broker-b的地址和端口\n 使用 tools.sh工具通过生成演示数据来测试 MQ 实际的运行情况  测试生产者发送消息\nexport NAMESRV_ADDR=[NameServer服务器的IP]:9876 sh tools.sh org.apache.rocketmq.example.quickstart.Producer 集群生效后，可以看到broker-a和broker-交替出现\n测试消费者接收消息\n# 设置环境变量 export NAMESRV_ADDR=[NameServer服务器的IP]:9876 # 运行测试程序 sh tools.sh org.apache.rocketmq.example.quickstart.Consumer 部署可视化界面 RocketMQ-Console 使用docker部署\n# 拉取镜像 docker pull apacherocketmq/rocketmq-console:2.0.0 # 运行容器 docker run -e \u0026#34;JAVA_OPTS=-Drocketmq.namesrv.addr=[NameServer服务器的IP]:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\u0026#34; -p 8080:8080 -t apacherocketmq/rocketmq-console:2.0.0 打开网址界面如下\n代码实践 生产者 Producer 发送消息 引入依赖\n\u0026lt;!-- RocketMQ客户端，版本与Broker保持一致 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 创建一个controller测试发送\n@RestController public class ProviderController { Logger logger = LoggerFactory.getLogger(ProviderController.class); @GetMapping(value = \u0026#34;/send_s1_tax\u0026#34;) public String send1() throws MQClientException { //创建DefaultMQProducer消息生产者对象  DefaultMQProducer producer = new DefaultMQProducer(\u0026#34;producer-group\u0026#34;); //设置NameServer节点地址，多个节点间用分号分割  producer.setNamesrvAddr(\u0026#34;192.168.31.200:9876;192.168.31.201:9876\u0026#34;); //与NameServer建立长连接  producer.start(); try { //发送一百条数据  for(int i = 0 ; i\u0026lt; 100 ; i++) { //数据正文  String data = \u0026#34;{\\\u0026#34;title\\\u0026#34;:\\\u0026#34;X市2021年度第一季度税务汇总数据\\\u0026#34;}\u0026#34;; /*创建消息 Message消息三个参数 topic 代表消息主题，自定义为tax-data-topic说明是税务数据 tags 代表标志，用于消费者接收数据时进行数据筛选。2021S1代表2021年第一季度数据 body 代表消息内容 */ Message message = new Message(\u0026#34;tax-data-topic\u0026#34;, \u0026#34;2021S1\u0026#34;, data.getBytes()); //发送消息，获取发送结果  SendResult result = producer.send(message); //将发送结果对象打印在控制台  logger.info(\u0026#34;消息已发送：MsgId:\u0026#34; + result.getMsgId() + \u0026#34;，发送状态:\u0026#34; + result.getSendStatus()); } } catch (RemotingException e) { e.printStackTrace(); } catch (MQBrokerException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } finally { producer.shutdown(); } return \u0026#34;success\u0026#34;; } } 启动应用调用接口后，可以在控制台看到\n2021-04-19 19:06:16.630 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEA71024E，发送状态:SEND_OK 2021-04-19 19:06:16.697 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEAB6024F，发送状态:SEND_OK 2021-04-19 19:06:16.777 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEAFA0250，发送状态:SEND_OK 2021-04-19 19:06:16.847 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEB490251，发送状态:SEND_OK 2021-04-19 19:06:16.953 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEB8F0252，发送状态:SEND_OK 2021-04-19 19:06:17.050 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEBF90253，发送状态:SEND_OK 消费者 Consumer 接收消息 引入同样依赖\n\u0026lt;!-- RocketMQ客户端，版本与Broker保持一致 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 创建一个controller测试接收\n@SpringBootApplication public class RocketmqConsumerApplication { private static Logger logger = LoggerFactory.getLogger(RocketmqConsumerApplication.class); public static void main(String[] args) throws MQClientException { SpringApplication.run(RocketmqConsumerApplication.class, args); //创建消费者对象  DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\u0026#34;consumer-group\u0026#34;); //设置NameServer节点  consumer.setNamesrvAddr(\u0026#34;192.168.31.200:9876;192.168.31.201:9876\u0026#34;); /*订阅主题， consumer.subscribe包含两个参数： topic: 说明消费者从Broker订阅哪一个主题，这一项要与Provider保持一致。 subExpression: 子表达式用于筛选tags。 同一个主题下可以包含很多不同的tags，subExpression用于筛选符合条件的tags进行接收。 例如：设置为*，则代表接收所有tags数据。 例如：设置为2020S1，则Broker中只有tags=2020S1的消息会被接收，而2020S2就会被排除在外。 */ consumer.subscribe(\u0026#34;tax-data-topic\u0026#34;, \u0026#34;*\u0026#34;); //创建监听，当有新的消息监听程序会及时捕捉并加以处理。  consumer.registerMessageListener(new MessageListenerConcurrently() { public ConsumeConcurrentlyStatus consumeMessage( List\u0026lt;MessageExt\u0026gt; msgs, ConsumeConcurrentlyContext context) { //批量数据处理  for (MessageExt msg : msgs) { logger.info(\u0026#34;消费者消费数据:\u0026#34;+new String(msg.getBody())); } //返回数据已接收标识  return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); //启动消费者，与Broker建立长连接，开始监听。  consumer.start(); } } 当应用启动后，Provider 产生新消息的同时，Consumer 端就会立即消费掉，控制台产生输出。\n2021-04-19 13:01:57.636 INFO 51389 --- [MessageThread_2] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 2021-04-19 13:01:57.692 INFO 51389 --- [MessageThread_1] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 2021-04-19 13:01:57.719 INFO 51389 --- [essageThread_18] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 2021-04-19 13:01:57.728 INFO 51389 --- [essageThread_10] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 2021-04-19 13:01:57.738 INFO 51389 --- [MessageThread_6] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 在可视化界面也可以看到变化。\nSpring Cloud 生态中还提供了 Spring Cloud Stream 模块，允许程序员采用“声明式”的开发方式实现与 MQ 更轻松的接入。\n","date":"2021-07-22T02:03:53+08:00","image":"https://ccqstark.github.io/p/rocketmq_startup/cover_hu9145d0cb10e9c56d586699b94d669fc3_38014_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/rocketmq_startup/","title":"RocketMQ入门"},{"content":"依赖 \u0026lt;!-- sleuth --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-sleuth\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- zipkin --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-zipkin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这里踩了大坑，不要用阿里的镜像，用Maven官方的，阿里的有问题！！\n配置文件 spring:sleuth:sampler:#采样器probability:1.0#采样率，采样率是采集Trace的比率，默认0.1rate:10000#每秒数据采集量，最多n条/秒Tracezipkin:#设置zipkin服务端地址base-url:http://49.234.82.226:9411然后去服务端部署zipkin的可视化监控程序，参照官网：\nhttps://zipkin.io/pages/quickstart.html\n推荐使用docker\ndocker run -d -p 9411:9411 openzipkin/zipkin 使用 之后调用的链路就可以在下面链接看到了\nhttp://49.234.82.226:9411/zipkin\n需要刷新和筛选一下\n点进去可以看到具体信息\n","date":"2021-07-22T01:56:55+08:00","image":"https://ccqstark.github.io/p/zipkin_startup/cover_hu6ef3ef375e80ecb9108b60353e3afbae_90400_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/zipkin_startup/","title":"Sleuth+Zipkin链路跟踪入门"},{"content":"建立数据库 建立个用于存放配置的数据库名为nacos-config，nacos/conf下有一个nacos-mysql.sql，运行一下便可获得存放配置信息的表\n配置数据源 修改nacos/conf/application.properties\n### If use MySQL as datasource: spring.datasource.platform=mysql ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://xxxxxxx:3306/nacos_config?characterEncoding=utf8\u0026amp;connectTimeout=1000\u0026amp;socketTimeout=3000\u0026amp;autoReconnect=true\u0026amp;useUnicode=true\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC db.user=root db.password=xxxxxxx 记得重启\n应用接入配置中心 依赖\n\u0026lt;!-- Spring Boot Web模块 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Nacos注册中心starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Nacos配置中心starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件，我们把原来的application.yml删除了，我们不再需要本地配置\n然后创建文件bootstrap.yml，注意名字要一模一样\nspring:application:name:order-service#微服务idprofiles:active:dev#环境名cloud:nacos:config:#Nacos配置中心配置file-extension:yml#文件扩展名server-addr:192.168.31.10:8848username:nacospassword:nacoslogging:#开启debug日志，仅为学习时使用level:root:debug定义一份配置文件是用微服务id-环境名.文件扩展名 三部分组合为有效的 data id，比如上面的就是order-service-dev.yml\n然后去Nacos把原来的那些应用配置给存到云端\n点击➕ 号新建配置\n注意data id 就是上面说的微服务id-环境名.文件扩展名 ，然后选择yaml格式，把我们以前写在本地的配置文件写到下面的配置内容中\n此时新建的配置信息其实就是用我们之前配置的MySQL存的，你会发现这些配置信息存在config-info表中了\n配置热加载技术 当我们突然修改配置文件后，为了生效我们必须重启一下应用，就有点麻烦，为了解决这个问题，我们用到了配置热加载技术\n为了支持热加载，服务的程序针对热加载需要作出如下变动：\n第一，配置数据必须被封装到单独的配置 Bean 中；\n第二，这个配置 Bean 需要被 @Configuration 与 @RefreshScope 两个注解描述。\n@Configuration @RefreshScope public class CustomConfig { @Value(\u0026#34;${custom.flag}\u0026#34;) private String flag; @Value(\u0026#34;${custom.database}\u0026#34;) private String database; public String getFlag() { return flag; } public void setFlag(String flag) { this.flag = flag; } public String getDatabase() { return database; } public void setDatabase(String database) { this.database = database; } } 在配置处用@Resource 注入即可\n@RestController public class TestController { @Resource private CustomConfig customConfig; @GetMapping(\u0026#34;/test\u0026#34;) public String test(){ return \u0026#34;flag:\u0026#34; + customConfig.getFlag() + \u0026#34;\u0026lt;br/\u0026gt; database:\u0026#34; + customConfig.getDatabase(); } } 现在我们需要变更配置文件时只需在Nacos中修改配置，它就会自动推送到应用而不需要每次都重启应用了。\n分环境配置 这个其实和原来没有用配置中心的差不多，生产环境的配置就在文件名后加-prod ，配置环境就加-dev ，共用的基础全局配置就直接application.yml 什么也不用加。\n对于现在微服务架构具体来说就是\n order-service-dev.yml 开发环境 order-service-prod.yml 生产环境 order-service.yml 共用  当然，如果要改变你要用的环境，还是需要改bootstrap.yml\nspring:profiles:active:prod#环境名","date":"2021-07-22T01:48:33+08:00","image":"https://ccqstark.github.io/p/nacos_config_startup/cover_hu2f85b5acfdf02eef7b8f3b3a65f67b73_18437_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/nacos_config_startup/","title":"Nacos配置中心入门"},{"content":"Feign 与 OpenFeign Spring Cloud OpenFeign 并不是独立的技术。它底层基于 Netflix Feign，Netflix Feign 是 Netflix 设计的开源的声明式 WebService 客户端，用于简化服务间通信。Netflix Feign 采用“接口+注解”的方式开发，通过模仿 RPC 的客户端与服务器模式（CS），采用接口方式开发来屏蔽网络通信的细节。OpenFeign 则是在 Netflix Feign 的基础上进行封装，结合原有 Spring MVC 的注解，对 Spring Cloud 微服务通信提供了良好的支持。使用 OpenFeign 开发的方式与开发 Spring MVC Controller 颇为相似。\n下面讲OpenFeign的使用方法。\n服务提供方 依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置 spring:application:name:warehouse-service#应用/微服务名字cloud:nacos:discovery:server-addr:192.168.31.102:8848#nacos服务器地址username:nacos#用户名密码password:nacosserver:port:80可被调用的服务 @RestController public class WarehouseController { @GetMapping(\u0026#34;/stock\u0026#34;) public Stock getStock(Long skuId){ /* code */ return stock; } } 服务调用方 依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- OpenFeign --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.5.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; OpenFeign 为了保证通信高可用，底层也是采用 Ribbon 实现负载均衡，其原理与 Ribbon+RestTemplate 完全相同，只不过相较 RestTemplate，OpenFeign 封装度更高罢了。\n添加启用注解 @SpringBootApplication **@EnableFeignClients** //启用OpenFeign public class OrderServiceApplication { public static void main(String[] args) { SpringApplication.run(OrderServiceApplication.class, args); } } @EnableFeignClients用于启用OpenFeign\n配置 spring:application:name:order-servicecloud:nacos:discovery:server-addr:192.168.31.102:8848username:nacospassword:nacosserver:port:80这里只需配置Nacos即可\n创建OpenFeign的通信接口与响应对象 **@FeignClient(\u0026#34;warehouse-service\u0026#34;)** public interface WarehouseServiceFeignClient { @GetMapping(\u0026#34;/stock\u0026#34;) public Stock getStock(@RequestParam(\u0026#34;skuId\u0026#34;) Long skuId); } 这里就是定义我们要调用的服务的接口，方法名，参数，路由什么的都要对应。\n@FeignClient注解里面就填要调用的微服务名。参数值 warehouse-service 为服务提供者 ID，这一项必须与 Nacos 注册 ID 保持一致。在 OpenFeign 发送请求前会自动在 Nacos 查询 warehouse-service 所有可用实例信息，再通过内置的 Ribbon 负载均衡选择一个实例发起 RESTful 请求，进而保证通信高可用。\n这里的@GetMapping/@PostMapping和以前我们在写控制器时经常使用的 @GetMapping 或者 @ PostMapping 不同，OpenFeign 的客户端使用这些注解的含义是：OpenFeign 向服务提供者 warehouse-service 的 stock 接口**发起 Get 请求。**不得不说这个方式和Dubbo还是很像的，\n@RequestParam，该注解说明方法参数与请求参数之间的映射关系。\n消费者调用 @RestController public class OrderController { //利用@Resource将IOC容器中自动实例化的实现类对象进行注入  **@Resource private WarehouseServiceFeignClient warehouseServiceFeignClient;** @GetMapping(\u0026#34;/create_order\u0026#34;) public Map createOrder(Long skuId , Long salesQuantity){ //查询商品库存，像调用本地方法一样完成业务逻辑。  Stock stock = warehouseServiceFeignClient.getStock(skuId); /* code */ return result; } } @Resource注入被调用服务的接口就可以像调用本地方法一样使用了。\n完整过程 1.在第一次访问 WarehouseServiceFeignClient 接口时，Spring 自动生成接口的实现类并实例化对象。\n2.当调用 getStock() 方法时，Ribbon 获取 warehouse-service 可用实例信息，根据负载均衡策略选择合适实例。\n3.OpenFeign 根据方法上注解描述的映射关系生成完整的 URL 并发送 HTTP 请求，如果请求方法是 @PostMapping，则参数会附加在请求体中进行发送。\n4.warehouse-service 处理完毕返回 JSON 数据，消费者端 OpenFeign 接收 JSON 的同时反序列化到 Stock 对象，并将该对象返回。\n生产环境 OpenFeign 的配置事项 如何更改 OpenFeign 默认的负载均衡策略 前面提到在 OpenFeign 使用时默认引用 Ribbon 实现客户端负载均衡。如果设置 Ribbon 的负载均衡策略，其实配置方式其实与之前 Ribbon+RestTemplate 方案完全相同，只需在 application.yml 中调整微服务通信时使用的负载均衡类即可。\n复制代码\nwarehouse-service:#服务提供者的微服务IDribbon:#设置对应的负载均衡类NFLoadBalancerRuleClassName:com.netflix.loadbalancer.RandomRule开启默认的 OpenFeign 数据压缩功能 在 OpenFeign 中，默认并没有开启数据压缩功能。但如果服务间单次传递数据超过 1K 字节，强烈推荐开启数据压缩功能。默认 OpenFeign 使用 Gzip 方式压缩数据，对于大文本通常压缩后尺寸只相当于原始数据的 10%~30%，这会极大提高带宽利用率。但有一种情况除外，如果应用属于计算密集型，CPU 负载长期超过 70%，因数据压缩、解压缩都需要 CPU 运算，开启数据压缩功能反而会给 CPU 增加额外负担，导致系统性能降低，这是不可取的。\n复制代码\nfeign:compression:request:# 开启请求数据的压缩功能enabled:true# 压缩支持的MIME类型mime-types:text/xml,application/xml, application/json# 数据压缩下限 1024表示传输数据大于1024 才会进行数据压缩(最小压缩值标准)min-request-size:1024# 开启响应数据的压缩功能response:enabled:true替换默认通信组件 OpenFeign 默认使用 Java 自带的 URLConnection 对象创建 HTTP 请求，但接入生产时，如果能将底层通信组件更换为Apache HttpClient、OKHttp 这样的专用通信组件，基于这些组件自带的连接池，可以更好地对 HTTP 连接对象进行重用与管理。作为 OpenFeign 目前默认支持 Apache HttpClient 与 OKHttp 两款产品。这里以OKHttp配置方式为例。\n 引入 feign-okhttp 依赖包。  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.openfeign\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;feign-okhttp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;11.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在应用入口，利用 Java Config 形式初始化 OkHttpClient 对象。  @SpringBootApplication @EnableFeignClients public class OrderServiceApplication { //Spring IOC容器初始化时构建okHttpClient对象  @Bean public okhttp3.OkHttpClient okHttpClient(){ return new okhttp3.OkHttpClient.Builder() //读取超时时间  .readTimeout(10, TimeUnit.SECONDS) //连接超时时间  .connectTimeout(10, TimeUnit.SECONDS) //写超时时间  .writeTimeout(10, TimeUnit.SECONDS) //设置连接池  .connectionPool(new ConnectionPool()) .build(); } public static void main(String[] args) { SpringApplication.run(OrderServiceApplication.class, args); } } 在 application.yml 中启用 OkHttp。  feign:okhttp:enabled:true至此，我们已将OpenFeign的默认通信对象从URLConnection调整为OKHttp，至于替换为HttpClient组件的配置思路是基本相同的。\n如果需要了解OpenFeign更详细的配置选项，可以访问Spring Cloud OpenFeign的官方文档进行学习。\nhttps://docs.spring.io/spring-cloud-openfeign/docs/2.2.6.RELEASE/reference/html/\n","date":"2021-07-22T01:43:44+08:00","image":"https://ccqstark.github.io/p/openfeign_startup/cover_hu74c9fdd8cb819657fbdd849b196b87b5_65974_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/openfeign_startup/","title":"OpenFeign服务调用入门"},{"content":"客户端负载均衡 负载均衡顾名思义，是指通过软件或者硬件措施。它将来自客户端的请求按照某种策略平均的分配到集群的每一个节点上，保证这些节点的 CPU、内存等设备负载情况大致在一条水平线，避免由于局部节点负载过高产生宕机，再将这些处理压力传递到其他节点上产生系统性崩溃。\n负载均衡按实现方式分类可区分为：服务端负载均衡与客户端负载均衡。\n服务端负载均衡顾名思义，在架构中会提供专用的负载均衡器，由负载均衡器持有后端节点的信息，服务消费者发来的请求经由专用的负载均衡器分发给服务提供者，进而实现负载均衡的作用。目前常用的负载均衡器软硬件有：F5、Nginx、HaProxy 等。\n客户端负载均衡是指，在架构中不再部署额外的负载均衡器，在每个服务消费者内部持有客户端负载均衡器，由内置的负载均衡策略决定向哪个服务提供者发起请求。通俗来讲，就是客户端在发送请求之前就通过某种策略选定了要请求的服务提供者，而不是让一个中间件来帮忙决定。\nRibbon Netfilx Ribbon 是 Netflix 公司开源的一个负载均衡组件，是属于客户端负载均衡器。目前Ribbon 已被 Spring Cloud 官方技术生态整合，运行时以 SDK 形式内嵌到每一个微服务实例中，为微服务间通信提供负载均衡与高可用支持。\n过程如下：\n 订单服务（order-service）与商品服务（goods-service）实例在启动时向 Nacos 注册； 订单服务向商品服务发起通信前，Ribbon 向 Nacos 查询商品服务的可用实例列表； Ribbon 根据设置的负载策略从商品服务可用实例列表中选择实例； 订单服务实例向商品服务实例发起请求，完成 RESTful 通信；  下面用一个实例来演示：\n创建服务生产者 创建springboot项目模块，引入web和nacos客户端依赖\n配置文件 spring:application:name:provider-service#应用/微服务名字cloud:nacos:discovery:server-addr:49.234.82.226:8848#nacos服务器地址username:nacos#用户名密码password:nacosserver:port:8081创建示例服务 @RestController public class ProviderController { @GetMapping(\u0026#34;/provider/msg\u0026#34;) public String sendMessage(){ return \u0026#34;This is the message from provider service one!\u0026#34;; } } 连续创建3个provider，注意配置文件中的应用/微服务名要一致，代表同一种服务，为了直接了当地识别服务来自不同的微服务示例，可以在返回的字符串中添加自己的标示。启动后可以在nacos中看到健康示例数为3:\n创建服务消费者 引入web和nacos客户端依赖之外，还要引入ribbon\n\u0026lt;!-- Ribbon --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-ribbon\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud-alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件和服务提供者只有应用名和端口的区别。\n服务调用示例 首先是要添加RestTemplate对象\n@SpringBootApplication public class ConsumerServiceApplication { //Java Config声明RestTemplate对象  //在应用启动时自动执行restTemplate()方法创建RestTemplate对象，其BeanId为restTemplate。  @Bean public RestTemplate restTemplate(){ return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(ConsumerServiceApplication.class, args); } } 然后添加controller\n@RestController public class ConsumerController { private Logger logger = LoggerFactory.getLogger(ConsumerController.class); //注入 Ribbon 负载均衡器对象  //在引入 starter-netflix-ribbon 后在 SpringBoot 启动时会自动实例化 LoadBalancerClient 对象。  //在 Controller 使用 @Resource 注解进行注入即可。  @Resource private LoadBalancerClient loadBalancerClient; @Resource //将应用启动时创建的 RestTemplate 对象注入 ConsumerController  private RestTemplate restTemplate; @GetMapping(\u0026#34;/consumer/msg1\u0026#34;) public String getProviderMessage1() { //loadBalancerClient.choose()方法会从 Nacos 获取 provider-service 所有可用实例，  //并按负载均衡策略从中选择一个可用实例，封装为 ServiceInstance（服务实例）对象  //结合现有环境既是从三个实例中选择一个包装为ServiceInstance  ServiceInstance serviceInstance = loadBalancerClient.choose(\u0026#34;provider-service\u0026#34;); //获取服务实例的 IP 地址  String host = serviceInstance.getHost(); //获取服务实例的端口  int port = serviceInstance.getPort(); //在日志中打印服务实例信息  logger.info(\u0026#34;本次调用由provider-service的\u0026#34; + host + \u0026#34;:\u0026#34; + port + \u0026#34; 实例节点负责处理\u0026#34; ); //通过 RestTemplate 对象的 getForObject() 方法向指定 URL 发送请求，并接收响应。  //getForObject()方法有两个参数：  //1. 具体发送的 URL，结合当前环境发送地址为：http://[ip]:[port]/provider/msg  //2. String.class说明 URL 返回的是纯字符串，如果第二参数是实体类， RestTemplate 会自动进行反序列化，为实体属性赋值  String result = restTemplate.getForObject(\u0026#34;http://\u0026#34; + host + \u0026#34;:\u0026#34; + port + \u0026#34;/provider/msg\u0026#34;, String.class); //输出响应内容  logger.info(\u0026#34;provider-service 响应数据:\u0026#34; + result); //向浏览器返回响应  return \u0026#34;consumer-service 响应数据:\u0026#34; + result; } } 调用服务测试 发现每次刷新都是不一样的服务示例来服务的，这里默认采用了轮询机制来负载均衡\n@LoadBalanced 采用注解模式用@LoadBalanced 注解就可以很大程度上简化代码\n注解加在RestTemplate对象上\n@SpringBootApplication public class ConsumerServiceApplication { //Java Config声明RestTemplate对象  //在应用启动时自动执行restTemplate()方法创建RestTemplate对象，其BeanId为restTemplate。  @Bean @LoadBalanced //使RestTemplate对象自动支持Ribbon负载均衡  public RestTemplate restTemplate(){ return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(ConsumerServiceApplication.class, args); } } 添加服务\n@GetMapping(\u0026#34;/consumer/msg2\u0026#34;) public String getProviderMessage2() { //关键点：将原有IP:端口替换为服务名，RestTemplate便会在通信前自动利用Ribbon查询可用provider-service实例列表  //再根据负载均衡策略选择节点实例  String result = restTemplate.getForObject(\u0026#34;http://provider-service/provider/msg\u0026#34;, String.class); logger.info(\u0026#34;consumer-service获得数据:\u0026#34; + result); return \u0026#34;consumer-service获得数据:\u0026#34; + result; } 可以发现比第一种方式减少了很多的代码\n如何配置 Ribbon 负载均衡策略 Ribbon 内置多种负载均衡策略，常用的分为以下几种。\n RoundRobinRule：  轮询策略，Ribbon 默认策略。默认超过 10 次获取到的 server 都不可用，会返回⼀个空的 server。\n RandomRule：  随机策略，如果随机到的 server 为 null 或者不可用的话。会不停地循环选取。\n RetryRule：  重试策略，⼀定时限内循环重试。默认继承 RoundRobinRule，也⽀持自定义注⼊，RetryRule 会在每次选取之后，对选举的 server 进⾏判断，是否为 null，是否 alive，并且在 500ms 内会不停地选取判断。而 RoundRobinRule 失效的策略是超过 10 次，RandomRule 没有失效时间的概念，只要 serverList 没都挂。\n BestAvailableRule：  最小连接数策略，遍历 serverList，选取出可⽤的且连接数最小的⼀个 server。那么会调用 RoundRobinRule 重新选取。\n AvailabilityFilteringRule：  可用过滤策略。扩展了轮询策略，会先通过默认的轮询选取⼀个 server，再去判断该 server 是否超时可用、当前连接数是否超限，都成功再返回。\n ZoneAvoidanceRule：  区域权衡策略。扩展了轮询策略，除了过滤超时和链接数过多的 server，还会过滤掉不符合要求的 zone 区域⾥⾯的所有节点，始终保证在⼀个区域/机房内的服务实例进行轮询。\n这里所有负载均衡策略名本质都是 com.netflix.loadbalancer 包下的类：\n修改微服务的负载均衡规则 直接修改配置文件application.yml添加\nprovider-service:#服务提供者的微服务idribbon:NFLoadBalancerRuleClassName:com.netflix.loadbalancer.RandomRule#设置对应的负载均衡类这里采用随机算法，用上面的示例测试一下：\n2021-04-14 01:20:04.122 INFO 82083 --- [nio-8090-exec-1] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service two! 2021-04-14 01:20:06.694 INFO 82083 --- [nio-8090-exec-2] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service one! 2021-04-14 01:20:09.022 INFO 82083 --- [nio-8090-exec-3] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service one! 2021-04-14 01:20:09.989 INFO 82083 --- [nio-8090-exec-4] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service three! 2021-04-14 01:20:20.379 INFO 82083 --- [nio-8090-exec-5] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service two! 果然是随机的！\n","date":"2021-07-22T01:38:45+08:00","image":"https://ccqstark.github.io/p/ribbon_startup/cover_hu23ccbb911fabf1d5535c01685f315954_288884_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/ribbon_startup/","title":"Ribbon负载均衡入门"},{"content":"docker单点部署 clone项目 git clone https://github.com/nacos-group/nacos-docker.git cd nacos-docker 修改配置文件 如果单机主机内存较小，可以修改配置文件example/standalone-derby.yaml 修改JVM运行内存\n在nacos的environment 那里添加- JVM_XMS=256m和 - JVM_XMX=256m\nversion: \u0026#34;2\u0026#34;services: nacos: image: nacos/nacos-server:latest container_name: nacos-standalone environment: - PREFER_HOST_MODE=hostname - MODE=standalone - JVM_XMS=256m - JVM_XMX=256m volumes: - ./standalone-logs/:/home/nacos/logs - ./init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - \u0026#34;8848:8848\u0026#34; prometheus: container_name: prometheus image: prom/prometheus:latest volumes: - ./prometheus/prometheus-standalone.yaml:/etc/prometheus/prometheus.yml ports: - \u0026#34;9090:9090\u0026#34; depends_on: - nacos restart: on-failure grafana: container_name: grafana image: grafana/grafana:latest ports: - 3000:3000 restart: on-failuredocker-compose启动容器 最后加个-d后台运行\ndocker-compose -f example/standalone-derby.yaml up -d 访问 地址：http://[ip地址]:8848/nacos/\n8848是nacos的默认端口号\nweb界面如下：\n普通部署 到github: https://github.com/alibaba/nacos/releases/ 去获取Nacos的压缩包\n# 解压tar -xvf nacos-server-1.4.0.tar.gz解压后 Nacos 目录结构如下。\n bin：保存启用/关闭 Nacos Server 脚本； conf：Nacos Server 配置目录； data：Nacos 数据目录； logs：存放日志目录； target：Nacos Jar 包存放目录；  # 进入bin目录cd bin# 修改虚拟机内存vim startup.sh# 单机启动sh startup.sh -m standaloneSpringboot工程准备 创建 因为是微服务项目，一般是多个springboot项目的多模块项目，所以先建立一个大的空Maven项目，以备之后使用，再在下面建立Module（对父项目根目录右键new→Module）\nSpring Initializr选中 Custom，写入阿里云地址http://start.aliyun.com\n建立一个springboot项目，名字为nacos-sample-service，依赖除了spring-web之后记得一定还要选一个nacos-discovery\n修改配置文件application.properties # 应用名称 spring.application.name=nacos-sample-service # 应用服务 WEB 访问端口 server.port=9000 # Nacos帮助文档: https://nacos.io/zh-cn/docs/concepts.html # 连接 Nacos 服务器使用的用户名、密码，默认为 nacos spring.cloud.nacos.discovery.username=nacos spring.cloud.nacos.discovery.password=nacos # Nacos 服务发现与注册配置，其中子属性 server-addr 指定 Nacos 服务器主机和端口 spring.cloud.nacos.discovery.server-addr=49.234.82.226:8848 # 注册到 nacos 的指定 namespace，默认为 public spring.cloud.nacos.discovery.namespace=public 启动项目 启动后看到日志：\n2021-04-13 23:42:46.933 INFO 75033 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 9000 (http) with context path \u0026#39;\u0026#39; 2021-04-13 23:42:47.577 INFO 75033 --- [ main] c.a.c.n.registry.NacosServiceRegistry : nacos registry, DEFAULT_GROUP nacos-sample-service 10.173.110.92:9000 register finished 2021-04-13 23:42:47.590 INFO 75033 --- [ main] c.c.n.NacosSampleServiceApplication : Started NacosSampleServiceApplication in 16.484 seconds (JVM running for 24.374) 且在web界面看到服务已经被注册就证明已经成功了\nNacos 注册中心的心跳机制 下图阐述了微服务与 Nacos 服务器之间的通信过程。在微服务启动后每过5秒，会由微服务内置的 Nacos 客户端主动向 Nacos 服务器发起心跳包（HeartBeat）。心跳包会包含当前服务实例的名称、IP、端口、集群名、权重等信息。\nnaming 模块在接收到心跳包后，会按下图逻辑处理心跳包并返回响应：\n naming 模块收到心跳包，首先根据 IP 与端口判断 Nacos 是否存在该服务实例？如果实例信息不存在，在 Nacos 中注册登记该实例。而注册的本质是将新实例对象存储在“实例 Map”集合中； 如果实例信息已存在，记录本次心跳包发送时间； 设置实例状态为“健康”； 推送“微服务状态变更”消息； naming 模块返回心跳包时间间隔。  到这里一次完整的心跳包处理已完成。\nNacos Server 每过 20 秒对“实例 Map”中的所有“非健康”实例进行扫描，如发现“非健康”实例，随即从“实例 Map”中将该实例删除。\n集群部署 配置数据库 用于同步各集群之间的数据，同步端口为7848，所以也记得要打开\n修改nacos/conf/application.properties\n### If use MySQL as datasource: spring.datasource.platform=mysql ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://xxxxxx:3306/nacos_config?characterEncoding=utf8\u0026amp;connectTimeout=1000\u0026amp;socketTimeout=3000\u0026amp;autoReconnect=true\u0026amp;useUnicode=true\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC db.user=root db.password=xxxxxx 配置集群ip列表 复制一份样例的集群ip节点列表\ncp cluster.conf.example cluster.conf vim cluster.conf 添加所有集群的ip，一行一条\n192.168.163.131:8848 192.168.163.132:8848 192.168.163.133:8848 启动集群 不用-m ，默认就是集群方式启动\n# 启动 sh startup.sh # 查看启动日志 tail -f ../logs/start.out 看到日志出现大概以下信息就说明启动成功\n2021-04-17 17:20:44,801 INFO Nacos is starting... 2021-04-17 17:20:44,957 INFO Nacos Log files: /home/nacos/nacos/logs 2021-04-17 17:20:44,958 INFO Nacos Log files: /home/nacos/nacos/conf 2021-04-17 17:20:44,958 INFO Nacos Log files: /home/nacos/nacos/data 2021-04-17 17:20:44,958 INFO Nacos started successfully in cluster mode. use external storage 内存不够记得改下jvm启动内存（修改startup.sh文件）\n最后打开Nacos管理界面的集群管理的节点列表：\n","date":"2021-07-22T01:30:53+08:00","image":"https://ccqstark.github.io/p/nacos_startup/cover_hu3dcfa387b55d54e5becd295f3f353ebe_40548_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/nacos_startup/","title":"Nacos服务注册与发现入门"},{"content":"主从复制搭建 拉取镜像 用docker，mysql5.7\ndocker pull mysql:5.7 启动 主节点\ndocker run -p 3306:3306 --name mysql_master -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 从节点\ndocker run -p 3306:3306 --name mysql——slave -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 Master配置 通过docker exec -it [容器名] bash 进入容器内部\n安装vim\napt-get update apt-get install vim 编辑配置文件my.cnf\ncd /etc/mysql vim my.cnf 添加以下内容\n[mysqld] ## 同一局域网内注意要唯一 server-id=100 ## 开启二进制日志功能，可以随便取（关键） log-bin=mysql-bin 完成后重启服务，重启服务后需要重启容器\nservice mysql restart docker start mysql_master 再次进入容器，创建用于同步数据的用户\nmysql -hlocalhost -uroot -p CREATE USER \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;; flush privileges; Slave配置 和Master一样要安装vim，然后在my.cnf中添加\n[mysqld] ## 设置server_id,注意要唯一 server-id=101 ## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用 log-bin=mysql-slave-bin ## relay_log配置中继日志 relay_log=edu-mysql-relay-bin 然后也要经过一样的重启过程\n链接Master和Slave 先在master里mysql中执行\nshow master status; 其中File字段和Position字段待会要用到，此时开始master不要再做任何操作，保证Position字段的值不再改变\n然后进入salve的mysql中执行\nchange master to master_host=\u0026#39;172.17.0.2\u0026#39;, master_user=\u0026#39;slave\u0026#39;, master_password=\u0026#39;123456\u0026#39;, master_port=3306, master_log_file=\u0026#39;mysql-bin.000001\u0026#39;, master_log_pos= 769, master_connect_retry=30;  master_host ：Master的ip地址 master_port：Master的端口号 master_user：用于数据同步的用户 master_password：用于同步的用户的密码 master_log_file：指定 Slave 从哪个日志文件开始复制数据，即上文中提到的 File 字段的值 master_log_pos：从哪个 Position 开始读，即上文中提到的 Position 字段的值 master_connect_retry：如果连接失败，重试的时间间隔，单位是秒，默认是60秒  最后每台slave都执行\nstart slave; 查询主从复制状态\nshow slave status \\G; 有2个yes就成功了\n原理解析 基本过程  master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中； slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件 同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志（relay log）中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后 I/O Thread 和 SQL Thread 将进入睡眠状态，等待下一次被唤醒。  要点  从库会生成两个线程，一个I/O线程，一个SQL线程； I/O线程会去请求主库的binlog，并将得到的binlog写到本地的relay-log(中继日志)文件中； 主库会生成一个log dump线程，用来给从库I/O线程传binlog； SQL线程，会读取relay log文件中的日志,并解析成sql语句逐一执行；  注意  master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）。 slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和master数据保持一致了。 MySQL复制至少需要两个Mysql的服务，当然MySQL服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。 MySQL复制最好确保master和slave服务器上的MySQL版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本） master和slave两节点间时间需同步  ","date":"2021-07-22T01:00:48+08:00","image":"https://ccqstark.github.io/p/mysql_master_slave_replic/cover_huff5578d477b5a7be0373e736738479ea_238860_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/mysql_master_slave_replic/","title":"MySQL主从复制搭建与原理"},{"content":"题目 给你一个链表的头节点 head 和一个整数 val ，请你删除链表中所有满足 Node.val == val 的节点，并返回 新的头节点 。\n \n示例 1: 输入: head = [1,2,6,3,4,5,6], val = 6 输出: [1,2,3,4,5] 示例 2: 输入: head = [], val = 1 输出: [] 示例 3: 输入: head = [7,7,7,7], val = 7 输出: [] 分析 很普通的一道链表移除元素题目。这里我们主要考虑两种方式：\n 直接在原链表上删除节点操作 增加一个虚拟节点（也叫哨兵节点）来操作  第二种方法主要是为了统一所有的删除节点操作，而不用在遇到要删除头节点情况时要单独写一段代码来处理。\n而对于普通节点，删除这个节点的操作一般是把自己的前驱节点的next指针指向自己的后驱节点，如图：\n  由于是单链表，我们不能获得一个被删节点的前驱节点，所以一般是判断一个节点的next的值是否为被删值。\n 对于C/C++，不能自动释放内存我们就要手动释放被删除的节点的内存，但Java会帮我们做好这一切。\n 代码 ListNode节点类的代码：\npublic class ListNode { int val; ListNode next; ListNode() {} ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } } 方法一：直接在原链表上操作 public ListNode removeElements1(ListNode head, int val) { ListNode ptr = head; while (ptr != null \u0026amp;\u0026amp; ptr.next != null) { if (ptr == head \u0026amp;\u0026amp; ptr.val == val) { // 删除头节点情况  head = head.next; ptr = head; } else if (ptr.next.val == val) { ptr.next = ptr.next.next; } else { ptr = ptr.next; } } // 处理只有一个节点的情况  if (head != null \u0026amp;\u0026amp; head.next == null \u0026amp;\u0026amp; head.val == val){ return null; } return head; } 这种方式对于要删除的点是头节点的情况就是把head节点往后移一位：\n \n方法二：虚拟头节点 public ListNode removeElements2(ListNode head, int val) { // 设置虚拟头节点 \tListNode virtualHead = new ListNode(0, head); ListNode ptr = virtualHead; while (ptr.next != null) { if (ptr.next.val == val) { ptr.next = ptr.next.next; } else { ptr = ptr.next; } } return virtualHead.next; } 下面是有了虚拟头节点之后删除头节点的操作，发现和其它的非头节点操作是可以统一的：\n \n复杂度分析  时间复杂度：O(N)，只遍历了一次。 空间复杂度：O(1)。  ","date":"2021-04-11T00:00:00+08:00","image":"https://ccqstark.github.io/p/remove_elements/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/remove_elements/","title":"[leetcode]203.移除链表元素"},{"content":"题目 给你一个正整数 n ，生成一个包含 1 到 n^2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵 matrix 。\n示例1: 输入:n = 3 输出:[[1,2,3],[8,9,4],[7,6,5]] 示例2: 输入: n = 1 输出: [[1]] 分析 第一次看到这道题感觉很懵很难，其实这道题也不涉及什么经典算法，就是考验你用代码复现这个过程道能力。\n我们可以把按照题目给的图的按顺序去填充矩阵中的值，从第一个位置开始先从左到右➡️ ，再从上到下⬇️ ，再从右到左⬅️ ，再从下到上⬆️ 。如此循环，直到填充完毕，当然如果n为奇数的话就要考虑中间那一格需要最后去单独填充，偶数的话就没有这个问题。\n当然每次循环还需要注意，每行/列都遵循的是左闭右开的原则，也就是说从头填到倒数第二个，最后一个就是下一行/列的，才能保证行/列填充行为的统一性。\n还有一点是每次循环之后，每行/列需要填充的个数就要少2，看下下面的图就可以很直观的理解了。\n下面就是n=5和n=4的例子：\n   \n代码 class Solution { public int[][] generateMatrix(int n) { // 矩阵本体  int[][] matrix = new int[n][n]; // 横行和纵向开始填充的起始点  int startx = 0, starty = 0; // 循环次数  int loop = n / 2; // n为奇数时矩阵的中间格  int mid = n / 2; // 用来填充的数字，从1开始  int count = 1; // 每列或每行在循环一次后，下一次循环时要填充的元素个数会减少2，用这个变量来记录当前减少的大小  int offset = 1; // 填充时用的指针，i为行，j为列  int i, j; while (loop-- != 0) { // 指针置于起始位置  i = startx; j = starty; // 上行，从左到右  for (j = starty; j \u0026lt; starty + n - offset; j++) { matrix[i][j] = count++; } // 右列，从上到下  for (i = startx; i \u0026lt; startx + n - offset; i++) { matrix[i][j] = count++; } // 下行，从右到左  for (; j \u0026gt; starty; j--) { matrix[i][j] = count++; } // 左列，从下到上  for (; i \u0026gt; startx; i--) { matrix[i][j] = count++; } // 循环一次后，下一次起始位置+1  startx++; starty++; // 下一次循环时，每行/列填充的个数要-2  offset += 2; } // n为奇数要填中间一格  if (n % 2 == 1) { matrix[mid][mid] = count; } return matrix; } } 复杂度分析  时间复杂度：O(n^2)，其中 nn 是给定的正整数。矩阵的大小是 n \\times nn×n，需要填入矩阵中的每个元素。 空间复杂度：O(1)。除了返回的矩阵以外，空间复杂度是常数。  ","date":"2021-04-07T21:07:00+08:00","image":"https://ccqstark.github.io/p/generate_matrix/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/generate_matrix/","title":"[leetcode]59.螺旋矩阵II"},{"content":"今天在看有关StringBuilder和StringBuffer的文章的时候看到里面提及了有关String中的final字段和不可变的性质，发现这个知识点不是很熟悉，去查了很多文章之后整理出这篇。\n新建字符串与缓冲池 新建一个String我们一般有下面2种方式：\nString a = \u0026#34;ok\u0026#34;; String b = new String(\u0026#34;ok\u0026#34;); 这两种写法都可以创建一个String对象。\n第一种用赋值运算符进行字符串初始化时，JVM自动为每个字符串生成一个String类的实例。\n第二种就是创建String类的对象，因为String本来就是一个类，而不是像int和double那样的基本数据类型。\nJava的字符串采用了缓冲池的技术，我们新建一个字符串的时候会去缓冲池寻找是否有已经存在的相同的字符串，如果有的话直接指向它即可；没有的话再创建，缓冲池是在堆里面的。\n如下图，是下面代码的结果：\n// one和two内容相同，指向同一String对象 String one = \u0026#34;someString\u0026#34;; String two = \u0026#34;someString\u0026#34;; 关于更深入的创建对象和之间的比较可以看下面这篇：\njava 字符串缓冲池 String缓冲池_天天的专栏-CSDN博客\n哪里不可变？ 那为什么说String不可变呢？我们明明可以通过给字符串变量赋一个新值来改变它的内容。\nString str = \u0026#34;aaaaaaa\u0026#34;; System.out.println(str); str = \u0026#34;bbbbbbbbb\u0026#34;; System.out.println(str); // 输出 //aaaaaaa //bbbbbbbbb 实际上，当我们给字符串重新赋值的时候，它并不是去改变这个String对象中的字符数组char[] value的值（下面会讲到），而是去缓冲池里寻找有没有已经存在这个值的String对象，有的话就直接指向它，没有的话创建一个对象再指向它。\n  str只是一个引用，指向的String对象是在堆中的。改变字符串的值其实只是改变整个对象的引用。\n而原来的String对象还是在那里没有被改变，之后要是有别的变量赋这个值可以继续指向它。\n为什么不可变？ 我们看下String的部分源码：\npublic final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 } 重点在这个字符数组value就是存放字符串内容的地方，注意它是被final 修饰的，也就是一旦初始化之后它的值就不能改变。\n不过它value也只是个引用，引用不可变，但是如果真的想改是可以改变数组中元素但值的，但由于String中没有setValue方法，我们要改的话就要通过反射了。\n利用反射改变 下面这段代码就利用了反射改变了value数组中的元素的值，但是数组的地址是没有改变的哦。\nString s=\u0026#34;123\u0026#34;; Field valueArray=String.class.getDeclaredField(\u0026#34;value\u0026#34;); valueArray.setAccessible(true); char[] array=(char[]) valueArray.get(s); array[0]=\u0026#39;2\u0026#39;; System.out.println(s);//223 设计成不可变的原因？ 代码安全 String类本身也是final 的，这样设计使得String不可被继承，不可扩展与重写方法，主要是为了安全。因为String作为一个比较底层的类使用得也比较频繁，而且很多实现是通过系统调用的，如果让开发者可以随意修改一些东西就很可能带来问题甚至注入病毒。\n为了实现字符串缓冲池 只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那改变一个字符串的值就会导致其它指向这个String对象的字符串引用对应的值也会改变。\n作为HashMap的键 因为字符串是不可变的，所以在它创建的时候HashCode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。\n线程安全 因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。字符串自己便是线程安全的。\n参考文章 Java String类为什么是final的？\n如何理解 String 类型值的不可变？\n","date":"2021-04-06T21:07:00+08:00","image":"https://ccqstark.github.io/p/string/java_hu4a52e4833b2d51fc82bb34a9877f5e42_192896_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/string/","title":"一次理解String的不可变性"},{"content":"题目 给定一个含有 n 个正整数的数组和一个正整数 target 。\n找出该数组中满足其和 ≥ target 的长度最小的 连续子数组 [numsl, numsl+1, \u0026hellip;, numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。\n示例 1: 输入: target = 7, nums = [2,3,1,2,4,3] 输出: 2 解释: 子数组 [4,3] 是该条件下的长度最小的子数组. 示例 2: 输入: target = 4, nums = [1,4,4] 输出: 1 示例 3: 输入: target = 11, nums = [1,1,1,1,1,1,1,1] 输出: 0 提示：\n 1 \u0026lt;= target \u0026lt;= 109 1 \u0026lt;= nums.length \u0026lt;= 105 1 \u0026lt;= nums[i] \u0026lt;= 105  分析 这道题一开始想到的是暴力解法，也就是把每种可能的子数组长度都试一遍，后来发现这是道典型的滑动窗口题目，用滑动窗口就解决了。之后看官方题解有前缀+二分搜索的方法作为扩展。\n代码 滑动窗口 public int minSubArrayLen(int target, int[] nums) { if (nums.length == 0) { return 0; } int left = 0, right = 0; int s = nums[0]; int windowLen = Integer.MAX_VALUE; while (right \u0026lt; nums.length - 1) { // 右指针移动  while (s \u0026lt; target \u0026amp;\u0026amp; right \u0026lt; nums.length - 1) { right++; s += nums[right]; } // 左指针移动  while (s \u0026gt;= target) { windowLen = Math.min(windowLen, right - left + 1); s -= nums[left]; left++; } } return windowLen == Integer.MAX_VALUE ? 0 : windowLen; } 方法很简单，就是一个左指针，一个右指针，窗口的范围就是2个指针之间的元素。\n一开始先移动右指针直到窗口内和大于等于target\n然后向右开始移动左指针，直到窗口内和小于target，由于每次就是一次满足s≥target的窗口，我们就要每次和当前的窗口长度进行比较从而找到最小的窗口长度，也就是最小的子数组长度。\n如果窗口长度为最大的int值说明没有找到任何一个满足s≥target的窗口，返回0。\n复杂度分析 时间复杂度：O(n)，其中 n 是数组的长度。指针最多各移动n次。\n空间复杂度：O(1)。\n前缀+二分搜索 public int minSubArrayLen(int target, int[] nums) { int n = nums.length; if (n == 0) { return 0; } int windowLen = Integer.MAX_VALUE; int[] sums = new int[n + 1]; // 前i个数之和  for (int i = 1; i \u0026lt;= n; i++) { sums[i] = sums[i - 1] + nums[i - 1]; } for (int i = 0; i \u0026lt; n; i++) { int s = target + sums[i]; // 二分搜索  int bound = Arrays.binarySearch(sums, s); // bound为负数表示找不到，返回的是插入位置，且从1开始  if (bound \u0026lt; 0) { bound = -bound - 1; } // 找到最小的  if (bound \u0026lt;= n) { windowLen = Math.min(windowLen, bound - i); } } return windowLen == Integer.MAX_VALUE ? 0 : windowLen; } 这个方法我们先计算出nums中不同长度的前i个数之和的数组sums，也就是sums[i]表示nums[0]到nums[i-1]中的所有数之和。\n然后我们用二分查找在sums数组中找到下标bound，使得sums[bound]-sums[i]\u0026gt;=target，且这个bound是所能找到的最小的。（由于nums都是正整数，sums一定是递增的，所以可以用二分搜索）\n最终bound-i就是我们要找的最小的窗口长度。\n  这里的二分搜索如果找不到的话要返回插入的位置，Java有个Arrays.binarySearch()工具类可以使用，返回值为：\n 如果找到关键字，则返回值为关键字在数组中的位置索引，且索引从0开始 如果没有找到关键字，返回值为负的插入点值，所谓插入点值就是第一个比关键字大的元素在数组中的位置索引，而且这个位置索引从1开始。  贴个这个工具类的源码：\nprivate static int binarySearch0(long[] a, int fromIndex, int toIndex, long key) { int low = fromIndex; int high = toIndex - 1; while (low \u0026lt;= high) { int mid = (low + high) \u0026gt;\u0026gt;\u0026gt; 1; long midVal = a[mid]; if (midVal \u0026lt; key) low = mid + 1; else if (midVal \u0026gt; key) high = mid - 1; else return mid; // key found  } return -(low + 1); // key not found. } 复杂度分析  时间复杂度：O(nlogn)，其中n是数组的长度。需要遍历每个下标作为子数组的开始下标，遍历的时间复杂度是 O(n)，对于每个开始下标，需要通过二分查找得到长度最小的子数组，二分查找得时间复杂度是 O(logn)，因此总时间复杂度是 O(nlogn)。 空间复杂度：O(n)，其中 n 是数组的长度。额外创建数组 sums 存储前缀和。  ","date":"2021-04-04T21:07:00+08:00","image":"https://ccqstark.github.io/p/min_sub_array_len/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/min_sub_array_len/","title":"[leetcode]209.长度最小的子数组"},{"content":"题目 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\n分析 对于数组而言，我们原地移除元素的话就肯定要把被移除的元素后面的全部元素都往前挪一个位，这是最基本的操作。所以最普通的暴力解法就是删除一个，整体挪动一个位。优化一点的话就是当有几个需要删除的数连在一起时，我们找到边界后一起挪动n个位，减少整体挪动的次数。\n最优的是经常被用到的双指针法，下面再解释。\n代码 混合暴力法 public int removeElement(int[] nums, int val) { int len = nums.length; for (int left = 0; left \u0026lt; len; left++) { if (nums[left] == val) { // left位于最后一个元素时  if (left == len - 1) { return len - 1; } int right = left + 1; while (right \u0026lt;= len - 1 \u0026amp;\u0026amp; nums[right] == val) right++; if (right == len - 1 \u0026amp;\u0026amp; nums[right] == val) { // right超过长度时  return len - (right - left); } // 把元素right处整体前移到left  moveUp(left, right, nums, len); len = len - (right - left); } } return len; } // 该函数用于将right及后面的元素完前移到left位置 public void moveUp(int left, int right, int[] nums, int len) { int step = len - 1 - right; for (int i = 0; i \u0026lt;= step; i++) { nums[left + i] = nums[right + i]; } }   此方法其实是初步优化的暴力法，假设我们要移除值为2的元素，left指针找到第一被删除的元素，right指向left后第一个不等于2的元素，然后把从right开始的后面全部元素都往前挪至left位置。\n这种方法在被删除元素都是在连续位置时可以很好提高速度。但是会有一些边界条件需要考虑，在上面代码中用注释强调了。\n双指针法 public int removeElement(int[] nums, int val) { int slowIndex = 0; for (int fastIndex = 0; fastIndex \u0026lt; nums.length; fastIndex++) { if (nums[fastIndex] != val) { nums[slowIndex++] = nums[fastIndex]; } } return slowIndex; } 双指针法用一个快指针和一个慢指针，都是从0开始。\n当快指针遇到要被删除的元素时，让慢指针不动，自己继续往后走，直到遇到一个非被删元素。\n然后就把快指针所处位置的值覆盖慢指针所处位置的值，然后两个指针一起向后走。\n最终慢指针的位置就是去掉所有要删除的元素的数组的末端，当快指针移到原数组最后一个元素时结束整个流程。\n其实慢指针就是用来一点点构建最终数据的指针，快指针就是用来找那些存在于最终数组中的元素，慢指针停留在要被删除的元素的位置时，就把快指针位置的元素搬过去覆盖，本质就是把最终会存在于数组中的（没有被删的）元素移到一起连成数组。\n复杂度分析  时间复杂度：O(n)，假设数组总共有 n 个元素，i 和 j 至少遍历 2n 步。 空间复杂度：O(1)。  ","date":"2021-04-02T21:07:00+08:00","image":"https://ccqstark.github.io/p/remove_element/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/remove_element/","title":"[leetcode]27.移除元素"},{"content":"题目 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\n你可以假设数组中无重复元素。\n示例 1: 输入: [1,3,5,6], 5 输出: 2 示例 2: 输入: [1,3,5,6], 2 输出: 1 示例 3: 输入: [1,3,5,6], 7 输出: 4 示例 4: 输入: [1,3,5,6], 0 输出: 0 分析 这道题就是找到数组中的数，遍历就不说了， 我们首先想到的比较好的解法当然是二分搜索\n需要注意的是当目标值不存在于数组中时，我们要如何去定位合适的插入点？先上代码再分析。\n代码 public int searchInsert(int[] nums, int target) { return binSearch(0,nums.length-1,target,nums); } public int binSearch(int left, int right, int x, int[] nums) { if (left \u0026gt; right) return left; int mid = (left + right) / 2; if (x \u0026lt; nums[mid]) return binSearch(left, mid - 1, x, nums); if (x \u0026gt; nums[mid]) return binSearch(mid + 1, right, x, nums); if (x == nums[mid]) return mid; return -1; } 这里是采用传统的递归来写二分，但其实这里可以不用，直接一个while循环就行\npublic int searchInsert(int[] nums, int target) { int left = 0; int right = nums.length - 1; while (left \u0026lt;= right) { // 防止溢出  int mid = left + ((right - left) \u0026gt;\u0026gt; 1); if (target == nums[mid]) { return mid; } else if (target \u0026lt; nums[mid]) { right = mid - 1; } else if (target \u0026gt; nums[mid]) { left = mid + 1; } } return left; } 二分搜索在目标值大于或小于mid位置的值时要如何改变left和right 就不说了，关键是为什么最后我们把left 作为插入位置呢？\n我们可以拿奇数个或偶数个元素的数组试一下，发现如果目标值不在数组中，那么它们最后都会面临这样一种情况：left和right相邻，而目标值就介于两者之间。\n举个例子，数组[0,2,4,5,6]，目标值3，如下图：\n  而下一个状态也是肯定的，因为此时mid和left相等，target\u0026gt;nums[mid]，则left = mid + 1 ，呈现下面的状态：left和right重叠，且在目标值的大一位\n  再下一个状态同样是一定的，mid此时就是left和right的位置，则target\u0026lt;nums[mid]，即right = mid - 1 ，right左移一位，达到while循环结束条件left\u0026gt;right\n  那很明显的，目标插入的位置就一定是最后这里left的位置。不管数组元素是奇数个还是偶数个，最终就会是这个情形，所以最后我们选择left 作为插入不存在目标值的位置。当然也可以提前一步，当left == right 时那个位置也是一样的，leetcode官方就是这么选择的。\n复杂度分析  时间复杂度：O(log n)，其中 n 为数组的长度。二分查找所需的时间复杂度为 O(log n)。 空间复杂度：O(1)。我们只需要常数空间存放若干变量。  这道题主要考察二分搜索，难点在于插入位置的选择。\n","date":"2021-04-01T21:07:00+08:00","image":"https://ccqstark.github.io/p/search_insert/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/search_insert/","title":"[leetcode]35.搜索插入位置"},{"content":"题目 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n你可以按任意顺序返回答案。\n示例 1: 输入: nums = [2,7,11,15], target = 9 输出: [0,1] 解释: 因为 nums[0] + nums[1] == 9, 返回 [0, 1]. 示例 2: 输入: nums = [3,2,4], target = 6 输出: [1,2] 示例 3: 输入: nums = [3,3], target = 6 输出: [0,1] 提示：\n 2 \u0026lt;= nums.length \u0026lt;= 103 -109 \u0026lt;= nums[i] \u0026lt;= 109 -109 \u0026lt;= target \u0026lt;= 109 只会存在一个有效答案  分析 这道题比较容易，就是在数组中找到数值x和target-x\n直接上代码\n代码 方法一：暴力枚举 public int[] twoSum(int[] nums, int target) { for (int i = 0; i \u0026lt; nums.length - 1; i++) { for (int j = i + 1; j \u0026lt; nums.length; j++) { if (nums[i] + nums[j] == target) { return new int[]{i, j}; } } } return null; } 这里我们只需关注一个点就是j = i + 1 ，我们是选中其中一个数作为x，再去找target-x的，所谓为了避免重复组合，我们从x的下一个开始找，保证每个组合只试一遍，同时避免了x和找自己。\n复杂度分析  时间复杂度：O(N^2)，其中N是数组中的元素数量。最坏情况下数组中任意两个数都要被匹配一次。 空间复杂度：O(1)。  方法二：哈希表 public int[] twoSum(int[] nums, int target) { Map\u0026lt;Integer, Integer\u0026gt; hashtable = new HashMap\u0026lt;Integer, Integer\u0026gt;(); for (int i = 0; i \u0026lt; nums.length; ++i) { if (hashtable.containsKey(target - nums[i])) { return new int[] { hashtable.get(target - nums[i]), i } ; } hashtable.put(nums[i], i); } return new int[0]; } 利用哈希表我们可以提高找target-x的速度，从头到尾拿出一个数x，查看target-x是否存在于哈希表中，如果不存在就把自己也加入哈希表（x作为key，下标作为value）。这样就可以快速找到我们要的组合。\n复杂度分析  时间复杂度：O(N)，其中N是数组中的元素数量。对于每一个元素 x，我们可以 O(1)地寻找target - x。 空间复杂度：O(N)，其中 N 是数组中的元素数量。主要为哈希表的开销。  ","date":"2021-03-31T21:07:00+08:00","image":"https://ccqstark.github.io/p/two_sum/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/two_sum/","title":"[leetcode]1.两数之和"},{"content":"项目中用到了之前说的日志门面slf4j+log4j，但是之后遇到了一些问题。比如程序报错没有记录在日志，记录的时间也和服务器的不一致（服务器是东八区时间），或者记录一些不需要的信息，此篇就来解决这些问题。\nslf4j与log4j 之前有一篇文章介绍了slf4j怎么整合进Springboot，slf4j是一个日志门面，和我们所用的logback、log4j这些日志框架不同，它是为这些日志框架统一调用的API，通过api来调用具体的日志实现，简化了日志的配置与使用。slf4j要与具体的日志框架搭配，我用的是log4j。\n\u0026lt;!-- SLF4j - log4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8.0-alpha2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 使用时只要用注解@Slf4j ，然后直接用log.info() 方法就可以记录日志了。\n日志等级 日志分为以下几个等级：\nOFF：最高等级的，用于关闭所有日志记录。\nFATAL：会导致应用程序推出的严重错误。\nERROR：虽然发生错误事件，但仍然不影响系统的继续运行，一般也是程序的各种Exception，但要注意的是并不是所有异常都会导致Error，这就是下面的要说的异常捕获。打印错误和异常信息，如果不想输出太多的日志，可以使用这个级别。\nWARN：警告，表明会出现潜在错误的情形，有些信息不是错误信息，只是一些提示。\nINFO：消息在粗粒度级别上突出强调应用程序的运行过程。打印一些你感兴趣的或者重要的信息，这个可以用于生产环境中输出程序运行的一些重要信息，但是不能滥用，避免打印过多的日志。\nDEBUG：主要用于开发过程中打印一些运行信息。但是打印但信息量过多，项目上线后不要用。\nTRACE：跟踪日志，日志消息的粒度太细，很低的日志级别，一般不会使用。\nALL：最低等级的，用于打开所有日志记录。\n通过修改日志配置文件log4j.properties来改变日志等级：\nlog4j.rootLogger = ERROR,stdout,log //第一个参数是日志等级 错误捕获 在SpringBoot我们希望有统一的操作来捕获系统运行过程中参数的所有错误，对未预测到对错误设置友好的返回值给用户，避免返回500状态码。甚至可以将系统产生的报错通过邮件发送给开发者，让生产环境中的错误能得到快速直接的监测和解决。\n我们用到@RestControllerAdvice和@ExceptionHandler 这两个注解\n@Slf4j @RestControllerAdvice // 用于拦截异常的注解 public class ExceptionProcesser extends ResponseEntityExceptionHandler { @Autowired private MailService mailService; /** * 全局异常捕获入日志 */ // 此注解用来标示处理哪个类的异常 \t@ExceptionHandler(value = Exception.class) // 表示所有的异常都会处理 \tpublic CommonResult\u0026lt;String\u0026gt; defaultErrorHandler(Exception e) { // slf4j下的日志用法，简洁易用 \tlog.error(\u0026#34;defaultErrorHandler:\u0026#34;, e); // 将报错栈的信息转为字符串 \tStringWriter errors = new StringWriter(); e.printStackTrace(new PrintWriter(errors)); // 发送邮件给开发者 \tmailService.sendSimpleMail(\u0026#34;xxxxx@qq.com\u0026#34;, \u0026#34;项目报错\u0026#34;, errors.toString()); return CommonResult.failed(\u0026#34;这里可能有bug，报错信息发给ccq了，找他改bug去\u0026#34;); } /** * 对一些无法try/catch的具体错误还可以专门处理 */ @ExceptionHandler(MultipartException.class) // 表示只处理MultipartException这个类相关的异常  public CommonResult\u0026lt;String\u0026gt; handleUploadFileTooLargeError() { return CommonResult.failed(ResultCode.FILE_TOO_BIG); } } 日志时差 应用部署到线上的时候可能会遇到日志的记录时间和我们的东八区时间有时差，那就是经典时区问题了，可以通过启动jar包时设置参数来解决\njava -jar -Duser.timezone=GMT+08 xxx.jar ","date":"2021-03-18T23:01:00+08:00","permalink":"https://ccqstark.github.io/p/log_catch_error/","title":"[SpringBoot]日志与异常捕获"},{"content":"简介 引入 对于搜索功能，大家以前都是怎么做的呢？我相信很多人一开始也是用SQL的LIKE关键字加上%来匹配关键字的吧，为了实现更好的模糊效果就再加一个分词器来拆分关键词。但是，一旦被搜索的数据量一大，这种方式就显得效率低下。为了实现更好的效果，我们可以使用当前最流行的分布式搜索引擎——ElasticSearch 。\n基本介绍 Elasticsearch 是一个分布式的免费开源搜索和分析引擎，适用于包括文本、数字、地理空间、结构化和非结构化数据等在内的所有类型的数据，基于著名的Lucene库进行开发，并以简单的RESTful风格的API进行调用，支持Java、JavaScript(Node)、Go、 C#(.NET)、PHP、Python、Ruby等多种语言。ElasticSearch已经成为非常流行的搜索引擎，一些著名厂商例如京东、滴滴、携程、Stack Overflow、GitHub等都在使用。\n官网地址：https://www.elastic.co/cn/elasticsearch/\n \n应用场景  应用程序搜索 网站搜索 企业搜索 日志处理和分析 基础设施指标和容器监测 应用程序性能监测 地理空间数据分析和可视化 安全分析 业务分析  ELK ELK，即ElasticSearch + logstash + Kibana ，是一套开源的日志收集与分析解决方案。利用ElasticSearch对数据进行快速的复杂条件检索，用logstash则作为数据管道从多个来源进行数据的采集、转换和传输，Kibana则通过生成多种可视化报表方便用户进行日志监控。\n一般小型系统我们分析日志可以直接在用grep、awk等命令进行过滤与检索，或者拉到本地用LogViewer等专门的日志工具打开查看。但是当系统体量一大，采用的是分布式架构，集群中的日志管理就成为一个难题。ELK目的就是为了解决大型系统中的日志收集、存储与分析问题，方便将节点中的日志统一管理从而提高效率。\n \n概念介绍 基本概念 ElasticSearch（简称es）搜索的时候不是去数据库里拿数据，它有自己的一套存储与索引体系。数据库中的数据需要同步到es中，通过索引的形式来存储数据才能实现高效检索。\nes索引体系的基本概念和关系型数据库中的有些类似，我们可以对比着来看\n   Index 索引 Database 数据库     Type 文档类型 Table 表   Document 文档 Row 记录   Field 字段 Column 属性   Mapping 映射 Schema 模型   Query DSL SQL    es的层次组织结构类似于MySQL这样的关系型数据库，index就像database那样存储着不同的type，也就是数据库中的table；再下一级就是document，类似于数据库中的一条条记录；每条记录的字段field就对应表中的column；mapping就如schema那样表示着库表的架构；es中的查询语言Query DSL则对标我们熟悉的SQL。通过类比可以更快地认识es的结构组成。\n⚠️ 注意：从6.x开始es慢慢放弃type，并统一默认type为_doc，预计在8.x正式将其移除。\n其它概念   Node 节点\n实际项目中我们往往不会只用一台服务器来部署elasticsearch，那样的话能够承载的用户数就非常少。因为es是一个分布式的搜索引擎，那我们完全可以部署一个es集群，而其中的一个服务器实例就叫做node(节点)。\n  Cluster 集群\n一个cluster是有多个node组成的，es集群可以扩大单个节点的数据存储量以及承载的搜索请求。在其中一个节点挂掉的情况下不影响其他节点的正常工作。es集群也可以设置或选举master node来负责创建索引、删除索引、分配分片、追踪集群中的节点状态等，当然也可能存在脑裂问题。其它普通节点称为data node，用来接受用户的搜索请求返回搜索结果。\n  Shard 分片\n上面说到集群可以扩大单机存储空间过小的问题，而其中实现的原理就是通过分片。es通过对数据进行水平拆分成多个部分，然后分发到多台物理机上，这个过程叫做索引分片(Sharding)，每个部分就是一个分片(Shard)。创建索引时可以指定分片数量，一旦指定就不可更改。sharding的过程是es自动完成的，数据被写入时会被指定写入的分片。es的分片是Lucene实现的。\n  Replica 索引副本\n索引副本就是对分片进行的拷贝。在某一分片请求负载导致阻塞时，replica同样可以处理用户的请求。而且不仅可以提高流量承载能力，同时数据也有了一份备份，即使主分片数据丢掉也可以用副本恢复。\n  安装与基本使用 容器部署 云原生时代推荐使用容器，这里以docker单机部署为例简单讲下。\n# 拉取镜像，这里是7.10.1，注意es版本间兼容性较差 docker pull elasticsearch:7.10.1 # 启动容器，配置文件和数据挂载出来 docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \\ -e ES_JAVA_OPTS=\u0026#34;-Xms256m -Xmx256m\u0026#34; -d \\ -v [主机挂载目录]/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ -v [主机挂载目录]/data:/usr/share/elasticsearch/data elasticsearch:7.10.1 es容器是比较占内存的，毕竟一开就是一个JVM，单节点内存较小可以通过设置ES_JAVA_OPTS 来调小JVM的内存占用，例如上面例子中都参数就是设置为256M。\n其他可能出现的问题以及更多相关组件安装如Kibana或ik分词器可以参看我的另一篇博客，这里不再赘述。\n[Elastic]使用docker安装ElasticSearch + Kibana\nRESTful风格操作 es使用RESTful风格的API进行CRUD，存储与传输使用的数据形式也是使用常见的JSON，常用的method和对应的功能如下：\n  其中查询支持多种类型的复杂查询，如match解析查询、排序查询、分页查询、bool查询、fileter查询、多关键字查询、term精确查询、高亮查询等等。详细可以查看我博客的另一篇文章。\n[ElasticSearch]REST风格操作\n客户端 es提供了多种语言的client，各种API文档都在官网可以找到。对于Java推荐使用Java High Level REST Client，与SpringBoot的整合可以看我另一篇博客。\n[SpringBoot]整合ElasticSearch\n官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html\nMySQL的LIKE探究 索引使用 我们习惯用LIKE进行模糊查询，但是当数据量很大时耗时就会比较久，也许你会想到用索引来实现优化，但是模糊查询使用索引是要满足一定条件的。\n 单%模糊，且查询字段加了索引 使用双%进行全模糊查询，且把主键作为结果集，因为覆盖索引所以查询会走索引 使用全文索引  为了探究在大量数据情况下LIKE+%方案的效果，下面用个例子来实践一下。\n数据准备 建一张简单的表供查询，引擎是InnoDB\nCREATE TABLE `test_like` ( `id` int(11) UNSIGNED NOT NULL AUTO_INCREMENT, `name` varchar(20) NOT NULL DEFAULT \u0026#39;\u0026#39;, `student_number` varchar(11) NOT NULL DEFAULT \u0026#39;\u0026#39;, PRIMARY KEY (`id`) ); 准备多点数据，这里我准备了10万条。\n注意这里一次性插入太多数据可能会出现PacketTooBigException，可以分批插入或者设置max_allowed_packet\n\u0026lt;insert id=\u0026#34;insertLikeTestData\u0026#34;\u0026gt; insert into test_like (`name`,`student_number`) VALUES \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (\u0026#39;ccq\u0026#39;,\u0026#39;50377880000\u0026#39;+#{item}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; 然后给我们用来查询的student_number加个索引\nALTER TABLE `test_like` ADD INDEX `idx_student_number`(`student_number`) USING BTREE; 查看执行计划 首先我们执行select * 的全模糊查询\nexplain select * from test_like where student_number like \u0026#39;%503%\u0026#39;\\G 发现并没有使用索引并进行了全表扫描\nid: 1 select_type: SIMPLE table: test_like partitions: NULL type: ALL possible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 100076 filtered: 11.11 Extra: Using where 1 row in set, 1 warning (0.00 sec) 然后我们执行select id 的单%查询，也就是将主键作为结果集\nexplain select id from test_like where student_number like \u0026#39;503%\u0026#39;\\G 发现的确使用了索引进行了优化，扫描行数只有一半\nid: 1 select_type: SIMPLE table: test_like partitions: NULL type: range possible_keys: idx_student_number key: idx_student_number key_len: 46 ref: NULL rows: 50038 filtered: 100.00 Extra: Using where; Using index 1 row in set, 1 warning (0.00 sec) 最后我们select id 的双%查询\nexplain select id from test_like where student_number like \u0026#39;%503%\u0026#39;\\G 这个时候我们发现确实使用我们创建的idx_student_number ，但是possible_keys居然是NULL\n而且还发现，使用索引与不使用索引，扫描行数都是一样的，而且都是全表扫描\nid: 1 select_type: SIMPLE table: test_like partitions: NULL type: index possible_keys: NULL key: idx_student_number key_len: 46 ref: NULL rows: 100076 filtered: 11.11 Extra: Using where; Using index 1 row in set, 1 warning (0.00 sec) 使用Trace查看优化器 我们跟踪一下MySQL的优化器是怎么做选择的\n-- 开启优化器跟踪 set session optimizer_trace=\u0026#39;enabled=on\u0026#39;; select * from test_like where student_number like \u0026#39;%503%\u0026#39;; -- 查看优化器追踪内容 select * from information_schema.optimizer_trace; 找到查询路径的选择\n\u0026#34;best_access_path\u0026#34;: { \u0026#34;considered_access_paths\u0026#34;: [ { \u0026#34;rows_to_scan\u0026#34;: 100076, \u0026#34;access_type\u0026#34;: \u0026#34;scan\u0026#34;, \u0026#34;resulting_rows\u0026#34;: 100076, \u0026#34;cost\u0026#34;: 20304, \u0026#34;chosen\u0026#34;: true } ] } 然后对选择主键的双%查询也进行同样的跟踪，发现两者同样都是用了顺序扫描，而没有用上B+Tree来优化。\n结论 从上面我们也可以看到，没有做其它的优化而只用索引来使用MySQL的LIKE进行全模糊查询，在数据量大的时候，性能还是不尽人意的，这也说明了使用ES的必要性。\n索引原理 这一部分我们来说说ES的一些原理，看看为什么ES在查询上能更胜MySQL一筹。\n倒排索引 es是通过Lucene的倒排索引Inverted Index技术来实现比普通关系型数据库更快的查询的，特别对多条件的复杂查询，这一点能更好地体现。\n那什么是倒排索引呢？引用维基上的定义：\n倒排索引是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。\n有两种不同的反向索引形式：\n 一条记录的水平反向索引（或者反向档案索引）包含每个引用单词的文档的列表。 一个单词的水平反向索引（或者完全反向索引）又包含每个单词在一个文档中的位置。  其实很好理解，就是把我们以前设计表的那种把文章对应里面有哪些单词的结构，倒过来，变成一个单词与被包含在哪些文章中的对应关系，当我们搜索一个单词的时候就能快速得到包含这个单词的文章列表来。\n举个例子：\n比方说下面这张表\n  对direct字段利用倒排索引，变成：\n  那只要我们想查frontend对应有哪些人，就可以直接获得他们的id列表[21,16,54]，如果想查boss有哪些人，就可以得到[67,98]。这样就可以很快检索到我们想要到结果，而不用进行全表的搜索。\n对于上面的倒排表，我们把其中每一项称为Term，被索引的那一列也就是实例的direct字段为Term Dictionary ，对应被检索出来的id_list字段为Posting List。\n被检索的direct如果按顺序排列的话就可以用二分搜索快速找出，或者也可以在其上再加一层BTree来索引，提高关键词本身的搜索速度。\nTerm Index 当数据量很大的时候，Term Dictionary也会变得很大，无法完全放入内存（es本身运行已经占用非常大的内存了），这个时候我们再加一层索引叫Term Index。\nes使用 Burst-Trie 结构来实现，它是字典树（前缀树）Trie 的一种变种，它主要是将后缀进行了压缩，降低了Trie的高度，从而获取更好查询性能。\n  可以看到这棵树的根节点为空，接下来每一层是单词的从头到位的顺序的字母，某一节点的子节点连接所有单词中可能出现的下一个字母，根据下一个字母的可能的情况来分叉，同时多余的后缀也被省略。查询时可以先将Term Index缓存到内存中，据此找到我们要的Term Dictionary再去读磁盘，可以减少磁盘I/O次数。\n联合查询合并 当我们用es进行联合查询时，比如查找方向为backend且年份等于2019的人，我们只需要对direct和year字段分别用倒排索引查找出结果集，最后对结果集进行合并就行了。\n在关系型数据库中我们一般会用join来合并两表，这里再次鞭尸一下MySQL，它的join实现性能也很差。比如下面这样的SQL：\nselect * from t2 straight_join t1 on (t2.a=t1.a); straight_join 保证优化器不改变驱动表，用Index Nested-Loop Join 算法执行流程如下：\n 从 t2 表中读取一行数据 L2 使用L2的 a 字段，去 t1 表中作为条件进行查询 取出 t1 中满足条件的行， 跟 L2组成相应的行，成为结果集的一部分 重复执行，直到扫描完 t2 表  所以阿里开发者规范禁止三张表以上的 join 操作，是有原因滴。\n而Elasticsearch使用跳表Skip List和位图Bitset来合并结果集，下面介绍一下这两种方法。\nSkip List合并策略 说到跳表，我们首先讲一下普通的链表，如下图：\n  图中的链表除了首位节点之外，其它节点都有一个指针指向下一个节点，但是由于不是顺序存储，我们无法从其中任意一个节点推算出其它任意一个节点的位置（除非是它指向的下一节点）。因此用这个数据结构来寻找某一节点效率偏低。\n然后说跳表Skip List，实际上是在链表的基础上多加了几层索引，使得查询效率加快，如图：\n  我们在原来的链表上多加了三层，而上面的每一层各节点之间的距离都在逐级递增，也就是说每次跨到本层的下一个节点，中间跳跃的相对与底层的节点数越来越多，所以叫跳表。利用这种数据结构的特性，我们在遍历原链表的时候就可以利用上面的索引来每次多跳几个节点，从而加快速度。\nES利用Skip List进行合并结果集的时候就是从上往下，找到节点值大于等于目标值的最小节点，如果还是大于目标值，那就往下一层，相当于增加查找精度。例如我现在要找的目标值为2，从最上一层开始找，这层是0—\u0026gt;6，6明显大于2了，到下一层；这一层是0—\u0026gt;4—\u0026gt;6，找到4还是大于2，那继续下一层；这时是0—\u0026gt;2—\u0026gt;4—\u0026gt;6，我们就可以找到目标值2了。\n利用跳表，ES在找两个结果集的交集的时候就会快很多。\nRoaring Bitset合并策略 除了用Skip List来加快合并之外，ES还会把不同条件查询的结果集Posting List放到内存中缓存。如果直接用普通的数据结构，比如数组这样的，就其实很消耗空间；如果用Bitset，可能会有过于稀疏而导致的空间浪费。所以ES采用压缩效率更高的Roaring Bitmap来存储。\n 这里插播一道面试题：给定含有40亿个不重复的位于[0, 2^32 - 1]区间内的整数的集合，如何快速判定某个数是否在该集合内？\n  如果我们要使用 unsigned long 数组来存储它的话，也就需要消耗 40亿 * 32 位 =160亿Byte，大约是 16000 MB。 如果使用位图 Bitset 来存储的话，即某个数如果存在的话，就将它对应的位图内的比特置为1，否则保持为0。这样多少个树就只需要消耗多少bit来存，这里是 2 ^ 32 位 = 512 MB，这可只有原来的 3.2 % 左右。\n Roaring Bitmap又是如何来解决稀疏的问题的呢？直接上图：\n  如图中所示，我们把待存数除以65535，并根据所得商和余数分组。然后把相同商的组分到同一个存储单元，这个存储单元称为container，最后只需要存各container中的余数即可。\n所以RoaringBitmap其实就是很多container的集合，如果是一个32位unsigned long的话，那最多就有2^32 / 65535 = 65535个container。\n对于其中的余数的存储（低16位），则是以下的存储规则：\n 余数小于 2 ^ 12 次方（4096）时，使用unsigned short类型的有序数组来存储，最大消耗空间为 8 KB。 余数大于 4096 时，则使用大小为 2 ^ 16 次方的普通 bitset 来存储，固定消耗 8 KB。有些时候也会对 bitset 进行run-length encoding压缩，进一步缩小占用内存。  ES利用Roaring Bitset缓存不同条件查出来的Posting List，最后通过与操作合并出最终结果集。\n小结  ElasticSearch是一个分布式开源搜索引擎，支持多种语言客户端，拥有丰富的应用场景，受到许多企业的青睐。 ElasticSearch方便部署集群，使用RESTful风格等API进行调用。 MySQL的LIKE字句只在特定情况下才使用索引，且性能不高，无法应对大数据亮搜索任务。 ElasticSearch使用倒排索引与Term Index来提高搜索效率，减少磁盘I/O。 ElasticSearch使用Skip List和Roaring Bitset来合并复杂条件查询的结果集。  参考文章  https://mp.weixin.qq.com/s/LU77ToU4b7O8WqjRRf1AqA https://www.cnblogs.com/Howinfun/p/12449975.html?spm=a2c6h.12873639.0.0.7b354fc6zDKM52 https://ccqstark.github.io/p/es_docker/ https://arxiv.org/pdf/1402.6407.pdf  ","date":"2021-03-13T23:01:00+08:00","image":"https://ccqstark.github.io/p/es_principle/es_hu709c9dbb1dd93df65cfe69a9e6744979_88514_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/es_principle/","title":"[ElasticSearch]ElasticSearch入门与原理浅析"},{"content":"简介 Dubbo原本是阿里的开源框架，有很多著名厂商都在用。但在14年停更，之后Spring Cloud大红大紫，Dubbo终于在17年再度更新，并在18年合并当当网的基于它开发出的DubboX推出了2.6版本。之后在18年除夕夜，阿里正式将Dubbo捐献给了著名开源组织Apache，成为Apache众多开源项目之一。\nApache Dubbo\nZooKeeper 也是 Apache 软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。\nZooKeeper 的架构通过冗余服务实现高可用性。\nZookeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。\n一个典型的分布式数据一致性的解决方案，分布式应用程序可以基于它实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。\nApache ZooKeeper\n安装 使用Dubbo引入相关依赖即可，下面具体实践会涉及。\nZooKeeper可以去官网下载安装，这里我还是用docker在Linux服务器上安装。\n# 拉取镜像 docker pull zookeeper # 启动 docker run -d \\ -p 2181:2181 \\ -v /home/zookeeper/data/:/data/ \\ --name=zookeeper \\ --privileged zookeeper # 如果想运行自带的客户端可以： docker exec -it zookeeper bash cd bin ./zkCli.sh # 之后就可以使用相关命令了 安装ZooInspector来可视化查看zookeeper\n\n# 下载后进入build目录运行jar包，输入zookeeper的地址即可连接 java -jar zookeeper-dev-ZooInspector.jar  \n使用dubbo-admin可视化监控服务 dubbo-admin是一个Springboot项目，可以监控我们注册到注册中心到服务。\n到github上下载\napache/dubbo-admin\n解压后在application.properties中修改zookeeper地址\ndubbo.registry.address=zookeeper://[ip]:2181 之后用mvn命令打包再运行jar包即可，也可以直接在idea里打包\n运行后浏览器 打开localhost:7001 ，输入账号密码默认都为root，来到主页\n  中间的搜索框可以搜索服务、应用、ip，菜单栏上也有各种监控服务的方式。\nSpringBoot Demo 用idea建立一个空项目，然后添加两个Modules，都为Springboot项目。\n一个作为服务提供者provider，一个作为服务消费者consumer\n两者都添加以下maven依赖\n\u0026lt;!-- https://mvnrepository.com/artifact/org.apache.dubbo/dubbo-spring-boot-starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.dubbo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dubbo-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/com.github.sgroschupf/zkclient --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.sgroschupf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zkclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.1\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-framework --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-framework\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.0\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-recipes --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.2\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; 其中Curator是zookeeper分布式协调服务的java客户端库，它包装了一系列操作zk的高级API和实用库，是的操作zk变得更加容易和可靠。\n在provider项目中创建并注册服务 包目录都是就直接com.xxx，不要多一级，然后在provider项目的com.xxx路径下创建一个service目录，写一个简单的服务接口\npackage com.ccqstark.service; public interface TicketService { String getTicket(); } 然后是其实现\nimport com.ccqstark.service.TicketService; import org.apache.dubbo.config.annotation.DubboService; import org.springframework.stereotype.Component; @DubboService // 服务注册注解 @Component public class TicketServiceImpl implements TicketService { @Override public String getTicket(){ return \u0026#34;dubbo+zookeeper!\u0026#34;; } } 其中注解@DubboService 用来把该服务注册到zookeeper中\n修改provider项目的application.properties\n# 服务应用名称 dubbo.application.name=provider-server # 注册中心地址 dubbo.registry.address=zookeeper://[ip]:2181 # 被注册的服务 dubbo.scan.base-packages=com.ccqstark.service 然后启动项目，就可以在之前安装的dubbo中发现该服务了\n \n在consumer项目中调用服务 配置文件中增加配置\n# 消费者暴露的服务应用名称 dubbo.application.name=consumer-server # 注册中心地址 dubbo.registry.address=zookeeper://[ip]:2181 同样创建com.xxx.service包，把provider里的TicketService的接口文件复制过来\n创建一个调用此服务的例子\nimport org.apache.dubbo.config.annotation.DubboReference; import org.springframework.stereotype.Service; @Service public class UserService { @DubboReference // 获取注册中心中的服务  TicketService ticketService; public void buyTicket() { String ticket = ticketService.getTicket(); System.out.println(\u0026#34;调用provider的服务：\u0026#34; + ticket); } } 注解@DubboReference 用于获取注册中心的服务\n写个单元测试\n@SpringBootTest class ConsumerServerApplicationTests { @Autowired UserService userService; @Test void contextLoads() { userService.buyTicket(); } } 运行之后就可以发现consumer项目调用provider的服务成功！\n  最基本的服务注册发现与rpc调用大概是demo这样。\n参考自： bilibili\n","date":"2021-02-24T23:01:00+08:00","image":"https://ccqstark.github.io/p/dubbo_zookeeper/dubbo-zookeeper_huceb4a22a384e0271fe532efed4b00fee_48645_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/dubbo_zookeeper/","title":"Dubbo + ZooKeeper 基础入门"},{"content":"随着互联网的发展，Web应用与服务的规模不断扩大，才能满足不断增加的用户和需求。而原来只用一台服务器来部署的单机应用的方式已经满足不了如此大的需求。为了提高性能，单机发展为分布式架构，简单来说就是通过增加服务器的数量来弥补性能上的不足，当然同时也带来了一些问题。\n分布式系统 分布式系统（distributed system）是由一组网络进行通信，为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统是为了用单体性能普通的机器完成单个计算机无法完成的计算、存储任务，通过合理调度各台计算机共同合作来提高性能，完成数量更多、体量更大的任务。\n  比如百度或淘宝这样体量规模都十分大的应用，为了满足如此大的用户数量和请求压力，背后肯定不止一台计算机在提供服务，而是部署了计算机集群，通过提升计算机的数量来提高处理数据的能力。在流量高峰时，大量的请求可以被均匀地分配给各台服务器去处理，从而避免其中一台服务器由于压力过大而宕机，这就是负载均衡，也就是nginx可以做的事情。\n  同时应用的各个模块也可以分别部署在不同的服务器上，比如淘宝这样的电商项目可以把服务拆分成商品、支付、订单、物流等不同的模块，不同模块可以部署在不同的服务器上。当一个模块部署到多台服务器上时，其中一台崩了，还有其他的服务器可以提供服务，提高了服务的稳定性与高可用。\n  而对于用户来说，他们都是访问一个域名来获取服务的，所以对于用户来说服务还是一个整体，而不需要知道是哪台服务器为他们提供了服务。\nRPC 下图是Dubbo官方文档中的一张图，说明了网站应用的架构演变\n  原来应用是单体应用，程序如果要调用一个函数或方法就直接调用就行了，因为都是在本地。\n现在应用采用分布式架构，服务被分散到不同的服务器上，一台服务器上的程序就会遇到需要调用另一台服务器上的某个方法的情况，这个时候就叫RPC(远程过程调用)(Remote Procedure call)\nRPC的调用过程如下图：\n  通过网络发送调用消息就需要先序列化，到目标服务器后成功调用对应的服务后返回，反序列化得到结果。\nDubbo就是一个流行的RPC框架，提供面向接口代理的高性能RPC调用、智能负载均衡、服务自动注册与发现、高度可扩展能力、运行期流量调度（灰度发布）、可视化工具等功能。\n流动计算架构 当服务增多时，服务的管理与资源的分配成为亟待解决的问题，此时，需要增加一个调度中心基于访问压力实时管理集群容量，提高集群的利用率。用于提高机器利用率的资源调度和治理中心(SOA)(Service Oriented Architecture)就十分重要。\n服务通过在注册中心进行注册，被统一的管理起来并可被发现，并对用户开放。当用户需要用到某一服务时，就去注册中心拿，注册中心就会将对应的服务提供给他。\n  注册中心用的比较多的是Zookeeper\n","date":"2021-02-24T23:01:00+08:00","image":"https://ccqstark.github.io/p/distributed_rpc/dis-rpc_hueac48662f0ecf63cc9ad2fc947cb2254_27950_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/distributed_rpc/","title":"浅谈分布式系统与RPC"},{"content":"导入依赖 我们使用springboot操作es要用到对应的data相关starter\n\u0026lt;!-- elasticsearch的starter依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-elasticsearch\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 将对象转为json传入source时要用 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.75\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  ⚠️ 各springboot的版本对应特定的elasticsearch版本，引入上面的依赖时会自动下载对应版本的rest-high-level-client，使用时尽量使得版本对应，避免潜在问题。\n 版本对应表如下：\n  我使用的这里用Springboot2.4.1，所以对应的elasticsearch是7.9.3版本\n配置类 config目录下新建es的配置类ElasticSearchClientConfig.java\n@Configuration public class ElasticSearchClientConfig { @Bean public RestHighLevelClient restHighLevelClient() { final CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(\u0026#34;elastic\u0026#34;, \u0026#34;[密码]\u0026#34;)); RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026#34;[ip]\u0026#34;, 9200, \u0026#34;http\u0026#34;)) .setHttpClientConfigCallback(httpClientBuilder -\u0026gt; { httpClientBuilder.disableAuthCaching(); return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); })); return client; } } 这里有用到x-pack基础安全功能，所以配置了用户和密码。如果没有用户和密码，参照官方文档连接代码如下：\nRestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026#34;localhost\u0026#34;, 9200, \u0026#34;http\u0026#34;), new HttpHost(\u0026#34;localhost\u0026#34;, 9201, \u0026#34;http\u0026#34;))); 使用客户端连接 使用时@Autowired一下，用自定义名字时就@Qualifier一下，不然就得对应上面的方法名\n@Autowired @Qualifier(\u0026#34;restHighLevelClient\u0026#34;) private RestHighLevelClient client; 索引相关操作 创建索引 void testCreateIndex() throws IOException { // 1. 创建索引请求  CreateIndexRequest request = new CreateIndexRequest(\u0026#34;test\u0026#34;); // 2. 执行请求  CreateIndexResponse createIndexResponse = client.indices().create(request, RequestOptions.DEFAULT); System.out.println(createIndexResponse); } 判断索引是否存在 void testExistIndex() throws IOException { GetIndexRequest request = new GetIndexRequest(\u0026#34;test2\u0026#34;); boolean exists = client.indices().exists(request, RequestOptions.DEFAULT); System.out.println(exists); } 删除索引 void testDeleteIndex() throws IOException { DeleteIndexRequest request = new DeleteIndexRequest(\u0026#34;test\u0026#34;); AcknowledgedResponse delete = client.indices().delete(request, RequestOptions.DEFAULT); System.out.println(delete.isAcknowledged()); } 文档相关操作 添加文档 void testAddDocument() throws IOException { // 创建对象  User user = new User(\u0026#34;ccqstark\u0026#34;, 20); // 创建请求  IndexRequest request = new IndexRequest(\u0026#34;test\u0026#34;); // 规则 put /test/_doc/1  request.id(\u0026#34;1\u0026#34;); // 设置超时时间，可以不写，有默认参数  request.timeout(TimeValue.timeValueSeconds(1)); request.timeout(\u0026#34;1s\u0026#34;); // 将数据放入请求  request.source(JSON.toJSONString(user), XContentType.JSON); // 客户端发送请求  IndexResponse indexResponse = client.index(request, RequestOptions.DEFAULT); System.out.println(indexResponse.toString()); System.out.println(indexResponse.status()); // 对应返回的状态 } 批量插入文档 void testBulkRequest() throws IOException { BulkRequest bulkRequest = new BulkRequest(); // 数据量多的话超时时间可以设置长一点  bulkRequest.timeout(\u0026#34;10s\u0026#34;); List\u0026lt;User\u0026gt; userList = new ArrayList\u0026lt;\u0026gt;(); userList.add(new User(\u0026#34;ccq1\u0026#34;, 1)); userList.add(new User(\u0026#34;ccq2\u0026#34;, 2)); userList.add(new User(\u0026#34;ccq3\u0026#34;, 3)); userList.add(new User(\u0026#34;ccq4\u0026#34;, 4)); userList.add(new User(\u0026#34;ccq5\u0026#34;, 5)); // 批处理请求  for (int i = 0; i \u0026lt; userList.size(); i++) { bulkRequest.add( // 批量更新或批量删除，就在这里修改对应的请求即可. 不指定id会自动生成随机不重复id  new IndexRequest(\u0026#34;test\u0026#34;) .id(\u0026#34;\u0026#34; + (i + 1)) .source(JSON.toJSONString(userList.get(i)), XContentType.JSON)); } BulkResponse bulkResponse = client.bulk(bulkRequest, RequestOptions.DEFAULT); // 是否失败，false代表成功  System.out.println(bulkResponse.hasFailures()); } 判断文档是否存在 void testIsExists() throws IOException { GetRequest getRequest = new GetRequest(\u0026#34;test\u0026#34;, \u0026#34;1\u0026#34;); // 不获取返回的_source上下文了  getRequest.fetchSourceContext(new FetchSourceContext(false)); // 排序的字段  getRequest.storedFields(\u0026#34;_none_\u0026#34;); boolean exist = client.exists(getRequest, RequestOptions.DEFAULT); System.out.println(exist); } 获取文档信息 void testGetDocument() throws IOException { // index id  GetRequest getRequest = new GetRequest(\u0026#34;test\u0026#34;, \u0026#34;1\u0026#34;); GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT); // 返回的全部内容，和用命令获取的结果一样  System.out.println(getResponse); // 以map获取结果的source  System.out.println(getResponse.getSourceAsMap()); // 以string获取结果source  System.out.println(getResponse.getSourceAsString()); } 更新文档 void testUpdateDocument() throws IOException { UpdateRequest updateRequest = new UpdateRequest(\u0026#34;test\u0026#34;, \u0026#34;1\u0026#34;); updateRequest.timeout(\u0026#34;1s\u0026#34;); User user = new User(\u0026#34;ccq java\u0026#34;, 18); updateRequest.doc(JSON.toJSONString(user), XContentType.JSON); UpdateResponse updateResponse = client.update(updateRequest, RequestOptions.DEFAULT); System.out.println(updateResponse.status()); } 删除文档 void deleteDocument() throws IOException { DeleteRequest deleteRequest = new DeleteRequest(\u0026#34;test\u0026#34;, \u0026#34;3\u0026#34;); DeleteResponse deleteResponse = client.delete(deleteRequest, RequestOptions.DEFAULT); System.out.println(deleteResponse.status()); } 高级查询 void testSearch() throws IOException { // SearchRequest 搜索请求  // SearchSourceBuilder 搜索条件构造  SearchRequest searchRequest = new SearchRequest(\u0026#34;test\u0026#34;); SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); // 不同查询方式都在这里设置  // QueryBuilders.termQuery() 精确查询  // QueryBuilders.matchAllQuery() 匹配所有  TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\u0026#34;name\u0026#34;, \u0026#34;ccq\u0026#34;); sourceBuilder.query(termQueryBuilder); sourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); // 分页  sourceBuilder.from(0); sourceBuilder.size(10); // 高亮  HighlightBuilder highlightBuilder = new HighlightBuilder(); // 设置高亮的字段  highlightBuilder.field(\u0026#34;name\u0026#34;); // 多个匹配字高亮  highlightBuilder.requireFieldMatch(true); // 设置高亮标签  highlightBuilder.preTags(\u0026#34;\u0026lt;span style=\\\u0026#34;color:#ffd73b\\\u0026#34;\u0026gt;\u0026#34;); highlightBuilder.postTags(\u0026#34;\u0026lt;/span\u0026gt;\u0026#34;); sourceBuilder.highlighter(highlightBuilder); // 执行搜索  searchRequest.source(sourceBuilder); SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT); System.out.println(JSON.toJSONString(searchResponse.getHits())); System.out.println(\u0026#34;=========================================\u0026#34;); for (SearchHit hit : searchResponse.getHits()) { // 获取高亮字段  Map\u0026lt;String, HighlightField\u0026gt; highlightFields = hit.getHighlightFields(); HighlightField highlightName = highlightFields.get(\u0026#34;name\u0026#34;); // 原来的结果  Map\u0026lt;String, Object\u0026gt; sourceAsMap = hit.getSourceAsMap(); // 用高亮替换原来的，这里要判断一个是否为空，因为有可能没有高亮结果  if (highlightName != null) { Text[] fragments = highlightName.fragments(); // 只有当要高亮搜索当字段是数组类型fragments才会有多个元素，如果是单字段就去第0个就行  sourceAsMap.put(\u0026#34;name\u0026#34;, fragments[0]); } System.out.println(sourceAsMap); } } 参考自狂神的ElasticSearch教程： 【狂神说Java】ElasticSearch7.6.x最新完整教程通俗易懂\n","date":"2021-02-04T23:01:00+08:00","image":"https://ccqstark.github.io/p/springboot_es/springboot-es_hu5dbd9828aef42d61c56fd952a73b2be9_64126_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/springboot_es/","title":"[SpringBoot]整合ElasticSearch"},{"content":"基本的rest命令    method url 功能     PUT localhost:9200/索引名称/类型名称/文档id 创建文档（指定文档id)   POST localhost:9200/索引名称/类型名称 创建文档（随机文档id）   POST localhost:9200/索引名称/类型名称/文档id/_update 修改文档   DELETE localhost:9200/索引名称/类型名称/文档id 删除文档   GET localhost:9200/索引名称/类型名称/文档id 查询文档，通过文档id   POST localhost:9200/索引名称/类型名称/_search 查询所有数据     ⚠️ 自定义类型将在以后的版本中弃用，规范起见一律使用_doc 类型\n 文档字段的数据类型   字符串类型\ntext keyword\n  数值类型\nlong integer short byte double float half float scaled float\n  日期类型\ndate\n  布尔类型\nboolean\n  二进制类型\nbinary\n等等\u0026hellip;..\n  基本操作  创建一个文档，如果索引不存在也会一起创建  PUT /test/_doc/1 { \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34;, \u0026#34;age\u0026#34;:3 } 没有指定字段的数据类型，es会默认配置\n 指定字段数据类型创建索引  PUT /test2 { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;age\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;birthday\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; } } } }  基本查询  # 查询索引库信息 GET /{index} # 查询具体某一文档 GET /{index}/_doc/{id}  查询es参数  GET _cat/[参数项]  PUT更新  PUT /{index}/_doc/{id} { \u0026#34;name\u0026#34;:\u0026#34;ccqstark666\u0026#34;, \u0026#34;age\u0026#34;:3 } 直接在对应字段写上更新后的信息，会覆盖旧的值\n如果漏了原来有的字段，那么这些字段会被删除，所以不推荐使用\n POST更新**（推荐）**  POST **/{index}/_update/{id}** { \u0026#34;doc\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark555\u0026#34; } } 被修改的文档的\u0026quot;_version\u0026quot;会递增1\n 删除  # 删除索引库 DELETE /{index} # 删除文档 DELETE /{index}/_doc/{id}  简单条件查询  GET /test/_doc/_search?q=name:ccqstark  ⚠️ 如果字段类型是keyword ，说明不可分割，查询的时候分词器不会分割这个词来搜索，而是当成一个整体，而text 类型可以被分词器解析\n  😮 查询出来的\u0026quot;hits\u0026quot;里有\u0026quot;_score\u0026quot;是说明匹配度的分数值，匹配度越高，分数越高\n 复杂(花式)搜索  match 查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34; } } } match不是精确搜索，会使用分词器解析再搜索（默认自带分词器把英文按空格分词，中文是每一个字都分开）\n使用json构建查询参数体\n\u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 3, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; } 查询结果中的 hits里有个total的value，为查询结果的总数量\n 过滤查询结果的字段  GET /test/_doc/_search { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34; } }, \u0026#34;_source\u0026#34;:[\u0026#34;name\u0026#34;,\u0026#34;age\u0026#34;] } \u0026quot;_source\u0026quot; 可以用来指定查询结果中的字段，相当于select xxx,xxx\n 结果排序  GET /test/_doc/_search { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34; } }, \u0026#34;sort\u0026#34;:{ \u0026#34;age\u0026#34;:{ \u0026#34;order\u0026#34;:\u0026#34;desc\u0026#34; } } } 这里 \u0026quot;sort\u0026quot; 指定age为用来排序的字段，\u0026quot;order\u0026quot; 为排序方式\n升序：asc\n降序：desc\n 分页查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34; } }, \u0026#34;from\u0026#34;:0, \u0026#34;size\u0026#34;:2 } “from”是从第几页开始，第一页为0\n“size”是每页多少条数据\n bool查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ccqstark\u0026#34; } }, { \u0026#34;match\u0026#34;: { \u0026#34;age\u0026#34;: 100 } } ] } } } 用bool可以实现多条件查询\n这里的must相当于and，也就是所有条件都要符合\n也可以用should ，相当于or\n还有must_not ，相当于not\n bool嵌套  GET /my_store/products/_search { \u0026#34;query\u0026#34; : { \u0026#34;filtered\u0026#34; : { \u0026#34;filter\u0026#34; : { \u0026#34;bool\u0026#34; : { \u0026#34;should\u0026#34; : [ { \u0026#34;term\u0026#34; : {\u0026#34;productID\u0026#34; : \u0026#34;KDKE-B-9947-#kL5\u0026#34;}}, { \u0026#34;bool\u0026#34; : { \u0026#34;must\u0026#34; : [ { \u0026#34;term\u0026#34; : {\u0026#34;productID\u0026#34; : \u0026#34;JODL-X-1937-#pV7\u0026#34;}}, { \u0026#34;term\u0026#34; : {\u0026#34;price\u0026#34; : 30}} ] }} ] } } } } } bool查询里再套一个bool，就相当于加了个括号：( A or ( B and C ))\n filter 查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must_not\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;陈楚权\u0026#34; } } ], \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gte\u0026#34;: 66, \u0026#34;lte\u0026#34;: 100 } } } } } } range 表示范围查询，age 指定了字段\n范围查询表达式\n   表达式 表示     gt \u0026gt;   gte \u0026gt;=   lt \u0026lt;   lte \u0026lt;=     多关键词查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ccq java\u0026#34; } } ] } } } 用空格隔开关键词就行\n term精确查询  GET /test3/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ccq说java\u0026#34; } } ] } } }  ⚠️ 使用term查询要求字段为keyword类型才能匹配出来\n term是精确查询，于match会用分词器解析不同，term是直接通过倒排索引指定的词条进行精确查找\n \n 高亮查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;java\u0026#34; } }, \u0026#34;highlight\u0026#34;: { \u0026#34;fields\u0026#34;: { \u0026#34;name\u0026#34;: {} } } } 返回值中的highlight字段里会有带高亮标签的搜索结果，默认标签为\u0026lt;em\u0026gt;，效果如下\n{ \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;6\u0026#34;, \u0026#34;_score\u0026#34; : 1.1631508, \u0026#34;_source\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;ccq说java\u0026#34;, \u0026#34;age\u0026#34; : 100 }, \u0026#34;highlight\u0026#34; : { \u0026#34;name\u0026#34; : [ \u0026#34;ccq说\u0026lt;em\u0026gt;java\u0026lt;/em\u0026gt;\u0026#34; ] } } 高亮标签可以自定义，用前标签pre_tags和后标签post_tags 来指定\nGET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;java\u0026#34; } }, \u0026#34;highlight\u0026#34;: { \u0026#34;pre_tags\u0026#34;: \u0026#34;\u0026lt;p class=\u0026#39;key\u0026#39; style=\u0026#39;color:red\u0026#39;\u0026gt;\u0026#34;, \u0026#34;post_tags\u0026#34;: \u0026#34;\u0026lt;/p\u0026gt;\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;name\u0026#34;: {} } } } 参考自狂神的ElasticSearch教程： 【狂神说Java】ElasticSearch7.6.x最新完整教程通俗易懂\n","date":"2021-02-03T23:01:00+08:00","image":"https://ccqstark.github.io/p/es_rest/restful_hud0b30a641456616a14ef2ef618957a76_22844_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/es_rest/","title":"[ElasticSearch]REST风格操作"},{"content":"由于这几天开始看《CS:APP》，我就开始寻求一款Mac上的轻量的C语言编辑器。找来找去，无非是VSCode、CLion和大名鼎鼎的Vim。\n为了减少磁盘占用同时让自己更接近于底层，我还是硬着头皮折腾起了Vim，这个上古神器之前就一直让我望而却步，我对它的掌握程度也差不多是会退出的程度，这一次就打算好好来折腾下。\n安装NeoVim Vim其实到目前为止，不同的分支版本还是很多的，比较流行的现代版本就要属NeoVim了，所以我在终端安装了它，用iTerm2运行着。\nbrew install neovim 安装完成后用nvim命令就可以打开\nnvim 配置文件路径\n传统的vim的配置配置文件为~/.vimrc\n而nvim的配置文件为/.config/nvim/init.vim ，之后修改nvim配置文件就用这个，以下简称为init.vim\n安装SpaceVim 作为小白，快速搭建一个好看实用的Vim开发环境那最好的选择就是SpaceVim 了，下面是官方的介绍：\n SpaceVim 是一个社区驱动的模块化的 Vim IDE，以模块的方式组织管理插件以及相关配置， 为不同的语言开发量身定制了相关的开发模块，该模块提供代码自动补全， 语法检查、格式化、调试、REPL 等特性。用户仅需载入相关语言的模块即可得到一个开箱即用的 Vim IDE。\n 官网地址：\n主页 | SpaceVim\n官网的文档还是很全的，按官方文档就可以快速搭建出来了。以MacOS为例：\n安装spacevim\ncurl -sLf https://spacevim.org/cn/install.sh | bash 完成后重新打开nvim就会自动下载相关插件。\n然后就是主界面：\n  主题的修改可以参考官方文档\nSpaceVim colorscheme 模块 | SpaceVim\n快捷键符号说明\nSPC 代表空格\n\u0026lt;Leader\u0026gt; 默认为\\\n以下一些功能需要对mac进行一定的设置才能正常使用。\n打开系统偏好设置 → 键盘\n勾选将F1、F2等键用作标准功能键\n这同时也解决了Chrome的F12 不能打开控制台的问题\n  文件目录树\n按F3 可以打开或关闭\n语法函数树\n按F2可以打开或关闭\nmac下可能会出现错误，解决方案：\nbrew install ctags-exuberant 然后init.vim里添加下面这行即可\nlet g:Tlist_Ctags_Cmd=\u0026#39;/usr/local/Cellar/ctags/5.8_1/bin/ctags\u0026#39; shell终端\nSPC ' 即可打开系统shell，如果用了oh-my-zsh主题什么的也会保留的\n配置C/C++环境 spacevim对大部分语言都有相关支持，文档也齐全，比如我需要的C语言环境：\n使用 Vim 搭建 C/C++ 开发环境 | SpaceVim\n按照官方文档修改spacevim的配置文件~/.SpaceVim.d/init.toml 即可，以下简称init.toml\n对于自带的模块基本只需要添加[[layers]]\n# 语法高亮 [[layers]] name = \u0026#39;lang#c\u0026#39; enable_clang_syntax_highlight = true # 代码格式化 [[layers]] name = \u0026#34;format\u0026#34; # 语法检查 [[layers]] name = \u0026#34;checkers\u0026#34; spacevim内置的模块还是很多的，但是很多功能相对简陋，为了实现更好的效果，我们还需要安装其他的插件。\n安装插件管理器vim-plug 虽然SpaceVim已经自带插件管理工具，在init.toml 里添加\n[[custom_plugins]] repo = \u0026#34;插件的github地址\u0026#34; 重启后即可自动下载\n用spacevim管理的这些从github上下载的插件存储在~/.cache/vimfiles/repos/github.com/\n这个自带的插件管理器大部分情况下还可以，但是有时不太好使，所以我选择多下载一个vim的主流插件管理器vim-plug\n使用curl安装，下面一条命令就够\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\  https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 如果遇到了Connection refused的错误，使用SwitchHosts! ，添加以下的host：\n199.232.68.133 raw.githubusercontent.com 199.232.68.133 user-images.githubusercontent.com 199.232.68.133 avatars2.githubusercontent.com 199.232.68.133 avatars1.githubusercontent.com 使用插件管理器安装新的插件的方法是，在init.vim 配置文件里添加：\ncall plug#begin() call plug#end() 然后把要安装的插件添加到这两行代码中间，以Plug 'xxx/xxx' 的格式，如：\ncall plug#begin() Plug \u0026#39;junegunn/vim-easy-align\u0026#39; call plug#end() 之后重启nvim，使用命令:PlugInstall 就可以安装了。\n若要卸载插件，就从配置文件中去除相应的那一行，然后使用命令:PlugClean 就可以卸载了。\n安装Coc.nvim SpaceVim自带的补全还行，但是为了达到效果更好的补全和语法检查，我选择安装插件coc.nvim\nneoclide/coc.nvim\n这可以说是神器了，除了基本的补全之外，还提供了众多扩展来支持不同的语言和不同的特性。\n用之前下的vim-plug 来安装\nPlug \u0026#39;neoclide/coc.nvim\u0026#39;, {\u0026#39;branch\u0026#39;: \u0026#39;release\u0026#39;} 安装完后可以先直接把官方的示例配置文件粘贴进init.vim，示例配置文件在github的readme里有。\n为了C语言更好的补全支持，我下载相关的coc扩展——coc-clangd\nneoclide/coc.nvim\n首先保证有node环境，然后运行以下命令安装coc-clangd\n:CocInstall coc-clangd 完成后打开一个c语言文件，若提示找不到clangd，则自己手动下载。\n进入github release页面下载clangd-mac-11.0.0.zip\nRelease 11.0.0 · clangd/clangd\n解压后目录下有一个bin文件夹和一个lib文件夹\n将bin下的clangd文件移动至/usr/local/bin/目录下\n将lib目录下的clang文件夹移动至~/Library/目录下\n再次打开即可正常使用，注意把spacevim自带的补全给禁用\n[[layers]] name = \u0026#39;autocomplete\u0026#39; enable = false 效果如下：\n  可以看到代码提示效果是非常好的\n当然，里面还有很多很实用的扩展也可以根据需要下\n括号引号自动补全 coc.nvim插件对于括号和引号还是没有自动补成一对的功能，可以在init.vim里添加\ninoremap ( ()\u0026lt;Esc\u0026gt;i inoremap [ []\u0026lt;Esc\u0026gt;i inoremap { {\u0026lt;CR\u0026gt;}\u0026lt;Esc\u0026gt;O autocmd Syntax html,vim inoremap \u0026lt; \u0026lt;lt\u0026gt;\u0026gt;\u0026lt;Esc\u0026gt;i| inoremap \u0026gt; \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;\u0026gt;\u0026#39;)\u0026lt;CR\u0026gt; inoremap ) \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;)\u0026#39;)\u0026lt;CR\u0026gt; inoremap ] \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;]\u0026#39;)\u0026lt;CR\u0026gt; inoremap } \u0026lt;c-r\u0026gt;=CloseBracket()\u0026lt;CR\u0026gt; inoremap \u0026#34; \u0026lt;c-r\u0026gt;=QuoteDelim(\u0026#39;\u0026#34;\u0026#39;)\u0026lt;CR\u0026gt; inoremap \u0026#39; \u0026lt;c-r\u0026gt;=QuoteDelim(\u0026#34;\u0026#39;\u0026#34;)\u0026lt;CR\u0026gt; function ClosePair(char) if getline(\u0026#39;.\u0026#39;)[col(\u0026#39;.\u0026#39;) - 1] == a:char return \u0026#34;\\\u0026lt;Right\u0026gt;\u0026#34; else return a:char endif endf function CloseBracket() if match(getline(line(\u0026#39;.\u0026#39;) + 1), \u0026#39;\\s*}\u0026#39;) \u0026lt; 0 return \u0026#34;\\\u0026lt;CR\u0026gt;}\u0026#34; else return \u0026#34;\\\u0026lt;Esc\u0026gt;j0f}a\u0026#34; endif endf function QuoteDelim(char) let line = getline(\u0026#39;.\u0026#39;) let col = col(\u0026#39;.\u0026#39;) if line[col - 2] == \u0026#34;\\\\\u0026#34; return a:char elseif line[col - 1] == a:char return \u0026#34;\\\u0026lt;Right\u0026gt;\u0026#34; else return a:char.a:char.\u0026#34;\\\u0026lt;Esc\u0026gt;i\u0026#34; endif endf 彩虹括号 vim里也有类似vscode或IDEA那样的彩虹括号插件\nPlug \u0026#39;luochen1990/rainbow\u0026#39; #或 repo = \u0026#39;luochen1990/rainbow\u0026#39; init.vim 添加\nlet g:rainbow_active = 1 let g:rainbow_conf = { \\  \u0026#39;guifgs\u0026#39;: [\u0026#39;darkorange3\u0026#39;, \u0026#39;seagreen3\u0026#39;, \u0026#39;royalblue3\u0026#39;, \u0026#39;firebrick\u0026#39;], \\  \u0026#39;ctermfgs\u0026#39;: [\u0026#39;lightyellow\u0026#39;, \u0026#39;lightcyan\u0026#39;,\u0026#39;lightblue\u0026#39;, \u0026#39;lightmagenta\u0026#39;], \\  \u0026#39;operators\u0026#39;: \u0026#39;_,_\u0026#39;, \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/ fold\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/ fold\u0026#39;, \u0026#39;start=/{/ end=/}/ fold\u0026#39;], \\  \u0026#39;separately\u0026#39;: { \\  \u0026#39;*\u0026#39;: {}, \\  \u0026#39;tex\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/\u0026#39;], \\  }, \\  \u0026#39;lisp\u0026#39;: { \\  \u0026#39;guifgs\u0026#39;: [\u0026#39;darkorange3\u0026#39;, \u0026#39;seagreen3\u0026#39;, \u0026#39;royalblue3\u0026#39;, \u0026#39;firebrick\u0026#39;], \\  }, \\  \u0026#39;vim\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/\u0026#39;, \u0026#39;start=/{/ end=/}/ fold\u0026#39;, \u0026#39;start=/(/ end=/)/ containedin=vimFuncBody\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/ containedin=vimFuncBody\u0026#39;, \u0026#39;start=/{/ end=/}/ fold containedin=vimFuncBody\u0026#39;], \\  }, \\  \u0026#39;html\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/\\v\\\u0026lt;((area|base|br|col|embed|hr|img|input|keygen|link|menuitem|meta|param|source|track|wbr)[ \u0026gt;])@!\\z([-_:a-zA-Z0-9]+)(\\s+[-_:a-zA-Z0-9]+(\\=(\u0026#34;[^\u0026#34;]*\u0026#34;|\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;[^\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;]*\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;|[^ \u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;\u0026#34;\u0026gt;\u0026lt;=`]*))?)*\\\u0026gt;/ end=#\u0026lt;/\\z1\u0026gt;# fold\u0026#39;], \\  }, \\  \u0026#39;css\u0026#39;: 0, \\  } \\} 安装CtrlP CtrlP是vim下一款很好的文件模糊搜索跳转插件\nkien/ctrlp.vim\n安装\nrepo = \u0026#39;kien/ctrlp.vim\u0026#39; 使用\n:CtrlP [要搜索的目录] 如果目录下的文件过多，比如系统根目录，就会花比较多的时间去索引。所以建议尽量缩小范围。\n之后便可以输入关键字进行搜索了\n \n其他插件 比如更好的代码格式化vim-clang-format和代码时间记录wakatime\nrhysd/vim-clang-format\nwakatime/vim-wakatime\n基本上想要的插件都可以在github上找到，根据官方文档使用即可\n常用快捷键 SPC 1/2/3 切换不同窗口，数字为窗口编号\nSPC l r 运行代码\nSPC b f 代码格式化\ng d 函数跳转\n\u0026lt;c-o\u0026gt; 回调到上次的位置（这个写法表示ctrl+o）\n更多功能可以SPC空格键唤出菜单查看\n尾声 到此一个基本的vim编程环境已经搭好了，用来写点小东西还是够用的。\n这一套折腾下来最大的感受是曾经觉得vim好难学好难用，但是通过这几天捣鼓之后发现只要熟练了其实效率还是很高的。难怪至今还有很多vim的使用者和爱好者。同时自己安装各种插件，修改配置文件，通过自定义来获得一款完全属于自己的编辑器的过程也是充满乐趣的，我很享受这个过程。\n","date":"2021-01-31T21:26:00+08:00","image":"https://ccqstark.github.io/p/vim/vim_hu721b1231aff42422e86b1dd0b5ea6e91_94583_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/vim/","title":"我的vim入门配置折腾"},{"content":"ElacticSearch索引中有大量的数据，如果没有一些安全措施的话会让系统处于一个十分危险的处境，引发的相关安全事件可以看看这篇文章。\n你的Elasticsearch在\u0026quot;裸奔\u0026quot;吗？\n而ElaticSearch官方的高级安全服务是收费的，主要给企业提供。但是从6.8和7.1版本开始，基础安全功能就免费了，而且已经集成在里面不用额外安装。\n除此之外诸如Search Guard、ReadonlyREST、Nginx 等开源免费等方法来达到安全的目的，这里介绍的是使用官方的x-pack的基础安全功能，对于小项目来说够用了。\n本文版本为7.10.1\n修改配置文件 在elasticsearch.yml里新增\nxpack.security.enabled:truexpack.security.transport.ssl.enabled:true之后重启 es\n在es目录下执行 elasticsearch-setup-passwords interactive 然后输入多个用户的密码\nInitiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: Reenter password for [elastic]: Passwords do not match. Try again. Enter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana]: Reenter password for [kibana]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: Changed password for user [apm_system] Changed password for user [kibana] Changed password for user [logstash_system] Changed password for user [beats_system] Changed password for user [remote_monitoring_user] Changed password for user [elastic] 其中elastic用户相当与es的root用户，之后使用es和kibana需要这个用户的密码\n设置完重启一下es\n测试 curl -GET -u elastic http://[ip]:9200/ 发现提示输入elastic用户的密码\nEnter host password for user \u0026#39;elastic\u0026#39;: 基本的安全就实现了，之后进一步防止暴力破解密码可以再使用iptables\nKibana设置 修改kibana.yml\nelasticsearch.username:\u0026#34;elastic\u0026#34;elasticsearch.password:\u0026#34;[密码]\u0026#34;xpack:apm.ui.enabled:falsegraph.enabled:falseml.enabled:falsemonitoring.enabled:falsereporting.enabled:falsesecurity.enabled:true# 这里要打开grokdebugger.enabled:falsesearchprofiler.enabled:false之后进入kibana进入登陆界面\n  用elastic用户和密码登陆即可\n代码中配置 Java High Level REST Client中配置账户和密码\nfinal CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(\u0026#34;elastic\u0026#34;, \u0026#34;123456\u0026#34;)); //es账号密码（默认用户名为elastic）  RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026#34;localhost\u0026#34;, 9200, \u0026#34;http\u0026#34;)) .setHttpClientConfigCallback(new RestClientBuilder.HttpClientConfigCallback() { public HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpClientBuilder) { httpClientBuilder.disableAuthCaching(); return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); } })); SpringBoot的配置文件\nspring.elasticsearch.rest.username=elasticspring.elasticsearch.rest.password=123456修改密码 curl -H \u0026#34;Content-Type:application/json\u0026#34; -XPOST -u elastic \u0026#39;http://127.0.0.1:9200/_xpack/security/user/elastic/_password\u0026#39; -d \u0026#39;{ \u0026#34;password\u0026#34; : \u0026#34;123456\u0026#34; }\u0026#39; 结尾 这里只是单节点示例，集群以及证书相关可以参看官方文档\n通过 TLS 加密和基于角色的访问控制确保 Elasticsearch 的安全\n","date":"2021-01-29T21:26:00+08:00","image":"https://ccqstark.github.io/p/x_pack/x-pack_huc4207ebc9b333ece948f0ec8e981e0d7_15854_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/x_pack/","title":"[Elastic]ElasticSearch 安全"},{"content":"安装logstash 在实际项目中使用es进行搜索，我们就要把mysql数据库中的数据同步到es索引库中。进行这项过程的工具很多，比如go-mysql-elasticsearch，canal等等，当然也可以使用ELK组合中的logsatsh 来完成。这里同样用docker来部署logstash容器。\n拉取镜像 docker pull logstash:7.10.1 启动容器 启动后进入容器内，修改jvm启动的内存设置，地址为/usr/share/logstash/config/jvm.options\n# 修改jvm内存分配 vi jvm.options # 修改下面的参数，单位可以为g和m -Xms256m -Xmx256m 修改后重启容器即可\n下载插件与依赖包 docker exec -it logstash bash 安装logstash-input-jdbc插件\nbin/logstash-plugin install logstash-input-jdbc 如果出现以下ERROR，说明logstash里本身已经包含有这个插件了，就无需安装。7.10.1的版本是已经自带了。\nERROR: Installation aborted, plugin \u0026#39;logstash-input-jdbc\u0026#39; is already provided by \u0026#39;logstash-integration-jdbc\u0026#39; 下载mysql-connector-java，也就是jdbc驱动\nMySQL官方下载地址：https://downloads.mysql.com/archives/c-j/\n下载对应版本后本地解压，上传到服务器，然后用docker cp命令复制到logstash容器中\n只需要其中的jar包即可\n# 把文件复制到容器内 docker cp [jar包路径] logstash:[容器内路径] 在/usr/share/logstash目录下新建mysql/目录，把jar包复制到这里\n同步配置文件 在刚刚的mysql目录下新建jdbc.conf 文件，来配置同步操作\n 单表同步  input { jdbc { # jar包的绝对路径 jdbc_driver_library =\u0026gt; \u0026#34;/usr/share/logstash/mysql/mysql-connector-java-5.1.48.jar\u0026#34; jdbc_driver_class =\u0026gt; \u0026#34;com.mysql.jdbc.Driver\u0026#34; # 数据库连接信息 jdbc_connection_string =\u0026gt; \u0026#34;jdbc:mysql://[ip]:3306/[库名]?characterEncoding=UTF-8\u0026amp;autoReconnect=true\u0026#34; jdbc_user =\u0026gt; \u0026#34;[mysql用户]\u0026#34; jdbc_password =\u0026gt; \u0026#34;[密码]\u0026#34; # cron的定时执行语法一样，默认每分钟同步一次 schedule =\u0026gt; \u0026#34;* * * * *\u0026#34; # 执行的sql语句语法，这里是通过将主键大于最后一次同步所记录的值来实现增量同步的 statement =\u0026gt; \u0026#34;SELECT * FROM activity WHERE activity_id \u0026gt; :sql_last_value order by activity_id asc\u0026#34; use_column_value =\u0026gt; true # 用来作为增量同步的判断字段，最好为表的主键 tracking_column =\u0026gt; \u0026#34;activity_id\u0026#34; # 是否记录上次执行结果，true表示会将上次执行结果的tracking_column字段的值保存到last_run_metadata_path指定的文件中； record_last_run =\u0026gt; true # record_last_run上次数据存放位置 last_run_metadata_path =\u0026gt; \u0026#34;/usr/share/logstash/mysql/last_id.txt\u0026#34; # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false clean_run =\u0026gt; false } } output{ elasticsearch{ hosts =\u0026gt; [\u0026#34;[ip]:9200\u0026#34;] index =\u0026gt; \u0026#34;[索引名]\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{activity_id}\u0026#34; } stdout { codec =\u0026gt; rubydebug } }  多表同步  多表配置和单表配置的区别在于input模块的jdbc模块有几个type，output模块就需对应有几个type\ninput { stdin {} jdbc { # 多表同步时，表类型区分，建议命名为“库名_表名”，每个jdbc模块需对应一个type； type =\u0026gt; \u0026#34;TestDB_DetailTab\u0026#34; # 其他配置此处省略，参考单表配置 # ... # ... # record_last_run上次数据存放位置； last_run_metadata_path =\u0026gt; \u0026#34;mysql\\last_id.txt\u0026#34; # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false； clean_run =\u0026gt; false # # 同步频率(分 时 天 月 年)，默认每分钟同步一次； schedule =\u0026gt; \u0026#34;* * * * *\u0026#34; } jdbc { # 多表同步时，表类型区分，建议命名为“库名_表名”，每个jdbc模块需对应一个type； type =\u0026gt; \u0026#34;TestDB_Tab2\u0026#34; # 多表同步时，last_run_metadata_path配置的路径应不一致，避免有影响； # 其他配置此处省略 # ... # ... } } filter { json { source =\u0026gt; \u0026#34;message\u0026#34; remove_field =\u0026gt; [\u0026#34;message\u0026#34;] } } output { # output模块的type需和jdbc模块的type一致 if [type] == \u0026#34;TestDB_DetailTab\u0026#34; { elasticsearch { # host =\u0026gt; \u0026#34;192.168.1.1\u0026#34; # port =\u0026gt; \u0026#34;9200\u0026#34; # 配置ES集群地址 hosts =\u0026gt; [\u0026#34;192.168.1.1:9200\u0026#34;, \u0026#34;192.168.1.2:9200\u0026#34;, \u0026#34;192.168.1.3:9200\u0026#34;] # 索引名字，必须小写 index =\u0026gt; \u0026#34;detailtab1\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{KeyId}\u0026#34; } } if [type] == \u0026#34;TestDB_Tab2\u0026#34; { elasticsearch { # host =\u0026gt; \u0026#34;192.168.1.1\u0026#34; # port =\u0026gt; \u0026#34;9200\u0026#34; # 配置ES集群地址 hosts =\u0026gt; [\u0026#34;192.168.1.1:9200\u0026#34;, \u0026#34;192.168.1.2:9200\u0026#34;, \u0026#34;192.168.1.3:9200\u0026#34;] # 索引名字，必须小写 index =\u0026gt; \u0026#34;detailtab2\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{KeyId}\u0026#34; } } stdout { codec =\u0026gt; json_lines } } 为了统一，把数据也放这个目录下，在mysql目录下再新建目录data\nmkdir data 启动logstash同步 cd回到/usr/share/logstash目录，启动同步\n./bin/logstash -f mysql/jdbc.conf --path.data=/usr/share/logstash/mysql/data/ 注意，要保证给elasticsearch的分配的内存足够大才行，测试用的256m是不够的，会导致es容器退出，至少给个1g\n—-path.data参数用来设置同步数据存放的位置\n启动之后控制台会打印出大概以下信息\nUsing bundled JDK: /usr/share/logstash/jdk OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. WARNING: An illegal reflective access operation has occurred WARNING: Illegal reflective access by org.jruby.ext.openssl.SecurityHelper (file:/tmp/jruby-423/jruby7667758569951782495jopenssl.jar) to field java.security.MessageDigest.provider WARNING: Please consider reporting this to the maintainers of org.jruby.ext.openssl.SecurityHelper WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations WARNING: All illegal access operations will be denied in a future release 开始同步会打印出从数据库读取的，插入到elasticsearch的信息\n实际使用中用nohup 来保持后台运行\n缺点 logstash的缺点很明显，就是只能同步mysql中新增的数据，对于更改的、删除的就无能为力了。这其实也很好理解，ELK其实本来就是用来收集与分析日志的，而同步增加的数据已经足够了。\n我觉得es与mysql最好的同步工具其实是阿里的开源的canal\nalibaba/canal\n","date":"2021-01-28T21:26:00+08:00","image":"https://ccqstark.github.io/p/logstash_mysql/logstash-mysql_hubd922da79b2e986df34a25cd755e9ffb_77309_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/logstash_mysql/","title":"[Elastic]使用logstash同步MySQL数据"},{"content":"安装ElasticSearch 拉取镜像 docker pull elasticsearch:7.10.1 启动容器 同时挂载目录（包括配置文件和data）（挂载出来的位置自己定义）\ndocker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=\u0026#34;-Xms256m -Xmx256m\u0026#34; -d \\ -v /home/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ -v /home/es/data:/usr/share/elasticsearch/data elasticsearch:7.10.1 注意这里还设置了JVM的内存大小，默认为2G，有点大，很可能会因为内存不够而无法正常启动。可以像我这里改为256m或者其他值。\n可能出现的错误 查看容器日志\ndocker logs elasticsearch 如果出现以下错误\nmax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 则要修改服务器配置\nvim /etc/sysctl.conf 添加这行\nvm.max_map_count=262144 立即生效, 执行：\n/sbin/sysctl -p 对挂载的宿主机data目录可能出现权限不足问题\nchmod 777 [宿主机data目录] 配置跨域 到挂载出来到位置编辑配置文件\nvim elasticsearch.yml 添加以下几行\nnetwork.host:0.0.0.0discovery.type:single-nodehttp.cors.enabled:truehttp.cors.allow-origin:\u0026#34;*\u0026#34;同时安全组和防火墙记得打开对应端口\n记得每次修改完配置都要重启 docker restart elasticsearch 浏览器访问测试 http://[IP]:9200 看到类似以下的json就成功了\n{ \u0026#34;name\u0026#34;: \u0026#34;8c819d377714\u0026#34;, \u0026#34;cluster_name\u0026#34;: \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34;: \u0026#34;-AkgwTlbS1SsjvzNtG45nw\u0026#34;, \u0026#34;version\u0026#34;: { \u0026#34;number\u0026#34;: \u0026#34;7.10.1\u0026#34;, \u0026#34;build_flavor\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;build_hash\u0026#34;: \u0026#34;1c34507e66d7db1211f66f3513706fdf548736aa\u0026#34;, \u0026#34;build_date\u0026#34;: \u0026#34;2020-12-05T01:00:33.671820Z\u0026#34;, \u0026#34;build_snapshot\u0026#34;: false, \u0026#34;lucene_version\u0026#34;: \u0026#34;8.7.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34;: \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34;: \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; }  如果无法访问到\n 如果开了安全组和防火墙的话还是无法访问到的话，看看在容器启动时是否有如下警告：\nWARNING: IPv4 forwarding is disabled. Networking will not work. 按如下步骤操作再访问即可\nvim /etc/sysctl.conf #添加如下代码： net.ipv4.ip_forward=1 #重启network服务 systemctl restart network #查看是否修改成功 sysctl net.ipv4.ip_forward #如果返回为“net.ipv4.ip_forward = 1”则表示成功了 #这时，重启容器即可。 安装elasticsearch-head 拉取镜像 docker pull mobz/elasticsearch-head:5 启动容器 docker run -it -d --name head -p 9100:9100 mobz/elasticsearch-head:5 浏览器打开\nhttp://[ip]:9100/ 在上面集群连接处的输入框输入elasticsearch的地址\nhttp://[IP]:9200 之后点击连接，右边的集群健康值字样出现绿色背景代表成功连接\n安装Kibana 拉取镜像 docker pull kibana:7.10.1 注意版本和ES的要对应\n配置文件kibana.yml 为了挂载配置文件，我们先在本机创建一个配置文件，这里以/home/kibana/config/kibana.yml 为例\n配置文件中写入\nserver.host:\u0026#39;0.0.0.0\u0026#39;elasticsearch.hosts:[\u0026#34;http://[ip地址]:9200/\u0026#34;]xpack:apm.ui.enabled:falsegraph.enabled:falseml.enabled:falsemonitoring.enabled:falsereporting.enabled:falsesecurity.enabled:falsegrokdebugger.enabled:falsesearchprofiler.enabled:false启动容器 docker run -d -it \\ --name kibana -p 5601:5601 \\ -v /home/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:7.10.1 浏览器打开\nhttp://[ip]:5601/ 安装ik分词器 首先进入es的容器内\ndocker exec -it elasticsearch /bin/bash 使用bin目录下的elasticsearch-plugin install安装ik分词器插件（注意版本要对应）\n# github官方 bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.10.1/elasticsearch-analysis-ik-7.10.1.zip 这里可能会很慢，可以用镜像加速\n# 镜像加速 bin/elasticsearch-plugin install https://github.91chifun.workers.dev//https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.10.1/elasticsearch-analysis-ik-7.10.1.zip 也可以选择本地下载解压完再上传到服务器，再把它移动到容器内的plugins文件夹里\n然后重启容器\ndocker restart elasticsearch 在kibana中测试 GET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;各地校车将享最高路权\u0026#34; } 有ik_smart 和 ik_max_word 两种模式，分别是最粗粒度的拆分和最细粒度的拆分\n","date":"2021-01-27T21:26:00+08:00","image":"https://ccqstark.github.io/p/es_docker/elastic-docker_hu1fc05f09d19ffda9f7576c23f66afe5c_19136_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/es_docker/","title":"[Elastic]使用docker安装ElasticSearch + Kibana"},{"content":"随着移动互联网发展，用户和数据量越来越多，对应用系统提出了更高的要求，系统必须支持高并发访问和海量数据处理。\n分布式系统技术就是用来解决集中式架构的性能瓶颈问题。一般来说，分布式系统是建立在网络之上的硬件或者软件系统，彼此之间通过消息等方式进行通信和协调。\n分布式系统的核心是可扩展性，通过对服务、存储的扩展，来提高系统的处理能力，通过对多台服务器协同工作，来完成单台服务器无法处理的任务，尤其是高并发或者大数据量的任务。\n单点故障（Single Point Failure）是指在系统中某个组件一旦失效，这会让整个系统无法工作。而分布式系统的设计就是为了避免出现单点故障问题，为了实现一个节点的失效不影响整个系统的运行。\n无状态，是因为无状态的服务才能满足部分机器宕机不影响全部，可以随时进行扩展的需求。\n由于分布式系统的特点，在分布式环境中更容易出现问题，比如节点之间通信失败、网络分区故障、多个副本的数据不一致等，为了更好地在分布式系统下进行开发，学者们提出了一系列的理论，其中具有代表性的就是 CAP 理论。\n  一致性是指“所有节点同时看到相同的数据”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，等同于所有节点拥有数据的最新版本。\n可用性是指“任何时候，读写都是成功的”，即服务一直可用，而且是正常响应时间。平时会看到一些 IT 公司说系统稳定性已经做到 3 个 9、4 个 9，即 99.9%、99.99%，这里的 n 个 9 就是对可用性的一个描述，叫做 SLA，即服务水平协议。比如我们说月度 99.95% 的 SLA，则意味着每个月服务出现故障的时间只能占总时间的 0.05%，如果这个月是 30 天，那么就是 21.6 分钟。\n分区容忍性具体是指“当部分节点出现消息丢失或者分区故障的时候，分布式系统仍然能够继续运行”，即系统容忍网络出现分区，并且在遇到某节点或网络分区之间网络不可达的情况下，仍然能够对外提供满足一致性和可用性的服务。\n在分布式系统中，由于系统的各层拆分，P 是确定的，CAP 的应用模型就是 CP 架构和 AP 架构。分布式系统所关注的，就是在 Partition Tolerance 的前提下，如何实现更好的 A 和更稳定的 C。\nCAP 理论说明在架构设计中，不要把精力浪费在如何设计能满足三者的完美分布式系统上，而要合理进行取舍，因为三者无法完全兼得。\n不同业务对于一致性的要求是不同的。例如，在微博上发表评论和点赞，用户对不一致是不敏感的，可以容忍相对较长时间的不一致，只要做好本地的交互，并不会影响用户体验；而我们在电商购物时，产品价格数据则是要求强一致性的，如果商家更改价格不能实时生效，则会对交易成功率有非常大的影响。\n需要注意的是，CAP 理论中是忽略网络延迟的，也就是当事务提交时，节点间的数据复制一定是需要花费时间的。即使是同一个机房，从节点 A 复制到节点 B，由于现实中网络请求总是需要一定时间的，所以总会有一段时间不一致。\n CP 架构：对于 CP 来说，放弃可用性，追求一致性和分区容错性。\n🔧 ZooKeeper就是采用了 CP 一致性，ZooKeeper 是一个分布式的服务框架，主要用来解决分布式集群中应用系统的协调和一致性问题。其核心算法是 Zab，所有设计都是为了一致性。在 CAP 模型中，ZooKeeper 是 CP，这意味着面对网络分区时，为了保持一致性，它是不可用的。\n AP 架构：对于 AP 来说，放弃强一致性，追求分区容错性和可用性，这是很多分布式系统设计时的选择，后面的 Base 也是根据 AP 来扩展的。\n📦 和 ZooKeeper 相对的是 Eureka，Eureka 是 Spring Cloud 微服务技术栈中的服务发现组件，Eureka 的各个节点都是平等的，几个节点挂掉不影响正常节点的工作，剩余的节点依然可以提供注册和查询服务，只要有一台 Eureka 还在，就能保证注册服务可用，只不过查到的信息可能不是最新的版本，不保证一致性。\n","date":"2021-01-21T23:01:00+08:00","permalink":"https://ccqstark.github.io/p/cap/","title":"什么是CAP理论？"},{"content":"为了提高在mac下连接ssh的效率，我们可以用alfred和iTerm配合，达到只要在输入框中输入ssh [主机名] 就可以快速连上了，效果如下图：\n \n使用ssh config 在~/.ssh/config文件里添加服务器信息，没有的话就新建一个\nvim ~/.ssh/config然后在文件中输入主机的信息，有多个主机就追加在后面就行\nHost [主机名] HostName [ip] User root Port [端口]使用密钥登陆 如果本地的~/.ssh 目录下没有id_rsa 私钥文件，可以是使用下面这个目录生成，一路回车即可，如果已经有了就可以跳过这步\nssh-keygen然后将私钥复制到远程服务器\nssh-copy-id -i -p[端口号] root@ip按提示输入一次密码，就会自动将刚才生成的公钥id_rsa.pub追加到远程主机的~/.ssh/authorized_keys后面了，这样以后的 ssh 连接都不用输入密码了\n安装alfred-ssh插件 https://github.com/deanishe/alfred-ssh\n到上面github链接下载最新版：Secure-SHell的alfredworkflow，双击自动添加到alfred的workflow\n添加后打开alfred的偏好设置可以看到效果如下：\n  测试用alfred输入ssh+主机名就可以连上服务器了，但是默认是用mac自带但终端，想用好看的iTrem2还需要进一步操作\n安装alfred集成iTerm2配置 如下图，打开iTrem2的偏好设置，如下图设置默认方式为ssh\n  进入下面github链接，按说明操作\nhttps://github.com/vitorgalvao/custom-alfred-iterm-scripts\n  按上面要求运行命令并粘贴到对应地方就完成了！\n参考文章： 开发效率神器之alfred集成ssh+iTerm2实现一步登录服务器\n","date":"2021-01-10T16:35:00+08:00","image":"https://ccqstark.github.io/p/alfred_iterm/ssh_hu16ae618dcf0f79ca9c769a7fb0762a5e_66847_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/alfred_iterm/","title":"Alfred + iTerm2 快速ssh连接服务器"},{"content":"DevOps现在非常流行，CI/CD持续集成、持续部署也大火，而Jenkins就是自动化部署主要的工具之一。\n这篇博客就来详细介绍用jenkins来实现自动化部署springboot项目的docker容器，堪称保姆级教学了。\n用docker拉取jenkins镜像，启动Jenkins容器 这里采用的jenkins本身也是用docker容器部署的，不得不说docker确实好用，当然也可以直接运行在主机上\n首先拉取Jenkins镜像 docker pull jenkins/jenkins ⚠️注意：切勿docker pull jenkins，已经废弃\n启动Jenkins容器 docker run -u root -itd --name jenkins \\ -p 6001:8080 \\ -v $(which docker):/usr/bin/docker \\ -v /var/run/docker.sock:/var/run/docker.sock -e TZ=\u0026#34;Asia/Shanghai\u0026#34; \\ -v /etc/localtime:/etc/localtime:ro \\ -v /volume1/docker/jenkins:/var/jenkins_home \\ jenkins/jenkins  -p 6001:8080Jenkins默认网页访问端口为8080，将端口映射到外部主机6001端口 -v $(which docker):/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock使Jenkins内部可以使用docker命令 -e TZ=\u0026quot;Asia/Shanghai\u0026quot; -v /etc/localtime:/etc/localtime:ro配置Jenkins容器的时区 -v /volume1/docker/jenkins:/var/jenkins_home 将Jenkins的配置映射到外部主机卷，容器删除仍可保留配置  测试Jenkins容器内部 # 进入Jenkins的容器内部 docker exec -it jenkins bash # 判断docker命令是否正常执行 docker info 访问Jenkins网页端 用http://主机IP:6001 就可以访问Jenkins的网页端了\nJenkins初始化 访问页面后需要输入初始密码，用cat 命令查看一下页面上给出的路径就可以获得初始密码，复制进去后就可以成功进入\n  到插件这里就选择安装推荐插件即可，等待安装完毕，速度稍慢。如果很多插件一直安装失败可以等下一步配置国内源之后再安装\n  然后按提示创建一个自己的管理员账户\n如果想重启Jenkins：\n在jenkins主页网址后加上/restart 后回车，点击确定即可\n安装插件和必要配置 修改插件国内源并安装其它插件 点击侧边栏系统管理→插件管理→高级\n将图中所示URL的输入中的链接改为阿里的：\nhttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json 安装一些插件 在插件管理中选择可选插件\n安装Maven Integration和Docker的插件，安装完重启\n全局工具配置 点击系统管理→全局工具配置\nJDK\n  用docker inspect jenkins 查看JAVA_HOME 路径后填入即可，这是个openjdk1.8，刚好用于项目，因为jenkins就是Java开发的\nGit\n  用默认即可\nMaven\n  可以用外部安装的，这里因为下了插件就用Jenkins里的插件就行，点击自动安装\nDocker\n  都好了之后点应用在点保存\nJenkins容器内使用vim 进入Jenkins容器内部后想使用vim的话还需要额外安装，后面需要用到vim\n# 更新一下软件源 apt-get update # 安装vim apt-get install vim 这里可能比较慢，就等一下，但只需用一次就不额外换源了\n修改maven插件的镜像源 因为jenkins在容器内，所以要进入容器内\ncd到目录~/.m2 下，ls 一下发现只有一个repository 目录，这个就是默认的maven仓库目录，然后就vim settings.xml 新建一个配置文件\n在命令模式下用:set paste 开启粘贴模式，然后把下面内容粘贴进去，记得检查一下内容和编码是不是utf-8\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;settings xmlns=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\u0026#34;\u0026gt; \u0026lt;localRepository\u0026gt;~/.m2/repository\u0026lt;/localRepository\u0026gt; \u0026lt;pluginGroups\u0026gt; \u0026lt;/pluginGroups\u0026gt; \u0026lt;proxies\u0026gt; \u0026lt;/proxies\u0026gt; \u0026lt;servers\u0026gt; \u0026lt;/servers\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;nexus-aliyun\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;*\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;Nexus aliyun\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt; 重启jenkins，之后下载包时发现已经更改为阿里源了\n创建项目准备自动化部署 左侧边栏新建一个任务，选择maven项目\n   \n添加GitHub仓库源码 这里用GitHub做代码仓库，也可以gitlab\n有2种方式：https和ssh\n  如果是https的话添加Credentials 的时候就直接配置自己的GitHub用户名和密码，仓库的URL填写github仓库的url就行\n如果是ssh的话要配置密钥，点击系统管理→Manage Credentials →全局 ,点击左侧边栏添加凭据\n  如果之前生成过，在自己机器上的~/.ssh 下cat一下就行，没有的话就ssh-keygen 生成\n注意此时url就要用ssh://git@github.com/[用户名]/[项目名].git 的格式\n加快代码拉取速度 为了加快构建速度，勾选此选项可以使jenkins不拉取代码的历史版本，从而加快构建速度\n  勾选浅克隆\n  初次之外，不要在本地打出jar包，不然这么大一个文件上传到仓库再被拉取很费时间\n构建触发器  \n添加maven构建步骤  ### 构建脚本\n这里是运行一些shell脚本来构建docker镜像和运行容器的\n  脚本如下，记得在项目目录下写好一个Dockerfile\n# 进入项目目录 cd /var/jenkins_home/workspace/[项目名] # 执行构建Dockerfile命令 docker build -f Dockerfile -t [镜像名]:[tag] . # 停止之前的容器运行 docker stop [容器名] # 删除之前的容器 docker rm [容器名] #运行刚刚创建的容器 docker run -d --name [容器名] -p [映射端口]:8080 [镜像名]:[tag] echo \u0026#34;构建完成\u0026#34; Dockerfile参考：\nFROMopenjdk:8MAINTAINER[作者]ADD /target/[项目名]-0.0.1-SNAPSHOT.jar [项目名].jarEXPOSE8080ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/[项目名].jar\u0026#34;]push触发构建 为了实现只要我们一向代码仓库push就可以自动进行构建，我们需要配置webhook\n点击系统管理→系统配置 ，找到GitHub选项，点击高级\n按下图操作：\n  打开自己GitHub项目页面\n  粘贴刚刚复制的地址\n  下面勾选Pushes和Active ，最后点击添加即可\n点击项目内左侧栏的立即构建 可以手动开始构建\n在进程中点击控制台输出 看到构建过程中的日志信息，这些信息很重要我们经常要看，用来发现构建过程中的错误\n清除无用的镜像 docker image prune 在多次构建之后可能会发现一些为none的镜像，用此命令清除\n配置邮箱通知 在这之前保证安装了相关插件，如果一开始是选安装推荐插件那应该都安装了\n点击系统管理→系统配置\n先配一下管理员邮箱\n  然后拉到下面，按图中配置，这个邮箱要填刚刚上面的管理员邮箱\n注意里面的密码是开启SMTP的密码，不是邮箱的密码\n然后可以点击发送测试邮件试试\n  上面还有一个Extended E-mail Notification 也配一下，也按这些信息填写\nDefault Recipients 是默认接收通知的邮箱，可以填写多个，用英文半角逗号隔开\nDefault Triggers 也可以配置一下，是触发邮件的事件\n  这里有个坑，在系统设置配置完之后，在项目里面的设置记得也要配置完整\n进入要发送邮箱功能的项目的配置\n  再点击增加构建后操作步骤\n    点击高级设置后设置触发条件\n  其他的诸如Content Type和Default Content 之类的就按需求配就行\n之后在控制台输出就可以看到构建项目到最后有发邮件的步骤日志\n主题美化 可以参考下面这篇文章，个人觉得还是习惯于原版\nJenkins自定义主题教程_FlyWine的博客-CSDN博客_jenkins自定义界面\n参考文章：\n最优雅的Docker+Jenkins pipeline部署Spring boot项目\nJenkins+Docker+github+Spring Boot自动化部署_linfen1520的博客-CSDN博客\njenkins+git+maven+docker持续集成部署_自动化_运维开发网_运维开发技术经验分享\nJenkins - SSH认证方式拉取Git代码\ncentos7的Jenkins的maven插件的settings.xml配置文件路径在哪里_festone000的专栏-CSDN博客\n","date":"2021-01-09T23:01:00+08:00","image":"https://ccqstark.github.io/p/jenkins_docker_springboot/jenkins-cicd_huac9b8bcc40d9704ef8edb1ad38827231_44206_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/jenkins_docker_springboot/","title":"Jenkins + docker + springboot 完美配合全流程教程"},{"content":"如果是单体应用的话nginx用docker部署其实是更麻烦的，不过既然操作过就记录一下。\n拉取nginx镜像 docker pull nginx 还是一样，默认是拉取latest版本，也可以选择想要的特定版本\n启动并挂载html目录 docker container run \\  -d \\  -p 80:80 \\  --name mynginx \\  --v [本机挂载目录]:/usr/share/nginx/html \\  nginx 复制出配置文件 docker container cp mynginx:/etc/nginx . 将复制出来的文件夹改名并移动到你想要的目录下，然后把容器停止并删除\n挂载配置文件目录 最后一步就是重新启动一个容器并把html和配置文件目录都挂载了\ndocker run \\  --name test-nginx \\  -v [本机挂载html目录]:/usr/share/nginx/html \\  -v [本机挂载nginx目录]:/etc/nginx \\  -p 80:80 \\  -d \\  nginx 访问一下试试就可以了！\n参考：\nNginx 容器教程\n","date":"2021-01-08T15:46:00+08:00","image":"https://ccqstark.github.io/p/docker_nginx/nginx-docker_hu2ff739cd1ceaefb705a9e30c4218e66c_86441_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/docker_nginx/","title":"[docker]用docker部署nginx"},{"content":"这篇文章介绍的是把整个Springboot后端项目部署到docker容器中，当然包括mysql和redis\n按下面步骤一步步来\n本地打出jar包 以Maven的话直接就IDEA里打出jar包到target目录下，这一步和以前一样\n编写Dockerfile 可以用IDEA里的插件来写，也可以自己写dockerfile\n在项目文件夹下新建一个文件Dockerfile\nFROMopenjdk:8MAINTAINERccqstarkADD /target/[项目jar包名].jar app.jarEXPOSE8080ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/app.jar\u0026#34;]⚠️注意：ADD后两个参数，第一个是项目jar包的相对路径，第二是把jar包在容器内重新命的名\n构建镜像 在Dockerfile所在文件夹下运行build 命令，注意最后有一个.\ndocker build -f Dockerfile -t [镜像名]:[版本tag] .构建之后用docker images 查看一下自己构架的镜像\n构建完之后本地run一下容器测试下\npush上传到镜像仓库 其实也可以把jar包上传服务器后用服务器的docker来构建和运行\n但这里采用的是把本地构建的镜像上传到repository，相当于镜像仓库，其他人想用这个镜像就可以从那拉取下来使用。\nrepository可以是官方的Docker Hub，但是比较慢，也可以花钱上传到阿里云的容器镜像服务就会快很多\n这里是上传到docker hub，首先要登陆自己到docker账号，没有的话可以去官网注册一个\ndocker login -u [账户名] 输入密码成功后登陆\n在push之前要给镜像打个tag，这样才能上传到自己账号对应的仓库下\ndocker tag [镜像名] [账户名]/[镜像仓库名]:latest 之后就可以上传了\ndocker push [账户名]/[镜像仓库名]:latest pull拉取镜像 docker pull [账户名]/[镜像仓库名]:[tag] 在服务器上拉取到镜像后就可以启动容器了\ndocker run -it -d -p [对外暴露端口]:8080 app:[tag] 部署MySQL容器 # 拉取mysql镜像 docker pull mysql:5.7 # 跑起来 docker run \\ -d \\ -p 3306:3306 \\ -v /home/mysql/conf:/etc/mysql/conf.d \\ -v /home/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=[设置mysql到root密码] \\  --name [容器名] \\ mysql:5.7 mysql容器到暴露端口要和代码中配到一样就行\n这里还把配置目录和数据目录挂载了出来，避免容器停止后数据丢失\n部署redis容器 # 拉取redis镜像 docker pull redis # 运行，这个时候指定密码，不指定默认为空 docker run -d --name myredis -p 6379:6379 redis --requirepass \u0026#34;mypassword\u0026#34; ⚠️注意：建议先把mysql和redis都部署好后再去启动jar包都镜像，防止应用启动时连不到它们而报错\n所有容器都成功启动起来之后就把整个后端部署到docker完毕了\n","date":"2021-01-07T21:39:00+08:00","image":"https://ccqstark.github.io/p/docker_springboot/docker-springboot_hu705e70abdc72815dabd2267940e19d94_40186_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/docker_springboot/","title":"[docker]用docker部署SpringBoot项目"},{"content":"Dockerfile介绍 dockfile是用来构建docker镜像的文件，命令参数脚本\n💡构建步骤：\n 编写dockerfile脚本 用docker build命令构建一个镜像 用docker run运行镜像 用docker push发布镜像（DockerHub、阿里云仓库）  在官网点击镜像会跳转到github对应的dockerfile\n可以发现这些镜像也是通过dockerfile来构建的\n  上图是centos的dockerfile，其中scratch是最基本的，90%都是基于这个镜像。\n然后ADD 就是添加来一层centos相关的镜像文件\n官方很多镜像都是基础包，功能很少，很多我们需要的都没有，所以我们通常都会构建自己的镜像。\n比如我们可以直接构建一个centos+jdk+tomcat+mysql的镜像，不就直接有来一个可以运行javaweb项目的环境镜像了吗？\nDockerfile构建过程 基本规则  每个关键字（保留字）都是大写的 执行顺序是从上到下的 \u0026ldquo;#\u0026rdquo; 表示注释 每一个指令都会创建一个新的镜像层，并提交    以前开发交付都是用jar包或war包，现在云原生时代交付的就是docker镜像，docker镜像也逐渐成为企业交付标准，而构建docker镜像就需要学会编写dockerfile\n什么是云原生？聊聊云原生的今生_阿里云开发者-CSDN博客\nDockerfile常用指令    指令关键字 作用     FROM 构建镜像所用的基础镜像   MAINTAINER 镜像作者，一般是姓名+邮箱   RUN 镜像构建时运行的命令   ADD 为镜像添加内容   WORKDIR 镜像的工作目录   VOLUME 挂载目录   EXPOSE 暴露的端口   CMD 容器启动时需要运行的命令，只有最后一个会生效，可被替代   ENTRYPOINT 也是指定启动时需要运行的命令，但是可以追加   ONBUILD 构建一个被继承的dockerfile时会运行ONBUILD的指令。触发指令   COPY 类似ADD，将文件拷贝到镜像中   ENV 构建时设置的环境变量    实践：构建自己的centos 举个例子：\nFROMcentos # centos为基础镜像MAINTAINERccqstark\u0026lt;xxxxxx@qq.com\u0026gt; # 作者名和邮箱ENV MYPATH /usr/local # 环境变量WORKDIR$MYPATH # 工作目录# 安装vim和ifconfig命令RUN yum -y install vim RUN yum -y install net-toolsEXPOSE80CMD echo $MYPATHCMD echo \u0026#34;---end---\u0026#34;CMD /bin/bashdocker build 之后 run 起来就可以使用了！\n还可以使用下面命令查看镜像构建的过程\ndocker history [镜像id] 参考自狂神的docker教程\n","date":"2021-01-06T21:13:00+08:00","image":"https://ccqstark.github.io/p/dockerfile/dockerfile_hua2299a9fb0d8a75d7ada60f608a774d6_160236_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/dockerfile/","title":"[docker]初识Dockerfile"},{"content":"把容器内的目录挂载到宿主机的某一个目录下，实现双向同步。\n也就是说两者都指向了同一文件目录下，在其中一端所做的修改都会同步。\n好处：\n MySQL数据持久化，不会因为删了容器就没了 方便修改文件，比如nginx的配置文件  基本使用 bind mounts 以启动一个centos容器为例\ndocker run -it -v [宿主机目录]:[容器内目录] centos /bin/bash -it ：-t选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开，通常写成-it\n-v ：挂载卷所需参数，后面的映射是[宿主机目录]:[容器内目录]\n用此命令查看容器参数\ndocker inspect [容器id]   如上图，在Mounts 字段中可以看到：\nSource 表示宿主机中被映射的目录\nDestination 表示容器内要映射的目录\n这种挂载方式称为bind mounts\n实践：MySQL挂载 拉取mysql镜像 docker search mysql docker pull mysql:5.7 启动容器 -d 后台运行\n-p 端口映射\n-v 数据卷挂载\n—name 容器名字\ndocker run \\ -d \\ -p 3310:3306 \\ -v /home/mysql/conf:/etc/mysql/conf.d \\ -v /home/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=[你配置的mysql密码] \\ --name [容器名] \\ mysql:5.7 -v可以一次写多个来多次挂载\n连接测试 运行成功后用navicat连接下试试\n 主机地址还是服务器公网ip 端口是映射出来的暴露端口，比如上面命令中的3310 密码就是-e MYSQL_ROOT_PASSWORD设置的密码  可以创建新的数据库看看宿主机对应映射目录下有没有同步出现新数据库的文件\n删除测试 docker rm -f [mysql容器名] 运行上面的指令删除掉容器，再在主机下查看/home/mysql/data 目录发现数据依旧都还在\n如果再次启动一个容器数据就还是和删除前一样，从而保证了数据安全，这就是MySQL数据卷挂载\n匿名挂载和具名挂载 volumes 匿名挂载 -P 随机映射端口\ndocker run -d -P --name nginx01 -v /etc/nginx nginx 如上图的命令，-v 是没有指定外部目录的，只写了内部目录，所以是匿名挂载，使用下面命令查看挂载的卷\ndocker volume ls 发现卷名是随机生成的字符串，所以是匿名的\n \n具名挂载 docker run -d -P --name nginx01 -v [自己起的卷名]:/etc/nginx nginx [卷名]:[目录名] 这样指定了卷名的形式就是具名挂载\n这样再用docker volume ls 看到的卷名就是自己指定的了\n查看挂载的目录 docker volume inspect [卷名] 用这条命令就可以查看卷的一些信息，其中Mountpoint 就是所挂载的外部目录\n  所以这种在没有指定目录的情况下（具名或匿名）都是挂载在/var/lib/docker/volumes/[卷名]/_data这个目录的\n大多数情况下都是用具名挂载\n这两种挂载方式统称volumes\n总结 -v [内路径] 匿名挂载 -v 卷名:内路径 具名挂载 -v 宿主机路径:容器内路径 指定路径挂载\n扩展 可以用参数改变读写权限\nro 只读，容器内不可修改，容器外可以\nre 可读可写\ndocker run -d -P --name nginx02 -v ccq-nginx:/etc/nginx:ro nginx docker run -d -P --name nginx02 -v ccq-nginx:/etc/nginx:rw nginx 使用Dockerfile来构建和挂载 Dockerfile是用来构建docker镜像的构建文件，里面就是构建的脚本\n这个文件可以用来生成镜像，由于镜像是一层一层的，所以脚本命令也是一句句对应一层层的\n以centos来举个例子，在dockerfile里写下下面这些内容：\nFROMcentos # 由哪个原始镜像构建VOLUME [\u0026#34;volume01\u0026#34;,\u0026#34;volume02\u0026#34;] # 挂载，此处匿名CMD echo \u0026#34;---end---\u0026#34;CMD /bin/bash运行构建命令如下：\ndocker build -f [dockerfile路径] -t [镜像名]:[版本tag] [生成目录] 然后用命令docker images 就可以看到自己刚刚构建的镜像了，docker run 就可以跑起来\n之后也可以docker inspect 查看挂载情况，挂载同样是数据内外目录同步的\n数据卷容器 之前是容器内的目录挂载到容器外到到目录，现在是一个容器挂载到另一个容器\n这样就实现了容器之间到数据同步\n—-volumes-from 使用此参数开启一个容器挂载到另一个容器\n被挂载的称为父容器\ndocker run -it --name [名字] --volumes-from [父容器名] [镜像名]:[版本tag] 测试一下，开两个容器，进入挂载到一起的目录创建文件试试，发现数据是同步的\n多重挂载 可以开启第三个容器挂载到第一或第二个容器，发现现在这3个容器对应到目录的数据都是同步的\n所以挂载其实是可以套娃的\n卷的挂载机制 不同容器的挂载机制并不是映射到单一到文件夹下的，如果这样的话其中一个容器被删除的话，其它所有容器对应都数据都会消失。\n实际上挂载是一种拷贝的机制，数据是有多份相同的备份的，删除一种一份其它的都还在，不会消失的，只是会占用更多的存储空间\n  只有把挂载这一卷的所有的容器都删除，这个卷才会消失\n当然，如果是bind到本地的目录那就删除全部容器数据也仍然在本地\n参考自狂神的docker教程\n","date":"2021-01-06T16:51:00+08:00","image":"https://ccqstark.github.io/p/docker_volumes/docker_hu22e70eb00a1bc79d3e2af88d0f9ef83b_73329_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/docker_volumes/","title":"[docker]容器数据卷"},{"content":"终于从Windows转到心心念念的MacOS上进行开发，虽然是黑苹果但是软件层面上没有太大的区别，程序员还是得用mac啊这终端上真的比windows好用无数倍，那终端到手后还是要折腾美化的，那就开始吧。 先看下我，还可以吧？ 准备工作 先保证自己下载homebrew和wget，安装软件或下载包很多情况下要用到它们，特别homebrew是mac下最好用的包管理器一定要有。下载方法网上也很多的，建议先下homebrew再用它下wget。\niTerm2 首先是下载第三方终端iTerm2，mac自带的终端用的比较少，大家用的最多还是这个。 官网下载\nzsh zsh是shell的一种，mac默认的shell是bash，一般来说我们也是用zsh比较多，因为命令更多更好用。\n下载zsh brew install zsh 切换shell为zsh # 查看当前使用的shell echo $SHELL # 切换为zsh chsh -s /bin/zsh 运行完上面命令后重启一下即可\noh-my-zsh oh-my-zsh用于美化终端，可以让你拥有很多好看的主题。\n安装 wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh sh install.sh 运行上面的命令来下载安装脚本并运行脚本，成功后会有如下画面\n更换主题 oh-my-zsh有很多默认的主题，可以在~/.zshrc中修改ZSH_THEME来切换不同主题。 这里我推荐powerlever10k，它集合了很多不同主题风格的样式，支持自定义，如果默认主题中没有你满意的那推荐就用它。下面就讲powerlevel10k的安装方法。\n下载 git clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 安装所需字体 # 安装 nerd-font 字体 brew tap homebrew/cask-fonts # 其他所需字体 cd ~ git clone https://github.com/powerline/fonts.git --depth=1 # 到目录下执行安装脚本 cd fonts ./install.sh # 删除刚刚下载的 cd .. rm -rf fonts 配置 vim ~/.zshrc 进入zsh配置文件中修改并增加\nZSH_THEME = \u0026#34;powerlevel10k/powerlevel10k\u0026#34; [[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh 之后启动向导\np10k configure 可以用下面命令查看颜色代号\nfor i in {0..255}; do print -Pn \u0026#34;%K{$i} %k%F{$i}${(l:3::0:)i}%f \u0026#34; ${${(M)$((i%6)):#3}:+$\u0026#39;\\n\u0026#39;}; done 接下来需要下载一些必要的字体或样式，在此之前需要先改host以正常下载 下载软件SwitchHosts! 之后如图加上\n199.232.68.133 raw.githubusercontent.com 199.232.68.133 user-images.githubusercontent.com 199.232.68.133 avatars2.githubusercontent.com 199.232.68.133 avatars1.githubusercontent.com 开启My hosts后重启终端，就会自动提示下载所需字体，耐心等待它下载完（有点慢）后，就可以根据引导一步步自定义属于自己的主题了！从图标到字体颜色风格到显示信息都可以自定义！\n背景透明+毛玻璃 打开iTerm2的偏好设置按下图即可调节背景透明和毛玻璃，下面还可以设置默认窗口大小。\n快捷键唤醒 如何让切出终端更快捷？可以设置Hotkey 按下图操作\n尾声 至此，一个好用又好看的mac终端基本配置完毕啦\n其他有趣的可以看下这篇博客讲的\n","date":"2021-01-06T02:07:00+08:00","image":"https://ccqstark.github.io/p/mac_terminal/Mojave-desktop_hu0caf60027e85952cdd6ae94392d12e9b_35582_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/mac_terminal/","title":"MacOS终端美化指北"},{"content":"事情经过 11月17号这天早上上着课，突然有用户反馈应用卡顿，使用不了。我感觉上去看了果然是这样，有时数据加载很慢甚至加载不出来，我感到焦虑与害怕，害怕数据库和别人一样被黑了然后删光要钱，课都没心情听了。然后手机下了个Termius，先把服务关了。\n中午回到宿舍后看了数据库发现数据完好无损，赶紧备份了一波，然后寻找问题。\n内存和CPU和磁盘都挺正常，看了服务器的安全日志，那登录记录刷刷的，有人在暴力破解我的root密码！\n由于下午还有体育课，就先直接关了服务器，然后上课去了。\n下午来到实验室，重新打开服务器，又开始攻击了，气死了。用脚本封了攻击者一百多个肉鸡ip，以为可以了之后，把服务开启，通知用户可以用了。\n结果用户又说太卡了，我又检查了一波，CPU、内存、磁盘正常，然后这个带宽就不太正常了，我学生机的1M/s都超了，应该是这个原因导致卡的。\n用命令找了进程发现好像也没哪个占用很多呀，弄了很久还是很迷惑，攻击者的ip也明明被我加入黑名单了呀，之后还开了腾讯云的专业机阻断，还是很卡，卡到我ssh都连不太上。然后有个办法叫我改ssh的22端口，我怕操作失误连自己都直接连不上就GG了，然后就算了不这样搞了。\n最后只能屁颠屁颠去找客服，他跟我说也是其他正常带宽跑满，叫我看有没有什么进程占用很多，主要是建议我临时升级带宽。\n我想着：啊好家伙，开始了。但是也没啥其他办法，就去买了3天升级到3M/s的带宽，不贵，结果也是真香。\n后来最多手动在安全组加了几个奇怪ip封掉，服务就完成稳定下来了，看来没有什么是加钱不能解决的。\n后来过了两天攻击者还在继续冲，除了影响我带宽之外其实也没太大问题反正他进不来的，问了师兄建议说改22端口，反正重要使用期也过了，我就试试改下，还真有用，安全日志也没攻击者那些破解记录了，带宽也占用也再降了，说明攻击者也是冲22，这下直接完全被挡住，带宽也不占了。\n第一次与黑客对线还是学到了很多的，也加强了我的安全防范意识\n查看系统状态命令 下面有些命令工具需要额外安装的，直接yum install xxx安装就行\n查看服务器安全日志(动态实时)(CentOS) tail -f /var/log/secure 查看CPU等的使用情况(按进程) top 查看内存使用情况 free -h 查看磁盘使用情况 df -hl 查看网络带宽占用(按ip) iftop -i eth0 jnettop 按Q退出\n查看网络带宽占用(按进程) nethogs 还有防火墙工具iptables和firewall-cmd\nhttps://wangchujiang.com/linux-command/c/iptables.html\nhttps://wangchujiang.com/linux-command/c/firewall-cmd.html\n编写自动化脚本封禁暴力破解登录的ip 从安全日志中读取记录，把那些多次登录失败的ip写进请求黑名单中（hosts.deny），但是这种办法只是拒绝连接，如果黑客继续攻击还是会占用带宽\n先找个目录，vim建立一个脚本文件\nvim /usr/local/secure_ssh.sh 然后编写脚本\n#! /bin/bash cat /var/log/secure|awk \u0026#39;/Failed/{print $(NF-3)}\u0026#39;|sort|uniq -c|awk \u0026#39;{print $2\u0026#34;=\u0026#34;$1;}\u0026#39; \u0026gt; /usr/local/bin/black.txt for i in `cat /usr/local/bin/black.txt` do IP=`echo $i |awk -F= \u0026#39;{print $1}\u0026#39;` NUM=`echo $i|awk -F= \u0026#39;{print $2}\u0026#39;` result=$(cat /etc/hosts.deny | grep $IP) if [[ $NUM -gt 10 ]];then if [[ $result = \u0026#34;\u0026#34; ]];then echo \u0026#34;sshd: $IP\u0026#34; \u0026gt;\u0026gt; /etc/hosts.deny fi fi done 设置定时任务\n#首先打开定时任务列表 crontab -e #添加下面这行，表示每十分钟 */10 * * * * bash /usr/local/secure_ssh.sh #保存退出后重启下 service crond restart 修改sshd的22端口 这个方法可以完全把对22端口的攻击直接拒之门外，安全日志都没记录破解登录事件，带宽也不会影响，但操作过程要小心一点点\n修改sshd配置文件\nvim /etc/ssh/sshd_config #Port 22 //这行去掉#号，然后在下面增加自己要新开的端口，保证新端口能用再去掉这行 下面新增端口\nPort xxxxx 防火墙开启对应端口，安全组也记得开，或者先把防火墙关了，之后试了新端口能用再开\nfirewall-cmd --zone=public --add-port=xxxxx/tcp --permanent\r重启sshd\n/etc/init.d/sshd restart #或者 service sshd restart 然后重新连服务器终端试试，没问题之后可以把22直接禁掉，防火墙和安全组也封了22，对新端口放行就行\n其他 使用强密码或者只用密钥登录\n数据库多做备份\n建立快照\n关键数据加密\n要增强安全意识呀！\n","date":"2020-11-22T22:10:00+08:00","permalink":"https://ccqstark.github.io/p/first_attack/","title":"记一次服务器被攻击"},{"content":"问题引入与研究目标 目标检测的数据集的收集往往是在现实场景中进行的，因此数据中目标的外观、背景、光照、图像质量等方面的巨大差异会导致训练数据和测试数据之间出现巨大的领域偏移。比如汽车在不同天气条件下驾驶收集到的数据，或者是相机的类型和设置的不同也会导致数据的领域偏移。这样的偏移会导致性能显著下降，尽管收集尽可能多的数据集可以降低这种影响，但是注释边界框也是一个费时费力的过程，因此开发一个新的算法来应对跨领域目标检测问题就尤为重要。\n论文中方法适用于无监督场景，在源域有完整的监督，而在目标域没有监督。这样就可以不增加人工标注成本的前提下减少跨域对目标检测效率的影响。\n关键术语介绍 目标检测 Object Detection 目标检测，也叫目标提取，是一种基于目标几何和统计特征的图像分割，它将目标的分割和识别合二为一，其准确性和实时性是整个系统的一项重要能力。尤其是在复杂场景中，需要对多个目标进行实时处理时，目标自动提取和识别就显得特别重要。目标检测主要有三个层次：\n一是分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其他任务提供了基础。在应用领域，人脸、场景的识别等都可以归为分类任务。\n二是检测（Detection）。分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置），因而，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。\n三是分割（Segmentation）。分割包括语义分割（semantic segmentation）和实例分割（instance segmentation），前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。\n领域自适应 Domain Adaptation 领域自适应（Domain Adaptation）是迁移学习中的一种代表性方法，指的是利用信息丰富的源域样本来提升目标域模型的性能。 领域自适应问题中两个至关重要的概念：\n源域（source domain）表示与测试样本不同的领域，但是有丰富的监督信息\n目标域（target domain）表示测试样本所在的领域，无标签或者只有少量标签。源域和目标域往往属于同一类任务，但是分布不同\n根据目标域和源域的不同类型，领域自适应问题有四类不同的场景：无监督的，有监督的，异构分布和多个源域问题。 通过在不同阶段进行领域自适应，研究者提出了三种不同的领域自适应方法：\n1）样本自适应，对源域样本进行加权重采样，从而逼近目标域的分布。\n2）特征层面自适应，将源域和目标域投影到公共特征子空间。\n3）模型层面自适应，对源域误差函数进行修改，考虑目标域的误差。\n散度 Divergence 在机器学习中，我们常常需要用一个分布Q去逼近一个目标分布P，我们希望能够找到一个目标函数D ( Q , P ) D( Q,P)D(Q,P)，计算Q到P的距离。而这一个目标函数，正是Divergence(散度)，比如常见的KL-Divergence，JS-Divergence等等。通过这个散度的计算我们就能不断地去优化我们的Q，寻找一个最优的参数去逼近真实的分布P。\nFaster R-CNN Faster R-CNN是何凯明等大神在2015年提出目标检测算法，该算法在2015年的ILSVRV和COCO竞赛中获得多项第一。该算法在Fast R-CNN基础上提出了RPN候选框生成算法，使得目标检测速度大大提高。\n \n \nFaster-RCNN由下面几部分组成：\n  数据集，image input\n  卷积层CNN等基础网络，提取特征得到feature map\n  RPN层，再在经过卷积层提取到的feature map上用一个3x3的slide window，去遍历整个feature map,在遍历过程中每个window中心按rate，scale（1:2,1:1,2:1）生成9个anchors，然后再利用全连接对每个anchors做二分类（是前景还是背景）和初步bbox regression，最后输出比较精确的300个ROIs。 把经过卷积层feature map用ROI pooling固定全连接层的输入维度。\n  然后把经过RPN输出的rois映射到ROIpooling的feature map上进行bbox回归和分类。\n  交叉熵 cross entropy 交叉熵描述了两个概率分布之间的距离，当交叉熵越小说明二者之间越接近。\n在信息论中，基于相同事件测度的两个概率分布的交叉熵是指，当基于一个“非自然”（相对于“真实”分布而言）的概率分布进行编码时，在事件集合中唯一标识一个事件所需要的平均比特数。\n梯度下降 gradient descent 在机器学习算法中，在最小化损失函数时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。\n梯度下降在机器学习中应用十分的广泛，不论是在线性回归还是Logistic回归中，它的主要目的是通过迭代找到目标函数的最小值，或者收敛到最小值。\n \n基本思路 论文中为了解决域偏移问题，在Faster R-CNN模型中加入了图像级和实例级的两个域适应组件，从而来最小化两个域之间的h散度。在每个组件中，训练一个领域分类器，并使用对抗性训练策略来学习领域不变量的鲁棒特征。并且进一步整合不同层次的域分类器之间的一致性规则，在Faster R-CNN模型中学习一个域不变区域建议网络(RPN)。\n研究成果   从概率的角度对跨域目标检测的域移问题进行了理论分析。\n  设计了两个域自适应组件，以缓解图像级和实例级的域差异。\n  进一步提出了一致性正则化，以促进RPN变成领域不变的。\n  将提出的组件集成到Faster R-CNN模型中，得到的系统可以以端到端的方式进行训练。\n  与用于分类的领域适应研究相比，其他计算机视觉任务的领域适应研究较少。近年来在语义分割、精细识别等方面进行了研究。对于检测任务，提出通过引入自适应支持向量机来缓解可变形零件模型(DPM)的域漂移问题。在近期的研究中，其他研究者使用R-CNN模型作为特征提取器，然后用子空间对齐方法对特征进行对齐。也有从其他来源学习探测器的工作，例如从图像到视频，从3D模型，或者从合成模型。以前的工作要么不能以端到端的方式进行培训，要么侧重于特定的案例。在这项工作中，论文作者建立了一个用于目标检测的端到端的可训练模型，也是世界上第一个。\n领域适应组件 Domain Adaptation Components 映像级别适应 Image-Level Adaptation 在Faster R-CNN模型中，指的功能映射输出映像级别表示基本卷积的层。消除域分布不匹配在图像层次,采用patch-based域分类器。\n这种选择的好处:\n 对齐图像级表示通常有助于减少由全局图像差异引起的位移，如图像风格、图像尺度、光照等。类似的基于块的损失在最近的关于style transfer的工作中也被证明是有效的，它也处理全局变换 由于使用了高分辨率的输入，对于训练一个目标检测网络来说，批处理的大小通常非常小。这种基于块的设计有助于增加训练领域分类器的训练样本的数量。  用Di表示第i个训练图像的定义域标签，源域的Di= 0，目标域的Di= 1。将经过基卷积层后的第i幅图像的feature map位于(u, v)处的激活表示为φu,v(Ii)。将域分类器的输出表示为pi(u,v)，利用交叉熵损失，图像级自适应损失可表示为:\n \n实例级适应 Instance-Level Adaptation 实例级表示是指在输入到最终的类别分类器之前基于ROI的特征向量\n对齐实例级表示有助于减少本地实例差异，如对象外观、大小、视点等。与图像级自适应相似，研究者训练了一个针对特征向量的领域分类器来对齐实例级分布。\n将第i幅图像中第j个区域建议的实例级域分类器的输出表示为pi,j。实例级适应损失现在可以写成:\n \n一致性正规化 Consistency Regularization 加强不同层次的域分类器之间的一致性有助于学习边界盒预测器(即Faster R-CNN模型中的RPN)的跨域鲁棒性。因此，研究者进一步设置了一个一致性规则。由于图像级域分类器会为图像级表示的每次激活生成一个输出，因此取图像中所有激活的平均值作为其图像级概率。一致性调节器可以写成:\n \n网络概述 Faster R-CNN与2个组件之间的整合关系如下图：\n \n在每一层上构建一个领域分类器，以一种对抗性的训练方式进行训练。在这两个分类器中加入了一致性规则器，以学习用于Faster R-CNN模型的领域不变RPN。\n左边部分是原始的Faster R-CNN模型。底层的卷积层在所有组件之间共享。然后在其上构建RPN和ROI池化层，然后构建两个完全连接的层来提取实例级特征。\n从合成数据中学习 随着计算机图形技术的发展，利用合成数据训练CNN变得越来越流行。尽管如此，合成的数据与真实世界的图像仍然有明显的视觉差异，并且通常与在真实数据上训练的模型存在性能差距。研究者用不同于真实世界的合成数据进行试验。\n数据集:是SIM 10k由10000张由侠盗猎车手(GTA5)渲染的图像组成，在SIM 10k中，10000张训练图像中提供了58,701辆车的包围框。所有的图像都在训练中使用。Cityscapes数据集是一个城市场景数据集为驾驶场景。这些图像是由车载摄像机拍摄的。2975图像训练集,500图像验证集。使用的标记图像训练集作为目标域适应我们的检测器, 并报告结果验证集。\n结果：不同方法的结果如下表所示。具体来说，与Faster R-CNN相比，仅使用图像级自适应组件获得+2.9%的性能提升，而仅使用实例级对齐组件获得+5.6%的性能提升。这表明，图像级适应和实例级适应组件可以有效地减少各层次上的域漂移。将这两个部分结合在一起可以得到7.7%的改进，这验证了关于减少两层域移位的必要性的猜想。通过进一步应用一致性正则化，域自适应Faster R-CNN模型将更快的R-CNN模型提高了+8.8%。\n \n其它 为了验证模型的效果，研究者还通过恶劣天气中收集的图像数据、不同摄像机拍摄出来的图像数据对算法进行测试，结果都显示出不错的结果\n还进一步分析了图像级和实例级适应的影响，做了有关于图像级和实例级对齐的实验，验证了模型可以从更高分辨率的图像输入中获得更好的性能结果。实验结论是从200像素增加到1000像素。\n还做了实验研究了使用一致性正则化前后RPN的性能，发现RPN的性能可以进一步提高到30.3%，说明一致性调节器提高了RPN的鲁棒性。\n","date":"2020-11-22T22:07:00+08:00","permalink":"https://ccqstark.github.io/p/ml_domain_adaptation/","title":"[机器学习论文]Domain Adaptive Faster R-CNN for Object Detection in the Wild"},{"content":"问题 设A和B是2个字符串。要用最少的字符操作将字符串A转换为字符串B。这里所说的字符操作包括 (1)删除一个字符； (2)插入一个字符； (3)将一个字符改为另一个字符。 将字符串A变换为字符串B所用的最少字符操作数称为字符串A到 B的编辑距离，记为d(A,B)。 对于给定的字符串A和字符串B，计算其编辑距离 d(A,B)。\n输入格式: 第一行是字符串A，文件的第二行是字符串B。\n提示：字符串长度不超过2000个字符。\n输出格式: 输出编辑距离d(A,B)\n输入样例: 在这里给出一组输入。例如：\nfxpimu\rxwrs 输出样例: 在这里给出相应的输出。例如：\n5\r思路 用动态规划算法可以将问题分解出最优子结构。\n设dp[i][j]表示把A字符串前i个字符组成的字符串转变为B字符串前j个字符组成的字符串所需的最少的字符操作数\n如果A字符串的第i个字符与B字符串的第j个字符串相同，则这个位置不需要操作，所需的操作等于dp[i-1][j-1]，否则需要进行修改，操作数就要+1\n由于每个位置都可以进行修改、删除、插入三种操作，因此需要把这三种操作中编辑距离最小的作为dp[i][j]的值\n递推公式(代码表示)：\nif (A[i - 1] == B[j - 1]) // dp矩阵以1开始，字符数组是0开始，因此对应的话要-1 \tdp[i][j] = dp[i - 1][j - 1]; // 如果对应的位置相同就不用操作，否则要修改所以要+1 else dp[i][j] = dp[i - 1][j - 1] + 1; // 修改 删除 插入 dp[i][j] = min(dp[i][j], min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); 表的维度：二维\n填表的范围：（len_A和len_B分别为字符串A、B的长度）\ni：1 ~ len_A\nj：1 ~ len_B\n填表顺序：从左至右，自顶向下（i与j的递增方向）\n时间复杂度：由于填写的是二维表，需要二重循环，所以时间复杂度是O(n^2)\n空间复杂度：需要一个二维数组，因而是O(n^2)\n代码 // 编辑距离问题 #include \u0026lt;iostream\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 2002 char A[MAX]; char B[MAX]; int dp[MAX][MAX]; int calculate_distance() { // a、b字符串的长度  int len_a = strlen(A); int len_b = strlen(B); // 边界初始化  for (int i = 0; i \u0026lt;= len_a; i++) dp[i][0] = i; for (int j = 0; j \u0026lt;= len_b; j++) dp[0][j] = j; for (int i = 1; i \u0026lt;= len_a; i++) { for (int j = 1; j \u0026lt;= len_b; j++) { // dp矩阵以1开始，字符数组是0开始，因此对应的话要-1  if (A[i - 1] == B[j - 1]) // 如果对应的位置相同就不用操作，否则要修改所以要+1  dp[i][j] = dp[i - 1][j - 1]; else dp[i][j] = dp[i - 1][j - 1] + 1; // 修改 删除 插入  dp[i][j] = min(dp[i][j], min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); } } return dp[len_a][len_b]; } int main() { cin \u0026gt;\u0026gt; A \u0026gt;\u0026gt; B; cout \u0026lt;\u0026lt; calculate_distance(); } ","date":"2020-10-31T17:03:00+08:00","permalink":"https://ccqstark.github.io/p/dp_edit_distance/","title":"DP动态规划——编辑距离问题"},{"content":"题目 假设要在足够多的会场里安排一批活动，并希望使用尽可能少的会场。设计一个有效的 贪心算法进行安排。（这个问题实际上是著名的图着色问题。若将每一个活动作为图的一个 顶点，不相容活动间用边相连。使相邻顶点着有不同颜色的最小着色数，相应于要找的最小 会场数。）\n输入格式: 第一行有 1 个正整数k，表示有 k个待安排的活动。 接下来的 k行中，每行有 2个正整数，分别表示 k个待安排的活动开始时间和结束时间。时间 以 0 点开始的分钟计。\n输出格式: 输出最少会场数。\n输入样例: 5\r1 23\r12 28\r25 35\r27 80\r36 50 输出样例: 在这里给出相应的输出。例如：\n3\r思路 首先这道题就很像书中那道在一个会场中安排尽可能多的活动，但是，不能完全按之前那个思路来做！\n这里是要用尽可能少的会场，而且从题中可以看出会场的结束时间没有限制，只要活动的开始时间比上一场要晚就行。如果我们按书中的办法把活动先按结束时间从小到大排序，然后对当前未安排的活动用一个会场进行尽可能多的安排，之后若还每安排完在开辟一个新的会场继续之前的操作。这样的算法是有问题的，因为这样的在一个会场中尽可能多的安排活动，而从全局来看（还有这道题的特点：会场结束时间无限制），这种策略并不能保证把所有活动安排在最少的会场，所以两个问题并不能完全等同，这就是我一开始犯的错误。\n其实原因就在于：会场结束时间无限制，要用最少的会场。\n正确解法有2种：\n 把活动按开始时间从小到大排，当开始时间相同则结束时间早的优先。遍历活动再用之前的那种在一个会场安排尽可能多的活动，完了之后开辟一个新的会场继续安排，直到全部活动安排完毕。 把活动按结束时间从小到大排，当结束时间相同则开始时间早的优先。遍历活动，每次再遍历一次所有会场看结束时间是否满足可以安排下，都不能安排下就新开一个会场，然后每次还要对所有已经开辟的会场按结束时间进行从大到小再次排序，这样直到所有活动遍历安排完毕。  所以这道题是要把有限的活动尽量塞在最少的会场中，要从所有会场全局去考虑，而且这道题的特点是单个会场的结束时间没有限制，所以第一种解法是按开始时间排的而不用按结束时间。第二种按结束时间的话就需要每次重新遍历所有会场，每次还重排，保证从全局去考虑。\n代码 解法1： // 按开始时间排序 #include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 666  struct activity { int start; int end; int arrage; } activities[MAX]; int n; bool struct_compare(activity a, activity b) { if (a.start != b.start) return a.start \u0026lt; b.start; //优先进行最先开始的活动  else return a.end \u0026lt; b.end; //当开始时间相同时,优先进行最早结束的活动 } int main() { cin \u0026gt;\u0026gt; n; for (int i = 0; i \u0026lt; n; i++) { cin \u0026gt;\u0026gt; activities[i].start; cin \u0026gt;\u0026gt; activities[i].end; activities[i].arrage = 0; } // 初始化会场数  int room = 0; // 对活动\u0026#39;开始时间\u0026#39;进行从小到大排序  sort(activities, activities + n, struct_compare); // 记录当前安排会场的结束时间，被安排的会场数  int lastest = 0, arrage_num = 0; // 如果会场还没有被全部安排完  while (arrage_num != n) { // 新增一个会场  room++; for (int i = 0; i \u0026lt; n; i++) { // 在一个会场中安排尽可能多的活动  if (activities[i].arrage == 0 \u0026amp;\u0026amp; activities[i].start \u0026gt;= lastest) { activities[i].arrage = 1; // 标记活动为已被安排  arrage_num++; lastest = activities[i].end; // 更新当前会场的结束时间  } } lastest = 0; } //另外一种写法，效果一样  /* for (int i = 0; i \u0026lt; n; i++) { if (activities[i].arrage == 0) { room++; activities[i].arrage = 1; lastest = activities[i].end; for (int j = i + 1; j \u0026lt; n; j++) { if (activities[j].arrage == 0 \u0026amp;\u0026amp; activities[j].start \u0026gt;= lastest) { activities[j].arrage = 1; lastest = activities[j].end; } } } } */ cout \u0026lt;\u0026lt; room; return 0; } 解法2： //按结束时间排序 #include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 666  struct activity { int start; int end; } activities[MAX]; int n; int end_time[MAX] = {0}; // 记录每个会场的结束时间 int room = 1; // 会场数  bool struct_compare(activity a, activity b) { if (a.end != b.end) return a.end \u0026lt; b.end; //优先进行最早结束的活动  else return a.start \u0026lt; b.start; //当结束时间相同时,优先进行最早开始的活动 } bool dcmp(int a, int b) { return a \u0026gt; b; // 从大到小排序 } int main() { cin \u0026gt;\u0026gt; n; for (int i = 0; i \u0026lt; n; i++) { cin \u0026gt;\u0026gt; activities[i].start; cin \u0026gt;\u0026gt; activities[i].end; } // 对活动按\u0026#39;结束时间\u0026#39;进行排序  sort(activities, activities + n, struct_compare); // 遍历活动  for (int i = 0; i \u0026lt; n; i++) { int flag = 0; // 标记是否在已开辟的会场中被安排  for (int j = 1; j \u0026lt;= room; j++) // 遍历已有会场寻找合适的  { if (activities[i].start \u0026gt;= end_time[j]) { end_time[j] = activities[i].end; flag = 1; break; } } // 已有会场找不到合适的就开辟一个新的  if (!flag) { room++; end_time[room] = activities[i].end; } // 每次安排完一个活动都要对会场们按结束时间从大到小重排  sort(end_time + 1, end_time + room + 1, dcmp); } cout \u0026lt;\u0026lt; room; return 0; } 参考博文\n","date":"2020-10-31T09:45:00+08:00","permalink":"https://ccqstark.github.io/p/greedy_activity/","title":"贪心算法——会场安排问题"},{"content":"题目 在一个地图上有n个地窖（n≤200）,每个地窖中埋有一定数量的地雷。同时，给出地窖之间的连接路径，并规定路径都是单向的,且保证都是小序号地窖指向大序号地窖，也不存在可以从一个地窖出发经过若干地窖后又回到原来地窖的路径。某人可以从任意一处开始挖地雷，然后沿着指出的连接往下挖（仅能选择一条路径），当无连接时挖地雷工作结束。设计一个挖地雷的方案，使他能挖到最多的地雷。\n输入格式: 第一行：地窖的个数；\n第二行：为依次每个地窖地雷的个数；\n下面若干行：\nxi yi //表示从xi可到yi，xi\u0026lt;yi。\n最后一行为\u0026quot;0 0\u0026quot;表示结束。\n输出格式: k1-k2−…−kv //挖地雷的顺序 挖到最多的雷。\n输入样例: 6\r5 10 20 5 4 5\r1 2\r1 4\r2 4\r3 4\r4 5\r4 6\r5 6\r0 0\r输出样例: 3-4-5-6\r34\r代码 #include \u0026lt;iostream\u0026gt;using namespace std; #define MAX 203 int matrix[MAX][MAX]; // 存放通路情况 int mines[MAX]; // 存放各坑地雷数 int dp_mat[MAX][MAX]; // 存放子问题最优解 int path[MAX]; // 存放路径 int n, ans, last_update; // last_update是最后一个更新最大值的点  void dig() { // 一行行扫  for (int i = 1; i \u0026lt;= n; i++) { // max_last是此点之前所有点可以挖到的最大地雷数  int max_last = 0; for (int k = 1; k \u0026lt;= i - 1; k++) { // 判断之前所有可以通向现在的点中，可以挖到最大的地雷数的路径的最后一点  if (matrix[k][i] == 1) { // 按列方向扫，可以通向本点的点  if (dp_mat[k][i] \u0026gt; max_last) { max_last = dp_mat[k][i]; path[i] = k; // 路径是所连接的上一点  } } } for (int j = i; j \u0026lt;= n; j++) { // max_last + 本点地雷数 = 以本点作为路径末点可以挖到的最大地雷数  dp_mat[i][j] = max_last + mines[i]; if (dp_mat[i][j] \u0026gt; ans) { // 更新最终答案的最大地雷数  ans = dp_mat[i][j]; // 记录最后更新最终答案的那个点，作为答案路径的末尾点，用数组回溯可以打印出完整路径  last_update = i; } } } } // 递归回溯打印完整路径 void print_path(int point) { if (point == 0) return; print_path(path[point]); if (point == last_update) { cout \u0026lt;\u0026lt; point \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; point \u0026lt;\u0026lt; \u0026#34;-\u0026#34;; } } int main() { cin \u0026gt;\u0026gt; n; for (int i = 1; i \u0026lt;= n; i++) { cin \u0026gt;\u0026gt; mines[i]; } int a, b; while (cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b) { if (a == 0 \u0026amp;\u0026amp; b == 0) break; matrix[a][b] = 1; } dig(); print_path(last_update); cout \u0026lt;\u0026lt; ans; } ","date":"2020-10-22T01:05:00+08:00","permalink":"https://ccqstark.github.io/p/dp_digmines/","title":"DP动态规划——挖地雷"},{"content":"题目 设计一个O(n2)时间的算法，找出由n个数组成的序列的最长单调递增子序列。\n输入格式: 输入有两行： 第一行：n，代表要输入的数列的个数 第二行：n个数，数字之间用空格格开\n输出格式: 最长单调递增子序列的长度\n输入样例: 在这里给出一组输入。例如：\n5\r1 3 5 2 9\r输出样例: 在这里给出相应的输出。例如：\n4\r思路 用动态规划的思想，利用子问题的最优解求更大一点的子问题。\n设一个数组dp[i]用于存放数组中从0到i下标的序列中，最长的递增子序列的长度\n双重遍历，如果arr[j]小于arr[i]，则dp[i]为dp[j]+1和dp[i]中较大的那个。即\ndp[i] = max{ dp[j]+1, dp[i] }\n由于每次重头又遍历了一次，并每次都分析最优解，避免了1 2 3 9 6 7 这样在最大数后面还有2个较小的数可以产生更长递增子序列的情况可能犯的错误。\n这也说明这个算法的时间复杂度只能是O(n2)\n代码 // 单调递增最长子序列 #include \u0026lt;iostream\u0026gt;using namespace std; #define MAX 666 int arr[MAX]; int dp[MAX]; int n; int longest_increasing(){ // 初始化第一个  dp[0] = 1; // 双重遍历  for (int i = 0;i\u0026lt;n;i++){ for (int j = 0;j\u0026lt;i;j++){ // 利用子问题最优解  if(arr[i]\u0026gt;arr[j]){ dp[i] = (dp[j]+1\u0026gt;dp[i])?dp[j]+1:dp[i]; } } } // 找出dp[]中最大的那个作为答案  int max_len = 1; for (int i = 0;i\u0026lt;n;i++){ max_len = (dp[i]\u0026gt;max_len)?dp[i]:max_len; } return max_len; } int main() { cin\u0026gt;\u0026gt;n; for (int i = 0;i\u0026lt;n;i++){ cin\u0026gt;\u0026gt;arr[i]; } cout\u0026lt;\u0026lt;longest_increasing(); } ","date":"2020-10-21T21:07:00+08:00","permalink":"https://ccqstark.github.io/p/dp_increasing/","title":"DP动态规划——单调递增最长子序列"},{"content":"添加依赖 \u0026lt;!-- shiro --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- JWT --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.auth0\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;java-jwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.11.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; JWT加密解密验证工具类 package com.ccqstark.springbootquick.util; import com.auth0.jwt.JWT; import com.auth0.jwt.JWTVerifier; import com.auth0.jwt.algorithms.Algorithm; import io.jsonwebtoken.Claims; import io.jsonwebtoken.JwtBuilder; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import org.apache.commons.codec.binary.Base64; import java.util.Date; import java.util.HashMap; import java.util.Map; import java.util.UUID; /* * 总的来说，工具类中有三个方法 * 获取JwtToken，获取JwtToken中封装的信息，判断JwtToken是否存在 * 1. encode()，参数是=签发人，存在时间，一些其他的信息=。返回值是JwtToken对应的字符串 * 2. decode()，参数是=JwtToken=。返回值是荷载部分的键值对 * 3. isVerify()，参数是=JwtToken=。返回值是这个JwtToken是否存在 * */ public class JwtUtil { // 创建默认的秘钥和算法，供无参的构造方法使用  private static final String defaultbase64EncodedSecretKey = \u0026#34;wdnmd\u0026#34;; private static final SignatureAlgorithm defaultsignatureAlgorithm = SignatureAlgorithm.HS256; // 无参构造，使用默认  public JwtUtil() { this(defaultbase64EncodedSecretKey, defaultsignatureAlgorithm); } private final String base64EncodedSecretKey; private final SignatureAlgorithm signatureAlgorithm; // 有参构造  public JwtUtil(String secretKey, SignatureAlgorithm signatureAlgorithm) { this.base64EncodedSecretKey = Base64.encodeBase64String(secretKey.getBytes()); this.signatureAlgorithm = signatureAlgorithm; } /* *这里就是产生jwt字符串的地方 * jwt字符串包括三个部分 * 1. header * -当前字符串的类型，一般都是“JWT” * -哪种算法加密，“HS256”或者其他的加密算法 * 所以一般都是固定的，没有什么变化 * 2. payload * 一般有四个最常见的标准字段（下面有） * iat：签发时间，也就是这个jwt什么时候生成的 * jti：JWT的唯一标识 * iss：签发人，一般都是username或者userId * exp：过期时间 * * */ public String encode(String iss, long ttlMillis, Map\u0026lt;String, Object\u0026gt; claims) { //iss签发人，ttlMillis生存时间，claims是指还想要在jwt中存储的一些非隐私信息  if (claims == null) { claims = new HashMap\u0026lt;\u0026gt;(); } long nowMillis = System.currentTimeMillis(); JwtBuilder builder = Jwts.builder() .setClaims(claims) .setId(UUID.randomUUID().toString())// 这个是JWT的唯一标识，一般设置成唯一的，这个方法可以生成唯一标识  .setIssuedAt(new Date(nowMillis))// 这个地方就是以毫秒为单位，换算当前系统时间生成的iat  .setIssuer(iss)// 签发人，也就是JWT是给谁的（逻辑上一般都是username或者userId）  .signWith(signatureAlgorithm, base64EncodedSecretKey);//这个地方是生成jwt使用的算法和秘钥  if (ttlMillis \u0026gt;= 0) { // 过期时间 = 当前时间 + 生存时间  long expMillis = nowMillis + ttlMillis; Date exp = new Date(expMillis);// 过期时间，这个也是使用毫秒生成的  builder.setExpiration(exp); } return builder.compact(); } //相当于encode的逆向，传入jwtToken生成对应的username和password等字段。Claim就是一个map  //也就是拿到荷载部分所有的键值对  public Claims decode(String jwtToken) { // 得到 DefaultJwtParser  return Jwts.parser() // 设置签名的秘钥  .setSigningKey(base64EncodedSecretKey) // 设置需要解析的 jwt  .parseClaimsJws(jwtToken) .getBody(); } //判断jwtToken是否合法  public boolean isVerify(String jwtToken) { //这个是官方的校验规则，这里只写了一个\u0026#34;校验算法\u0026#34;，可以自己加  Algorithm algorithm = null; switch (signatureAlgorithm) { case HS256: algorithm = Algorithm.HMAC256(Base64.decodeBase64(base64EncodedSecretKey)); break; default: throw new RuntimeException(\u0026#34;不支持该算法\u0026#34;); } JWTVerifier verifier = JWT.require(algorithm).build(); verifier.verify(jwtToken); // 校验不通过会抛出异常  //判断合法的标准：1. 头部和荷载部分没有篡改过。2. 没有过期  return true; } public static void main(String[] args) { JwtUtil util = new JwtUtil(\u0026#34;wdnmd\u0026#34;, SignatureAlgorithm.HS256); //以tom作为秘钥，以HS256加密  Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;username\u0026#34;, \u0026#34;ccq\u0026#34;); map.put(\u0026#34;password\u0026#34;, \u0026#34;1428\u0026#34;); map.put(\u0026#34;age\u0026#34;, 20); String jwtToken = util.encode(\u0026#34;ccqstark\u0026#34;, 30000, map); System.out.println(jwtToken); util.decode(jwtToken).entrySet().forEach((entry) -\u0026gt; { System.out.println(entry.getKey() + \u0026#34;: \u0026#34; + entry.getValue()); }); } } 关闭shiro的session package com.ccqstark.springbootquick.auth; import org.apache.shiro.subject.Subject; import org.apache.shiro.subject.SubjectContext; import org.apache.shiro.web.mgt.DefaultWebSubjectFactory; // 关闭shiro的session public class JwtDefaultSubjectFactory extends DefaultWebSubjectFactory { @Override public Subject createSubject(SubjectContext context) { // 不创建 session  context.setSessionCreationEnabled(false); return super.createSubject(context); } } 使用UsernamePasswordToken package com.ccqstark.springbootquick.auth; import org.apache.shiro.authc.AuthenticationToken; //这个就类似UsernamePasswordToken public class JwtToken implements AuthenticationToken { private String jwt; public JwtToken(String jwt) { this.jwt = jwt; } @Override//类似是用户名  public Object getPrincipal() { return jwt; } @Override//类似密码  public Object getCredentials() { return jwt; } //返回的都是jwt } Realm验证类 package com.ccqstark.springbootquick.auth; import com.ccqstark.springbootquick.util.JwtUtil; import lombok.extern.slf4j.Slf4j; import org.apache.shiro.authc.*; import org.apache.shiro.authz.AuthorizationInfo; import org.apache.shiro.realm.AuthorizingRealm; import org.apache.shiro.subject.PrincipalCollection; @Slf4j public class JwtRealm extends AuthorizingRealm { /* * 多重写一个support * 标识这个Realm是专门用来验证JwtToken * 不负责验证其他的token（UsernamePasswordToken） * */ @Override public boolean supports(AuthenticationToken token) { //这个token就是从过滤器中传入的jwtToken  return token instanceof JwtToken; } //授权  @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { return null; } //认证  //这个token就是从过滤器中传入的jwtToken  @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { String jwt = (String) token.getPrincipal(); if (jwt == null) { throw new NullPointerException(\u0026#34;jwtToken 不允许为空\u0026#34;); } //判断  JwtUtil jwtUtil = new JwtUtil(); if (!jwtUtil.isVerify(jwt)) { throw new UnknownAccountException(); } //下面是验证这个user是否是真实存在的  String username = (String) jwtUtil.decode(jwt).get(\u0026#34;username\u0026#34;);//判断数据库中username是否存在  log.info(\u0026#34;在使用token登录\u0026#34;+username); return new SimpleAuthenticationInfo(jwt,jwt,\u0026#34;JwtRealm\u0026#34;); //这里返回的是类似账号密码的东西，但是jwtToken都是jwt字符串。还需要一个该Realm的类名  } } Filter过滤器 package com.ccqstark.springbootquick.auth; import lombok.extern.slf4j.Slf4j; import org.apache.shiro.web.filter.AccessControlFilter; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /* * 自定义一个Filter，用来拦截所有的请求判断是否携带Token * isAccessAllowed()判断是否携带了有效的JwtToken * onAccessDenied()是没有携带JwtToken的时候进行账号密码登录，登录成功允许访问，登录失败拒绝访问 * */ @Slf4j public class JwtFilter extends AccessControlFilter { /* * 1. 返回true，shiro就直接允许访问url * 2. 返回false，shiro才会根据onAccessDenied的方法的返回值决定是否允许访问url * */ @Override protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception { log.warn(\u0026#34;isAccessAllowed 方法被调用\u0026#34;); //这里先让它始终返回false来使用onAccessDenied()方法  return false; } /** * 返回结果为true表明登录通过 */ @Override protected boolean onAccessDenied(ServletRequest servletRequest, ServletResponse servletResponse) throws Exception { log.warn(\u0026#34;onAccessDenied 方法被调用\u0026#34;); //这个地方和前端约定，要求前端将jwtToken放在请求的Header部分  //所以以后发起请求的时候就需要在Header中放一个Authorization，值就是对应的Token  HttpServletRequest request = (HttpServletRequest) servletRequest; String jwt = request.getHeader(\u0026#34;Authorization\u0026#34;); log.info(\u0026#34;请求的 Header 中藏有 jwtToken {}\u0026#34;, jwt); JwtToken jwtToken = new JwtToken(jwt); /* * 下面就是固定写法 * */ try { // 委托 realm 进行登录认证  //所以这个地方最终还是调用JwtRealm进行的认证  getSubject(servletRequest, servletResponse).login(jwtToken); //也就是subject.login(token)  } catch (Exception e) { e.printStackTrace(); onLoginFail(servletResponse); //调用下面的方法向客户端返回错误信息  return false; } return true; //执行方法中没有抛出异常就表示登录成功  } //登录失败时默认返回 401 状态码  private void onLoginFail(ServletResponse response) throws IOException { HttpServletResponse httpResponse = (HttpServletResponse) response; httpResponse.setStatus(HttpServletResponse.SC_UNAUTHORIZED); httpResponse.getWriter().write(\u0026#34;login error\u0026#34;); } } shiro配置 package com.ccqstark.springbootquick.config; import com.ccqstark.springbootquick.auth.*; import org.apache.shiro.mgt.DefaultSessionStorageEvaluator; import org.apache.shiro.mgt.DefaultSubjectDAO; import org.apache.shiro.mgt.SubjectFactory; import org.apache.shiro.realm.Realm; import org.apache.shiro.spring.web.ShiroFilterFactoryBean; import org.apache.shiro.web.filter.authc.AnonymousFilter; import org.apache.shiro.web.filter.authc.LogoutFilter; import org.apache.shiro.web.mgt.DefaultWebSecurityManager; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import javax.servlet.Filter; import java.util.HashMap; import java.util.LinkedHashMap; import java.util.Map; //springBoot整合jwt实现认证有三个不一样的地方，对应下面abc @Configuration public class ShiroConfig { /* * a. 告诉shiro不要使用默认的DefaultSubject创建对象，因为不能创建Session * */ @Bean public SubjectFactory subjectFactory() { return new JwtDefaultSubjectFactory(); } @Bean public Realm realm() { return new JwtRealm(); } @Bean public DefaultWebSecurityManager securityManager() { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(realm()); /* * b * */ // 关闭 ShiroDAO 功能  DefaultSubjectDAO subjectDAO = new DefaultSubjectDAO(); DefaultSessionStorageEvaluator defaultSessionStorageEvaluator = new DefaultSessionStorageEvaluator(); // 不需要将 Shiro Session 中的东西存到任何地方（包括 Http Session 中）  defaultSessionStorageEvaluator.setSessionStorageEnabled(false); subjectDAO.setSessionStorageEvaluator(defaultSessionStorageEvaluator); securityManager.setSubjectDAO(subjectDAO); //禁止Subject的getSession方法  securityManager.setSubjectFactory(subjectFactory()); return securityManager; } @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean() { ShiroFilterFactoryBean shiroFilter = new ShiroFilterFactoryBean(); shiroFilter.setSecurityManager(securityManager()); shiroFilter.setLoginUrl(\u0026#34;/unauthenticated\u0026#34;); shiroFilter.setUnauthorizedUrl(\u0026#34;/unauthorized\u0026#34;); /* * c. 添加jwt过滤器，并在下面注册 * 也就是将jwtFilter注册到shiro的Filter中 * 指定除了login和logout之外的请求都先经过jwtFilter * */ Map\u0026lt;String, Filter\u0026gt; filterMap = new HashMap\u0026lt;\u0026gt;(); //这个地方其实另外两个filter可以不设置，默认就是  filterMap.put(\u0026#34;anon\u0026#34;, new AnonymousFilter()); filterMap.put(\u0026#34;jwt\u0026#34;, new JwtFilter()); filterMap.put(\u0026#34;logout\u0026#34;, new LogoutFilter()); shiroFilter.setFilters(filterMap); // 拦截器  Map\u0026lt;String, String\u0026gt; filterRuleMap = new LinkedHashMap\u0026lt;\u0026gt;(); filterRuleMap.put(\u0026#34;/login\u0026#34;, \u0026#34;anon\u0026#34;); filterRuleMap.put(\u0026#34;/logout\u0026#34;, \u0026#34;logout\u0026#34;); filterRuleMap.put(\u0026#34;/**\u0026#34;, \u0026#34;jwt\u0026#34;); shiroFilter.setFilterChainDefinitionMap(filterRuleMap); return shiroFilter; } } 测试Controller package com.ccqstark.springbootquick.controller; import com.ccqstark.springbootquick.util.JwtUtil; import io.jsonwebtoken.SignatureAlgorithm; import lombok.extern.slf4j.Slf4j; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; import java.util.HashMap; import java.util.Map; @Slf4j @Controller public class LoginController { @RequestMapping(\u0026#34;/login\u0026#34;) public ResponseEntity\u0026lt;Map\u0026lt;String, String\u0026gt;\u0026gt; login(String username, String password) { log.info(\u0026#34;username:{},password:{}\u0026#34;,username,password); Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); if (!\u0026#34;tom\u0026#34;.equals(username) || !\u0026#34;123\u0026#34;.equals(password)) { map.put(\u0026#34;msg\u0026#34;, \u0026#34;用户名密码错误\u0026#34;); return ResponseEntity.ok(map); } JwtUtil jwtUtil = new JwtUtil(\u0026#34;wdnmd\u0026#34;, SignatureAlgorithm.HS256); Map\u0026lt;String, Object\u0026gt; chaim = new HashMap\u0026lt;\u0026gt;(); chaim.put(\u0026#34;username\u0026#34;, username); // 生存时间在这里设置  String jwtToken = jwtUtil.encode(username, 20*1000, chaim); map.put(\u0026#34;msg\u0026#34;, \u0026#34;登录成功\u0026#34;); map.put(\u0026#34;token\u0026#34;, jwtToken); return ResponseEntity.ok(map); } @RequestMapping(\u0026#34;/testdemo\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; testdemo() { return ResponseEntity.ok(\u0026#34;我爱蛋炒饭\u0026#34;); } } 请求登录接口，密码正确后返回一个token，以后每次请求带上这个token以header里的Authorization字段的形式\n之后的页面都会经过拦截器分配到对应的过滤器进行验证token是否有效，实现了鉴权。\n","date":"2020-10-17T16:52:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_shiro_jwt/","title":"[SpringBoot]整合shiro+JWT做鉴权"},{"content":"开通服务 登录阿里云，开通OSS服务，默认按量计费，为了业务稳定可以购买包月包年的资源包。\n准备工作 创建Bucket，如果是为了作为网站的静态资源存储供用户访问的话把权限设为公共读，填写信息后创建成功，可以在Bucket下新建目录什么的。\n单独创建一个RAM子用户用来调用API，选择编程访问，创建成功后一定要把AccessKeyID和AccessKeySecret等重要信息记下来，后面配置文件要用到。\n然后要给这个子用户添加权限AliyunOSSFullAccess\nMaven依赖 \u0026lt;!-- OSS --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-sdk-oss\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.2\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件 endpoint就是在存储桶的概览里地域节点，填外网访问那个就行\nurl填资源访问的URL的前面部分（填到.com/）\naccessKeyId和accessKeySecret就是创建子用户时那个\nbucketName就是存储桶的名字\n# 阿里云ossoss:endpoint:*url:*accessKeyId:*accessKeySecret:*bucketName:*配置类 项目的config目录下新建OSS的配置类\npackage com.ccqstark.springbootquick.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import java.io.Serializable; /** * @Description: 阿里云 OSS 配置信息 * @Author: ccq * @Date: 2020/10/16 */ @Component //注册bean @Data @Configuration @ConfigurationProperties(prefix = \u0026#34;oss\u0026#34;) public class OSSConfig implements Serializable { private String endpoint; private String url; private String accessKeyId; private String accessKeySecret; private String bucketName; } 上传文件工具类 项目的util目录下新建这上传工具类\npackage com.ccqstark.springbootquick.util; import com.aliyun.oss.ClientConfiguration; import com.aliyun.oss.OSSClient; import com.aliyun.oss.common.auth.DefaultCredentialProvider; import com.ccqstark.springbootquick.config.OSSConfig; import org.springframework.web.multipart.MultipartFile; import java.io.IOException; import java.util.UUID; /** * @Description: 阿里云 oss 上传工具类(高依赖版) * @Author: ccq * @Date: 2020/10/17 */ public class OSSBootUtil { private OSSBootUtil(){} /** * oss 工具客户端 */ private volatile static OSSClient ossClient = null; /** * 上传文件至阿里云 OSS * 文件上传成功,返回文件完整访问路径 * 文件上传失败,返回 null * * @param ossConfig oss 配置信息 * @param file 待上传文件 * @param fileDir 文件保存目录 * @return oss 中的相对文件路径 */ public static String upload(OSSConfig ossConfig, MultipartFile file, String fileDir){ // 初始化客户端  initOSS(ossConfig); // 文件URL  StringBuilder fileUrl = new StringBuilder(); try { String suffix = file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf(\u0026#39;.\u0026#39;)); String fileName = System.currentTimeMillis() + \u0026#34;-\u0026#34; + UUID.randomUUID().toString().substring(0,18) + suffix; if (!fileDir.endsWith(\u0026#34;/\u0026#34;)) { fileDir = fileDir.concat(\u0026#34;/\u0026#34;); } fileUrl = fileUrl.append(fileDir + fileName); // 上传文件到指定的存储空间，并将其保存为指定的文件名称  ossClient.putObject(ossConfig.getBucketName(), fileUrl.toString(), file.getInputStream()); } catch (IOException e) { e.printStackTrace(); return null; } fileUrl = fileUrl.insert(0,ossConfig.getUrl()); return fileUrl.toString(); } /** * 初始化 oss 客户端 * @param ossConfig * @return */ private static OSSClient initOSS(OSSConfig ossConfig) { if (ossClient == null ) { synchronized (OSSBootUtil.class) { if (ossClient == null) { ossClient = new OSSClient(ossConfig.getEndpoint(), new DefaultCredentialProvider(ossConfig.getAccessKeyId(), ossConfig.getAccessKeySecret()), new ClientConfiguration()); } } } return ossClient; } } 服务层 在项目的service目录下新建服务层接口\npackage com.ccqstark.springbootquick.service; import com.ccqstark.springbootquick.model.ApiResult; import org.springframework.web.multipart.MultipartFile; /** * @Description: 公共业务 * @Author: ccq * @Date: 2020/10/17 */ public interface CommonService { /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ ApiResult uploadOSS(MultipartFile file, String uploadKey) throws Exception; } 新建实现类\npackage com.ccqstark.springbootquick.service; import com.ccqstark.springbootquick.config.OSSConfig; import com.ccqstark.springbootquick.model.ApiResult; import com.ccqstark.springbootquick.util.OSSBootUtil; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.web.multipart.MultipartFile; import java.util.HashMap; import java.util.Map; /** * @Description: 公共业务具体实现类 * @Author: ccq * @Date: 2020/10/17 */ @Service(\u0026#34;commonService\u0026#34;) public class CommonServiceImpl implements CommonService { @Autowired private OSSConfig ossConfig; /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ @Override public ApiResult uploadOSS(MultipartFile file, String uploadKey) throws Exception { // 高依赖版本 oss 上传工具  String ossFileUrlBoot = null; ossFileUrlBoot = OSSBootUtil.upload(ossConfig, file, \u0026#34;image/\u0026#34;); // 注意这里填写的是存储桶中你要存放文件的目录  Map\u0026lt;String, Object\u0026gt; resultMap = new HashMap\u0026lt;\u0026gt;(16); resultMap.put(\u0026#34;ossFileUrlBoot\u0026#34;, ossFileUrlBoot); return new ApiResult(200, resultMap); } } Controller上传测试 package com.ccqstark.springbootquick.controller; import com.ccqstark.springbootquick.model.ApiResult; import com.ccqstark.springbootquick.service.CommonService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpHeaders; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.multipart.MultipartFile; /** * @Description: 上传文件 * @Author: ccq * @Date: 2020/10/17 */ @Slf4j @RestController @RequestMapping(\u0026#34;/upload\u0026#34;) public class UploadController { @Autowired private CommonService commonService; /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ @RequestMapping(value = \u0026#34;/oss\u0026#34;, method = {RequestMethod.POST}, produces = {MediaType.APPLICATION_JSON_VALUE}) public ResponseEntity\u0026lt;?\u0026gt; uploadOSS(@RequestParam(value = \u0026#34;file\u0026#34;) MultipartFile file, String uploadKey) throws Exception { ApiResult apiResult = commonService.uploadOSS(file, uploadKey); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return new ResponseEntity\u0026lt;\u0026gt;(apiResult, headers, HttpStatus.CREATED); } } Postman工具，用POST请求，在form-data中用file字段对应图片或其他类型的文件，然后请求接口\n返回的URL在浏览器中可以用公网访问说明成功了！\n","date":"2020-10-17T10:54:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_oss/","title":"[SpringBoot]使用阿里云OSS上传文件"},{"content":"添加依赖 \u0026lt;!-- druid数据库连接池 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.21\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySql数据库驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- log4j日志 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 添加配置 spring:datasource:username:rootpassword:root#serverTimezone=UTC解决时区的报错url:jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf-8driver-class-name:com.mysql.cj.jdbc.Drivertype:com.alibaba.druid.pool.DruidDataSource#Spring Boot 默认是不注入这些属性值的，需要自己绑定#druid 数据源专有配置initialSize:5minIdle:5maxActive:20maxWait:60000timeBetweenEvictionRunsMillis:60000minEvictableIdleTimeMillis:300000validationQuery:SELECT 1 FROM DUALtestWhileIdle:truetestOnBorrow:falsetestOnReturn:falsepoolPreparedStatements:true#配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入#如果允许时报错 java.lang.ClassNotFoundException: org.apache.log4j.Priority#则导入 log4j 依赖即可，Maven 地址：https://mvnrepository.com/artifact/log4j/log4jfilters:stat,wall,log4jmaxPoolPreparedStatementPerConnectionSize:20useGlobalDataSourceStat:trueconnectionProperties:druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500测试 编写测试类\n@SpringBootTest class SpringbootQuickApplicationTests { @Autowired DataSource dataSource; @Test void contextLoads() throws SQLException { System.out.println(dataSource.getClass()); Connection connection = dataSource.getConnection(); System.out.println(connection); connection.close(); } } 运行后控制台出现如下druid连接池相关字样说明成功\n2020-10-15 10:40:34.179 INFO 11352 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} inited\rDEBUG [main] - {conn-10005} pool-connect\rcom.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@31db34da\rDEBUG [main] - {conn-10005} pool-recycle\r添加后台监控 项目应用目录下的cofig目录添加\n@Configuration public class DruidConfig { @ConfigurationProperties(prefix = \u0026#34;spring.datasource\u0026#34;) @Bean public DataSource druidDataSource(){ return new DruidDataSource(); } @Bean // 后台监控  public ServletRegistrationBean statViewServlet(){ ServletRegistrationBean\u0026lt;StatViewServlet\u0026gt; bean = new ServletRegistrationBean\u0026lt;\u0026gt;(new StatViewServlet(),\u0026#34;/druid/*\u0026#34;); // 存储账号密码  HashMap\u0026lt;String,String\u0026gt; initParameters = new HashMap\u0026lt;\u0026gt;(); // 设置后台登录账号密码  initParameters.put(\u0026#34;loginUsername\u0026#34;,\u0026#34;admin\u0026#34;); initParameters.put(\u0026#34;loginPassword\u0026#34;,\u0026#34;123456\u0026#34;); // 谁都可以访问  initParameters.put(\u0026#34;allow\u0026#34;,\u0026#34;\u0026#34;); bean.setInitParameters(initParameters); // 设置初始化参数  return bean; } // filter  public FilterRegistrationBean webStatFilter(){ FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); // 被过滤的请求  Map\u0026lt;String,String\u0026gt; initParameters = new HashMap\u0026lt;\u0026gt;(); initParameters.put(\u0026#34;exclusions\u0026#34;,\u0026#34;*.js,*.css,/druid/*\u0026#34;); bean.setInitParameters(initParameters); return bean; } } 运行项目后打开localhost:8080/druid/出现后台监控登录页面说明成功\n","date":"2020-10-17T10:54:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_druid/","title":"[SpringBoot]整合Druid数据源"},{"content":"以我的项目目录结构为例: com.ccqstark.springbootquick\n导入依赖 \u0026lt;!-- springboot的mybatis --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置 #整合mybatismybatis:type-aliases-package:com.ccqstark.springbootquick.pojomapper-locations:classpath:mybatis/mapper/*.xml编写POJO(用了Lombok) 在com.ccqstark.springbootquick下新建目录pojo，然后新建类User.java，用于存储数据的对象（与数据库中的表对应）\npackage com.ccqstark.springbootquick.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class User { private int id; private String name; private String pwd; } 编写Mapper 在com.ccqstark.springbootquick下新建目录mapper，然后新建UserMapper.java，用于写接口，CRUD函数\npackage com.ccqstark.springbootquick.mapper; import com.ccqstark.springbootquick.pojo.User; import org.apache.ibatis.annotations.Mapper; import org.springframework.stereotype.Repository; import java.util.List; // Mapper注解说明这是一个mybatis的mapper类 //@Mapper //如果有扫描的话这里可以不用写这个注解了 @Repository public interface UserMapper { List\u0026lt;User\u0026gt; queryUserList(); User queryByUserId(int id); int addUser(User user); int updateUser(User user); int deleteUser(int id); } 如果是以扫描的形式，就是在项目的app启动类加上注解**@MapperScan**\n@SpringBootApplication // 也可以用着方式扫描，就不用一个个写@Mapper了 @MapperScan(\u0026#34;com.ccqstark.springbootquick.mapper\u0026#34;) public class SpringbootQuickApplication { public static void main(String[] args) { SpringApplication.run(SpringbootQuickApplication.class, args); } } 在XML里编写SQL语句 在resources目录下新建mybatis/mapper目录，再在下面新建xml文件，如这里的UserMapper.xml，在里面记得配好namespace，然后就可以写自定义SQL语句啦\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.ccqstark.springbootquick.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;!-- namespace要配好，如上面的格式，对应源码目录中的mapper接口 --\u0026gt; \u0026lt;!-- 下面就是CRUD的SQL语句 --\u0026gt; \u0026lt;!-- id对应的就是接口定义的函数名 --\u0026gt; \u0026lt;select id=\u0026#34;queryUserList\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; // id对现有 SELECT * FROM user \u0026lt;/select\u0026gt; \u0026lt;!-- #{id}就是模板待填空位--\u0026gt; \u0026lt;select id=\u0026#34;queryByUserId\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; SELECT * FROM user WHERE id = #{id} \u0026lt;/select\u0026gt; \u0026lt;insert id=\u0026#34;addUser\u0026#34; parameterType=\u0026#34;User\u0026#34;\u0026gt; INSERT into user (id,name,pwd) values (#{id},#{name},#{pwd}) \u0026lt;/insert\u0026gt; \u0026lt;update id=\u0026#34;updateUser\u0026#34; parameterType=\u0026#34;User\u0026#34;\u0026gt; UPDATE user SET name=#{name},pwd=#{pwd} where id = #{id} \u0026lt;/update\u0026gt; \u0026lt;delete id=\u0026#34;deleteUser\u0026#34; parameterType=\u0026#34;int\u0026#34;\u0026gt; DELETE FROM user WHERE id = #{id} \u0026lt;/delete\u0026gt; \u0026lt;/mapper\u0026gt; 调用来进行CRUD 在Controller或者Service里调用Mybatis进行CRUD，先@Autowired注入一个Mapper，然后利用这个接口类型指向的对象就可以调用接口里面的方法了。这些方法对应的sql语句操作就是在xml中定义的。\n@RestController @RequestMapping(\u0026#34;/mybatis\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @PostMapping(\u0026#34;/query\u0026#34;) public List\u0026lt;User\u0026gt; queryUserList(){ List\u0026lt;User\u0026gt; userList = userMapper.queryUserList(); return userList; } @PostMapping(\u0026#34;/create\u0026#34;) public String createUser(){ userMapper.addUser(new User(4,\u0026#34;wuhu\u0026#34;,\u0026#34;5555\u0026#34;)); return \u0026#34;ok\u0026#34;; } @PostMapping(\u0026#34;/update\u0026#34;) public String updateUser(){ userMapper.updateUser(new User(1,\u0026#34;qqq\u0026#34;,\u0026#34;33\u0026#34;)); return \u0026#34;ok\u0026#34;; } @PostMapping(\u0026#34;/delete\u0026#34;) public String deleteUser(){ userMapper.deleteUser(4); return \u0026#34;ok\u0026#34;; } } ","date":"2020-10-17T10:54:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_mybatis/","title":"[SpringBoot]整合Mybatis"},{"content":"导入依赖 \u0026lt;!-- SLF4j - log4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8.0-alpha2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 然后要在IDEA下载插件Maven Helper中把logback相关的包给Exclude，否则会出现冲突\n配置 log4j.properties中配置\n# rootLogger参数分别为：根Logger级别，输出器stdout，输出器log\rlog4j.rootLogger = info,stdout,log\r# 输出信息到控制台\rlog4j.appender.stdout = org.apache.log4j.ConsoleAppender\rlog4j.appender.stdout.layout = org.apache.log4j.PatternLayout\rlog4j.appender.stdout.layout.ConversionPattern = %d [%-5p] %l %rms: %m%n\r# 输出DEBUG级别以上的日志到D://log/debug.log，这个是日志文件存放的路径，根据时间情况进行设置\rlog4j.appender.log = org.apache.log4j.DailyRollingFileAppender\rlog4j.appender.log.DatePattern = '.'yyyy-MM-dd\rlog4j.appender.log.File = D://log/debug.log\rlog4j.appender.log.Encoding = UTF-8\r#log4j.appender.log.Threshold = INFO\rlog4j.appender.log.layout = org.apache.log4j.PatternLayout\rlog4j.appender.log.layout.ConversionPattern = %d [%-5p] (%c.%t): %m%n\r测试 编写测试类，使用@Slf4j注解之前确保使用了lombok\npackage com.ccqstark.springbootquick; import lombok.extern.slf4j.Slf4j; import org.junit.Test; @Slf4j public class LoggerTest { // private static final Logger log = LoggerFactory.getLogger(LoggerTest.class);  @Test public void TestSLF4j(){ log.info(\u0026#34;Current Time: {}\u0026#34;, System.currentTimeMillis()); log.info(\u0026#34;Current Time: \u0026#34; + System.currentTimeMillis()); log.info(\u0026#34;Current Time: {}\u0026#34;, System.currentTimeMillis()); log.trace(\u0026#34;trace log\u0026#34;); log.warn(\u0026#34;warn log\u0026#34;); log.debug(\u0026#34;debug log\u0026#34;); log.info(\u0026#34;info log\u0026#34;); log.error(\u0026#34;error log\u0026#34;); } } 运行后输出以下说明成功\n2020-10-15 16:36:45,459 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:13) 0ms: Current Time: 1602751005450\r2020-10-15 16:36:45,464 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:14) 5ms: Current Time: 1602751005464\r2020-10-15 16:36:45,465 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:15) 6ms: Current Time: 1602751005465\r2020-10-15 16:36:45,466 [WARN ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:17) 7ms: warn log\r2020-10-15 16:36:45,466 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:19) 7ms: info log\r2020-10-15 16:36:45,468 [ERROR] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:20) 9ms: error log\r用法 添加注解@Slf4j（确保使用了lombok）\n然后如测试类中log.info或其他类型的日志便可以使用了\n","date":"2020-10-17T10:54:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_slf4j-log4j/","title":"[SpringBoot]整合SLF4J-log4j"},{"content":"问题引入 学过线性代数都知道矩阵的乘法，比如说矩阵A×B，就是A的每一行上的元素分别和B的每一列上对应位置的元素相乘再总体相加，每次得到一个位置上的元素的值。\n假设A是p × q，B是q × r，那结果矩阵就是p × r，当然，能够相乘的条件是A的列数等于B的行数。\n而A×B总共需要做的乘法数是p × q × r，由矩阵乘法的过程可知。\n可以发现，当至少3个矩阵相乘时，比如ABC，(AB)C和(A)BC两种计算顺序所需做的乘法数是不同的。\n现在的问题是一个矩阵链，比如A × B × C × D × E × F × G，要以什么样的顺序相乘才能得使得所需做的乘法数最小呢？\n题目 输入格式: 每个输入文件为一个测试用例，每个测试用例的第一行给出一个正整数(1≤n≤100)，表示一共有n个矩阵A​1​​ ,A​2​​ ,…,A​n​​ ，第二行给出n+1个整数P​0​​ ,P​1​​ …P​n​​ ，以空格分隔，其中1≤P​i​​ ≤100(0≤i≤n)，第i个矩阵A​i​​ 是阶为P​i−1​​ ∗P​i​​ 的矩阵。\n输出格式: 获得上述矩阵的乘积，所需的最少乘法次数。\n输入样例: 在这里给出一组输入。例如：\n 5\n30 35 15 5 10 20\n 输出样例: 在这里给出相应的输出。例如：\n 11875\n 思路 可以先求2个2个相邻相乘的值，然后用他们求3个3个相乘的，再4个\u0026hellip;依照此规律直到n个\n当前个数阶段也需要把每种划分方案进行尝试，并得出最小的那种。比如我在算4个4个相乘的，那划分位置就有3个，每个都要遍历算一次，最后选最小那个，为下一阶段使用。\n我们利用二维数组m[i][j]表示第i个到第j个矩阵连乘的最优解，有如下公式。\n就是每次划分为2部分，整体最优解=左部分最优解+右部分的最优解+两者相乘所需乘法数\n矩阵i的行数为p[i-1]，列数为p[i]\n \n我们用一个二维矩阵来存储各阶段结果，数据就一步步往右上角填上去，最终答案就在最右上角。\n代码 // 矩阵链相乘问题 #include \u0026lt;iostream\u0026gt;#include \u0026lt;string.h\u0026gt;using namespace std; const int MAX = 1000; int p[MAX]; // 存放行列数，就是题目输入的序列 int m[MAX][MAX]; // 存放局部和最终结果的矩阵 int n; // 需要相乘的矩阵个数  void matrix() { memset(m, 0, sizeof(m)); // 初始化矩阵为0  // 同时连续相乘的个数  for (int r = 2; r \u0026lt;= n; r++) { // 从第几个开始(到第几组了)  for (int i = 1; i \u0026lt;= n - r + 1; i++) { // 相乘链的最后一个  int j = i + r - 1; // 为了通过比较从而得出最小的那个，要有一个比较的初值，这里是划分第一个和其余的为2组  m[i][j] = m[i + 1][j] + p[i - 1] * p[i] * p[j]; // 一步步移动划分点  for (int k = i + 1; k \u0026lt; j; k++) { // 以k位置为划分点，划分i到j的相乘链  int t = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j]; // 比较找出最小的那个  if (t \u0026lt; m[i][j]) { m[i][j] = t; } } } } } int main() { cin \u0026gt;\u0026gt; n; // 输入的数字总数比矩阵个数多1  for (int i = 0; i \u0026lt; n + 1; i++) { cin \u0026gt;\u0026gt; p[i]; } matrix(); // 最后答案会在右上角出现  cout \u0026lt;\u0026lt; m[1][n]; } 参考博文\n","date":"2020-10-12T21:07:00+08:00","permalink":"https://ccqstark.github.io/p/dp_matrix/","title":"DP动态规划——矩阵链相乘问题"},{"content":"“工欲善其事，必先利其器”，作为后端搬砖工，我们敲代码之前需要给我们的电脑配上所需的软件环境，这样我们写的代码才能跑起来，原地起飞！\n下载集成环境工具 可以选择xampp或phpenv（二选一就行）\nxampp xampp = Apache + MySQL(MariaDB) + PHP + Perl，是一个集成环境软件，装了一个就可以轻松获得服务器，数据库和php语言的环境，轻松快捷而且免费，唯一的缺点可能是因为是外网所以速度稍慢或者可能需要科学上网\n官网下载：https://www.apachefriends.org/zh_cn/index.html\n选择自己的平台，然后点击下载，完成后运行exe\n按普通安装步骤来就好，下面这个界面也默认选择就好，有些环境之后会用到\n \n安装路径建议安装在D盘，然后等待安装完成就可以了，打开软件看到主面板\n \n点击Apache和start按钮，等待图标变绿后再点击admin按钮或者浏览器地址栏输入localhost进行访问\n如果可以看到服务器主页面说明成功\n然后点击MySQL的start和admin，或者地址栏输入localhost/phpmyadmin/\n出现一个登录界面，账号填写root，密码为空不用填，直接点击登录，出现下面画面说明成功\n \nphpEnv 如果xampp实在太慢或者根本无法下载，也可以用phpEnv\n官网下载：https://www.phpenv.cn/\n根据你电脑是64位或者32位进行选择对应版本下载，如果不知道自己电脑是几位的可以点击教程查看\n同样建议放在D盘，其它的默认就行，运行后出现下面界面\n \n点击启动服务上面的图标，再点击打开主页的图标，看到phpEnv的主页面就说明成功了\n页面拉到最下面如下\n \n数据库端口填3306\n用户名填root\n密码也填root（注意：这里和xampp不一样）\n点击连接按钮后再把页面拉到最下面显示连接成功就行啦\n点击顶部菜单栏的开始，再点击phpMyAdmin，然后按上面xampp的对应内容操作就行\n安装IDE IDE(Integrated Development Environment)，集成开发环境，为开发者提供了基本的代码编辑器的同时还提供了许多适用工具，功能强大，是码农开发的利器。\nphp语言我们使用的比较多的是JetBrains公司出的PhpStorm\n官网下载：https://www.jetbrains.com/phpstorm/\n软件体积较大，如果你不想装它的话可以自己下载VSCode然后下载相应插件（自己查）\n由于软件是收费的，但是我们是学生，可以用学校给的邮箱进行学生认证就可以在毕业前都免费使用\n学生认证地址：https://www.jetbrains.com/community/education/#students\n学校邮箱获取方法 进入学校官网，进入智慧广外，\t在个人事务中可以看到自己的邮箱地址，一般是学号@gdufs.edu.cn\n \n下载破解版也可以，但可能比较花时间\n按步骤完成后打开phpstorm，进行下面的配置流程\n1. 新建一个项目  \n2. 选择创建路径 建议把目录建在集成环境指定的网络根目录下，目录路径如下（以安装在D盘为例）：\nxampp：D:\\xampp\\htdocs\nphpEnv：D:\\phpEnv\\www\\localhost\n \n路径最后自定义一个项目名，比如我这里叫test，然后点击creat\n3. 修改运行目录  \n如图打开设置\n \n选择Deployment，点击顶部+号，选择Local or mounted folder\n \nFolder就填写自己安装的集成环境软件的网络根目录\nWeb server URL记得要在最后补上斜杆和当前项目名\n点击右下角的Apply和OK\n4. Hello World!  \n对项目文件夹右键新建一个php文件，自定义命名，然后开始写下第一行php代码吧：\n\u0026lt;?php echo \u0026#34;hello world!\u0026#34;; 鼠标移到右上角选择一个浏览器运行，或者右键并选择run，或者快捷键Ctrl+Shift+F10\n \n如果出现了提醒你选择php解释器的情况\n \n就选择一个已有的版本就行，在settings -\u0026gt; Languages\u0026amp;Frameworks -\u0026gt; PHP也可以设置\n点击运行后出现\n \n或者是\n \n大功告成！现在可以愉快地敲代码了！\n当然，这是为了方便本地开发而安装的集成环境，有兴趣的小朋友可以自己尝试分别安装每个环境或者在Linux上进行编译安装\nPHPer现在可以带着世界上最好的语言开冲了！\n \n","date":"2020-10-10T11:39:00+08:00","image":"https://ccqstark.github.io/p/php_env/php_hu30aa9710d612d752c63ae5cdcfcf5665_61468_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/php_env/","title":"php后台开发基础环境搭建教程"},{"content":"基本操作 下载hugo 首先要有Golang的环境\n然后在GitHub上选择对应平台下载\nhttps://github.com/gohugoio/hugo/releases\nWindows下载完要设置环境变量\n创建新的站点 hugo new site \u0026lt;path\u0026gt; \n在指定路径下创建博客站点目录，目录最后是博客站点名\n找到心仪主题 在下面这个网站上找到喜欢的主题，按照各自的文档进行设置\nhttps://themes.gohugo.io/\n本地预览 hugo server -t \u0026lt;theme\u0026gt; --buildDrafts \u0026lt;theme\u0026gt;的位置填写主题的名称\n创建博客 hugo new post/blog.md 博客的markdown文件一开始都是放在\\content\\post目录下\n创建GitHub/Gitee仓库 Github把仓库命名为\u0026lt;name\u0026gt;.github.io即可开启博客托管服务\nGitee直接命名为自己的用户名，一字不差，同时需要手动开启Gitee Page服务\n部署到远端仓库  生成\\public目录  hugo --theme=hugo-theme-stack --baseUrl=\u0026#34;https://ccqstark.github.io/\u0026#34; --buildDrafts 根据具体仓库修改，也可以是\u0026quot;https://ccqstark.gitee.io/\u0026quot; 然后cd进public目录 在这个目录下创建git仓库，部署也是部署这个目录中的内容\n 三部曲  git add . git commit -m \u0026#39;...\u0026#39; git push github master 更新博客 要新增一篇博客就继续按下面这个步骤走\nhugo new post/name.md hugo --theme=hugo-theme-stack --baseUrl=\u0026#34;https://ccqstark.github.io/\u0026#34; --buildDrafts cd public git add . git commit -m \u0026#39;...\u0026#39; git push github master 如果只是更新就重新运行生成\\public目录的命令，再重新部署即可\n主题Stack配置 此博客的主题用的是Stack，下面是主题地址，可以找到文档和Demo\nhttps://themes.gohugo.io/hugo-theme-stack/\nicon设置 使用.ico文件类型的图标，并将其放置在\\public目录下\n\\layouts\\partials\\head下新建一个custom.html，写上\n\u0026lt;link rel=\u0026#34;shortcut icon\u0026#34; href=\u0026#34;https://ccqstark.github.io/icon.ico\u0026#34;/\u0026gt; 为了访问稳定也可以改为gitee\n文章外部展示图 在\\content\\post目录下创建博客时，先创建博客标题命名的文件夹，再在其下创建md文件index.md\n图片也是放在其下，在md文件开头的设置中添加image: \u0026quot;image.jpg\u0026quot;即可\nTags和分类 文章开头设置\ntags: - Spring categories: - Tech 一个是打标签，一个是分类\nAbout和Archives 在\\content\\page目录下创建about.md和archives.md\nabout.md用于写个人信息页面，需要文章顶部的设置写法改为字段加冒号的形式，配置slug为about\narchives.md用于分类和归档页面，用exampleSite的就行，不用做任何修改\nCategories 在\\content\\categories目录下创建以各分类命名的文件夹\n各分类的文件夹下放置_index.md和分类的展示图\n_index.md中的内容就是普通文章顶部的配置项，注意图片名配置对了就行\n","date":"2020-10-04T02:44:33+08:00","image":"https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/hugo_hu8b6407a07803ab5ecf8133363f04b00e_28892_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","title":"使用Hugo+github/gitee搭建个人博客"}]