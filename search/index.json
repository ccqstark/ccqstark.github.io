[{"content":"简介 AQS（Abstract Queue Synchronizer）在java.util.concurrent.locks包下面，是一个用来构建锁和同步器的框架，使用AQS可以简单高效地构造出大量应用广泛的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于 AQS 的。当然，我们自己也能利用 AQS 非常轻松容易地构造出符合我们自己需求的同步器。\n基本原理   AQS内部维护了一个FIFO的CLH队列，用来对获取资源线程的阻塞和排队。 还使用一个 int 成员变量state来表示同步状态，AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。\nprivate volatile int state; // 共享变量，使用volatile修饰保证线程可见性 状态信息通过 protected 类型的getState()，setState()，compareAndSetState() 进行操作。 不同的自定义同步器争用共享资源的方式也不同，实际上就是对共享资源state的获取与释放方式进行不同的实现，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法：\n  tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。\n  tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。\n  tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。\n  tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 AQS使用了模板方法的设计模式，用户实现自己的同步组件的时候只需要重写以上几个方法，实现自己对state操作的逻辑，然后这些子类重写的方法就会被AQS顶层的一些方法调用去实现线程排队阻塞唤醒等具体操作。\n实现例子     ReentrantLock：state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。\n  CountDownLatch：任务分为N个子线程去执行，state也初始化为N，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会唤醒主调用线程，然后主调用线程就会从await()函数返回，继续后续动作。\n锁的分类    独占锁：也就是同一时刻只允许一个线程访问资源，类似写锁。 共享锁：允许多个线程同时访问一个资源，类似读锁。  Node节点状态  CANCELLED(1)：表示当前结点已取消调度。当timeout或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。 SIGNAL(-1)：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为SIGNAL。 CONDITION(-2)：表示结点等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。（使用到Condition时才有等待队列的概念，原本的CLH队列是同步队列） PROPAGATE(-3)：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。共享式同步状态获取将会无条件传播下去。 初始值(0)：新结点入队时的默认状态。   负值表示结点处于有效等待状态，而正值表示结点已被取消。所以源码中很多地方用\u0026gt;0、\u0026lt;0来判断结点的状态是否正常。\n 独占锁源码 获取 acquire()  acquire()方法就是用来获取锁的，ReentrantLock的lock()方法实际上也就是调用AQS这个方法。\n public final void acquire(int arg) { // 先看尝试获取同步状态看是否成功，如果成功则方法结束返回  // 若失败则先调用addWaiter()方法加入到等待队列尾  // 再调用acquireQueued()方法在队列中等待重试竞争锁或休眠  if (!tryAcquire(arg) \u0026amp;\u0026amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } acquire()根据tryAcquire()尝试获得同步状态成功与否做了两件事情：\n 成功，则方法结束返回 失败，则先调用addWaiter()然后在调用acquireQueued()方法。  addWaiter()  获取同步状态失败，进行入队操作 当线程获取独占式锁失败后就会将当前线程加入同步队列，那么加入队列的方式是怎样的了？我们接下来就应该去研究一下addWaiter()和acquireQueued()。addWaiter()源码如下：\n private Node addWaiter(Node mode) { // 1.将当前线程构建成Node类型  Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure  // 2.尾节点是否为null？  Node pred = tail; if (pred != null) { // 2.2 将当前节点以尾插的方式插入同步队列中  node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } //2.1 当前同步队列尾节点为null，说明当前线程是第一个加入同步队列进行等待的线程  enq(node); return node; } 分析可以看上面的注释。程序的逻辑主要分为两个部分：\n 当前同步队列的尾节点为null，调用方法enq()插入; 当前队列的尾节点不为null，则采用尾插入（先node.prev = tail再compareAndSetTail()方法）的方式入队。  enq() 此时还会有另外一个问题：如果 if (compareAndSetTail(pred, node))为false怎么办？确实会继续执行到enq()方法，同时很明显compareAndSetTail是一个CAS操作，通常来说如果CAS操作失败会继续自旋（死循环）进行重试。因此，enq()方法可能承担两个任务：\n  处理当前同步队列尾节点为null时进行入队操作，同时完成头节点初始化;\n  如果CAS尾插入节点失败后负责自旋进行重试，直到成功。\nprivate Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize  //1. 构造头结点  if (compareAndSetHead(new Node())) tail = head; } else { // 2. 尾插入，CAS操作失败自旋尝试  node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } }   在上面的分析中我们可以看出，如果当前插入的节点是第一个入队的（tail为null时），那么会会先创建头结点，说明同步队列是带头结点的链式存储结构（实际上这个头节点是个傀儡节点，后面可以体会到真正在竞争资源的是老二节点）。带头结点与不带头结点相比，会在入队和出队的操作中获得更大的便捷性，因此同步队列选择了带头结点的链式存储结构。 compareAndSetTail(t, node)方法会利用CAS操作设置尾节点，如果CAS操作失败会在for (;;)死循环中不断尝试，直至成功return返回为止。\nacquireQueued() 现在我们已经知道获取独占式锁失败的线程被包装成Node，然后插入同步队列的过程了。那么紧接着会有下一个问题：进入了同步队列中的节点会做什么事情了来保证自己能够有机会再次尝试获取独占式锁？来看看acquireQueued()方法，从方法名就可以很清楚，这个方法的作用就是排队来获取锁的过程，源码如下：\nfinal boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { // 1.获得当前节点的先驱节点  final Node p = node.predecessor(); // 2.当前节点能否获取独占式锁  // 2.1 如果当前节点的先驱节点是头结点并且成功tryAcquire获取同步状态，即可以获得独占式锁  if (p == head \u0026amp;\u0026amp; tryAcquire(arg)) { // 队列头指针用指向当前节点  setHead(node); // 释放前驱节点  p.next = null; // help GC  failed = false; return interrupted; } // 2.2 获取锁失败，线程进入等待状态，尝试park挂起  if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 程序逻辑通过注释已经标出，整体来看这是一个这又是一个自旋的过程（for (;;)），代码首先获取当前节点的先驱节点，如果先驱节点是头结点的并且成功获得同步状态的时候（if (p == head \u0026amp;\u0026amp; tryAcquire(arg))），当前节点所指向的线程就能够获取锁。反之，获取锁失败进入等待状态park挂起。整体示意图为下图：  \n 获取锁成功，出队操作\n 获取锁的节点出队的逻辑是：\n// 队列头结点引用指向当前节点，因为头结点是傀儡节点，所以相当于出队了 setHead(node); // 释放前驱节点 // 拆掉原头结点的next引用，指向它的prev引用在setHead()中已经拆掉 p.next = null; // help GC failed = false; return interrupted; acquireQueued()在自旋过程中主要完成了两件事情：\n 如果当前节点的前驱节点是头节点，并且能够获得同步状态也就是锁的话，头节点出队，当前节点成为新的头结点，方法结束； 获取锁失败的话，先将前驱节点状态设置成SIGNAL表示当前节点之后需要被唤醒，然后调用LookSupport.park()方法使得当前线程阻塞(shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp;parkAndCheckInterrupt())。等待下一次唤醒，一般就是此节点的前驱结点获取到了锁后执行完了他想要的操作，然后要release了，就会去唤醒它（unparkSuccessor()）。  setHead() setHead()方法设置头结点为：\nprivate void setHead(Node node) { head = node; node.thread = null; node.prev = null; } 拆掉原头节点的next的prev，无任何引用方便GC时能够将内存进行回收。示意图如下：  \nshouldParkAfterFailedAcquire() 那么当获取锁失败的时候会调用shouldParkAfterFailedAcquire()方法和parkAndCheckInterrupt()方法，看看他们做了什么事情。shouldParkAfterFailedAcquire()方法源码为：\nprivate static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; // 前驱节点为signal状态  if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 前驱节点为cancel状态  if (ws \u0026gt; 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus \u0026gt; 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don\u0026#39;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 将前驱节点设置为signal，表示当前需要被唤醒  // 相当于给自己设一个闹钟再去睡，这个闹钟会在恰当的时候叫醒自己  compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false; } shouldParkAfterFailedAcquire()方法主要逻辑是使用compareAndSetWaitStatus(pred, ws, Node.SIGNAL)使用CAS将节点状态由初始值设置成SIGNAL，表示当前线程阻塞。当compareAndSetWaitStatus设置失败则说明shouldParkAfterFailedAcquire方法返回false，然后会在acquireQueued()方法中for (;;)死循环中会继续重试，直至compareAndSetWaitStatus设置节点状态位为SIGNAL时shouldParkAfterFailedAcquire返回true时才会执行方法parkAndCheckInterrupt()方法，该方法的源码为：\nparkAndCheckInterrupt() private final boolean parkAndCheckInterrupt() { //使得该线程阻塞  LockSupport.park(this); return Thread.interrupted(); } 该方法的关键是会调用LookSupport.park()方法，该方法是用来阻塞当前线程的。\n经过上面的分析，独占式锁的获取过程也就是acquire()方法的执行流程如下图所示：  \n释放 release() public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; // 唤醒头节点的后继节点  if (h != null \u0026amp;\u0026amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false; } 如果tryRelease成功的话，就获取头结点h，当判断到头节点不为null且状态不为0，就使用unparkSuccessor()唤醒头结点的下一个节点\n h != null \u0026amp;\u0026amp; h.waitStatus != 0的意思\n 当一个head节点的waitStatus为0说明什么呢，说明这个head节点后面没有在挂起等待中的后继节点了(如果有的话, head的ws就会被后继节点设为Node.SIGNAL了)， 自然也就不用执行 unparkSuccessor 操作了.\nunparkSuccessor() private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws \u0026lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 获取头节点的后继节点  Node s = node.next; // 此后继节点为null或处于cancel状态  if (s == null || s.waitStatus \u0026gt; 0) { s = null; // 通常情况下, 要唤醒的节点就是自己的后继节点  // 如果后继节点存在且也在等待锁, 那就直接唤醒它  // 但是有可能存在 后继节点是取消等待锁（ws\u0026gt;0）的情况  // 此时从尾节点开始向前找起, 直到找到距离head节点最近的ws\u0026lt;=0的节点  for (Node t = tail; t != null \u0026amp;\u0026amp; t != node; t = t.prev) if (t.waitStatus \u0026lt;= 0) s = t; } if (s != null) // 后继节点不为null时唤醒节点对应线程  LockSupport.unpark(s.thread); } 首先获取头节点的后继节点，当后继节点的时候会调用LookSupport.unpark()方法，该方法会唤醒该节点的后继节点所包装的线程。因此，每一次锁释放后就会唤醒队列中该节点的后继节点所引用的线程，从而进一步可以佐证获得锁的过程是一个FIFO（先进先出）的过程。\n独占锁总结 通过学习源码的方式非常深刻的学习到了独占式锁的获取和释放的过程以及同步队列。可以做一下总结：\n 线程获取锁失败，线程被封装成Node进行入队操作，核心方法在于addWaiter()和enq()，同时enq()完成对同步队列的头结点初始化工作以及CAS操作失败的重试; 线程获取锁是一个自旋的过程，当且仅当 当前节点的前驱节点是头结点并且成功获得同步状态时，节点出队即该节点引用的线程获得锁，否则，当不满足条件时就会调用LookSupport.park()方法使得线程阻塞； 释放锁的时候会唤醒后继节点，也就是在unparkSuccessor()中使用LookSupport.unpark()；  总体来说：在获取同步状态时，AQS维护一个同步队列，获取同步状态失败的线程会加入到队列中进行自旋；移除队列（或停止自旋）的条件是前驱节点是头结点并且成功获得了同步状态。在释放同步状态时，同步器会调用unparkSuccessor()方法唤醒后继节点。\n共享锁源码 获取 acquireShared() public final void acquireShared(int arg) { if (tryAcquireShared(arg) \u0026lt; 0) doAcquireShared(arg); } tryAcquireShared返回值是一个int类型，当返回值为大于等于0的时候方法结束说明获得成功获取锁，否则，表明获取同步状态失败即所引用的线程获取锁失败\ndoAcquireShared() private void doAcquireShared(int arg) { final Node node = addWaiter(Node.SHARED); boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); // 当前节点的前驱节点是头结点并且tryAcquireShared()返回值大于等于0即表示能成功获得同步状态。  if (p == head) { int r = tryAcquireShared(arg); if (r \u0026gt;= 0) { // 当该节点的前驱节点是头结点且成功获取同步状态  setHeadAndPropagate(node, r); p.next = null; // help GC  if (interrupted) selfInterrupt(); failed = false; return; } } if (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } 这段逻辑和独占锁的accquireQueued()的大同小异，只是对获取到同步状态的判断有点不同而已（见上方注释）。而且由于是共享式，会有多个线程同时获取到线程，也可能同时释放线程，空出很多同步状态，所以当排队中的老二获取到同步状态，如果还有可用资源，会继续传播下去（通过setHeadAndPropagate()方法）。\nsetHeadAndPropagate() private void setHeadAndPropagate(Node node, int propagate) { Node h = head; // Record old head for check below  // 设置新的头节点就是为了让获取共享资源的操作传播下去  setHead(node); if (propagate \u0026gt; 0 || h == null || h.waitStatus \u0026lt; 0) { Node s = node.next; // 如果下个节点为null或是共享的就进行释放  if (s == null || s.isShared()) doReleaseShared(); } } 这个方法就是设置了新的头结点，就是为了让获取资源这个操作传播下去，直到资源都被用完了（因为只有前驱节点为头结点的节点才可以去tryAcquireShared），如果下个节点为空节点或也是共享节点就要调用doReleaseShared释放，但是实际上是为了唤醒后续的节点，使其也来拿锁。\n释放 releaseShared() public final boolean releaseShared(int arg) { if (tryReleaseShared(arg)) { doReleaseShared(); return true; } return false; } 这个就没啥好说的，就尝试释放，成功了就doReleaseShared。\ndoReleaseShared() private void doReleaseShared() { /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ for (;;) { Node h = head; if (h != null \u0026amp;\u0026amp; h != tail) { int ws = h.waitStatus; if (ws == Node.SIGNAL) { if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases  // 唤醒后续节点  unparkSuccessor(h); } else if (ws == 0 \u0026amp;\u0026amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS  } if (h == head) // loop if head changed  break; } } 这段方法跟独占式锁释放过程有一点点不同，在共享式锁的释放过程中，持有同步状态的线程可能有多个，必须保证多个线程能够安全的释放同步状态，这里采用的CAS保证，当CAS操作失败continue，在下一次循环中进行重试。\n细节 为什么从后往前遍历？ unparkSuccessor()方法中的遍历是从尾节点开始的，那为什么不从头开始呢？ 看到入队方法addWaiter()中有这么一段\nnode.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } 可以看到是先设置了prev指针，再通过CAS去设置tail，成功后再设置next指针，所以如果在遍历过程中，恰好有一个节点入队，但是只设置了prev指针，在CAS操作之后t.next=node之前，这时候切换上下文到别的线程，那么从头往后遍历就会因为没有next指针而漏掉这个节点以及其之后的节点，从后往前因为有prev指针而不会漏掉。可以看图：  \ninterrupted变量的作用 在源码中，我们随处可见一个叫interrupted的变量，从字面意义上来看它就是用来标志当前线程是否被终端的，但是它其实只是一个标志位，并不能真正强行进行强行中断线程，具体进行什么操作还是线程自己决定的（这样有利于资源回收，和Thread类中的中断标志位如出一辙）。 那具体怎么发挥作用的呢？ 看到parkAndCheckInterrupt()方法，最后是return了Thread.interrupted()，这个方法是返回线程的中断标志位，并清除它。\nprivate final boolean parkAndCheckInterrupt() { LockSupport.park(this); // 在这里被挂起了, 唤醒之后就能继续往下执行了  return Thread.interrupted(); } 如果这里返回true，那么返回来到下面的语句(acquireQueued()方法)\nif (shouldParkAfterFailedAcquire(p, node) \u0026amp;\u0026amp; parkAndCheckInterrupt()) interrupted = true; 那么if判断为true，来到语句interrupted = true;，因为这里是for (;;)死循环，要抢到锁才返回，所以就继续下一次循环直到抢到锁然后会返回interrupted，acquireQueued()方法结束，再返回到acquire()方法\npublic final void acquire(int arg) { if (!tryAcquire(arg) \u0026amp;\u0026amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 此时上面这个大if为true，就执行selfInterrupt();，源码如下：\nstatic void selfInterrupt() { Thread.currentThread().interrupt(); } 这个方法就是自我中断了。 那么这么一圈下来，它的意义是什么？ 当我们从park(this)处被唤醒，我们并不知道是因为什么原因被唤醒，可能是因为别的线程释放了锁，调用了unpark(s.thread)，也有可能是因为当前线程被其他线程调用interrupt()方法中断了park()，因此我们通过Thread.interrupted()方法检查了当前线程的中断标志，并将它记录下来，在我们最后返回acquire()方法后，如果发现当前线程曾经被其它线程中断过，那我们就把当前线程再中断一次。\n 为什么要这么做呢？\n 从上面的代码中我们知道，即使线程在等待资源的过程中被中断唤醒，它还是会不依不饶的继续抢锁，直到它抢到锁为止。也就是说，当线程处于等待队列中时，是不去响应外部的中断请求的，仅仅是记录下自己被人中断过。 最后，当它抢到锁返回了，如果它发现自己曾经被中断过，它就再中断自己一次，将这个中断补上。\n注意，中断对线程来说只是一个建议，一个线程被中断只是其中断状态被设为true，线程可以选择忽略这个中断，中断一个线程并不会影响线程的执行，当然也可以自己决定响应这个中断要去执行的操作。\n总结 AQS是JUC中很多同步组件的构建基础，简单来讲，它内部实现主要是状态变量state和一个FIFO队列来完成，同步队列的头结点是当前获取到同步状态的结点，获取同步状态state失败的线程，会被构造成一个结点（或共享式或独占式）加入到同步队列尾部（采用自旋CAS来保证此操作的线程安全），随后线程会阻塞；释放时唤醒头结点的后继结点，使其加入对同步状态的争夺中。\nAQS为我们定义好了顶层的处理实现逻辑，我们在使用AQS构建符合我们需求的同步组件时，只需重写tryAcquire，tryAcquireShared，tryRelease，tryReleaseShared几个方法，来决定同步状态的释放和获取即可，至于背后复杂的线程排队，线程阻塞/唤醒，如何保证线程安全，都由AQS为我们完成了，这也是非常典型的模板方法的应用。AQS定义好顶级逻辑的骨架，并提取出公用的线程入队列/出队列，阻塞/唤醒等一系列复杂逻辑的实现，将部分简单的可由使用者决定的操作逻辑延迟到子类中去实现。\n参考 https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\nhttps://github.com/CL0610/Java-concurrency\nhttps://segmentfault.com/a/1190000015752512\n","date":"2022-01-15T17:13:23+08:00","image":"https://ccqstark.github.io/p/aqs/cover_hu61c3bca774698dc1e72a329e3b4305c2_117700_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/aqs/","title":"[并发编程]AQS源码分析"},{"content":"前言 上篇分析完HashMap之后，这次来分析下ConcurrentHashMap这个并发条件下线程安全的HashMap又有哪些精妙绝伦、惊为天人的设计呢🤔\n 本文同样主要分析JDK1.8版本的ConcurrentHashMap\n sizeCtl的作用 这个变量的作用比较复杂，起到标识位作用的同时也可以记录阈值等实际意义，主要有以下几种情况\n   sizeCtl值的情况 意义     0 代表数组未初始化，且数组的初始容量为16   正数 如果数组未初始化，那么其记录的是数组的初始容量；如果数组已经初始化，那么其记录的就是i扩容阈值（数组的初始容量*0.75）   -1 表示数组正在进行初始化   负数且不是-1 表示数组正在扩容，高16位是扩容标识戳，低16位是扩容线程数+1    扰动函数 static final int spread(int h) { // HASH_BITS（01111111111111111111111111111111）保证hash值一定是为正数，因为符号位为0  // 高低位去异或运算，这里和HashMap的类似，让高位参与运算是为了哈希得更均匀  return (h ^ (h \u0026gt;\u0026gt;\u0026gt; 16)) \u0026amp; HASH_BITS; } table数组的初始化 private final Node\u0026lt;K,V\u0026gt;[] initTable() { Node\u0026lt;K,V\u0026gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) { if ((sc = sizeCtl) \u0026lt; 0) // 如果sizeCtl小于0说明数组要么在初始化，要么在扩容，所以当前线程在让出CPU资源，也就是自旋  Thread.yield(); // lost initialization race; just spin  // 这里就是用CAS操作吧sizeCtl修改为-1，表示数组数组正在扩容  else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { // 这里采用双重校验锁的形式，防止别的线程拿到锁之后重复初始化操作  if ((tab = table) == null || tab.length == 0) { // 下面就是简单的初始化Node数组并赋给table成员变量的过程  int n = (sc \u0026gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\u0026#34;unchecked\u0026#34;) Node\u0026lt;K,V\u0026gt;[] nt = (Node\u0026lt;K,V\u0026gt;[])new Node\u0026lt;?,?\u0026gt;[n]; table = tab = nt; // (n \u0026gt;\u0026gt;\u0026gt; 2)就是n/4，所以这里相当于 n * 0.75 ，也就是计算扩容阈值  sc = n - (n \u0026gt;\u0026gt;\u0026gt; 2); } } finally { // 初始化完成后，sizeCtl记录的就是数组的扩容阈值了  sizeCtl = sc; } break; } } return tab; } putVal()方法分析 final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); // 扰动函数计算哈希值  int hash = spread(key.hashCode()); int binCount = 0; // 这里是一个死循环  for (Node\u0026lt;K,V\u0026gt;[] tab = table;;) { Node\u0026lt;K,V\u0026gt; f; int n, i, fh; // 判断到table数组为null或者长度为0，此时要先进行初始化  if (tab == null || (n = tab.length) == 0) tab = initTable(); // tabAt()就是用UnSafe类去获取对应下标的节点，下标的计算方式和HashMap的一样都是(n - 1) \u0026amp; hash)  // 如果桶位为null的话，可以CAS放到桶中，结束循环  else if ((f = tabAt(tab, i = (n - 1) \u0026amp; hash)) == null) { if (casTabAt(tab, i, null, new Node\u0026lt;K,V\u0026gt;(hash, key, value, null))) break; // no lock when adding to empty bin  } // 这里的MOVED表示这是一个Forward节点，说明在扩容过程中已经迁移到新数组中去了  // 所以不能直接放进数组中，要进行协助扩容  else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; // 这里就用synchronized锁住了当前的桶位  // 注意这里只是锁住了当前这一个桶位以及其链表或红黑树，不影响其它桶位  // 相比HashTable一锁就是锁住整个数组来说提高了并发度，同时也保证了线程安全  synchronized (f) { // 下面就是比较常规的变量这个链表中是否存在这个key，去决定下一步是覆盖还是插在链表中  if (tabAt(tab, i) == f) { if (fh \u0026gt;= 0) { binCount = 1; for (Node\u0026lt;K,V\u0026gt; e = f;; ++binCount) { K ek; if (e.hash == hash \u0026amp;\u0026amp; ((ek = e.key) == key || (ek != null \u0026amp;\u0026amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node\u0026lt;K,V\u0026gt; pred = e; if ((e = e.next) == null) { pred.next = new Node\u0026lt;K,V\u0026gt;(hash, key, value, null); break; } } } // 这就是红黑树的情况了  else if (f instanceof TreeBin) { Node\u0026lt;K,V\u0026gt; p; binCount = 2; if ((p = ((TreeBin\u0026lt;K,V\u0026gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { // 这里就是判断链表节点是否达到8个，以及treeifyBin()方法中判断数组长度是否到达64来决定是否树化  // 这里的判断逻辑就和HashMap基本是一样的  if (binCount \u0026gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } // 维护集合的长度，包含fullAddCount()方法  addCount(1L, binCount); return null; } 当要往一个桶位添加节点的时候，synchronized只会锁住当前这个桶位，不会影响其它桶位，如图：\n \n集合长度的维护 这里其实就和LongAdder 的设计基本一样：\n就是把集合里元素的数量拆分成一个baseCount和一个CounterCell数组之和，每次新增一个元素需要对元素的数量+1，首先优先会对baseCount进行CAS+1的操作，如果失败则跳到fullAddCount 方法。 fullAddCount 方法会来到CounterCell数组中找一个位置进行+1，数组中的每一个CounterCell对象就维护这个一个value来+1，而找到我们要操作的位置就是通过当前线程进行哈希来定位，之后的+1也是通过CAS。而且这个过程中可能还会对CounterCell数组进行扩容，但是数组长度受到当前机器CPU核数的限制，因为超过同时竞争的线程数再扩容就意义不大。\n其中fullAddCount 方法中是通过一个for的死循环，会进行很多次CAS操作直到成功为止。涉及到以下几个变量：\n cellsBusy CountCell 的操作标记位，如果正在修改、新建、操作 CountCell 数组中的元素会，会将其 cas 为 1，否则为0。 wasUncontended 表示 cas 是否失败，如果失败则考虑操作升级。 collide 是否冲突，如果冲突，则考虑扩容 CountCell 数组的长度。  其中涉及到一些double check保证线程安全，还有尝试更新失败后的操作可能是下一个循环重试、或者对线程的rehash再重试、或者是对baseCount进行CAS重试等操作，基本都是逐步升级的，以最小代价完成这个+1的操作。\n这个fullAddCount方法基本上思路就是这样，这里就不一行行分析了，因为这个方法非常复杂，可以看这个视频的讲解就带你一行行去看懂。(ConcurrentHashMap的fullAddCount方法就对应LongAdder的longAccumulate方法)\n \n这样做的意义其实是为了提高高并发下统计数量的性能，也就是与AtomicLong 这种对一个value值进行CAS的操作相比，在大量线程竞争的时候，会有很多线程自旋造成CPU的较大的开销；而使用LongAdder 这种设计思路来维护一个数组就让多个线程来增加这个统计数的时候可以分散的操作，减少竞争冲突，提高了并发度，而我们要得到这个统计数就只需用baseCount去加上数组里所有元素之和就可以了。\n高并发情况下LongAdder 性能是比AtomicLong 要好的，但是LongAdder在计算统计值的时候如果有线程在修改那么可能就会有些许误差，所以一般也用于允许一定误差的场景来提高性能。\n扩容 扩容标识sizeCtl 首先在扩容过程中，sizeCtl的值会经过一系列操作：\n下面是resizeStamp()方法：\nstatic final int resizeStamp(int n) { return Integer.numberOfLeadingZeros(n) | (1 \u0026lt;\u0026lt; (RESIZE_STAMP_BITS - 1)); } 首先numberOfLeadingZeros(n)的作用是返回n的最高非0位前面的0的个数，比如n=16，因为16是 10000。一个int是32位，32-5就是27。那么 Integer.numberOfLeadingZeros(n)返回值就是27。\n然后RESIZE_STAMP_BITS是16，1 \u0026lt;\u0026lt; (RESIZE_STAMP_BITS - 1)就是让1左移15位，最后得到1后面15个0。 两者相或，会让这个numberOfLeadingZeros(n)得到的这个数的第16位变成1，这个1待会会用到。addCount()方法中把这个resizeStamp()方法的返回值赋给变量rs。\n然后看到addCount()方法中在发现元素数量已经超过扩容阈值时，有这么一段：\nelse if (U.compareAndSwapInt(this, SIZECTL, sc, (rs \u0026lt;\u0026lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); rs \u0026lt;\u0026lt; RESIZE_STAMP_SHIFT) + 2 这个表达式的作用就是把rs左移16位，这样一来上面原本rs的第16位的1就变成了符号位，这个也就变成了负数，原本的rs被移到了高16位；然后加2，低16位就是2，也就是表示当前扩容的线程数+1 。而上面这个CAS操作成功的话，sizeCtl就变成了这个很大的负数，也就标志着当前容器正式进入了扩容状态。\n \n判断扩容是否结束也是靠这个标识，在transfer()方法中：\nif (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { if ((sc - 2) != resizeStamp(n) \u0026lt;\u0026lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit } 先对线程数-1，判断(sc - 2) != resizeStamp(n) \u0026lt;\u0026lt; RESIZE_STAMP_SHIFT 是否为真，其实就是形式变换了一下，本质上还是判断这个扩容标识值是否还原为原来初始化时的值，如果是则证明扩容迁移过程都完成了，finishing 标志为置为true。\n协助扩容的时机 有两种情况会让这个线程一起协助扩容\n  addCount()方法\naddCount方法在判断sizeCtl\u0026lt;0后会有这么一段：\nif (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); 这里CAS是把当前协助扩容的线程数+1，因为只有低16位与扩容线程数有关，所以尽管此时sizeCtl为负数也是直接+1的。CAS成功后就进入transfer()方法进行扩容\n  putVal()方法\nelse if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); 上面分析putVal()方法中也分析了这一点，MOVED表示这是一个Forward节点，说明在扩容过程中已经迁移到新数组中去了，所以不能直接放进数组中，要进行协助扩容。\nhelpTransfer 方法中同样有对线程数+1的操作：\nif (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) { transfer(tab, nextTab); break; }   多线程协助扩容 正式开始扩容后，新建一个新的数组，长度为原来的2倍，然后我们就需要把原数组中的数据迁移过去。由于是多线程环境，所以迁移过程由多个线程共同完成，它是将数组划分成了几个部分，每个部分由一个线程来进行迁移操作，顺序是从后往前迁移的。每个线程迁移的最小任务量是16个桶位。\n每迁移完一个节点，就会把这个桶位的节点变为Forward节点(fwd)，这种节点的hash为常量MOVED，相当于一个标识位，表示当前节点已经迁移到新数组中去了。当某个putVal时遇到这种节点就要去协助扩容而不能直接插入了。\n在多线程环境下，如果该线程触发了上面说的协助扩容的时机，就会去“领任务”，也就是被分配一段自己负责的迁移数据的范围，由transferIndex 记录下一个分配工作范围开始的位置，更具一个线程的任务量 stride 去计算此次分配任务的左边界bound ，再CAS去更新transferIndex 的值让他向左移动一个stride 为下一次分配做准备。\n \n这里图解一下，为了容易看一点这里假设最小任务量是4，原数组有16个桶位，所以可以划分出4个工作量。每次分配完transferIndex就左移一个线程工作量，当扩容时有多个线程触发协助扩容条件就会进来拿到一个自己要帮助迁移的工作范围，做完之后可以领下一个直到全部迁移完。所以同一时刻可能有多个不同的线程在一起帮助扩容，利用了多线程的特点提高了迁移的效率。\ntransfer()方法源码解析 private final void transfer(Node\u0026lt;K,V\u0026gt;[] tab, Node\u0026lt;K,V\u0026gt;[] nextTab) { int n = tab.length, stride; // stride就是每次给线程分配的任务数  // 如果是多cpu，那么每个线程划分任务，最小任务量是16个桶位的迁移  if ((stride = (NCPU \u0026gt; 1) ? (n \u0026gt;\u0026gt;\u0026gt; 3) / NCPU : n) \u0026lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range  // 如果是第一个发起扩容的线程(非协助迁移的)，此时新数组为null  if (nextTab == null) { // initiating  try { @SuppressWarnings(\u0026#34;unchecked\u0026#34;) // 两倍扩容创建新数组  Node\u0026lt;K,V\u0026gt;[] nt = (Node\u0026lt;K,V\u0026gt;[])new Node\u0026lt;?,?\u0026gt;[n \u0026lt;\u0026lt; 1]; nextTab = nt; } catch (Throwable ex) { // try to cope with OOME  sizeCtl = Integer.MAX_VALUE; return; } nextTable = nextTab; // 记录线程开始迁移的桶位，从后往前迁移  transferIndex = n; } // 记录新数组的末尾  int nextn = nextTab.length; // 已经迁移的桶位，会用ForwardingNode节点占位（这个节点的hash值为-1（MOVED））  ForwardingNode\u0026lt;K,V\u0026gt; fwd = new ForwardingNode\u0026lt;K,V\u0026gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab  for (int i = 0, bound = 0;;) { Node\u0026lt;K,V\u0026gt; f; int fh; while (advance) { int nextIndex, nextBound; // i记录当前正在迁移桶位的索引值  // bound记录下一次任务迁移的开始桶位  // --i也是从后往前迁移的体现  // --i \u0026gt;= bound 成立表示当前线程分配的迁移任务还没有完成  if (--i \u0026gt;= bound || finishing) advance = false; // 没有元素需要迁移 =\u0026gt; 后续会去将扩容线程数减1，并判断扩容是否完成  else if ((nextIndex = transferIndex) \u0026lt;= 0) { i = -1; advance = false; } // 计算下一次任务迁移的开始桶位，并将这个值赋值给transferIndex  // 因为迁移是从后往前的，所以用 nextIndex - stride  else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex \u0026gt; stride ? nextIndex - stride : 0))) { bound = nextBound; i = nextIndex - 1; advance = false; } } // 如果没有更多的需要迁移的桶位，就进入该if  if (i \u0026lt; 0 || i \u0026gt;= n || i + n \u0026gt;= nextn) { int sc; // 扩容结束后，保存新数组，并重新计算扩容阈值，赋值给sizeCtl  if (finishing) { nextTable = null; table = nextTab; // 这里实际上是0.75n * 2，用位运算加速  sizeCtl = (n \u0026lt;\u0026lt; 1) - (n \u0026gt;\u0026gt;\u0026gt; 1); return; } // 扩容任务线程数减1  if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) { // 判断当前所有扩容任务线程是否都执行完成  if ((sc - 2) != resizeStamp(n) \u0026lt;\u0026lt; RESIZE_STAMP_SHIFT) return; // 所有扩容线程都执行完，标识结束  finishing = advance = true; i = n; // recheck before commit  } } // 当前迁移的桶位没有元素，直接在该位置添加一个fwd节点  else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 当前节点已经被迁移  else if ((fh = f.hash) == MOVED) advance = true; // already processed  else { // 当前节点需要迁移，加锁迁移，保证多线程安全  // 此处的迁移逻辑和HashMap的基本一样，也就是拆分高低位链表，所以就不再重复分析了  synchronized (f) { if (tabAt(tab, i) == f) { Node\u0026lt;K,V\u0026gt; ln, hn; if (fh \u0026gt;= 0) { int runBit = fh \u0026amp; n; Node\u0026lt;K,V\u0026gt; lastRun = f; for (Node\u0026lt;K,V\u0026gt; p = f.next; p != null; p = p.next) { int b = p.hash \u0026amp; n; if (b != runBit) { runBit = b; lastRun = p; } } if (runBit == 0) { ln = lastRun; hn = null; } else { hn = lastRun; ln = null; } for (Node\u0026lt;K,V\u0026gt; p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph \u0026amp; n) == 0) ln = new Node\u0026lt;K,V\u0026gt;(ph, pk, pv, ln); else hn = new Node\u0026lt;K,V\u0026gt;(ph, pk, pv, hn); } setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } else if (f instanceof TreeBin) { TreeBin\u0026lt;K,V\u0026gt; t = (TreeBin\u0026lt;K,V\u0026gt;)f; TreeNode\u0026lt;K,V\u0026gt; lo = null, loTail = null; TreeNode\u0026lt;K,V\u0026gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node\u0026lt;K,V\u0026gt; e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode\u0026lt;K,V\u0026gt; p = new TreeNode\u0026lt;K,V\u0026gt; (h, e.key, e.val, null, null); if ((h \u0026amp; n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } ln = (lc \u0026lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin\u0026lt;K,V\u0026gt;(lo) : t; hn = (hc \u0026lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin\u0026lt;K,V\u0026gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; } } } } } } 与JDK1.7相比 1.7 中的 concurrentHashMap 使用了分段锁的机制，定义了Segment，每个 Segment 是 一个单独的容器，单独获取一把ReentrantLock锁。Segment 都是一个类似 HashMap 数组的结构，它可以扩容，它的冲突会转化为链表。但是 Segment 的个数一但初始化就不能改变。\n1.8的ConCurrentHashMap大部分采用的是synchronized与CAS操作去保证线程安全的，synchronized现在有锁升级机制性能好很多了，CAS是用sun.misc.Unsafe 类实现的底层是CMPXCHG指令，putVal的时候加锁只会锁住一个桶位不影响其他的，容器内元素的长度采用的是LongAdder的数组累加的提高并发的设计，扩容时允许多个线程一起协助迁移数据，还有一个sizeCtl的变量来标识当前容器的各种状态、扩容阈值或者扩容线程数。\n一些感想 看了ConcurrentHashMap的源码以及之前的HashMap源码不得不感叹真的是太精妙了，不仅大量使用位运算来提高性能，甚至一个变量都掰成高16位和低16位使用，大量使用CAS能不加锁的地方绝不加锁，最绝的是一个统计长度的变量都能拆成一个数组的和来优化，真的是对性能追求到了极致，优化到了极致。最后说一句：Doug Lea大神牛逼！\n \n参考 https://xilidou.com/2018/11/27/LongAdder/\nhttps://www.cnblogs.com/juniorMa/p/13838947.html\n面试必备之ConcurrentHashMap终结篇-黑马程序员杭州校区出品_哔哩哔哩_bilibili\n","date":"2022-01-03T02:15:23+08:00","image":"https://ccqstark.github.io/p/concurrenthashmap/cover_huc96d02dfde7960de9a20cc4a3d1809da_315641_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/concurrenthashmap/","title":"ConcurrentHashMap源码分析"},{"content":" 本文主要针对JDK1.8进行分析\n 四个构造方法 // 默认构造函数。 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // 其他字段都是默认值 } // 包含另一个“Map”的构造函数 public HashMap(Map\u0026lt;? extends K, ? extends V\u0026gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } // 指定“容量大小”的构造函数 public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } // 指定“容量大小”和“加载因子”的构造函数 public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity \u0026lt; 0) throw new IllegalArgumentException(\u0026#34;Illegal initial capacity: \u0026#34; + initialCapacity); if (initialCapacity \u0026gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor \u0026lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\u0026#34;Illegal load factor: \u0026#34; + loadFactor); this.loadFactor = loadFactor; // tableSizeFor方法是返回一个大于等于传入值的一个2的幂的数  // 所以经过这个构造方法的hashmap的threshold是2的幂，在扩容时的某种情况下可以赋给新的容量（详见下面resize分析）  this.threshold = tableSizeFor(initialCapacity); } 为什么负载因子默认是0.75f？ 因为如果负载因子太大，也就是越接近于1，数据就会比较密集，链化会比较严重，查询效率就会比较低；如果负载因子太小，就会导致数组比较松散，数组的空间利用率低。所以默认0.75是官方对空间和时间效率的一个平衡选择。\n给定的默认容量为 16，负载因子为 0.75。Map 在使用过程中不断的往里面存放数据，当数量达到了 16 * 0.75 = 12 就需要将当前 16 的容量进行扩容，而扩容这个过程涉及到 rehash、复制数据等操作，所以非常消耗性能。\n与 HashTable 的比较  HashMap是Hashtable的轻量级实现，HashMap允许key和value为null，但最多允许一条记录的key为null。而HashTable不允许。 HashTable中的方法是线程安全的，使用 synchronized 来进行同步，而HashMap不是线程安全的。 HashMap具有fail-fast机制  fail-fast机制 fail-fast 机制是 java 集合(Collection)中的一种错误机制。 当多个线程对同一个集合的内容进行操作时，就可能会产生 fail-fast 事件。\n这一策略在源码中的实现是通过成员变量modCount，表示修改次数，每次对 HashMap 内容（当然不仅仅是 HashMap 才会有，其他例如 ArrayList 也会）的修改都会进行modCount++，那么在迭代器初始化过程中会将这个值赋给迭代器的 expectedModCount。在操作过程中判断 modCount 跟 expectedModCount 是否相等，如果不相等就表示已经有其他线程修改了容器内容，就会抛出ConcurrentModificationException\nif (modCount != expectedModCount) throw new ConcurrentModificationException(); 为什么modCount不用volatile来修饰？\n理论上我们为了各线程都保证对modCount的可见性，但是实际上即使modCount用volatile关键字修饰，还是保证不了多线程下记录正确的modcount，因为valotile是弱同步机制保证不了线程安全，所以也无法保证每次多线程修改都可以触发ConcurrentModificationException ，同时还会增加额外的开销，所以就没有必要用volatile修饰modCount了。\n为什么数组的长度总是2的幂 因为我们寻址的话一般就是对hash值进行取模，也就是hash%length ，如果length是2的次方数，那么取模的公式其实是等于hash\u0026amp;(length-1) ，而使用位运算的话CPU计算会快一点，提高了性能。\nhash%length == hash\u0026amp;(length-1) 的原因是当length为2的幂时，假如是16，那二进制就为10000，减去1就是01111，任何数与其相与都是保留其低4位，也就是0到15这样一个范围，效果自然就和取模是一样的了。\nhash方法 static final int hash(Object key) { int h; // h = key.hashCode() 为第一步 取hashCode值  // h ^ (h \u0026gt;\u0026gt;\u0026gt; 16) 为第二步 高位参与运算  return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u0026gt;\u0026gt;\u0026gt; 16); } 通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h \u0026raquo;\u0026gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。\n上面代码是JDK1.8的实现，相比1.7减少了扰动次数，优化了一点性能。\n \nput方法过程  \n所以put主要有四种情况：\n 对应桶位为null就可以直接插入 对应key已经存在，直接覆盖value 对应位置已经树化，那就用插入到红黑树中 对应位置已经链化，进行链表的插入。此时如果链表长度大于8，再判断如果当前数组的长度小于 64，那么会选择先进行数组扩容，而如果数组长度大于64了才转换为红黑树。  扩容机制 为什么需要扩容？ 为了解决数据量大的情况下哈希冲突严重导致大量节点链化，影响查询的效率（链表查询为O(n)），扩容可以缓解该问题。\n扩容时机 由上面的put方法流程图中可以看出，在一开始table为空或者length为0，或者当size超过threshold的时候会触发resize方法进行扩容，而threshold = 容积 * 负载因子。\nresize方法源码分析 这里把resize方法拆成两部分进行分析\n 第一部分：主要是为了计算出新数组的长度以及新的扩容阈值  final Node\u0026lt;K,V\u0026gt;[] resize() { // oldTab:引用扩容前的哈希表  Node\u0026lt;K,V\u0026gt;[] oldTab = table; // oldCap:表示扩容之前table数组的长度  int oldCap = (oldTab == null) ? 0 : oldTab.length; // oldThr:表示扩容之前的扩容阈值，也就是触发此次扩容的阈值  int oldThr = threshold; // newCap:扩容之后table数组的长度  // newThr：扩容之后的扩容阈值，也就是下一次触发扩容的条件  int newCap, newThr = 0; // 判断如果hashmap已经初始化过了，这是一次正常的扩容  if (oldCap \u0026gt; 0) { // 扩容之前发现table数组大小已经达到了最大容量限制，不扩容，并把阈值设置为int的最大值(非常少数的情况)  if (oldCap \u0026gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // oldCap左移一位实现数值翻倍（2倍），并赋给newCap，如果newCap小于最大容量限制且oldCap大于等于16  // 则让下一次扩容的阈值等于当前阈值的翻倍  else if ((newCap = oldCap \u0026lt;\u0026lt; 1) \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; oldCap \u0026gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr \u0026lt;\u0026lt; 1; // double threshold  } // 此时oldCap==0， 说明hashmap中的散列表为null，就是通过一下三种情况进行初始化的  // 1. new HashMap(initialCapacity, loadFactor);  // 2. new HashMap(initialCapacity);  // 3. new HashMap(map); 通过一个含有数组的map进行初始化  else if (oldThr \u0026gt; 0) // initial capacity was placed in threshold  // 此时的oldThr也就是threshold一定是2的幂，保证了newCap也是2的次方  // 因为这里都是tableSizeFor()方法设置的threshold  newCap = oldThr; // 此时oldCap==0 且 oldThr==0  // 也就是无参构造出来的 new HashMap();  else { // zero initial threshold signifies using defaults  newCap = DEFAULT_INITIAL_CAPACITY; // 16  newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); // 12  } // newThr为零，这种情况一般就是初始化时自己指定了一个数组大小且这个值小于默认的16比如为8  // 所以就导致上面的newThr赋值语句都没有执行到  if (newThr == 0) { // newThr = 容量 * 负载因子  float ft = (float)newCap * loadFactor; newThr = (newCap \u0026lt; MAXIMUM_CAPACITY \u0026amp;\u0026amp; ft \u0026lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } // 赋值给成员变量threshold  threshold = newThr; // === 这是分界线，上面前半段都是为了计算出newCap和newThr ===  第二部分：rehash过程，主要是把原来的链表拆分成高低位链表  // 这里开始是rehash过程  @SuppressWarnings({\u0026#34;rawtypes\u0026#34;,\u0026#34;unchecked\u0026#34;}) // 用newCap创建了一个更大的数组  Node\u0026lt;K,V\u0026gt;[] newTab = (Node\u0026lt;K,V\u0026gt;[])new Node[newCap]; // 新数组赋给table数组  table = newTab; // 说明本次扩容之前table数组不为null  if (oldTab != null) { // 去遍历原数组里的元素  for (int j = 0; j \u0026lt; oldCap; ++j) { // 当前的node节点  Node\u0026lt;K,V\u0026gt; e; // 说明当前桶位有数据，具体为单节点还是链表还是红黑树就分情况去处理  if ((e = oldTab[j]) != null) { // 置为null方便JVM GC时回收内存  oldTab[j] = null; // 第一种情况：单节点，也就是从未发生过碰撞  if (e.next == null) // 直接找到新桶位然后赋值进去  // 这里新桶位也是不会发生冲突的，因为同一个桶位映射到新数组中也是一一对应的  newTab[e.hash \u0026amp; (newCap - 1)] = e; // 第二种情况：当前节点以及树化  else if (e instanceof TreeNode) ((TreeNode\u0026lt;K,V\u0026gt;)e).split(this, newTab, j, oldCap); // 第三种情况：当前节点已经形成链表  else { // preserve order  // 低位链表：在新数组中的位置与存放在扩容前数组的位置一致  Node\u0026lt;K,V\u0026gt; loHead = null, loTail = null; // 高位链表：存放在新数组的下标 = 原数组下标 + 原数组长度  Node\u0026lt;K,V\u0026gt; hiHead = null, hiTail = null; Node\u0026lt;K,V\u0026gt; next; do { next = e.next; // 判断为低位链表  if ((e.hash \u0026amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } // 判断为高位链表  else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { // 虽然拆成两部分了，但是在存在于原链表中的next指针可能还连着，所以这里要去除一下  loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; // 这里就是高位链表下标 = 原数组下标 + 原数组长度  newTab[j + oldCap] = hiHead; } } } } } return newTab; } rehash的过程分为了三种情况：\n  当前节点是单节点\n原数组中桶位是单节点，在新数组中虽然可能在高桶位或低桶位（见下面第3点），但是也是和原数组下标一一对应的，在新数组中不会与别的节点冲突，所以直接放到新桶位就行不用其他操作。\n  当前节点树化了\n本质上和第三种情况一样也是拆分成两块放在新数组的不同位置，只不过此时是红黑树，而第三种情况是链表。具体源码就不分析了，比较麻烦（其实是因为我也没去仔细看doge），大概过程如下：\n 当低位区小红黑树元素个数小于等于6时，开始去树化untreeify操作； 当低位区小红黑树元素个数大于6且高位区红黑树不为null时，开始树化操作(赋予红黑树的特性)。    当前节点链化了\n这里拆成高低位两部分，拆分的依据就是，这个节点的hash值的二进制值在新长度二进制值为1的那个位，是1还是0。\n这样说比较抽象，举个例子，原来数组长度是16，扩容之后就变成了32，对应的二进制就分别是10000 和 100000 ，就是多了一个0，这个1所在的位置就高了一位。\n现在有2个hash值分别为10（01010）和26（11010）的节点，他们在长度为16的数组中是同一个桶位，根据公式hash\u0026amp;(length-1) 计算可得。但是在长度为32中，由于最高位的不同，计算结果也不同，从而被分成了两类，而高位的桶位下标 = 低位桶位下标 + 原数组长度（本例中是16），也正是多了最前面那个1 （如下图）\n \n拆分成高低位链表过程看下图更明显（蓝色节点为低位链表，绿色为高位）：\n \n  与JDK1.7相比 JDK1.7的HashMap中的链表采用的是头插法，当在扩容时需要对原数组的链表迁移到新数组的正确位置时，采用头插法就会使得链表元素的顺序倒过来了。而且，在多线程的情况下，可能在迁移过程中出现循环链表的情况，导致在之后遍历这个链表时出现死循环，问题就很大了。\n所以JDK1.8时采用的时尾插法避免了这种情况，但是无论如何在并发情况下还是不建议直接使用普通的HashMap的，因为它的线程不安全的。需要线程安全的场合建议用ConcurrentHashMap。\n参考 HashMap全B站最细致源码分析课程，看完月薪最少涨5k！_哔哩哔哩_bilibili\nJava 8系列之重新认识HashMap\nHashMap源码\u0026amp;底层数据结构分析\n","date":"2022-01-01T13:58:40+08:00","image":"https://ccqstark.github.io/p/hashmap/cover_hu1511f3a3e5b8bd5321cac5b96fbe8ed4_1324881_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/hashmap/","title":"HashMap源码与扩容机制分析"},{"content":"前言 由于最近在看Java的容器，看到HashMap，发现它底层有用到红黑树，想起了一些段子以及很久之前曾经挑战过学习它但是没有成功，于是这次打算再次挑战一波，并写成博客。\n应用场景  JDK的HashMap、TreeMap和TreeSet Linux内核的虚拟内存管理 Nginx的Timer管理 C++的STL  可以看到在实际工程场景中还是用得很多的一种数据结构的。\n五大基本性质 首先红黑树是一颗二叉搜索树，然后再加上下面五大性质：\n 节点有红色和黑色两种 根节点一定是黑色的 叶子节点（nil节点）都是黑色的 不能有连续的红色节点 任意节点到叶子节点所经过的黑色节点数相同   第5点就是红黑树维持平衡的重要条件，我们常说的达到黑色平衡或者红黑树达到平衡主要说的就是达到这个条件。\n 如果精力充足的话建议可以再去了解一下2-3-4树，红黑树就是对概念模型2-3-4树的一种实现，这里推荐我当时看的敖丙写的一篇文章，介绍了2-3-4树的概念及其与红黑树的转化，最后介绍了红黑树的简化版——左倾红黑树的插入与删除。\n本质与意义 这一部分要说的就是面试经常问的：为什么有了二查找查找树/平衡树还需要红黑树？\n二叉查找树的缺点 二叉查找树大家应该很熟悉，特点就是左子树的节点都比父节点小，而右子树的节点值都比父节点大。基于这个特点，我们在二叉查找树查找某一个值时，采用类似二分查找的思想，时间复杂度只用O(logn)。\n但是这是正常情况下，因为二叉查找树有可能出现一种极端，就是所有节点都同一方向上（如下图），这个时候二叉搜索树以及近似退化为一条链表了，查找的时间复杂度也顿时变成了O(n) ，那这样的话二叉搜索树也就失去了原本的意义——让搜索变得更快。\n \n为了解决这个问题，出现了平衡二叉搜索树（也就是我们常说的AVL树）。\nAVL树 为了解决二叉搜索树可能退化为链表的问题而生，有以下特点：\n 拥有二叉树的全部特性 每个节点的左子树和右子树的高度差不超过1  由于第二点的约束使得AVL树不会出现大量节点一边倒的情况，但是在AVL树构建的过程中就需要很多额外的操作来保证其符合这个特性，使得其最坏情况下查找的时间复杂度也还是为O(logn)\n为什么有了AVL树还要红黑树？ 虽然AVL树解决了二叉搜索树退化了近似链表的缺点，但是由于每个节点的左子树和右子树的高度差不超过1这个要求实在是太严苛了，导致每次插入和删除节点的时候很容易就破坏了这条规则，之后就需要左大量的左旋和右旋来进行调整时期再次符合AVL树的要求。\n所以如果在插入和删除很频繁的场景中，AVL树需要很频繁地进行调整，这样的话效率就大大降低了，为了解决这个问题所以出现了红黑树。（如果在面试中接下来这里就可以说出红黑树的那5个特点）。\n正由于红黑树的这些特点，使其最坏情况下不仅还能维持用O(logn)的时间复杂度找到某个节点，而且与AVL树相比，优势就在于不会那么频繁地破坏红黑树的规则，从而不用那么频繁地进行调整，这就是我们大多数情况下使用红黑树的原因。\n所以红黑树是一种相对AVL树来说不那么严格的平衡树，也就是一种折中的方案，介于普通的二叉搜索树和AVL树之间。极端情况下左右子树的节点数（也就是深度）相差一倍，也就是左边都有黑节点，右边都是红黑相间，右子树的节点数或者说深度就也是左子树的2倍，这个要求就比AVL树的相差最多只能为1宽松多了，因此调整也就更少，效率也就更高。\n为什么红黑树查找的时间复杂度还能维持在O(logn)？ 我们对最坏情况下的时间复杂度进行计算。\n最坏情况下就是上面说的红黑相间，总节点数=红节点数+黑节点数，红黑节点数一致。\n$$n = n_r + n_b$$\n所以时间复杂度就是\n$$O(2* \\log n_b ) = O(2 * \\log \\frac{n}{2})$$\n常数2直接去掉\n$$O(\\log \\frac{n}{2}) = O(\\log n - 1)$$\n然后因为这里是二分，所以log底数取2，就转换为如上的最终形式，去掉常数-1后可以发现此时最坏情况下的时间复杂度仍然还是O(logn) 。\n红黑树的插入  下面要介绍的插入和删除操作涉及左旋和右旋概念，需要先保证了解这两个基本操作。\n 插入和删除操作推荐用这个数据结构动画演示网站搭配食用：https://www.cs.usfca.edu/~galles/visualization/RedBlack.html\n总结表格 插入操作的话相对删除还是要简单一点的，但是还是分出了几种情况，这里就用b站up free-coder总结的表格：\n \n叔节点：父节点的兄弟节点\n祖父节点：父节点和叔节点的父节点，也就是爷爷节点\n 为了尽可能不去破环平衡，我们插入的新节点都是默认为红色的，插入后再检查是否破坏了红黑树的定义，如果破坏了我们再去进行调整。\n 具体解析 表格中一共有6种情况，由于其中有两组是镜像的，所以下面归纳为4中情况：\n 情况1：父节点是黑节点  由于父节点是黑节点，插入的新节点就一定是红节点（因为不能有连续的红节点），而红节点不影响红黑树的平衡，所以也无需任何调整操作了。\n \n如图，父节点是根节点也就是黑的，值为1，插入了一个2为红节点，所以无需任何操作。\n 情况2：父节点是红节点，叔节点是黑节点（“左左”和“右右”类型）  在情况1的基础上我们插入一个3\n \n可以看到此时3的父节点2是红，叔节点nil节点是黑的，我们先进行一个左旋，发现出现连续的红色，所以再进行一个变色即可。\n这里2和3节点都是它们各自父节点的右子节点，也就是对应上面表格中类型的“右右”，但其实“左左”只是镜像了一下，这里就不再赘述。\n 情况3：父节点和叔节点都是红  我们在情况2 的基础上再插入一个4\n \n插入4后父亲节点3和叔节点1都是红的，所以我们把父叔都变黑，祖父变红，然后祖父变为当前节点，向上递归这个逻辑直到根节点，由于根节点一定是黑的所以就把节点2变黑即可。\n 情况4：父节点是红节点，叔节点是黑节点（“左右”和“右左”类型）   \n这里插入的是11，我们发现插入11后，节点10、12、11形成了一个“右左”类型，形状上就是一个折了一下的类似三角的感觉，这时我们只需要右旋一下，诶就转为“右右”类型了，然后再按“右右”类型去左旋+变色就可以调整完成。\n同样的，“左右”类型和“右左”类型是镜像，这里也不再赘述。\n红黑树的删除 删除操作是红黑树中最难、情况最多的操作。红黑树的其他方面我感觉还行，就是删除操作我感觉才是红黑树难的精髓之处。\n通过替换来删除 删除和插入一样，都可能会破坏红黑树原本的性质，所以在删除后我们是需要做一些调整才让树维持红黑树的性质。\n首先从我们直觉上来看，如果删除的节点位于叶子节点处，或者相对来说位置比较低，那删除节点后应该对整棵树的影响会比较小，所需做的调整应该也简单很多甚至不用调整。但是如果被删除的节点位于树的相对中间的位置，而且这个节点还有左右子树，那要做的调整相对来说就会多一点。\n所以，我们一般采用一种方法，就是通过替换去删除，具体来说就是找到被删除节点的左邻节点或者右邻节点，然后把左邻或右邻节点放到被删除节点进行覆盖，然后把左邻右邻节点原来位置上的节点进行删除。\n左邻和右邻是我自己叫的名字，实际上就是在这棵搜索树的所有节点中，排序刚好比被删除节点小一位和大一位的节点，具体在位置：\n左邻节点：本节点左子树中的最大节点，即左子树中最右的节点\n右邻节点：本节点右子树中的最小节点，即右子树中最左的节点\n示例：\n \n如图，D是被删除节点，R是其右邻节点，我们用R覆盖了D，然后把R原来位置删除，就完成了这个过程。\n然后我们将删除分为三种情况：\n 情况一：被删除节点无子节点， 直接删除 情况二：被删除节点只有一个子节点，用子节点替换要被删除的节点 情况三：被删除节点有两个子节点，可以用左邻节点或者右邻节点进行替换删除操作  所以实际上三种情况都可以概括为这样一个过程：找到一个用来替换的节点，覆盖要被删除的节点，最后再删除用于替换的节点原本所在的节点。\n具体到红黑树，可以分为三大场景，9种小情况，其中场景二和三互为镜像，可以结合在一起看。\n删除场景一 删除场景一：替换节点是红节点\n \n替换节点如果是红节点，删除之后不影响红黑树的平衡，只需要把让替换节点覆盖后把颜色设置为被删除节点原来的颜色即可。\n删除场景二  删除场景二：替换节点是黑色节点，而且此替换节点是它父节点的左子节点\n 由于替换节点是黑色节点，删除后势必会破坏红黑树的黑色平衡，所以要进行调整，这里又分出四种小情况。\n 情况2.1：替换节点的兄弟节点是红节点。  删除替换节点（黑）后，左子树的黑色节点会减少一个，所以我们要进行的操作是用替换节点的兄弟节点来补充一下左子树的黑节点数。\n \n具体操作：将替换节点的父节点P设为红色，兄弟节点S设置为黑色，然后对节点P左旋操作，转换为情况2.4 ，接下来就用情况2.4 的操作继续进行。\n 注意场景二、三的图例都是还没进行覆盖和删除的时候的R，只是根据其位置和周边节点的特点来讨论和推断它被删除后红黑树平衡被破坏的状态以及之后要采取的自平衡操作。\n  情况2.2：替换节点的兄弟节点是黑色，同时兄弟节点的右子节点是红色的，左子节点任意颜色  这种情况同样要借助兄弟节点来补充左子树的黑节点数，达到平衡。\n \n 注意图中的灰色节点表示可以为任意颜色\n 具体操作：将替换节点的兄弟节点S设置为父节点的颜色，兄弟节点的右子节点SR设置为黑色，父节点P设置为黑色，然后对P进行左旋操作。此时发现同样也是给左子树补了一个黑节点同时右子树黑节点数不变。\n 情况2.3：替换节点的兄弟节点是黑色，且兄弟节点的左子节点是红色，右子节点是黑色   \n具体操作 ：将兄弟节点S设置为红色，兄弟节点的左子节点SL设置为黑色，再对节点S进行右旋，这时候就转换为情况2.2了，按2.2的步骤继续操作即可。\n 情况2.4：替换节点的兄弟节点的左右子节点都是黑色   \n具体操作 ：把替换节点当作当前节点，当前节点的兄弟节点S设为红色，然后把父节点P当作当前节点（相当于向上移动当前节点的指针），然后自底向上递归处理。\n可以看到，局部上就把右子树的黑节点数减少了1，达到平衡，可是把S变为红色之后有可能破坏红黑树不能有连续的红节点的规则，所以还需要递归向上处理。\n删除场景三  删除场景三：替换节点是黑色节点，而且此替换节点是它父节点的右子节点\n 场景三就是场景二的镜像了，所以场景二是左子树少了一个黑节点数需要补，场景三是右子树少了一个黑节点数需要补。看场景三建议结合场景二一起看，这一部分就相对写得简略一点了。\n 情况3.1：替换节点的兄弟节点是红节点   \n具体操作：将替换节点的父节点P设置红色，将兄弟节点S设置成黑色，再对节点P右旋操作，转换为情况3.4。\n 情况3.2 ：替换节点的兄弟节点是黑色，且兄弟节点的左子节点是红色、右子节点是任意颜色   \n具体操作：替换节点的兄弟节点S设置成父节点P的颜色，兄弟节点的左子节点SL设置为黑色，父节点P设置为黑色，再对节点P右旋操作。\n相当于给右子树补充了一个黑节点。\n 情况3.3 ：替换节点的兄弟节点是黑色且兄弟节点的右子节点是红色、左子节点为黑色   \n具体操作：替换节点的兄弟节点S设置成红色，兄弟节点的右子节点SL设置为黑色，再对节点S左旋操作，转换到了情况3.2，再进行情况3.2的操作。\n 情况3.4：替换节点的兄弟节点的左右子节点都是黑色   \n具体操作：把替换节点当作当前节点，当前节点的兄弟节点S设为红色，然后把父节点P当作当前节点（相当于向上移动当前节点的指针），然后自底向上递归处理。\n写在最后 经过一天多高强度看文章以及视频，算是学得七七八八了。虽然面试不太会经常问到红黑树而且尽管问到一般也不会深入到具体的插入和删除过程，最多性质和意义就得了，所以很多人都说如果面试官让你手写红黑树那证明他不想要你，你就可以直接告辞了😂 。但是我觉得在实际工程中使用这么广泛的数据结构作为一个程序员还是要好好学一下的，所以才肝出了这篇文章。\n所以很多时候为了功利很多知识的学习只是为了应对面试，就比如八股文的学习，但是作为一个程序员这样的身份，还是要有那股我们一直以来最崇尚的求知欲，尽管是八股文的学习，也要学得明白、学得透彻才行。\n参考 【数据结构】红 黑 树_哔哩哔哩_bilibili\n通俗易懂的红黑树图解(下)\nalgo-basic/腾讯面试题：有了二叉查找树，平衡树为啥还需要红黑树？.md at master · iamshuaidi/algo-basic\n","date":"2021-12-30T00:52:42+08:00","image":"https://ccqstark.github.io/p/red_black_tree/cover_hub9c0e50fdb57d51b987a72e16255d0e2_204381_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/red_black_tree/","title":"红黑树，这次终于拿下了"},{"content":"volatile简介 synchronized在锁竞争激烈的情况下会升级为重量级锁，而volatile是Java虚拟机提供的另一种轻量的同步机制。它会将共享变量从主内存中拷贝到线程自己的工作内存中，然后基于工作内存中的数据进行操作处理。而被volatile修饰的变量经过Java虚拟机的特殊约定，使一个线程对其的修改会立刻被其他线程所感知，就不会出现脏读的现象，从而保证数据的“可见性”。\n相关概念 内存可见性 由于JMM（Java内存模型）是让线程在工作时把共享变量的副本拷贝到线程的本地内存，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它自己的拷贝副本值，造成数据的不一致。\n \n内存可见性，指的是线程之间的可见性，当一个线程修改了共享变量时，另一个线程可以读取到这个修改后的值。\n重排序 为了优化程序的性能，对原有的指令顺序进行重新排序。也就是说在指令层面，执行不一定是按原本顺序一条条执行的。重排序可能发生在多个阶段，比如编译重排序、CPU重排序等。\nhappens-before规则 happens-before规则是JVM对程序员作出的一个承诺，它保证指令在多线程之间的顺序性符合程序员的预期，但是实际的代码执行顺序可能是经过重排序的，也就是说JVM保证结果的正确性，实际优化实现则对程序员透明。\nvolatile的两个主要功能  保证变量的内存可见性 禁止volatile变量与普通变量重排序  保证可见性的原理（内存语义） 上面说到线程会把共享变量复制一份到自己线程的工作内存进行计算操作，之后再在某个时机写回主内存中，而volatile保证的可见性就是通过通知另外的线程说它拷贝的值是旧的，需要去主内存中去重新读最新的，具体操作如下：\n在生成汇编代码时会在volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令，这个Lock前缀的指令在多核处理器下主要有两方面影响：\n 将当前处理器缓存（即CPU缓存，如L1，L2）的数据写回系统内存 这个写回内存的操作回使得其他CPU里缓存来该内存地址的数据无效  在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，之后需要对此变量进行操作的时候需要去主存中读取最新值。\n所以volatile可以保证被修饰的变量可以让每个线程都获取它的最新值，也就是保证了可见性。\n阻止重排序的原理 阻止重排序主要靠的是内存屏障 的策略：\n 在每个volatile写操作前插入一个StoreStore屏障； 在每个volatile写操作后插入一个StoreLoad屏障； 在每个volatile读操作后插入一个LoadLoad屏障； 在每个volatile读操作后再插入一个LoadStore屏障。   \nvolatile与普通变量的重排序规则:\n 如果第一个操作是volatile读，那无论第二个操作是什么，都不能重排序； 如果第二个操作是volatile写，那无论第一个操作是什么，都不能重排序； 如果第一个操作是volatile写，第二个操作是volatile读，那不能重排序。  理解：\n volatile读就是让当前缓存行的数据失效，重新去主存中读取变量 volatile写就是把当前线程缓存行的变量刷到主存中让别的线程可以读到这个最新的，保证可见性   如果第一个操作是volatile 读，第二个是另外一种操作还进行重排序的话，那肯定不行，因为先volatile读就是为了保证后面的操作拿到的数值是最新的。 如果第二个操作是volatile写，第一个是另外一种操作还进行重排序的话，那肯定也不行，因为我们要保证valatile写更新到主存中的数据是最新的。 第三个很好理解，先把最新数据更新到主存，再去主存中读才能读到最新的。  并发编程的三个重要特性  原子性 : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么都不执行。synchronized 可以保证代码片段的原子性。 可见性 ：当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。 有序性 ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。  ","date":"2021-12-12T22:38:19+08:00","image":"https://ccqstark.github.io/p/concurrent_volatile/cover_hu7fad456951eb20fdb97374db4ac4bdd8_54974_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/concurrent_volatile/","title":"[并发编程]volatile篇"},{"content":"synchronized在JDK1.6之后官方对其进行优化，先要了解CAS和Java对象头，再去学习锁的四种状态：无锁、偏向锁、轻量级锁、重量级锁。这篇文章参考了多方资料，算是总结得比较全面，希望可以帮到你。\nCAS CAS操作（又称为无锁操作）是一种乐观锁策略，它假设所有线程访问共享资源的时候不会出现冲突。CAS就是compare and swap ，通过比较内存中当前的值等不等于预期值，如果等于就可以赋值成功，如果不等于说明这个值被修改过了不再是预期的旧值。\n当多个线程使用CAS操作一个变量的时候，只有一个线程会成功，其他的会因为冲突失败，失败后一般就会自旋重试，多次失败后选择挂起线程。\nCAS实现需要硬件指令集的支撑，在JDK1.5后虚拟机才可以使用处理器提供的CMPXCHG 指令实现。\nsynchronized和CAS的区别 未优化的Synchronized最主要的问题是：当存在线程竞争的情况下会出现线程阻塞和唤醒带来的开销问题，这是一种阻塞同步（互斥同步）。而CAS不是直接就把线程挂起，在CAS操作失败后会进行一定的重试，而非直接进行耗时的挂起和唤醒等操作，因此叫做非阻塞同步。\nCAS存在的问题   ABA问题\n因为CAS会检测旧的值有没有发生变化，但是假如一个值从A变成了B，然后又变成了A，刚好CAS在检查的时候发现旧值A没有发生变化，但是实际上是发生了变化的。解决办法是添加一个版本号，Java在1.5后的atomic包中提供了AtomicStampedReference来解决ABA问题，思路也是这样的。\n  自旋时间过长\nCAS是非阻塞同步，会自选（死循环）进行下一次尝试，如果自旋时间过长的话对性能又很大影响。\n  只能保证一个共享变量的原子操作\n当CAS对一个变量进行操作时可以保证其原子性，如果对多个变量进行操作就不能保证其原子性，解决办法就是利用对象去整合多个共享变量，然后对整个对象进行CAS操作就可以保证原子性来。atomic包提供来AtomicReference来保证引用对象之间的原子性。\n  Java对象头 Java的锁是基于对象的，而不是基于线程的（所以wait、notify等方法是Object中的不是Thread中的），那锁的存放自然是在对象中，存储在Java的对象头中。\n1字宽在32位处理器中是32位，64位中是64。每个对象都有对象头，非数组类型长度是2个字宽，数组是3个。\n   长度 内容 说明     1字宽 Mark Word 存储对象的hashCode、分代信息、锁信息等   1字宽 Class Metadata Address 存储到对象类型数据的指针   1字宽 Array length 数组的长度（如果是数组）    Mark Word的格式：\n   锁状态 29 bit 或 61 bit 1 bit 是否是偏向锁？ 2 bit 锁标志位     无锁  0 01   偏向锁 线程ID 1 01   轻量级锁 指向栈中锁记录的指针 此时这一位不用于标识偏向锁 00   重量级锁 指向互斥量（重量级锁）的指针 此时这一位不用于标识偏向锁 10   GC标记  此时这一位不用于标识偏向锁 11    当对象状态为偏向锁时，Mark Word存储的是偏向的线程ID；\n当状态为轻量级锁时，Mark Word存储的是指向线程栈中Lock Record的指针；\n当状态为重量级锁时，Mark Word为指向堆中的monitor对象的指针。\n无锁 上面介绍的CAS原理及应用即是无锁的实现。\n无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。\n无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。\n偏向锁 HotSpot的作者研究发现，大多数情况下锁都不存在多线程竞争，一般总是由同一个线程多次获得，为了让线程获得锁的代价更低，引入了偏向锁。\n偏向锁的获取 一个线程在第一次进入同步块时，会在对象头和栈帧中的锁记录里存储锁的偏向的线程ID。当下次该线程进入这个同步块时，会去检查锁的Mark Word里面是不是放的自己的线程ID。\n如果是，直接表明该线程已经获得了锁，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁 ；如果不是，就代表有另一个线程来竞争这个偏向锁。这个时候会尝试使用CAS来替换Mark Word里面的线程ID为新线程的ID，这个时候要分两种情况：\n 成功，表示之前的线程不存在了， Mark Word里面的线程ID为新线程的ID，锁不会升级，仍然为偏向锁； 失败，表示之前的线程仍然存在，那么暂停之前的线程，进行偏向锁的撤销（下面介绍），设置偏向锁标识为0，并设置锁标志位为00，升级为轻量级锁，会按照轻量级锁的方式进行竞争锁。  偏向锁的撤销 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时， 持有偏向锁的线程才会释放锁。\n偏向锁升级成轻量级锁时，会暂停拥有偏向锁的线程，重置偏向锁标识，过程如下：\n 在一个全局安全点（没有字节码在执行）停止拥有锁的线程。 遍历线程栈，如果存在锁记录的话，需要将锁记录和Mark Word改为无锁状态。 唤醒被停止的线程，将当前锁升级成轻量级锁。  如果程序中的锁通常处于竞争状态，那么偏向锁就起不到提高性能的作用，我们可以用参数把偏向锁关闭：\n-XX:UseBiasedLocking=false 下面有个经典的图总结了偏向锁的获得和撤销：\n \n轻量级锁 多个线程在不同时段获取同一把锁，即不存在锁竞争的情况，也就没有线程阻塞。针对这种情况，JVM采用轻量级锁来避免线程的阻塞与唤醒。\n轻量级锁的获取 JVM会为每个线程在当前线程的栈帧中创建用于存储锁记录的空间Lock Record , 包含两部分：\n 识别哪个对象被锁的所必需的元数据 Displaced Mark Word  **如果一个线程获得锁的时候发现是轻量级锁，会把锁的Mark Word复制到自己的Displaced Mark Word里面。**然后线程尝试用CAS将锁的Mark Word替换为指向Lock Record的指针。如果成功，当前线程获得锁；如果失败，表示Mark Word已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使用自旋来获取锁。\n如下图，如果Mark Word成功更新为指向了某一线程栈帧中的Lock Record则证明此线程获得锁成功：\n \n适应性自旋 自旋过多也会造成CPU较大的开销，JDK采用的是更好的适应性自旋 。\n自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能就会减少自选的次数或者省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。\n自旋也不是一直进行下去的，如果自旋到一定程度（和JVM、操作系统相关），依然没有获取到锁，称为自旋失败，那么这个线程会阻塞。同时这个锁就会升级成重量级锁。\n轻量级锁的释放 在释放锁时，当前线程会使用CAS操作将Displaced Mark Word的内容复制回锁的Mark Word里面。如果没有发生竞争，那么这个复制的操作会成功。如果有其他线程因为自旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阻塞的线程。\n \n重量级锁 重量级锁依赖于操作系统的互斥量（mutex） 实现的，而操作系统中线程间状态的转换需要相对比较长的时间，所以重量级锁效率很低，但被阻塞的线程不会消耗CPU。\n在 Java 中每个对象都有一个 monitor 对象与之对应，在重量级锁的状态下，对象的Mark Word存放的是一个指针，指向了与之对应的 monitor 对象。这个 monitor 对象就是实现重量锁的关键。\n一个 monitor 对象包括这么几个关键字段：ContentionList，EntryList ，WaitSet，owner。其中 ContentionList、EntryList 、WaitSet 都是由 ObjectWaiter 的链表结构，owner 指向持有锁的线程。\n每一个对象都可以当做一个锁，当多个线程同时请求某个对象锁时，对象锁会设置几种状态用来区分请求的线程：\nContention List：所有请求锁的线程将被首先放置到该竞争队列 Entry List：Contention List中那些有资格成为候选人的线程被移到Entry List Wait Set：那些调用wait方法被阻塞的线程被放置到Wait Set OnDeck：任何时刻最多只能有一个线程正在竞争锁，该线程称为OnDeck Owner：获得锁的线程称为Owner !Owner：释放锁的线程  JVM 每次从队列的尾部取出一个数据用于锁竞争候选者(OnDeck)，但是并发情况下，ContentionList 会被大量的并发线程进行 CAS 访问，为了降低对尾部元素的竞争，JVM 会将一部分线程移动到 EntryList 中作为候选竞争线程。 Owner 线程会在 unlock 时，将 ContentionList 中的部分线程迁移到 EntryList 中，并指定EntryList 中的某个线程为 OnDeck 线程(一般是最先进去的那个线程)，被选中的线程叫做Heir presumptive ，即假定继承人。 Owner 线程并不直接把锁传递给 OnDeck 线程，而是把锁竞争的权利交给 OnDeck。 OnDeck 需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM 中，也把这种选择行为称之为“竞争切换”。 OnDeck 线程获取到锁资源后会变为 Owner 线程，而没有得到锁资源的仍然停留在 EntryList中。如果 Owner 线程被 wait 方法阻塞，则转移到 WaitSet 队列中，直到某个时刻通过 notify或者 notifyAll 唤醒，会重新进去 EntryList 中。处于 ContentionList、EntryList、WaitSet 中的线程都处于阻塞状态，该阻塞是由操作系统来完成的(Linux 内核下采用 pthread_mutex_lock 内核函数实现的)。 Synchronized 是非公平锁。 Synchronized 在线程进入 ContentionList 时，等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁资源。 每个对象都有个 monitor 对象，加锁就是在竞争 monitor 对象，代码块加锁是在前后分别加上 monitorenter 和 monitorexit 指令来实现的，方法加锁是通过一个标记位ACC_SYNCHRONIZED来判断的（在synchronized篇讲过了）  转换关系如下图：\n \n总结锁的升级流程  每一个线程在准备获取共享资源时，第一步，检查Mark Word里面是不是放的自己的Thread ID，如果是，表示当前线程获取了该资源的偏向锁。 如果Mark Word不是自己的Thread ID，这时候用CAS来尝试替换，成功的话就仍然为偏向锁，失败的话就会锁升级，新线程根据Mark Word里面现有的Thread ID通知之前的线程暂停，这个之前的线程进行偏向锁的撤销操作，同时锁升级为轻量级锁。 此时为轻量级锁来竞争资源，两个线程都把锁对象的Hash Code复制到自己新建的用于存储锁的记录空间Lock Record，接着通过CAS，把锁对象的Mark Word内容修改为指向自己Lock Record的地址的方式来竞争锁。 第三步中的CAS成功的就拿到来锁，失败的就自旋。 自旋线程在自旋过程中，如果之前先拿到锁的线程释放了锁让它可以获得资源，就仍然保持在轻量级锁，如果自选失败就会膨胀为重量级锁。 进入重量级锁后，原本自旋的线程就只能进入阻塞状态，等锁被释放后再让别的线程来唤醒自己。  关于锁是否可以降级 大多数文章写的都是锁只能升级而不能降级，其实不然：\n HotSpot JVM、JRockit JVM是支持锁降级的 HotSpot JVM、JRockit JVM是偏向锁是可以重偏向的 重量级锁降级发生于STW阶段，降级对象为仅仅能被VMThread访问而没有其他JavaThread访问的对象  各种锁的优缺点对比 下表来自《Java并发编程的艺术》：\n   锁 优点 缺点 适用场景     偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法比仅存在纳秒级的差距。 如果线程间存在锁竞争，会带来额外的锁撤销的消耗。 适用于只有一个线程访问同步块场景。   轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度。 如果始终得不到锁竞争的线程使用自旋会消耗CPU。 追求响应时间。同步块执行速度非常快。   重量级锁 线程竞争不使用自旋，不会消耗CPU。 线程阻塞，响应时间缓慢。 追求吞吐量(非公平锁)。同步块执行时间较长。    参考 9 synchronized与锁\n不可不说的Java\u0026quot;锁\u0026quot;事\nSynchronized的实现丶Java教程网-IT开发者们的技术天堂\n","date":"2021-12-11T17:09:24+08:00","image":"https://ccqstark.github.io/p/concurrent_synchronized_optimization/cover_hu4d840036f83d7884a510888303887b86_1060410_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/concurrent_synchronized_optimization/","title":"[并发编程]Synchronized优化篇——Java中的各种锁"},{"content":"基本介绍 对于ReentrantLock（重入锁），是常用的Lock接口的一个实现，最主要的是了解他的重入性和公平锁/非公平锁，还有用他于synchronized机械能对比，下面进行具体介绍。\n重入性实现原理 重入性有2个基本特点：\n 在线程获取锁的时候，如果锁已经存在且锁还是当前线程的，那可以直接再次获取成功 由于锁可以被同一线程获取n次，在释放时同样要释放n次才能把锁完全释放开。  许多同步组件都是通过重写AQS的方法来实现自己的同步功能的，下面以ReentrantLock的非公平锁的源码来解析其重入的实现。核心方法nonfairTryAcquire ：\nfinal boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); //1. 如果该锁未被任何线程占有，该锁能被当前线程获取  if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //2.若被占有，检查占有线程是否是当前线程  else if (current == getExclusiveOwnerThread()) { // 3. 再次获取，计数加一  int nextc = c + acquires; if (nextc \u0026lt; 0) // overflow  throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } return false; } 首先是判断当前是否存在锁，如果不存在，那自然可以获取。\n如果存在，而且占有锁的还是当前这个线程，那就可以重入，同步状态（锁的计数器）+1。\n对于释放，也是同样的道理，核心方法tryRelease ：\nprotected final boolean tryRelease(int releases) { //1. 同步状态减1  int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) { //2. 只有当同步状态为0时，锁成功被释放，返回true  free = true; setExclusiveOwnerThread(null); } // 3. 锁未被完全释放，返回false  setState(c); return free; } 用一个变量free来表示锁是否被完全释放，只有当同步状态（锁的计数器）为0时才会设置为true，否则还是上锁的状态。\n公平锁和非公平锁 设置公平性 ReentrantLock支持公平锁和非公平锁，默认是非公平的（无参构造方法），也可以用一个带有boolean值的构造方法来指定公平性。\n// 默认非公平锁 public ReentrantLock() { sync = new NonfairSync(); } // true为公平锁，false为非公平锁 public ReentrantLock(boolean fair) { sync = fair ? new FairSync() : new NonfairSync(); } 公平性的意思就是，如果是公平锁，那么线程获取锁的顺序就是按它们请求时的顺序，维护来一个队列进行排队，FIFO；如果是非公平锁，则没有进行排队，线程发起请求时就立刻可以去尝试获取锁。\n源码解析 上面的nonfairTryAcquire 就是非公平锁的源码来，下面我们看一下公平锁tryAcquire的：\nprotected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { // 不同点在这里  if (!hasQueuedPredecessors() \u0026amp;\u0026amp; compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc \u0026lt; 0) throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;); setState(nextc); return true; } return false; } } 其实大部分逻辑和非公平锁是相似的，不同在于公平锁在判断到当前资源的同步状态为0后，还多判断来一次hasQueuedPredecessors() ，这个方法用于判断当前节点在同步队列中是否有前驱节点，也就是当前线程是否位于同步队列的队头（判断时取反）。如果是才能进行下面的逻辑来获取资源的锁，否则根据公平性是会获取失败的。\n对比  公平锁每次都只能让位于同步队列中的第一个线程进行获取资源，保证请求资源时间上的绝对顺序；而非公平锁可能产生刚刚释放锁的线程又立刻拿到锁了，导致其他线程迟迟拿不到，造成了“饥饿”现象。 公平锁为了保证时间上的顺序，往往后涉及频繁的上下文切换，造成比较大的开销。而非公平锁则会降低一定的上下文切换，提高了性能，所以ReentrantLock默认是非公平的，保证系统更大的吞吐量。  参考 GitHub - CL0610/Java-concurrency: Java并发知识点总结\n","date":"2021-12-11T17:05:58+08:00","image":"https://ccqstark.github.io/p/concurrent_reentrantlock/cover_huceae91d367533a91416a74330952ccc4_41335_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/concurrent_reentrantlock/","title":"[并发编程]ReentrantLock篇"},{"content":"说一说你对synchronized的理解？ synchronized关键字用于解决多个线程访问临界资源的同步问题，它可以保证同一时刻只有一个线程在操作一个临界资源。\n在Java的早期版本synchronized属于重量级锁，效率低下。因为监视器锁（monitor）是以来于操作系统底层的Mutex Lock来实现的，Java的线程映射到操作系统的原生线程上，要挂起或者唤醒一个线程实现线程的切换，都需要涉及到操作系统的用户态和内核态的转换，开销比较大。\n但是在Java6之后，Java官方在JVM层面对synchronized进行来优化，JDK1.6实现来自旋锁、自适应自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等减少来锁的开销。\n说说synchronized怎么使用的？  加在实例方法上，获取的是当前对象实例的锁 加在静态方法上，获取的是class的锁，不会与实例对象上的锁冲突 加载某一代码块上，可以this来表示要获得当前对象的锁，也可以写类.class表示获取类的锁  使用synchronized实现双重检验锁方法写的单例模式 保证了线程安全\n// 单例：双重校验锁 public class Singleton { private volatile static Singleton instance; private Singleton() { } public static Singleton getUniqueInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } } 为什么要加双重锁呢，因为instance = new Singleton(); 这段代码其实是分三步执行的：\n 为instance分配空间 初始化instance 将instance指向分配的内存地址  但是由于JVM有指令重排的特性，执行循序又可能变成1→3→2，多线程环境下有可能导致一个线程获得一个还没有初始化的实例。比如线程A执行了1和3，此时线程B调用getUniqueInstance()后发现instance不为空，但是得到的instance此时还未被初始化。\n使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。\n构造方法可以使用synchronized关键字修饰吗？ 构造方法不能用synchronized关键字修饰，因为构造方法本身就是线程安全的，不存在同步的构造方法一说。\n讲一下synchronized关键字的底层原理？ 同步代码块 查看使用了synchronized关键字的代码的字节码，会发现同步语块使用的是monitorenter和montorexit 指令，monitorenter 指令指向同步代码块的开始位置，monitorexit 指令表示同步代码块的结束位置。\n当执行 monitorenter 指令时，线程试图获取锁也就是获取 对象监视器 monitor 的持有权。\n在执行monitorenter时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\n在执行 monitorexit 指令后，将锁计数器设为 0，表明锁被释放。\n同步方法 synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\n不过两者的本质都是对对象监视器monitor的获取\n说说 JDK1.6 之后的 synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗？ JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。\n锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。\n关于具体的优化和Java中各种锁的介绍，在Synchronized优化篇——Java中的各种锁中介绍。\n谈谈 synchronized 和 ReentrantLock 的区别？ 相同点：  两者都是可重入锁  “可重入锁”指的是可以再次获取自己已经获得的锁。如果锁不可重入的话就会导致死锁。同一个线程获取锁，锁的计数器会自增1，所以要等到锁的计数器下降为0时才能释放锁。\n不同点：  synchronized依赖于JVM而ReentrantLock依赖于API  synchronized是依赖于JVM实现的，包括之前说的Java官方在JDK1.6做的很多优化也是在虚拟机层面去实现的，没有直接暴露给我们。\nReentrantLock是JDK层面实现的，可以直接查看到源码看他是怎么实现的，调用lock()和unlock()方法时也要配合try，catch去完成。\n ReentrantLock比synchronized增加来一些高级功能    等待可中断\n提供了lockInterruptibly()方法实现了等待可中断机制，就是当前线程在等待锁的过程中，可以中断来放弃等待，不去获取锁了。不过只有该线程执行了interrupt()方法之后，lockInterruptibly()才起作用。\n  可以指定是公平锁还是非公平锁\n具体在RreentrantLock篇中介绍\n  可实现选择性通知\n原本我们的notify() 是由JVM进行随机唤醒一条线程的，但是用了Condition我们可以进行指定唤醒，线程对象可以注册在指定的Condition上，实现“选择性通知”。\n而 notifyAll()方法的话就会通知所有处于等待状态的线程，造成很大的效率问题，而Condition实例的signalAll()方法只会唤醒注册在该Condition实例中的所有等待线程。\n  什么是虚假唤醒？如何避免？ 虚假唤醒就是比如一个消费者和生产者的场景，商品只有一个，生产者也只有一个，但是消费者有很多个。如果生产者生产了一个商品后notifyAll() ，那很多个消费者线程都会被唤醒，但是只能有一个获得锁并进行消费，其他人都还获取不到，就是虚假唤醒；但是其他人都在这第一个消费者之后获取了锁还继续执行了消费的操作，导致商品数量变为负数，这个时候就出现问题了。\npublic synchronized void consume() { // if换成while来解决  if (num \u0026lt;= 0) { System.out.println(\u0026#34;库存已空，无法消费\u0026#34;); try { // 等待生产者生产  this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } num--; // 进行消费  this.notifyAll(); // 唤醒其他所有线程 } 因为多个消费者线程被同时唤醒后进行资源争抢，但是他们获取锁之后就不再判断当前资源是否还有剩余，或者说满足消费操作的条件就直接继续执行后面的消费操作了，这样就会导致资源超卖变成负数。\n解决办法当然是让他们在从wait()返回获取锁之后，仍然还要再次判断资源是否满足条件，避免前面已经有别的消费者已经消费了。而让他们再次判断资源是否满足条件那就把if换成while就可以了，这也是JDK官方建议的做法。\n","date":"2021-12-11T16:56:15+08:00","image":"https://ccqstark.github.io/p/concurrent_synchronized/cover_hu2a1927aa31c8cd3f96cce7e92e6162a3_102344_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/concurrent_synchronized/","title":"[并发编程]synchronized篇"},{"content":"什么是进程？什么是线程？ 进程是程序的一次执行过程，是系统运行程序的基本单位，进程是一个系统对一个程序从创建，运行到消亡的过程。\n在Java中，我们启动main函数就是启动了一个JVM的进程，main函数所在线程就是这个进程中的主线程。\n线程是程序的一个更小的执行单位，一个进程在执行过程中可以产生多个线程。不同在与，同类的多个线程可以共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，系统在线程之间切换的代价要比进程小得多。\n请简要描述线程与进程的关系,区别及优缺点？ 从JVM的角度说明\n \n一个进程中包括多个线程，线程可以共享进程的堆和方法区，但是每个线程都有自己的虚拟机栈，本地方法栈，程序计数器\n线程是进程划分成的更小的运行单位，区别在与进程基本上是各自独立的，而同一进程的不同线程则可能会相互影响。线程开销更小，但是不利于资源的管理和保护；进程则相反。\n程序计数器为什么是私有的？ 程序计数器主要作用：\n 字节码解释器通过改变程序计数器的位置来读取指令，从而实现代码的流程控制。如：顺序执行、选择、循环、异常处理。 多线程环境下，程序计数器用于记录当前程序的运行到的位置，当从别的线程切换回来的时候才能从上次运行到的位置继续运行。  所以程序计数器私有主要是为了线程切换回来后，能从原来停止的位置正确恢复运行。\n虚拟机栈和本地方法栈为什么是私有的?  虚拟机栈：每个Java方法在执行的同时会创建一个栈帧用于存储局部变量表、函数返回地址和参数、划定栈帧范围的ebp和esp指针等信息。一个方法从被调用到执行完成，就对应着一个栈帧在Java虚拟机中入栈和出栈的过程。 本地方法栈：和虚拟机栈作用差不多，区别在与虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为Native方法用的。在HotSpot虚拟机中两者合二为一。  所以为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈就是线程私有的。\n简单介绍下堆和方法区 堆和方法区都是线程共享的资源。\n堆是进程中最大的一块内存，主要用于存放新创建的对象，几乎所有的对象都在这里分配内存。\n方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n说说并发和并行的区别？  并行：在单位时间内多个任务同时进程，一般在是多核CPU上出现， 并发：在同一段时间内，多个任务由CPU切换着处理，在某一瞬间是不一定同时处理多个任务的。例外就是当我们CPU使用了因特尔的超线程技术，一个内核被虚拟成2个逻辑内核，当两个任务分别用到CPU的不同运算资源时，比如一个任务计算整数另一个计算浮点数，这个时候就又可能是真的同时进行的。  为什么要使用多线程？ 从总体上说：\n 从计算机底层的角度，线程是轻量级的进程，是程序执行的最小单位，线程切换的开销要远小于进程的切换，另外多核CPU时代意味着多个线程可以同时运行，再次减少了开销。 从当代互联网的发展趋势角度：现在的系统基本上就动辄百万千万级的并发，多线程技术就是高并发系统的基础，可以大大提高系统整体的性能和并发能力。  从计算机底层来说：\n 单核时代：如果我们只有一个线程，那请求进程IO就会阻塞我们整个进程，而CPU就会被闲置了，如果由多个线程，那我们可以在一个线程被IO阻塞的时候，用另一个线程继续使用CPU的运算能力，提高系统整体的资源利用效率。 多核时代：如果有多个核心，那多个线程可以映射不同核心上并行执行，在没发生资源争抢的情况下执行效率就会显著提高。  使用多线程可能会带来什么问题？  内存泄漏：ThreadLocal就可能会导致内存泄漏 死锁：两个线程互相占用对方需要的资源并互相等待其释放 线程不安全：多线程访问并修改临界资源  说说线程的生命周期和状态？    状态名称 说明     NEW 初始状态，线程被构建，但是还没有调用start()方法   RUNNABLE 运行状态，Java线程将操作系统中的就绪和运行   BLOCKED 阻塞状态，表示线程阻塞于锁   WAITING 等待状态，表示线程进入等待状态，进入该状态表示当前线程需要等待其它线程作出一些特定动作（通知或中断）   TIME_WAITING 超时等待状态，该状态不同于WAITING，它是可以在指定的时间自行返回的   TERMINATED 终止状态，表示当前线程已经执行完毕    线程随着代码的执行在不同状态之间切换，Java线程状态变迁如下所示：\n（文字描述省略，要用自己的话能描述出下面这副图）\n \n什么是上下文切换？ 线程在执行过程中有自己的运行条件和状态（也成上下文），比如程序计数器，栈帧的一些信息，出现如下情况的时候，线程会从占用CPU状态中退出：\n 调用了sleep(), wait()，主动让出CPU 时间片用完 ，操作系统要防止一个线程或者进程长时间占用CPU导致其它线程饿死 调用了阻塞类的系统中断，比如请求IO，线程被阻塞 被终止或结束运行  前三种都会发生线程切换，这意味这要保存线程的上下文，留着线程下次占用CPU的时候恢复现场，并加载下一个要占用CPU的线程上下文。\n什么是线程死锁？如何避免死锁？ 认识线程死锁 死锁就是多个线程同时被阻塞，他们中的一个或者全部都在等待某个资源被释放，而资源却又同时被对方占用锁住，此时线程就会无限期等待，程序就无法正常终止。\n \n死锁的代码例子（代码来源于《并发编程之美》）：\npublic class DeadLockDemo { private static Object resource1 = new Object();//资源 1  private static Object resource2 = new Object();//资源 2  public static void main(String[] args) { new Thread(() -\u0026gt; { synchronized (resource1) { System.out.println(Thread.currentThread() + \u0026#34;get resource1\u0026#34;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread() + \u0026#34;waiting get resource2\u0026#34;); synchronized (resource2) { System.out.println(Thread.currentThread() + \u0026#34;get resource2\u0026#34;); } } }, \u0026#34;线程 1\u0026#34;).start(); new Thread(() -\u0026gt; { synchronized (resource2) { System.out.println(Thread.currentThread() + \u0026#34;get resource2\u0026#34;); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(Thread.currentThread() + \u0026#34;waiting get resource1\u0026#34;); synchronized (resource1) { System.out.println(Thread.currentThread() + \u0026#34;get resource1\u0026#34;); } } }, \u0026#34;线程 2\u0026#34;).start(); } } 代码中先让线程A获取资源1的锁，如何sleep1秒让系统切换运行线程B，线程B获取资源2的锁，然后线程A和线程B都在尝试获取被对方占用着的资源，陷入互相等待的状态，因此也造成了死锁。\n造成死锁的四个必要条件  互斥条件：该资源任意一个时刻只由一个线程占用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。  如何预防死锁？ 破坏死锁产生的必要条件即可\n 一次性申请所有资源 破环不剥夺条件：占用部分资源的线程进一步申请其它资源时，如果申请不到，可以主动释放资源。 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件条件。  如果避免死锁？ 避免死锁就是在资源分配时，借助算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。\n安全状态指的是系统能够按照某种进程推进顺序（P1、P2、P3\u0026hellip;..Pn）来为每个进程分配所需资源，直到满足每个进程对资源的最大需求，使每个进程都可顺利完成。称\u0026lt;P1、P2、P3\u0026hellip;..Pn\u0026gt;序列为安全序列。 上述代码线程B的获取资源顺序改为资源1→资源2就可以解决死锁，因为线程A首先获取了资源1，线程B再去获取就得不到了，就阻塞在这里，然后资源2也不会被它获取，而是被线程A顺利获取。线程A使用完后释放资源1和2线程B也可以正常获取，这就破坏了循环等待的条件，避免了死锁。\n说说sleep()方法和wait()方法区别和共同点？ 共同点：两者都可以用于暂停线程的执行。\n两者的主要区别在于：\n sleep()方法不会释放锁，而wait()方法释放了锁。 wait()方法通常用于线程间交互/通信，sleep()主要用于暂停线程的执行 wait()方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的notify()或者notifyAll()方法。sleep()方法执行完成之后线程会自动苏醒。或者可以用wait(long timeout)超时后线程会自动苏醒.  为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？ new一个Thread进入新建状态，然后调用start() 方法就会启动这个线程进入就绪状态，当分配到时间片就可以开始执行了。start()会执行线程的一些准备工作，然后就会自动执行run()方法中的内容，这就是真正的多线程工作。\n但是如果直接执行run()方法，会把run()当成main线程下的一个普通方法进行执行，而不会在一个新的线程中去执行它，所以这并不是多线程工作。\n参考 Java 并发常见知识点\u0026amp;面试题总结（基础篇）\n栈帧(Stack Frame) - 掘金\n超线程技术在线程这个层面是否是真正的空间并行？\n","date":"2021-12-05T20:20:47+08:00","image":"https://ccqstark.github.io/p/concurrent_basic/cover_huf957eb7cc0803733802fcc4099cfd7cb_64471_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/concurrent_basic/","title":"[并发编程]基础篇"},{"content":"前言 众所周知，跨域设置CORS的话我们需要设置Access-Control-Allow-Origin、Access-Control-Allow-Methods 等header，但是我们的Access-Control-Allow-Origin 只能设置为三种情况：\n 星号 * 单域名 none  同时还有一个限制就是设置为星号的时候，Access-Control-Allow-Credentials 不能设置为true，下面来自MDN：\n 对于附带身份凭证的请求，服务器不得设置 Access-Control-Allow-Origin 的值为“*”。这是因为请求的首部中携带了 Cookie 信息，如果 Access-Control-Allow-Origin 的值为“*”，请求将会失败。\n 而Access-Control-Allow-Credentials 则一般是服务器用来设置是否允许前端携带Cookies的标志位，withCredentials 是前端用来表示是否给服务器发请求的时候带上Cookies的标志位：\n 将 [XMLHttpRequest](https://developer.mozilla.org/en-US/DOM/XMLHttpRequest)的 withCredentials 标志设置为 true，从而向服务器发送 Cookies。因为这是一个简单 GET 请求，所以浏览器不会对其发起“预检请求”。但是，如果服务器端的响应中未携带 Access-Control-Allow-Credentials: true ，浏览器将不会把响应内容返回给请求的发送者。\n 基于以上的规则，如果我们需要发Cookies的话，前端withCredentials 和后端的Access-Control-Allow-Credentials 都要设置为true，同时Access-Control-Allow-Origin 不能设置为星号，只能设置为单域名。\n问题 但是在我看一个开源项目源码的时候，看到它CORS的地方：\n@Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026#34;/**\u0026#34;).allowedOrigins(\u0026#34;*\u0026#34;) .allowedMethods(\u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;DELETE\u0026#34;, \u0026#34;OPTIONS\u0026#34;) .allowCredentials(true).maxAge(3600); } 出现了疑惑，为什么它同时设为星号同时设置了true但是仍然请求正常呢？\n打开了F12看响应的header，发现Access-Control-Allow-Origin 是前端的地址，不是设置了星号吗，怎么变成单origin了？然后把allowCredentials方法里传个false，发现请求就异常了，开始搞不懂了，因为这个项目其实也没有用到cookies呀，只用了token，token也是放在header里的。\n探究 然后只能猜测是Spring MVC帮我们做了这一切，就去扒源码了，果然扒到了！\n在org.springframework.web.cors 下的CorsConfiguration 类，有这么一个checkOrigin方法：\n@Nullable public String checkOrigin(@Nullable String requestOrigin) { if (!StringUtils.hasText(requestOrigin)) { return null; } else if (ObjectUtils.isEmpty(this.allowedOrigins)) { return null; } else if (this.allowedOrigins.contains(\u0026#34;*\u0026#34;)) { return this.allowCredentials != Boolean.TRUE ? \u0026#34;*\u0026#34; : requestOrigin; } else { Iterator var2 = this.allowedOrigins.iterator(); String allowedOrigin; do { if (!var2.hasNext()) { return null; } allowedOrigin = (String)var2.next(); } while(!requestOrigin.equalsIgnoreCase(allowedOrigin)); return requestOrigin; } } 在判断到我们设置类星号且allowCredentials也设置为true后，会把Access-Control-Allow-Origin 设置为当前请求的origin，也就是动态去设置它，这个值就一直会是请求过来的origin，解决了跨域的同时也不会违反星号和true的限制，想想之前确实有这种写法，不过其实我们不用手动去实现这个过程，因为框架都帮我们做好了。\n当然，如果项目只用token不用cookies的话，withCredentials和allowCredentials同时设置为false，allowOrigin设置为星号，也是没问题的。\n总结 Access-Control-Allow-Origin 设置为星号时，Access-Control-Allow-Credentials 不能同时设置为true，Spring MVC帮我们规避了这个错误，会在这种情况下帮你把allowOrigin设置为当前request的origin。\n如果前端withCredentials为true，但是后端的Access-Control-Allow-Credentials 为false则会请求失败，反过来则可以。\n","date":"2021-12-02T18:31:11+08:00","image":"https://ccqstark.github.io/p/cors_credentials/cover_hu39f51a010fc67188807a44ea669744a2_15023_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/cors_credentials/","title":"关于CORS的Access-Control-Allow-Credentials设置问题"},{"content":"Mock介绍 基本介绍 为了提高代码质量，除了做静态代码测试，动态的单元测试也少不了。而在单元测试过程中，Mock是少不了的技术。\nMock是允许用模拟对象替换测试中的系统部件，并断言它们是如何被使用的一项技术。\nMock的作用如下  解决依赖问题：当测试一个接口或者功能模块的时候，如果这个接口或者功能模块依赖其他接口或其他模块，那么如果所依赖的接口或功能模块未开发完毕，那么我们就可以使用Mock模拟被依赖接口，完成目标接口的测试。 单元测试：如果某个功能未开发完成，又要进行测试用例的代码编写，也可以先模拟这个功能进行测试。 模拟复杂业务的接口：实际工作中如果我们在测试一个接口功能时，如果这个接口依赖一个非常复杂的接口业务或者来源于第三方接口（如第三方支付接口），那么我们完全可以使用Mock来模拟这个复杂的业务接口，其实这个和解决接口依赖是一样的原理。 前后端联调：进行前后端分离编程时，如果进行一个前端页面开发，需要根据后合返回的状态展示不同的页面，那么就需要调用后合的接口，但是后合接口还未开发完成，完全可以借助mock来模拟后台这个接口返回想要的数据。  Mock与Stub(桩)  桩代码(Stub)：用来代替真实代码的临时代码，主要作用是使被测代码能够独立编译、 链接，并独立运行 Mock代码：也是用来代替真实代码的临时代码，起到隔离和补齐的作用，但是它还可深入的模拟对象之间的交互方式，可以对结果进行验证  Mockito测试框架 Mockito是Java单元测试中使用率最高的Mock框架之一，同时也是SpringBoot默认引入的mock框架(spring-boot-starter-test包括JUnit, Hamcrest 和 Mockito)\nMaven依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mockito\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mockito-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.12.4\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 验证某些行为是否被调用 Mockito可以验证某些行为：一旦mock对象被创建了，mock对象会记住所有的交互\n使用方法verify() 判断方法是否被调用过\n@Test void verifyTest(){ Person mockPerson = Mockito.mock(Person.class); mockPerson.setId(1); Mockito.verify(mockPerson).setId(1); Mockito.verify(mockPerson).setName(\u0026#34;cc\u0026#34;); // 此方法没有调用过，所以会报错 } 测试桩Stub Mockito可以做一些测试桩（Stub），做测试桩的目的是为了在某些方法还没有开发出来，但我们测试时却需要调用它的时候，给这个方法模拟一个假的返回值供我们测试用。\n默认情况下，所有函数都有返回值。mock函数默认返回的是null，一个空的集合或者一个被对象类型包装的内置类型。\n当我们要指定某的函数的返回值时，可以使用when() 和 ThenReturn() 、ThenThrow() 方法\n之后调用这些函数时，就会返回我们上面指定的值（注意返回类型也要正确）\n@Test void stubTest(){ Person mockPerson = Mockito.mock(Person.class); Mockito.when(mockPerson.getId()).thenReturn(1); Mockito.when(mockPerson.getName()).thenThrow(new NoSuchMethodError()); System.out.println(mockPerson.getId()); // 返回1  System.out.println(mockPerson.getName()); // 抛出异常NoSuchMethodError } 一个方法可能多次调用，想要每次调用都设置对应返回值也是可以的\n@Test void constStubTest(){ Person personMock = mock(Person.class); when(personMock.getName()) .thenReturn(\u0026#34;cc\u0026#34;) .thenReturn(\u0026#34;1\u0026#34;); System.out.println(personMock.getName()); // 第一次返回cc  System.out.println(personMock.getName()); // 第二次返回1 } 类型范围 使用anyInt() 、anyString()、anyList()等方法可以对参数类型进行限制或者放宽范围\n@Test void matchTest(){ Person mockPerson = Mockito.mock(Person.class); when(mockPerson.setKeyById(anyInt())).thenReturn(\u0026#34;0001Test1000\u0026#34;); // 表示只要传入int类型就返回\u0026#34;0001Test1000\u0026#34;  System.out.println(mockPerson.setKeyById(10)); verify(mockPerson).setKeyById(10); } 方法调用次数验证 times()可以用来验证方法的调用次数，如果不是预期次数则会不通过\n@Test void timesTest(){ Person mockPerson = mock(Person.class); mockPerson.setId(1); mockPerson.setName(\u0026#34;cc\u0026#34;); mockPerson.setName(\u0026#34;cc\u0026#34;); verify(mockPerson).setId(1); verify(mockPerson, times(2)).setName(\u0026#34;cc\u0026#34;); } 方法调用顺序验证 当我们需要验证方法调用的前后顺序是否符合预期，可以InOrder 类以及它的verify() 方法\n不仅使用与单个对象，多个对象的方法之间的调研顺序也可以进行判断\n@Test void orderTest() { Person singeMock = mock(Person.class); singeMock.setName(\u0026#34;cc\u0026#34;); singeMock.setName(\u0026#34;qq\u0026#34;); // 单个对象方法的调用顺序  InOrder inOrder = inOrder(singeMock); inOrder.verify(singeMock).setName(\u0026#34;cc\u0026#34;); inOrder.verify(singeMock).setName(\u0026#34;qq\u0026#34;); // 顺序正确  Person firstMock = mock(Person.class); Person secondMock = mock(Person.class); firstMock.setId(1); secondMock.setId(2); // 多个方法的调用顺序  InOrder inOrder1 = inOrder(firstMock, secondMock); inOrder1.verify(secondMock).setId(2); inOrder1.verify(firstMock).setId(1); // 顺序错误 } spy监控对象 spy可以监控或控制一个真正new创建出来的对象，而不是去mock的对象，两者区别在于mock的对象如果不指定返回值就会返回null这样的零值，而spy则介于真正的bean和mock之间，对于被我们指定了返回值的优先按指定的，没有指定的就按对象实际值返回。\n下面的例子是修改一个对象中某个属性的返回值，使得其返回值不在是属性的真实值\n也可以用@Spy 注解\n@Test void spyTest(){ Person person = new Person(1, \u0026#34;cc\u0026#34;, null); Person spy = spy(person); when(spy.getName()).thenReturn(\u0026#34;qq\u0026#34;); System.out.println(spy.getName()); // 返回qq，而不是cc  System.out.println(spy.getId()); // 返回1，因为没有设置过 } Spring Boot中的单元测试 Spring Boot的结构上来说，Service层是依赖Dao层的，而Controller层又依赖于Service层\n从单元测试的角度，对某个Service和Controller进行单元测试的时候，所有需要依赖的类或方法都应该mock，只针对某一段代码进行运行逻辑测试，测试Service层时，就可以使用Mockito来隔离Dao层；Dao层的单元测试可以用工具随机生成测试数据，然后使用工具测试SQL即可，就不要还启动整个应用，效率比较低。\n下面是几种mock的方案\n 在before函数中直接mock实例化对象  @BeforeEach public void before(){ userService = mock(UserService.class); }  使用@Mock注解来Mock对象  @Mock private UserSerice userService; @BeforeEach public void before(){ MockitoAnnotations.initMocks(this); // 此方法已被deprecad }  使用@RunWith(MockitoJunitRunner.class) ，搭配@Mock就可以直接使用了，不用再初始化（此方法只能用于Junit4）（较为推荐）  @RunWith(MockitoJunitRunner.class) @SpringBootTest public class Test { @Mock private UserSerice userService; @Test public void test(){ // code \t} }  使用MockitoRule，但是对象的访问级别必须是public（此方法也只能用于Junit4）  @RunWith(JUnit4.class) @SpringBootTest public class Test { @Rule public MockitoRule rule = MockitoJUnit.rule(); @Mock private UserSerice userService; @Test public void test(){ // code \t} } 单元测试常用 注解 @Test 标注一个测试方法\n@BeforeEach / @AfterEach 在每个测试方法之前/后运行\n@BeforeAll / @AfterAll 在整个测试流程之前/后运行，整个测试过程只会运行一次\n@SpringBootTest 初始化Spring上下文来进行测试，当测试中用到类需要用Spring容器管理时加\n@MockBean 同Mockito的@Mock\n@SpyBean 同Mockito的@Spy\n断言  Assert类  JUnit4提供，使用较为简单，点进去看源码的方法即可。\n Assertions类  JUnit5提供，和Assert类差不多。\n assertThat(T actual, Matcher\u0026lt;? super T\u0026gt; matcher);  assertThat(Assert类中)是JUnit 4.4引入的一个全新的断言语法，可以只使用这一个方法，实现所有的断言测试。\n其中actual为需要测试的变量值，matcher为使用Hamcrest的匹配符来表达变量actual期望值的声明，如果值与matcher所表达的期望值相符，则测试成功，否则失败。\n匹配器有可读性强、满足复杂匹配条件等优点，常用匹配器可以查文档，也不难使用。\n","date":"2021-08-30T12:34:20+08:00","image":"https://ccqstark.github.io/p/mockito/cover_hu0fac036fa1f4a6a5daf062f2a604284c_100124_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/mockito/","title":"Java单元测试利器——Mockito"},{"content":"什么是布隆过滤器 简介 布隆过滤器（Bloom Filter）是 1970 年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。\n具体实现原理  \n如上图所示，布隆过滤器的原理就是通过几个哈希函数把要存储的数据映射到一个二进制的数组里，映射到的对应位标为1，如上图就为（2，5，9）。后续有元素加入时，若该位本就为1，则不对该位再做处理。\n当要判断一个元素是否在过滤器中，也是先进行Hash计算出对应的位，判断二进制数组中所有对应的位是否都为1，是的话表示元素在其中；反之不在。\n存在的问题 布隆过滤器存在误判率，也是可能会把一个不存在的元素判定为存在的。因为在加入大量元素后，二进制数组中可能大部分位都被置为1了，所以一个新的数据Hash出来对应的位就很可能也都置为1了。\n解决办法就是增加二进制数组的长度，使得二进制数组不那么快饱和，就可以容纳更多的元素，降低误判概率；或者增加Hash次数，使得数据更加分散。\n所以但布隆过滤器判断一个元素存在时，可能不一定真的存在；但假如它判断一个元素不存在，那这个元素一定不存在，这种情况不存在误判。\n还有一个问题是删除困难，因为在元素较多的情况下它们对应的位总有交叉，如果你把其中一个元素对应的位都置0了，那很可能也会影响到其他的元素，很难仅仅删除一个元素。\n应用场景  网页爬虫对 URL 去重，避免爬取相同的 URL 地址； 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱； Google Chrome 使用布隆过滤器识别恶意 URL； Medium 使用布隆过滤器避免推荐给用户已经读过的文章； Google BigTable，Apache HBbase 和 Apache Cassandra 使用布隆过滤器减少对不存在的行和列的查找。  除了上述的应用场景之外，布隆过滤器还有一个应用场景就是解决缓存穿透的问题。所谓的缓存穿透就是服务调用方每次都是查询不在缓存中的数据，这样每次服务调用都会到数据库中进行查询，如果这类请求比较多的话，就会导致数据库压力增大，这样缓存就失去了意义。\n所以当有黑客生成大量随机的不存在的值请求服务器导致查询数据库，造成大量缓存穿透的情况时。我们可以用布隆过滤器进行拦截，被布隆过滤器判断为不存在的值就不需要查询数据库了，直接返回，大大减低了数据库压力。(少量判断为存在的值因为有误判率所以可以进行下一步查询)\n在redis中安装布隆过滤器 redis本身是不自带布隆过滤器功能的，要么基于bitmap自己实现，要么安装插件\n（布隆过滤器在guava包中也有实现）\n安装redis插件 非docker安装的redis可以采用安装插件的方式来\n# 去这个github仓库看看最新版本 wget https://github.com/RedisLabsModules/rebloom/archive/v2.2.4.tar.gz # 解压 tar zxvf v2.2.4.tar.gz # 编译 cd RedisBloom-2.2.4 make 以上执行完之后在目录下多了一个rebloom.so文件，将其移动到一个合适的位置\n然后在redis的配置文件里增加以下一行（最好添加在MODULES区域，规范点，redis配置文件所在路径可以在redis-cli中用info 命令查看）\n# 后面为rebloom.so文件所在的目录 loadmodule /xxx/xxx/xxx/rebloom.so 重启redis后进入redis-cli尝试以下命令\nbf.add test 1 bf.add test 2 bf.exists test 1 bf.exists test 222 Docker镜像 拉取镜像并运行容器\ndocker run -d -p 6379:6379 --name redis-redisbloom redislabs/rebloom:latest 进入容器测试命令\n# 进入容器 docker exec -it redis-redisbloom bash # 启动客户端 redis-cli 同样去测试bf.add和bf.exists命令即可\n使用Redisson的API进行操作 Redisson是著名的redis客户端，有很多强大的功能，其中就包括了布隆过滤器的实现，而且是直接基于redis的bitmap的，所以也不需要去在redis安装布隆过滤器的插件，原生的redis即可。\n引入依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;redisson-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.16.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 如果只为了使用redisson的布隆过滤器api，则不需要配置其他东西，只需要在项目配置文件中配好redis地址密码等，用redistemplate原来那些配置就行。\n简单使用demo @Test public void TestRedissonBloomFilter() { // 先根据key获取一个布隆过滤器（不管存不存在）  RBloomFilter\u0026lt;Integer\u0026gt; bloomFilter = redissonClient.getBloomFilter(\u0026#34;phoneList\u0026#34;); //初始化布隆过滤器：预计元素为100000000L,误差率为3%  bloomFilter.tryInit(100000000L, 0.03); //将号码10086插入到布隆过滤器中  bloomFilter.add(666); //判断下面号码是否在布隆过滤器中  System.out.println(bloomFilter.contains(666));//false  System.out.println(bloomFilter.contains(66666));//true } 封装进RedisUtil /** * 初始化一个布隆过滤器 * * @param expectedInsertions 预期元素数量 * @param falseProbability 误判率 * @return 是否创建成功 */ public \u0026lt;T\u0026gt; boolean initBloomFilter(RBloomFilter\u0026lt;T\u0026gt; bloomFilter, long expectedInsertions, double falseProbability) { return bloomFilter.tryInit(expectedInsertions, falseProbability); } /** * 获取布隆过滤器 */ public \u0026lt;T\u0026gt; RBloomFilter\u0026lt;T\u0026gt; getBloomFilter(String key) { return redissonClient.getBloomFilter(key); } /** * 在布隆过滤器中增加一个值 */ public \u0026lt;T\u0026gt; boolean addInBloomFilter(RBloomFilter\u0026lt;T\u0026gt; bloomFilter, T value) { try { bloomFilter.add(value); } catch (IllegalStateException e) { initBloomFilter(bloomFilter, 50000L, 0.01); } return bloomFilter.add(value); } /** * 判断某值是否存在于过滤器中 */ public \u0026lt;T\u0026gt; boolean containsInBloomFilter(RBloomFilter\u0026lt;T\u0026gt; bloomFilter, T value) { try { bloomFilter.contains(value); } catch (IllegalStateException e) { initBloomFilter(bloomFilter, 50000L, 0.01); } return bloomFilter.contains(value); } 为了方便使用这些API，这里我自己封装了一些工具类。\n因为BloomFilter不像redis其他数据结构，不用初始化就可以直接set和get，如果getBloomFilter 方法获取了一个未初始化的过滤器，并进行了add和contains操作，就会报错。因此我在这两个操作的方法中捕获了未初始化的异常，假如检测到了异常就自动进行初始化（默认值），简化了使用。\n点赞功能的设计与思考 点赞，一个看起来很简单的功能实现，在数据量大，并发量大情况下就不是这么回事了。\n可以代入微博的场景来思考，假如明星发一条微博，瞬间几十万点赞，这波流量要顶住也不是那么容易，尽管只是一个点赞功能而已。最近在做公司那个项目的点赞功能，为了设计得更加高可用，也是去好好地思考了。\n功能拆解 点赞，说到底就两个方面需要实现\n 对应帖子的点赞数 用户与点赞帖子的关联关系  第一个本质就是一个计数器，我们需要对每一个帖子被点赞的次数进行计数\n第二个主要是用来判断此用户是否已经点赞过文章，从而避免二次点赞或者进行取消点赞的操作，需要维护的是一个类似二元组的关系结构（用户id，帖子id）\n方案主要也是从两个数据库入手，即MySQL和Redis，也就是怎么处理好存储层和缓存层之间的关系、怎么最合理地配合使用它们来达到最佳的实现效果，这也是这个问题的本质。\n看透问题的本质再思考方案与动手实践，才是正确的解决问题的方式。教父曾经说过：“花半秒钟就看透事物本质的人，和花一辈子都看不清事物本质的人，注定是截然不同的命运。”（doge）\n方案一 这个方案是我最开始在翻阅查询了晚上的一些资料后想出来的，看起来好像有模有样，其实问题还是挺多的，主要也是和公司的同事讨论后被指出很多不合理的地方。\n \n方案介绍\n 这个流程主要是在点赞时前端直接在本地将点赞数+1并改变样式，然后再去请求后端， 然后就是请求的接口是把点赞的这个消息或者说任务，放到了消息队列里，之后等待被消费。每次消费是先直接在redis对计数器incr。 接着用户是否点赞是存在布隆过滤器中的，一篇文章一个bloom filter，里面存的就是点过赞的用户的id。 最后是定期将redis中的数据持久化到mysql。  反思\n前端本地先+1主要是为了用户直观感觉到点赞可以立马得到反馈，而不是因为到等待后端返回而带来的延迟感，影响用户体验。\n消息队列，加入它的本意是为了让消息可以被准确消费从未保证点赞数较为精确，后来发现这样失去了实时性同时增加了开销，而且我还得去保证消息的可靠消费，就为了其实压根不需要很准确的点赞数，实在没有必要，所以后续删了。\n之前在学redis的应用场景的时候好像就听过可以用incr来做点赞，所以这次要做点赞就直接先到了incr。得益于redis单线程，这样没有并发修改问题，速度也快，但同步到mysql是个大问题。\n没错，我直接用一个布隆过滤器当做存储用了，还在想之后持久化到mysql可以用binary类型来存，完全没有意识到人家是一个过滤器，不是一个存储器，我直接忽略了布隆过滤器的误判率可能导致人家都没点赞过你给直接判定为点赞过了的情况。导致这些错误的使用也是当时对它认识还不够深刻。\n对于持久化到mysql，当时还没仔细往下查具体的方案，感觉业内应该会有一个成熟的机制或者什么插件中间件之类的可以方便快捷稳定地完成这个任务，后来发现并没有，需要自己业务代码做定时任务定期写入库，感觉就比较麻烦不好非常优雅完美地实现，如果缓存中的数据越来越多，这个同步任务岂不是越来越庞大？这个暂时不知道如何解决。\n总结就是方案十分不成熟，漏洞百出，是一个孬方案。\n方案二 在与同事讨论后对方案一进行改良后的方案，也是最后确定使用的方案。\n \n方案介绍\n 首先前端还是和方案一一样，不再赘述。 如何采用了MyBatis的二级缓存，将每次查询到的结果缓存到redis中，有变更就清除，查不到再回库查。点赞数就在查的时候缓存到了redis中，但是每次更新点赞数都是直接到库中操作的，而且附带一个清缓存的操作。 用户是否点赞用一个布隆过滤器先做过滤，一个redis的set来存储点赞和帖子的关系，直接用redis的持久化机制，不入MySQL。  反思\n这个方案对比方案一明显有了改进，首先是去掉了意义不大的消息队列，很好。\n然后是二级缓存，虽然每次点赞都会直接操作库，对性能有影响而且同时还清缓存，导致下一次查询也要进库才能再设缓存，但是考虑到项目一开始用户应该不多，点赞行为的发生次数相对来说不会非常多，至少要比普通的查询少上一些，这样一来hit到缓存的几率还是不小的，缓存还是能起到一定的作用的，而且二级缓存也不仅仅只是用在点赞功能上，而是全线使用。\n接着夸一下这次布隆过滤器用的不错，真当一个过滤器用了，用来过滤掉很多元素不存在的情况，对性能提升作用还是不小的；然后就是点赞关系的存储，有人说既然是一个类似二元组的关系为啥不一个Hash结构搞定呢？考虑到目前直接用redis持久化的，如果慢慢积累下来，这个Hash变得硕大无比，也是会影响性能的。所以我是通过树形的key来使得一篇帖子有一个set集合（同时也有一个布隆），集合里放点赞过的userID。\n最后说一下redis和mysql同步的问题，在讨论过程中搜了一下，发现很多同步方案都是针对于mysql的改动同步到redis的（而不是redis同步到mysql），常见的有两种：\n 触发器+用户自定义函数UDF 中间件canal（binlog）  后来在学习redis当MyBatis的二级缓存中发现其实没有必要搞这个了，二级缓存本质已经解决了数据需要更新的问题（清除再设置）\n总结就是改进不少，但是仍有不足，或许是现阶段现情景下最好的选择。\n 说完上面两个用了布隆过滤器的方案，该对自己进行一个灵魂拷问，用布隆过滤器到底是为了什么？它到底优化了什么？\n实际上，过滤器过滤器，说到底就是用来过滤的，由于布隆过滤器最大的优点是缓解我们redis的缓存穿透，也就是挡住了很多不存在的数据防止打到mysql上，那么想一下我们的业务场景中用户获取文章被点赞的状态的时候，大部分肯定都是没有被点赞过的，因为系统给用户推荐的内容肯定大部分都是用户没浏览过的，那么实际上这部分判断到没有点赞过的流量就被bloom filter拦截下来了，而不是去mysql中去查文章id和user id对应记录是否存在来判断，就减轻了数据库很大的压力，达到了一定的优化效果。\n 方案三 这个是在我对着搜索引擎直接输入关键字“redis实现点赞功能”后查出来的常见方案，大同小异，这里简答讲下就行。和之前的方案主要的不同是数据修改都是直接缓存中操作，然后再在业务代码中用定时任务例如Quartz每隔一段时间写入到mysql中；还有一个是存储点赞关系用redis的Hash。\n我这于两个不同点的看法上面也提到过了，在这里只能这样说也不失为一种方案吧。\n总结 方案很多，但是哪种最优，哪种更好，可能脱离场景的情况下不会有一个标准答案，对于好方案的追求与优化我也将不断追寻。。。（升华了doge）\n参考链接 https://juejin.cn/post/6844904007790673933\nhttps://zhuanlan.zhihu.com/p/346651831\nhttps://blog.csdn.net/ChenMMo/article/details/93615438\n","date":"2021-08-26T03:57:56+08:00","image":"https://ccqstark.github.io/p/bloom_filter/cover_hu4ee9ebaa10fc0f0205471a9a6145c894_228532_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/bloom_filter/","title":"Redis布隆过滤器与点赞功能设计"},{"content":"缓存的分类 本地缓存(local cache)：存在应用服务器内存中的数据称为本地缓存\n分布式缓存(dustribute cache)：存储在当前应用服务器之外的数据称为分布式缓存\n这里顺带提及集群和分布式的区别\n集群(cluster)：将同一种服务的多个节点放在一起共同对系统提供服务，称为集群\n分布式(distribute system)：有多个不同服务集群功能对系统提供服务，这个系统称之为分布式系统\n所以两者虽然都是多个服务器节点，区别就在多个节点中，集群侧重的是同一种服务，而分布式侧重的是不同的服务，而且分布式还是建立在集群的基础之上的。\n缓存发挥的作用  \n由图中可以看出，缓存是作为存储层和客户端之间的中间层，当客户端的请求过来时，首先请求缓存中的内容，如果查到（hit）则直接返回，不再去查找存储层；如果没有（miss），则去存储层中查找并将结果写入缓存（write cache）再返回，以便之后相同的请求可以去缓存中获取。\n之所以加入缓存层是因为存储层一般是需要读写磁盘的，而缓存层在内存中，两者的读写速度完全不是一个量级，内存快的多。而大部分应用的请求都有一个特点——读多写少，所以将总是需要查到的数据放在缓存层中可以大大提高应用的响应速度，减少存储层的压力。\n一般Web应用中，存储层就是我们用的关系型数据库，MySQL、Oracle、SQLServer等，而缓存层分类上面已经提到，常用的有Redis，Memcached等。\nMyBatis开启二级缓存 MyBatis一级缓存中，其最大的共享范围就是一个SqlSession内部，如果多个SqlSession之间需要共享缓存，则需要使用到二级缓存。\n开启方法：\n在业务的mapper.xml文件中添加\n\u0026lt;cache/\u0026gt; 二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。\n当开启缓存后，数据的查询执行的流程就是 二级缓存 -\u0026gt; 一级缓存 -\u0026gt; 数据库。\n \n这样开启的是本地二级缓存，这样有个缺点就是应用重新启动后，JVM重新分配内存，这样的话之前的缓存就都没了，所以我们得用分布式缓存来解决。\n使用Redis作为Mybatis的二级缓存 MyBatis的缓存实现类默认是PerpetualCache，它继承类Cache接口，除此之外还有其他实现类。\n原理就是维护一个HashMap，将查询的SQL以及Mapper的namespace作为Key，然后查询的结果作为Value，通过键值对的方式来实现缓存查询过的sql语句的结果，所以要用redis替换也还是十分合适的。\nCache接口 public interface Cache { String getId(); void putObject(Object var1, Object var2); Object getObject(Object var1); Object removeObject(Object var1); void clear(); int getSize(); ReadWriteLock getReadWriteLock(); } 解析\ngetId ：这个方法其实是获取了执行的sql对应的namespace，可以用来组成缓存的key\nputObject ：此方法就是用来将数据放入缓存的\ngetObject ：用以根据key获取缓存的值\nremoveObject ：删除某一缓存项目，MyBatis暂未实现与启用此方法，所以暂时无用\nclear ：每次执行update/delete/insert语句都会调用此方法进行清除原有的缓存\ngetSize ：获取缓存大小，暂时用处不大\ngetReadWriteLock ：获取读写锁，这是用来拿到互斥锁解决缓存击穿问题的\n所以我们只要恰当地实现以上方法，对接上redis，就可以使用redis作为mybatis的二级缓存了。\nMyBatisRedisCache实现类 这里在网上找了一个博主实现地比较好的，链接在文章最后，作者为Leven\nSpringBoot配置 mybatis:configuration:cache-enabled:trueRedisConfig中配置RedisTemplate /** * Redis缓存配置 * @author Leven * @date 2019-09-07 */ @Configuration public class RedisConfig { /** * 配置自定义redisTemplate * @return redisTemplate */ @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); template.setConnectionFactory(redisConnectionFactory); // 使用Jackson2JsonRedisSerializer来序列化和反序列化redis的value值  Jackson2JsonRedisSerializer\u0026lt;Object\u0026gt; jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer\u0026lt;\u0026gt;(Object.class); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); ObjectMapper mapper = new ObjectMapper(); mapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); mapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(mapper); template.setKeySerializer(stringRedisSerializer); template.setValueSerializer(jackson2JsonRedisSerializer); template.setHashKeySerializer(stringRedisSerializer); template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; } } RedisService接口 /** * redis基础服务接口 * @author Leven * @date 2019-09-07 */ public interface RedisService { // =============================common============================  /** * 指定缓存失效时间 * @param key 键 * @param time 时间(秒) */ void expire(String key, long time); /** * 指定缓存失效时间 * @param key 键 * @param expireAt 失效时间点 * @return 处理结果 */ void expireAt(String key, Date expireAt); /** * 根据key 获取过期时间 * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ Long getExpire(String key); /** * 判断key是否存在 * @param key 键 * @return true 存在 false不存在 */ Boolean hasKey(String key); /** * 删除缓存 * @param key 可以传一个值 或多个 */ void delete(String... key); /** * 删除缓存 * @param keys 可以传一个值 或多个 */ void delete(Collection\u0026lt;String\u0026gt; keys); // ============================String=============================  /** * 普通缓存获取 * @param key 键 * @return 值 */ Object get(String key); /** * 普通缓存放入 * @param key 键 * @param value 值 */ void set(String key, Object value); /** * 普通缓存放入并设置时间 * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 */ void set(String key, Object value, long time); /** * 普通缓存放入并设置时间 * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 */ void set(String key, Object value, long time, TimeUnit timeUnit); /** * 递增 * @param key 键 * @param value 要增加几(大于0) * @return 递增后结果 */ Long incr(String key, long value); /** * 递减 * @param key 键 * @param value 要减少几(大于0) * @return 递减后结果 */ Long decr(String key, long value); // ================================Map=================================  /** * HashGet * @param key 键 不能为null * @param item 项 不能为null * @return 值 */ Object hashGet(String key, String item); /** * 获取hashKey对应的所有键值 * @param key 键 * @return 对应的多个键值 */ Map\u0026lt;Object, Object\u0026gt; hashEntries(String key); /** * HashSet * @param key 键 * @param map 对应多个键值 */ void hashSet(String key, Map\u0026lt;String, Object\u0026gt; map); /** * HashSet 并设置时间 * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) */ void hashSet(String key, Map\u0026lt;String, Object\u0026gt; map, long time); /** * 向一张hash表中放入数据,如果不存在将创建 * @param key 键 * @param item 项 * @param value 值 */ void hashSet(String key, String item, Object value); /** * 向一张hash表中放入数据,如果不存在将创建 * @param key 键 * @param item 项 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 */ void hashSet(String key, String item, Object value, long time); /** * 删除hash表中的值 * @param key 键 不能为null * @param item 项 可以使多个 不能为null */ void hashDelete(String key, Object... item); /** * 删除hash表中的值 * @param key 键 不能为null * @param items 项 可以使多个 不能为null */ void hashDelete(String key, Collection items); /** * 判断hash表中是否有该项的值 * @param key 键 不能为null * @param item 项 不能为null * @return true 存在 false不存在 */ Boolean hashHasKey(String key, String item); /** * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * @param key 键 * @param item 项 * @param value 要增加几(大于0) * @return 递增后结果 */ Double hashIncr(String key, String item, double value); /** * hash递减 * @param key 键 * @param item 项 * @param value 要减少记(小于0) * @return 递减后结果 */ Double hashDecr(String key, String item, double value); // ============================set=============================  /** * 根据key获取Set中的所有值 * @param key 键 * @return set集合 */ Set\u0026lt;Object\u0026gt; setGet(String key); /** * 根据value从一个set中查询,是否存在 * @param key 键 * @param value 值 * @return true 存在 false不存在 */ Boolean setIsMember(String key, Object value); /** * 将数据放入set缓存 * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ Long setAdd(String key, Object... values); /** * 将数据放入set缓存 * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ Long setAdd(String key, Collection values); /** * 将set数据放入缓存 * @param key 键 * @param time 时间(秒) * @param values 值 可以是多个 * @return 成功个数 */ Long setAdd(String key, long time, Object... values); /** * 获取set缓存的长度 * @param key 键 * @return set长度 */ Long setSize(String key); /** * 移除值为value的 * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ Long setRemove(String key, Object... values); // ===============================list=================================  /** * 获取list缓存的内容 * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return 缓存列表 */ List\u0026lt;Object\u0026gt; listRange(String key, long start, long end); /** * 获取list缓存的长度 * @param key 键 * @return 长度 */ Long listSize(String key); /** * 通过索引 获取list中的值 * @param key 键 * @param index 索引 index\u0026gt;=0时， 0 表头，1 第二个元素，依次类推；index\u0026lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * @return 值 */ Object listIndex(String key, long index); /** * 将list放入缓存 * @param key 键 * @param value 值 */ void listRightPush(String key, Object value); /** * 将list放入缓存 * @param key 键 * @param value 值 * @param time 时间(秒) */ void listRightPush(String key, Object value, long time); /** * 将list放入缓存 * @param key 键 * @param value 值 */ void listRightPushAll(String key, List\u0026lt;Object\u0026gt; value); /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) */ void listRightPushAll(String key, List\u0026lt;Object\u0026gt; value, long time); /** * 根据索引修改list中的某条数据 * @param key 键 * @param index 索引 * @param value 值 */ void listSet(String key, long index, Object value); /** * 移除N个值为value * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ Long listRemove(String key, long count, Object value); } RedisServiceImpl实现 /** * redis基础服务接口实现 * * @author Leven * @date 2019-09-07 */ @Slf4j @Service public class RedisServiceImpl implements RedisService { private static final String PREFIX = \u0026#34;应用名\u0026#34;; @Autowired private RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate; // =============================common============================  /** * 指定缓存失效时间 * * @param key 键 * @param time 时间(秒) */ @Override public void expire(String key, long time) { redisTemplate.expire(getKey(key), time, TimeUnit.SECONDS); } /** * 指定缓存失效时间 * * @param key 键 * @param expireAt 失效时间点 * @return 处理结果 */ @Override public void expireAt(String key, Date expireAt) { redisTemplate.expireAt(getKey(key), expireAt); } /** * 根据key 获取过期时间 * * @param key 键 不能为null * @return 时间(秒) 返回0代表为永久有效 */ @Override public Long getExpire(String key) { return redisTemplate.getExpire(getKey(key), TimeUnit.SECONDS); } /** * 判断key是否存在 * * @param key 键 * @return true 存在 false不存在 */ @Override public Boolean hasKey(String key) { return redisTemplate.hasKey(getKey(key)); } /** * 删除缓存 * * @param keys 可以传一个值 或多个 */ @Override public void delete(String... keys) { if (keys != null \u0026amp;\u0026amp; keys.length \u0026gt; 0) { if (keys.length == 1) { redisTemplate.delete(getKey(keys[0])); } else { List\u0026lt;String\u0026gt; keyList = new ArrayList\u0026lt;\u0026gt;(keys.length); for (String key : keys) { keyList.add(getKey(key)); } redisTemplate.delete(keyList); } } } /** * 删除缓存 * * @param keys 可以传一个值 或多个 */ @Override public void delete(Collection\u0026lt;String\u0026gt; keys) { if (keys != null \u0026amp;\u0026amp; !keys.isEmpty()) { List\u0026lt;String\u0026gt; keyList = new ArrayList\u0026lt;\u0026gt;(keys.size()); for (String key : keys) { keyList.add(getKey(key)); } redisTemplate.delete(keyList); } } // ============================String=============================  /** * 普通缓存获取 * * @param key 键 * @return 值 */ @Override public Object get(String key) { return key == null ? null : redisTemplate.opsForValue().get(getKey(key)); } /** * 普通缓存放入 * * @param key 键 * @param value 值 */ @Override public void set(String key, Object value) { redisTemplate.opsForValue().set(getKey(key), value); } /** * 普通缓存放入并设置时间 * * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 */ @Override public void set(String key, Object value, long time) { set(key, value, time, TimeUnit.SECONDS); } /** * 普通缓存放入并设置时间 * * @param key 键 * @param value 值 * @param time 时间 time要大于0 如果time小于等于0 将设置无限期 * @param timeUnit 时间单位 */ @Override public void set(String key, Object value, long time, TimeUnit timeUnit) { if (time \u0026gt; 0) { redisTemplate.opsForValue().set(getKey(key), value, time, timeUnit); } else { set(getKey(key), value); } } /** * 递增 * * @param key 键 * @param value 要增加几(大于0) * @return 递增后结果 */ @Override public Long incr(String key, long value) { if (value \u0026lt; 1) { throw new BizException(\u0026#34;递增因子必须大于0\u0026#34;); } return redisTemplate.opsForValue().increment(getKey(key), value); } /** * 递减 * * @param key 键 * @param value 要减少几(大于0) * @return 递减后结果 */ @Override public Long decr(String key, long value) { if (value \u0026lt; 1) { throw new BizException(\u0026#34;递减因子必须大于0\u0026#34;); } return redisTemplate.opsForValue().decrement(getKey(key), value); } // ================================Map=================================  /** * HashGet * * @param key 键 不能为null * @param item 项 不能为null * @return 值 */ @Override public Object hashGet(String key, String item) { return redisTemplate.opsForHash().get(getKey(key), item); } /** * 获取hashKey对应的所有键值 * * @param key 键 * @return 对应的多个键值 */ @Override public Map\u0026lt;Object, Object\u0026gt; hashEntries(String key) { return redisTemplate.opsForHash().entries(getKey(key)); } /** * HashSet * * @param key 键 * @param map 对应多个键值 */ @Override public void hashSet(String key, Map\u0026lt;String, Object\u0026gt; map) { redisTemplate.opsForHash().putAll(getKey(key), map); } /** * HashSet 并设置时间 * * @param key 键 * @param map 对应多个键值 * @param time 时间(秒) */ @Override public void hashSet(String key, Map\u0026lt;String, Object\u0026gt; map, long time) { String k = getKey(key); redisTemplate.opsForHash().putAll(k, map); if (time \u0026gt; 0) { expire(k, time); } } /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 */ @Override public void hashSet(String key, String item, Object value) { redisTemplate.opsForHash().putIfAbsent(getKey(key), item, value); } /** * 向一张hash表中放入数据,如果不存在将创建 * * @param key 键 * @param item 项 * @param value 值 * @param time 时间(秒) 注意:如果已存在的hash表有时间,这里将会替换原有的时间 */ @Override public void hashSet(String key, String item, Object value, long time) { String k = getKey(key); redisTemplate.opsForHash().putIfAbsent(k, item, value); if (time \u0026gt; 0) { expire(k, time); } } /** * 删除hash表中的值 * * @param key 键 不能为null * @param item 项 可以使多个 不能为null */ @Override public void hashDelete(String key, Object... item) { redisTemplate.opsForHash().delete(getKey(key), item); } /** * 删除hash表中的值 * * @param key 键 不能为null * @param items 项 可以使多个 不能为null */ @Override public void hashDelete(String key, Collection items) { redisTemplate.opsForHash().delete(getKey(key), items.toArray()); } /** * 判断hash表中是否有该项的值 * * @param key 键 不能为null * @param item 项 不能为null * @return true 存在 false不存在 */ @Override public Boolean hashHasKey(String key, String item) { return redisTemplate.opsForHash().hasKey(getKey(key), item); } /** * hash递增 如果不存在,就会创建一个 并把新增后的值返回 * * @param key 键 * @param item 项 * @param value 要增加几(大于0) * @return 递增后结果 */ @Override public Double hashIncr(String key, String item, double value) { if (value \u0026lt; 1) { throw new BizException(\u0026#34;递增因子必须大于0\u0026#34;); } return redisTemplate.opsForHash().increment(getKey(key), item, value); } /** * hash递减 * * @param key 键 * @param item 项 * @param value 要减少记(小于0) * @return 递减后结果 */ @Override public Double hashDecr(String key, String item, double value) { if (value \u0026lt; 1) { throw new BizException(\u0026#34;递减因子必须大于0\u0026#34;); } return redisTemplate.opsForHash().increment(getKey(key), item, -value); } // ============================set=============================  /** * 根据key获取Set中的所有值 * * @param key 键 * @return set集合 */ @Override public Set\u0026lt;Object\u0026gt; setGet(String key) { return redisTemplate.opsForSet().members(getKey(key)); } /** * 根据value从一个set中查询,是否存在 * * @param key 键 * @param value 值 * @return true 存在 false不存在 */ @Override public Boolean setIsMember(String key, Object value) { return redisTemplate.opsForSet().isMember(getKey(key), value); } /** * 将数据放入set缓存 * * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ @Override public Long setAdd(String key, Object... values) { return redisTemplate.opsForSet().add(getKey(key), values); } /** * 将数据放入set缓存 * * @param key 键 * @param values 值 可以是多个 * @return 成功个数 */ @Override public Long setAdd(String key, Collection values) { return redisTemplate.opsForSet().add(getKey(key), values.toArray()); } /** * 将set数据放入缓存 * * @param key 键 * @param time 时间(秒) * @param values 值 可以是多个 * @return 成功个数 */ @Override public Long setAdd(String key, long time, Object... values) { String k = getKey(key); Long count = redisTemplate.opsForSet().add(k, values); if (time \u0026gt; 0) { expire(k, time); } return count; } /** * 获取set缓存的长度 * * @param key 键 * @return set长度 */ @Override public Long setSize(String key) { return redisTemplate.opsForSet().size(getKey(key)); } /** * 移除值为value的 * * @param key 键 * @param values 值 可以是多个 * @return 移除的个数 */ @Override public Long setRemove(String key, Object... values) { return redisTemplate.opsForSet().remove(getKey(key), values); } // ===============================list=================================  /** * 获取list缓存的内容 * * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return 缓存列表 */ @Override public List\u0026lt;Object\u0026gt; listRange(String key, long start, long end) { return redisTemplate.opsForList().range(getKey(key), start, end); } /** * 获取list缓存的长度 * * @param key 键 * @return 长度 */ @Override public Long listSize(String key) { return redisTemplate.opsForList().size(getKey(key)); } /** * 通过索引 获取list中的值 * * @param key 键 * @param index 索引 index\u0026gt;=0时， 0 表头，1 第二个元素，依次类推；index\u0026lt;0时，-1，表尾，-2倒数第二个元素，依次类推 * @return 值 */ @Override public Object listIndex(String key, long index) { return redisTemplate.opsForList().index(getKey(key), index); } /** * 将list放入缓存 * * @param key 键 * @param value 值 */ @Override public void listRightPush(String key, Object value) { redisTemplate.opsForList().rightPush(getKey(key), value); } /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) */ @Override public void listRightPush(String key, Object value, long time) { String k = getKey(key); redisTemplate.opsForList().rightPush(k, value); if (time \u0026gt; 0) { expire(k, time); } } /** * 将list放入缓存 * * @param key 键 * @param value 值 */ @Override public void listRightPushAll(String key, List\u0026lt;Object\u0026gt; value) { redisTemplate.opsForList().rightPushAll(getKey(key), value); } /** * 将list放入缓存 * * @param key 键 * @param value 值 * @param time 时间(秒) */ @Override public void listRightPushAll(String key, List\u0026lt;Object\u0026gt; value, long time) { String k = getKey(key); redisTemplate.opsForList().rightPushAll(k, value); if (time \u0026gt; 0) { expire(k, time); } } /** * 根据索引修改list中的某条数据 * * @param key 键 * @param index 索引 * @param value 值 */ @Override public void listSet(String key, long index, Object value) { redisTemplate.opsForList().set(getKey(key), index, value); } /** * 移除N个值为value * * @param key 键 * @param count 移除多少个 * @param value 值 * @return 移除的个数 */ @Override public Long listRemove(String key, long count, Object value) { return redisTemplate.opsForList().remove(getKey(key), count, value); } private String getKey(String key) { return PREFIX + \u0026#34;:\u0026#34; + key; } } 实现Cache接口的MybatisRedisCache /** * MyBatis二级缓存Redis实现 * 重点处理以下几个问题 * 1、缓存穿透：存储空值解决，MyBatis框架实现 * 2、缓存击穿：使用互斥锁，我们自己实现 * 3、缓存雪崩：缓存有效期设置为一个随机范围，我们自己实现 * 4、读写性能：redis key不能过长，会影响性能，这里使用SHA-256计算摘要当成key * @author Leven * @date 2019-09-07 */ @Slf4j public class MybatisRedisCache implements Cache { /** * 统一字符集 */ private static final String CHARSET = \u0026#34;utf-8\u0026#34;; /** * key摘要算法 */ private static final String ALGORITHM = \u0026#34;SHA-256\u0026#34;; /** * 统一缓存头 */ private static final String CACHE_NAME = \u0026#34;MyBatis:\u0026#34;; /** * 读写锁：解决缓存击穿 */ private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); /** * 表空间ID：方便后面的缓存清理 */ private final String id; /** * redis服务接口：提供基本的读写和清理 */ private static volatile RedisService redisService; /** * 信息摘要 */ private volatile MessageDigest messageDigest; /////////////////////// 解决缓存雪崩，具体范围根据业务需要设置合理值 //////////////////////////  /** * 缓存最小有效期 */ private static final int MIN_EXPIRE_MINUTES = 60; /** * 缓存最大有效期 */ private static final int MAX_EXPIRE_MINUTES = 120; /** * MyBatis给每个表空间初始化的时候要用到 * @param id 其实就是namespace的值 */ public MybatisRedisCache(String id) { if (id == null) { throw new IllegalArgumentException(\u0026#34;Cache instances require an ID\u0026#34;); } this.id = id; } /** * 获取ID * @return 真实值 */ @Override public String getId() { return id; } /** * 创建缓存 * @param key 其实就是sql语句 * @param value sql语句查询结果 */ @Override public void putObject(Object key, Object value) { try { String strKey = getKey(key); // 有效期为1~2小时之间随机，防止雪崩  int expireMinutes = RandomUtils.nextInt(MIN_EXPIRE_MINUTES, MAX_EXPIRE_MINUTES); getRedisService().set(strKey, value, expireMinutes, TimeUnit.MINUTES); log.debug(\u0026#34;Put cache to redis, id={}\u0026#34;, id); } catch (Exception e) { log.error(\u0026#34;Redis put failed, id=\u0026#34; + id, e); } } /** * 读取缓存 * @param key 其实就是sql语句 * @return 缓存结果 */ @Override public Object getObject(Object key) { try { String strKey = getKey(key); log.debug(\u0026#34;Get cache from redis, id={}\u0026#34;, id); return getRedisService().get(strKey); } catch (Exception e) { log.error(\u0026#34;Redis get failed, fail over to db\u0026#34;, e); return null; } } /** * 删除缓存 * @param key 其实就是sql语句 * @return 结果 */ @Override public Object removeObject(Object key) { try { String strKey = getKey(key); getRedisService().delete(strKey); log.debug(\u0026#34;Remove cache from redis, id={}\u0026#34;, id); } catch (Exception e) { log.error(\u0026#34;Redis remove failed\u0026#34;, e); } return null; } /** * 缓存清理 * 网上好多博客这里用了flushDb甚至是flushAll，感觉好坑鸭！ * 应该是根据表空间进行清理 */ @Override public void clear() { try { log.debug(\u0026#34;clear cache, id={}\u0026#34;, id); String hsKey = CACHE_NAME + id; // 获取CacheNamespace所有缓存key  Map\u0026lt;Object, Object\u0026gt; idMap = getRedisService().hashEntries(hsKey); if (!idMap.isEmpty()) { Set\u0026lt;Object\u0026gt; keySet = idMap.keySet(); Set\u0026lt;String\u0026gt; keys = new HashSet\u0026lt;\u0026gt;(keySet.size()); keySet.forEach(item -\u0026gt; keys.add(item.toString())); // 清空CacheNamespace所有缓存  getRedisService().delete(keys); // 清空CacheNamespace  getRedisService().delete(hsKey); } } catch (Exception e) { log.error(\u0026#34;clear cache failed\u0026#34;, e); } } /** * 获取缓存大小，暂时没用上 * @return 长度 */ @Override public int getSize() { return 0; } /** * 获取读写锁：为了解决缓存击穿 * @return 锁 */ @Override public ReadWriteLock getReadWriteLock() { return readWriteLock; } /** * 计算出key的摘要 * @param cacheKey CacheKey * @return 字符串key */ private String getKey(Object cacheKey) { String cacheKeyStr = cacheKey.toString(); log.debug(\u0026#34;count hash key, cache key origin string:{}\u0026#34;, cacheKeyStr); String strKey = byte2hex(getSHADigest(cacheKeyStr)); log.debug(\u0026#34;hash key:{}\u0026#34;, strKey); String key = CACHE_NAME + strKey; // 在redis额外维护CacheNamespace创建的key，clear的时候只清理当前CacheNamespace的数据  getRedisService().hashSet(CACHE_NAME + id, key, \u0026#34;1\u0026#34;); return key; } /** * 获取信息摘要 * @param data 待计算字符串 * @return 字节数组 */ private byte[] getSHADigest(String data) { try { if (messageDigest == null) { synchronized (MessageDigest.class) { if (messageDigest == null) { messageDigest = MessageDigest.getInstance(ALGORITHM); } } } return messageDigest.digest(data.getBytes(CHARSET)); } catch (Exception e) { log.error(\u0026#34;SHA-256 digest error: \u0026#34;, e); throw new SPIException(ExceptionCode.RUNTIME_UNITE_EXP,\u0026#34;SHA-256 digest error, id=\u0026#34; + id + \u0026#34;.\u0026#34;); } } /** * 字节数组转16进制字符串 * @param bytes 待转换数组 * @return 16进制字符串 */ private String byte2hex(byte[] bytes) { StringBuilder sign = new StringBuilder(); for (byte aByte : bytes) { String hex = Integer.toHexString(aByte \u0026amp; 0xFF); if (hex.length() == 1) { sign.append(\u0026#34;0\u0026#34;); } sign.append(hex.toUpperCase()); } return sign.toString(); } /** * 获取Redis服务接口 * 使用双重检查保证线程安全 * @return 服务实例 */ private RedisService getRedisService() { if (redisService == null) { synchronized (RedisService.class) { if (redisService == null) { redisService = ApplicationContextUtils.getBeanByClass(RedisService.class); } } } return redisService; } } 配置实现类 有两种方式配置二级缓存实现类到mapper上，二选一\n Java代码（注解）  @CacheNamespace(implementation=com.leven.mybatis.core.cache.MybatisRedisCache.class) public interface UserMapper extends OracleMapper\u0026lt;UserDO\u0026gt; { } XML  \u0026lt;cache type=\u0026#34;com.leven.mybatis.core.cache.MybatisRedisCache\u0026#34;/\u0026gt; 实现类解析与缓存三大问题的解决 通过阅读以上实现类源码可以看出其中一些设计的精巧，下面一一来分析。\n Key的命名  key的命名可以看到使用了一些前缀，比如最终对某一sql运行结果缓存的key实际上是\n应用名:MyBatis:SQL转为的HEX\n可以看出是用冒号隔开的，一层一层的，类似命名空间一样的方式，这种key命名方式的好处是可以很好地区分不同业务的key，使得缓存的存储更有条理更加规范，同时也可以使得在RDM等redis可视化界面中呈现树形的结构。\nkey的摘要处理  MyBatis原始的key里是直接包含了被执行的sql语句，但是这样会导致key的长度太大，对redis性能有一定的影响，所以这里的处理是用SHA-256算法计算出原本为string的key的摘要，最后将其转换为十六进制的表示形式。\n这样做的优点是可以缩短key的长度，提升redis性能，同时也保证了sql与key的唯一对应性，只是需要一点开销去计算这个过程。\nCacheNamespace  网上很多其他的clear方法的实现类都是flushdb的，这样做不好，因为很多情况下不同namespace下的数据并无关联，这边的修改不会影响那边，所以只需要清除本SQL所在的namespace即可，不需要全部清除，被清除的之后还要去数据库中取也是增加了开销。（如果有关联的缓存则用另一种方法处理，文章下面有介绍）\n上面的实现类就是通过redis维护一个hash结构，key为namespace，里面的每个field就是其下的执行过的SQL的摘要，value只是标志位。而SQL对应的查询结果缓存则是单独用普通的string的key-value进行存储，只是我们制定了序列化用json而已。在clear时，查询到此namespace下的所有摘要，想删除了对应的所有的string的key-value，再去把hash结构删了。\n那有人可能会说，为啥不直接在hash中field对应的value里存储SQL的查询结果，要在外面另外的用key-value结构去存呢，这样我clear的时候直接删除整个namespace对应的hash就行了呗。这其实也是一种方案，但是缺点有两个：（一）无法对每一个SQL摘要进行单独设置过期时间，最多只能对hash结构的大key设置；（二）hash中的filed不宜过多\n随机过期时间——应对缓存雪崩  缓存雪崩，简单来说就是当我们有一组key因为过期时间点相近，在那一小段时间内这组key集体失效，而此时又有很多请求过来要获取这组key的内容，那就全部打在MySQL上，可能就会造成数据库压力过大而崩溃。\n解决方法是在设置key的过期时间时加上随机数，使得他们的过期时间尽量分散，避免在同一时间内集体失效。\n存储空值——应对缓存穿透  缓存穿透 ，当客户端请求一个数据库中没有的值得时候，缓存中自然也不会有，那就穿过缓存直接来到数据库进行查询，如果这样的请求多了的话对数据库也不利。\n解决方法是对查询不存在的结果也在缓存中存储空值来解决，这个由MyBatis实现，下次再来请求这个不存在的值得时候就可以拦截在缓存中了。\n如果遇到那种黑客攻击，生成了一堆随机的，不存在的值来穿透，来打到我们的数据库怎么办？那就要用大名鼎鼎的布隆过滤器（bloom filter）了，这里不展开。\n使用互斥锁——应对缓存击穿  缓存击穿 ，这个跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是一个热点的key失效，经常有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。这种现象就叫做缓存击穿。\n解决方案是互斥锁，当这个热点key失效时先加把互斥锁，拿到锁的线程去数据库中查找，其它线程只能等到重试，等load db完成后再写到缓存中，拿到锁的线程才释放锁，这时其他线程就可以去缓存中取了，这样就减少了数据库的压力。当然，用了锁就会影响系统一定的性能。\n关联缓存 当遇到不同namespace之间的数据有关联，也就是在清除一个namespace时，也需要清除另一个与之相关联的避免读到脏数据，这个时候我们可以使用关联缓存。\n开启方法：在对应的mapper下加上以下标签：\n\u0026lt;cache-ref namespace=\u0026#34;xxxxxxx\u0026#34;/\u0026gt; 设置之后本mapper的缓存会放到cache-ref制定的namespace下，也就是不再自己一个namespace，共用了指向的namespace，那到时清除的时候就会一块清除。\n参考链接 MyBatis整合Redis实现二级缓存\n聊聊MyBatis缓存机制\n【编程不良人】适合后端编程人员的Redis实战教程、redis应用场景、分布式缓存、Session管理、面试相关等已完结!\n","date":"2021-08-25T16:07:15+08:00","image":"https://ccqstark.github.io/p/redis_mybatis_cache/cover_hu98723c96db4cad61d3193fddfb3126c4_90918_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/redis_mybatis_cache/","title":"Redis分布式缓存实现"},{"content":"前言 最近在看周志明老师的经典《深入理解Java虚拟机》，第1章最后是一个自己编译JDK的实战，想到羊哥之前也出过这样一期视频，觉得做一做也蛮有成就感的，还可以加深下对Java的理解，所以边做边写下此篇博文。\n环境准备 系统环境 我的环境是macOS10.14.6(黑苹果)，问题相对Windows应该会少很多，推荐大家也是用Linux或者macOS来进行编译。\n \nXcode下载 一些C/C++相关的工具链一般是用Xcode带的，所以去官网下载就行。但是如果像我一样是黑苹果，系统不是最新的，官网的版本很可能不适配（目前最新Xcode 13要求macOS 11以上），所以只能翻到以前百度云里存的Xcode11.xip下载解压并安装就可以了。\nxip文件在解压时需要用系统自带的解压工具，不要用第三方的，不然解压出来不是一个.app文件。\n还有就是解压时可能会遇到系统验证问题，通过以下两步解决：\n 运行以下命令行  # 最后是xip文件的位置 xattr -d com.apple.quarantine Xcode_11.xip 在系统设置中修改系统的时间约为2018年7月，然后允许任何来源的软件安装。  所有软件环境基础 以下都是编译中需要用到的软件环境，确保都已经安装\n# 有一个已经可用的jdk，版本至少是要编译的版本-1 java -version # 输出 openjdk version \u0026#34;11.0.9\u0026#34; 2020-10-20 OpenJDK Runtime Environment (build 11.0.9+11) OpenJDK 64-Bit Server VM (build 11.0.9+11, mixed mode) # C的编译器 clang --version # 输出 Apple clang version 11.0.0 (clang-1100.0.33.8) Target: x86_64-apple-darwin18.7.0 Thread model: posix InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin # C++的编译器 clang++ --version # 输出 Apple clang version 11.0.0 (clang-1100.0.33.8) Target: x86_64-apple-darwin18.7.0 Thread model: posix InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin # 自动配置工具autoconf # 下载方式：brew install autoconf autoconf --version # 输出 autoconf (GNU Autoconf) 2.69 # 编译构建工具 make --version # 输出 GNU Make 3.81 # 渲染库freetype freetype-config --ftversion # 输出 2.10.4 源码下载 这次要编译的目标版本是jdk11，所以下载jdk11的源码\n方式一：通过Mercurial JDK是通过这个叫Mercurial的版本管理工具来进行代码管理的，这个和git是一类工具，只不过过于小众。而且这种方式慢，不推荐。\n 安装Mercurial  brew install mercurial   去网址hg.openjdk.java.net上复制地址\n https://cdn.jsdelivr.net/gh/ccqstark/image-bed@master/images/20210727020008.png \n  使用命令clone源码包\n  hg clone https://hg.openjdk.java.net/jdk/jdk11/ 方式二：官网下载压缩包 这种方式速度快，推荐这种方式\n前往地址：\nJava Platform, Standard Edition 11 Reference Implementations\n点击下载zip压缩包即可\n \n新建一个专门的文件夹存放源码包，解压后就可以看到目录结构\n \nsrc就是源码部分，看到里面基本都是C和C++的代码，说明Java就是用C和C++写的。\n自动配置工作 这一步进行编译前的自动编译工作\n# 首先cd进源码目录，也就是上图的openjdk11 cd openjdk11 # 运行脚本 sh configure 这个过程较快，最后会输出一些概览信息。\n正式编译工作 第一次编译直接进行全量编译，执行：\nmake all 这个过程比较久，耐心等待，会生成可执行文件，JDK成品镜像等很多东西\n过程中的警告可以忽略，只要不出现错误导致整个过程停止即可\n可以看到这个过程中我的mac的活动监视器，CPU快要炸了\n \n直到控制台最后几行输出一下信息就证明成功了\nCreating support/demos/image/jfc/SampleTree/SampleTree.jar Creating support/demos/image/jfc/TableExample/TableExample.jar Creating support/demos/image/jfc/TransparentRuler/TransparentRuler.jar Creating jdk image Finished building target \u0026#39;all\u0026#39; in configuration \u0026#39;macosx-x86_64-normal-server-release\u0026#39; 成品验收 完成上一步后就可以发现目录下多了一个build目录，进入build/macosx-x86_64-normal-server-release/目录可以看到如下文件\n \n命令行验证下\n# 进入编译后的jdk的bin目录 cd build/macosx-x86_64-normal-server-release/jdk/bin # 执行java命令查看版本 ./java -version # 输出 openjdk version \u0026#34;11-internal\u0026#34; 2018-09-25 OpenJDK Runtime Environment (build 11-internal+0-adhoc.ccqstark.openjdk11) OpenJDK 64-Bit Server VM (build 11-internal+0-adhoc.ccqstark.openjdk11, mixed mode) 最终的JDK成品就在images/jdk目录下，这个就和我们平时在官网上下载的JDK基本是一样的\n \nIDEA中使用新JDK 新建一个Hello World项目\n添加自己编译的JDK的路径\n \n切换项目所用的JDK为刚刚新增的\n \n运行之后可以看到我们使用的JDK已经换成自己编译得到的了\n \n定制JDK 当我们需要自己定制一套属于自己的JDK的时候就需要我们去修改源码中的一些实现，修改之后要生效的话必须重新编译一次，这次的编译就可以用增量编译了。\n修改Sourcepath 删除原来全部路径\n \n重新添加我们一开始下载的压缩包中解压出来的src目录下的源码，并让IDEA重新索引\n修改源码 我们Ctrl加鼠标点击进入println源码，并做点修改意思意思\n \n增量编译 再次cd到解压出来的大目录下，执行\nmake images 进行增量编译，速度会比全量编译快\n再次运行代码发现之前对源码的修改已经生效\n \n参考资料  《深入理解Java虚拟机》 周志明 JDK都没手动编译过，敢说自己是Java程序员吗？实战编译Java源码（JDK源码,JVM）视频教程 CodeSheep  ","date":"2021-07-27T03:44:28+08:00","image":"https://ccqstark.github.io/p/compile_jdk/cover_hucf54841c06fdf75c53fe986b35c09dc3_55691_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/compile_jdk/","title":"[实战]自己动手编译JDK实录"},{"content":"题目 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。\n注意：答案中不可以包含重复的三元组。\n示例 1： 输入：nums = [-1,0,1,2,-1,-4] 输出：[[-1,-1,2],[-1,0,1]] 示例 2： 输入：nums = [] 输出：[] 示例 3： 输入：nums = [0] 输出：[] 分析 这里本可以借鉴两数之和的哈希法，通过判断0-(a+b)是否存在数组中来解答，但是由于题目要求的不能包含重复的三元组用这个方法实在很难去处理，所以这里就不推荐用哈希法了。\n这里推荐排序+双指针法 来解决。先对数组进行排序，然后用一个指针i对所有元素进行遍历，每一次遍历我们都有两个指针叫left和right，left一开始指向i+1，right一开始指向数组最后一位，然后开始判断此时三个指针之和sum是否为0。\n如果不是又分为两种情况，sum大于0，则让right左移一位，让sum减小；如果sum小于0，则让left右移一位，让sum增加。如果是找到了的话，就两边同时收缩。整个过程就是通过调整left和right指针来毕竟让sum逼近0，再注意一下去除重复情况即可。\n动画如下：\n \n代码 // 排序+双指针法（较优） public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; threeSum(int[] nums) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); // 排序  Arrays.sort(nums); for (int i = 0; i \u0026lt; nums.length; i++) { // 首位大于0的直接返回  if (nums[i] \u0026gt; 0) { return result; } // i的去重  if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } int left = i + 1; int right = nums.length - 1; // 循环  while (right \u0026gt; left) { // 计算此时的三数之和  int sum = nums[i] + nums[left] + nums[right]; // 三种情况  if (sum \u0026gt; 0) { right--; } else if (sum \u0026lt; 0) { left++; } else { // 找到一种答案添加到结果集  result.add(Arrays.asList(nums[i], nums[left], nums[right])); // 去重  while (right \u0026gt; left \u0026amp;\u0026amp; nums[right] == nums[right - 1]) right--; while (right \u0026gt; left \u0026amp;\u0026amp; nums[left] == nums[left + 1]) left++; // 找到一个答案后两边指针都收缩  right--; left++; } } } return result; } 时间复杂度：O(n^2)\n延伸 这里顺便把四数之和也说了，思路也是差不多的，多了一个数其实就多加一层循环再去使用left和right算sum罢了，时间复杂度就变成O(n^3)，如果有五数之和、六数之和也是一样的道理。\n直接上代码：\npublic List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; fourSum(int[] nums, int target) { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); Arrays.sort(nums); // 四数之和实际上是在三数之和上多加了一层循环  for (int i = 0; i \u0026lt; nums.length; i++) { if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i - 1]) { continue; } for (int j = i + 1; j \u0026lt; nums.length; j++) { if (j \u0026gt; i + 1 \u0026amp;\u0026amp; nums[j] == nums[j - 1]) { continue; } int left = j + 1; int right = nums.length - 1; while (left \u0026lt; right) { int sum = nums[i] + nums[j] + nums[left] + nums[right]; if (sum \u0026gt; target) { right--; } else if (sum \u0026lt; target) { left ++; } else { result.add(Arrays.asList(nums[i], nums[j], nums[left], nums[right])); // 去重  while (left \u0026lt; right \u0026amp;\u0026amp; nums[right] == nums[right - 1]) right--; while (left \u0026lt; right \u0026amp;\u0026amp; nums[left + 1] == nums[left]) left++; // 找到后左右指针各收缩一下  right--; left++; } } } } return result; } ","date":"2021-07-23T16:55:26+08:00","image":"https://ccqstark.github.io/p/three_sum/cover_huf957eb7cc0803733802fcc4099cfd7cb_35766_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/three_sum/","title":"[leetcode]15.三数之和"},{"content":"注解 概述 不是程序本身，可以对程序作出解释，可以被其他程序（如编译器等）读取\n可以附加在package、class、method、field等上面，可以通过反射机制编程实现对这些元数据对访问\n内置注解 @Override\n只用修饰方法，表示一个方法声明打算重写超类中的另一个方法声明\n@Deprecated\n可以用于修饰方法，属性，类，表示不鼓励程序猿使用，但是还是可以使用的，只是使用它可能有危险或者存在更好的选择。\n@SuppressWarnings\n用来抑制编译时的警告信息，需要添加一个参数\n \n元注解 @Target\n用于描述注解的使用范围\n@Target(value = {ElementType.METHOD, ElementType.TYPE}) @Retention\n表示需要在什么级别保存该注释信息（SOURCE \u0026gt; CLASS \u0026gt; RUNTIME）\n@Retention(value = RetentionPolicy.RUNTIME) @Document 说明该注解将被包含在javadoc中\n@Inherited\n说明子类可以继承父类中的该注解\n自定义注解 使用@interface自定义注解时,自动继承了java. lang.annotation Annotation接口\n@interface用来声明一个注解，格式: public @interface 注解名 { 定义内容 }\n其中的每一个方法实际上是声明了一个配置参数，方法的名称就是参数的名称 返回值类型就是参数的类型(返回值只能是基本类型, Class, String, enum)\n可以通过 default来声明参数的默认值\n如果只有一个参数成员,一般参数名为 value 注解元素必须要有值，我们定义注解元素时，经常使用空字符串和0作为默认值\n@Target({ElementType.TYPE, ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) @interface MyAnnotation2 { // 方法名为参数名  String name() default \u0026#34;\u0026#34;; int age() default 0; int id() default -1; // 如果默认值为-1, 代表不存在  String[] schools() default {\u0026#34;西部开源\u0026#34;, \u0026#34;东部闭源\u0026#34;}; } 反射 概述 Java不是动态语言，但是可以通过反射机制获得类似动态语言的特性。\nReflection（反射）允许程序在执行期间借助 Reflection API 取得任何类的内部信息，并能直接操作任意对象的内部属性及方法。\n加载完类之后，在堆内存的方法区中就产生了一个Class类型的对象（一个类只有一个Class对象），这个对象就包含了完整的类的结构信息。我们可以通过这个对象看到类的结构。\n \nJava反射机制提供的功能  在运行时判断任意一个对象所属的类 在运行时构造任意一个类的对象 在运行时判断一个类所具有的成员变量和方法 在运行时获取泛型信息 在运行时调用任意一个对象的成员变量和方法 在运行时处理注解 生成动态代理 \u0026hellip;  优点：可以实现动态创建对象和编译，体现出很大的灵活性\n缺点：对性能有影响。使用反射是让JVM执行我们命令的操作，这类操作总是慢于直接执行相同的操作。\nClass类  Class本身也是一个类 Class对象只能由系统创建对象 一个加载的类在JVM中只会有一个Class实例 一个Class对象对应的是一个加载到JVM的一个.class文件 每个类的实例都会记得自己是由哪个Class实例所生成的 通过Class可以完整的得到一个类中所有被加载的结构 Class类是Reflection的根源，针对任何想动态加载、运行的类，唯有先获得相应的Class对象   \n得到Class的几种办法 // 方式一：通过对象获得 Class c1 = person.getClass(); System.out.println(c1.hashCode()); // 方式二：通过forName获得 Class c2 = Class.forName(\u0026#34;com.ccqstark.reflection.Person\u0026#34;); System.out.println(c2.hashCode()); // 方法三：通过类名.class获得 Class c3 = Student.class; System.out.println(c3.hashCode()); // 方法四：基本内置类型的包装类都有一个Type属性 Class c4 = Integer.TYPE; System.out.println(c4); // 获得父类类型 Class c5 = c1.getSuperclass(); System.out.println(c5); 有Class对象的类型  class 外部类，成员（成员内部类，静态内部类），局部内部类，匿名内部类 interface 接口 数组 enum 枚举 annotation 注解 primitive type 基本数据类型 void  类加载器的作用 类加载的作用：将class文件字节码内容加载到内存中，并将这些静态数据转换成方法区的运行时数据结构，然后在堆中生成一个代表这个类的java.lang.Class对象，作为方法区中类数据的访问入口。\n类缓存：标准的JavaSE类加载器可以按要求查找类，但一旦某个类被加载到类加载器中，它将维持加载（缓存）一段时间。不过JVM垃圾回收机制可以回收这些Class对象。\n \n三种类加载器：\n 引导类加载器：用C++编写的，是JVM自带的类加载器，负责Java平台核心库(rt.jar)，用来转载核心类库。该加载器无法直接获取 扩展类加载器：负责jre/lib/ext目录下的jar包或者-D java.ext.dirs指定目录下的jar包装入工作库 系统类加载器：负责 java -classpath 或 -D java.class.path 所指目录下的类与jar包装入工作，是常用的加载器   \n示例代码：\n// 获取系统的类加载器 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader); // 获取系统的类加载器的父类加载器--\u0026gt;扩展类加载器 ClassLoader parent = systemClassLoader.getParent(); System.out.println(parent); // 获取扩展类加载器的父类加载器--\u0026gt;根加载器(c/c++) ClassLoader parent1 = parent.getParent(); System.out.println(parent1); // 测试当前的类是哪个加载器加载的 ClassLoader classLoader = Class.forName(\u0026#34;com.ccqstark.reflection.Test07\u0026#34;).getClassLoader(); System.out.println(classLoader); // 测试JDK内置的类是谁加载的 classLoader = Class.forName(\u0026#34;java.lang.Object\u0026#34;).getClassLoader(); System.out.println(classLoader); // 获得系统类加载器可以加载的路径 System.out.println(System.getProperty(\u0026#34;java.class.path\u0026#34;)); 获得运行时类的完整结构 上代码：\nClass c1 = Class.forName(\u0026#34;com.ccqstark.reflection.User\u0026#34;); // 获得类的名字 System.out.println(c1.getName()); System.out.println(c1.getSimpleName()); // 获得类的属性 System.out.println(\u0026#34;========================\u0026#34;); Field[] fields = c1.getFields(); // 只能找到public属性  fields = c1.getDeclaredFields(); // 找到全部的属性 for (Field field : fields) { System.out.println(field); } // 获得指定属性的值 Field name = c1.getDeclaredField(\u0026#34;name\u0026#34;); System.out.println(name); // 获得方法 System.out.println(\u0026#34;=========================\u0026#34;); Method[] methods = c1.getMethods(); // 获得本类及其父类的全部public方法 for (Method method : methods) { System.out.println(\u0026#34;父类以及公有的：\u0026#34; + method); } methods = c1.getDeclaredMethods(); // 获得本类的所有方法 for (Method method : methods) { System.out.println(\u0026#34;本类所有的方法：\u0026#34; + method); } // 获得指定的方法 Method getName = c1.getMethod(\u0026#34;getName\u0026#34;, null); Method setName = c1.getMethod(\u0026#34;setName\u0026#34;, String.class); System.out.println(getName); System.out.println(setName); // 获得指定的构造器 System.out.println(\u0026#34;==========================\u0026#34;); Constructor[] constructors = c1.getConstructors(); // 获得公有的 for (Constructor constructor : constructors) { System.out.println(constructor); } constructors = c1.getDeclaredConstructors(); // 获取全部 for (Constructor constructor : constructors) { System.out.println(\u0026#34;#\u0026#34; + constructor); } // 获得指定的构造器 Constructor declaredConstructor = c1.getDeclaredConstructor(String.class, int.class, int.class); System.out.println(\u0026#34;指定：\u0026#34; + declaredConstructor); 通过反射动态创建对象 创建类的对象：调用Class对象的newInstance()方法：\n 类必须有一个无参构造器 类的构造器的访问权限需要足够  也可以通过调用有参构造器：\n 通过Class类的getDeclaredConstructor(Class ... parameterTypes)取得本类的指定参数类型的构造器 向构造器的形参中传递一个对象数组进去，里面包含了构造器中所需的各个参数 通过Constructor实例化对象（newInstance()方法）  示例代码：\n// 获得Class对象 Class c1 = Class.forName(\u0026#34;com.ccqstark.reflection.User\u0026#34;); // 构造一个对象 User user = (User) c1.newInstance(); System.out.println(user); // 通过构造器创建对象 Constructor constructor = c1.getConstructor(String.class, int.class, int.class); User user2 = (User) constructor.newInstance(\u0026#34;ccq\u0026#34;, 1, 2); System.out.println(user2); 通过反射调用指定的方法 通过反射，调用类中的方法，通过Method类完成\n 通过Class类的getMethod(String name, Class...parameterTypes)方法取得一个Method对象，并设置此方法操作时所需的参类型。 之后使用Object invoke(Object obj, Object[] args)进行调用，并向方法中传递要调用此方法的obj对象以及方法的参数   \n示例代码：\n// 通过反射调用普通方法 User user3 = (User) c1.newInstance(); // 通过反射获取一个方法 Method setName = c1.getDeclaredMethod(\u0026#34;setName\u0026#34;, String.class); // invoke(对象, \u0026#34;方法的参数\u0026#34;) setName.invoke(user3, \u0026#34;ccq\u0026#34;); System.out.println(user3.getName()); Object invoke(Object obj, Object\u0026hellip; args)\n Object对应原方法的返回值，若原方法无返回值，此时返回null 若原方法若为静态方法，此时形参Object obj可为null 若原方法的形参列表为空，则Object[] args为null 若原方法声明为private，则需要在调用此invoke()方法前，显示调用方法对象的setAccessible(true)方法，将可访问private的方法。  setAccessible\n Method和 Field、 Constructor 对象都有 setaccessible()方法 setAccessible作用是启动和禁用访问安全检查的开关。 参数值为true则指示反射的对象在使用时应该取消Java语言访问检查。  提高反射的效率。如果代码中必须用反射，而该句代码需要频繁的被调用，最好设置为true 使得原本无法访问的私有成员也可以访问   参数值为false则指示反射的对象应该实施Java语言访问检查  反射操作泛型 public void test01(Map\u0026lt;String, User\u0026gt; map, List\u0026lt;User\u0026gt; list) { System.out.println(\u0026#34;test01\u0026#34;); } public Map\u0026lt;String, User\u0026gt; test02() { System.out.println(\u0026#34;test02\u0026#34;); return null; } public static void main(String[] args) throws NoSuchMethodException { Method method = Test11.class.getMethod(\u0026#34;test01\u0026#34;, Map.class, List.class); // 获得范型参数类型  Type[] genericParameterTypes = method.getGenericParameterTypes(); for (Type genericParameterType : genericParameterTypes) { System.out.println(genericParameterType); // 如果是参数化类型  if (genericParameterType instanceof ParameterizedType) { // 强转为参数化类型，并且获得真实类型  Type[] actualTypeArguments = ((ParameterizedType) genericParameterType).getActualTypeArguments(); for (Type actualTypeArgument : actualTypeArguments) { System.out.println(actualTypeArgument); } } } method = Test11.class.getMethod(\u0026#34;test02\u0026#34;, null); // 获得泛型返回类型  Type genericReturnType = method.getGenericReturnType(); if (genericReturnType instanceof ParameterizedType) { Type[] actualTypeArguments = ((ParameterizedType) genericReturnType).getActualTypeArguments(); for (Type actualTypeArgument : actualTypeArguments) { System.out.println(actualTypeArgument); } } } 通过反射操作注解 通过反射操作注解来实现一些功能就是很多框架的原理了，像Spring、MyBatis中的注解底层就是通过反射来获得一些信息并进行一些操作来达成某些功能的。\n例如下面的实现ORM的示例，通过自定义注解让用户使用，让用户定义类名对应的表名，属性名对应的字段名，然后通过反射获取这些信息，就可以生成对应的SQL了。\n// 反射操作注解 public class Test12 { public static void main(String[] args) throws ClassNotFoundException, NoSuchFieldException { Class c1 = Class.forName(\u0026#34;com.ccqstark.reflection.Student2\u0026#34;); // 通过反射获得注解  Annotation[] annotations = c1.getAnnotations(); for (Annotation annotation : annotations) { System.out.println(annotation); } // 获得注解的value值，这里通过反射获得了映射表名的注解的值，也就是获得了表名  TableCcq tableCcq = (TableCcq) c1.getAnnotation(TableCcq.class); String value = tableCcq.value(); System.out.println(value); // 通过反射操作field的注解，获得了属性映射的表字段的信息，如字段名、类型、长度  Field f = c1.getDeclaredField(\u0026#34;name\u0026#34;); FieldCcq annotation = f.getAnnotation(FieldCcq.class); System.out.println(annotation.columnName()); System.out.println(annotation.type()); System.out.println(annotation.length()); } } @TableCcq(\u0026#34;db_ccq\u0026#34;) class Student2 { @FieldCcq(columnName = \u0026#34;db_id\u0026#34;, type = \u0026#34;int\u0026#34;, length = 10) private int id; @FieldCcq(columnName = \u0026#34;db_age\u0026#34;, type = \u0026#34;int\u0026#34;, length = 10) private int age; @FieldCcq(columnName = \u0026#34;db_name\u0026#34;, type = \u0026#34;varchar\u0026#34;, length = 3) private String name; } // 类名-\u0026gt;表名 的注解 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @interface TableCcq { String value(); } // 属性-\u0026gt;字段 的注解 @Target(ElementType.FIELD) @Retention(RetentionPolicy.RUNTIME) @interface FieldCcq { String columnName(); String type(); int length(); } 总结 注解是给程序做的注释、标记，让程序可以读取一些额外信息并做出一些行为\n反射让Java程序在运行时可以获取到类和对象的信息（类名、属性、方法\u0026hellip;）\n注解和反射与Java很多流行框架息息相关，两者的搭配使用是它们的底层原理，所以非常重要。\n参考自：\n【狂神说Java】注解和反射\n","date":"2021-07-22T23:43:42+08:00","image":"https://ccqstark.github.io/p/java_annotaion_reflection/cover_hud3682ca23d8f51585d79a941911fa5ce_24013_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/java_annotaion_reflection/","title":"Java注解和反射"},{"content":"RESTful 与 RPC 的区别 在微服务定义中提道，每个小服务运行在自己的进程中，并以轻量级的机制进行通信。这里并没有明确给出具体的通信方式，只是要求以轻量级的机制进行通信，虽然作者推荐使用 RESTful 作为首选方案，但微服务间通信本身还有另一个轻量级的选择：以 Dubbo 为代表的 RPC通信方式。\nRPC 是远程过程调用（Remote Procedure Call）的缩写形式，RPC 与 RESTful 最大的不同是，RPC 采用客户端（Client) - 服务端（Server） 的架构方式实现跨进程通信，实现的通信协议也没有统一的标准，具体实现依托于研发厂商的设计。\n \n目前开源市场上 RPC 框架有很多，例如 GoogleRPC、Alibaba Dubbo、Facebook Thrift，每一种产品都有自己的设计与实现方案。\n那 RESTful 与 RPC 有什么区别呢？通过一个表格进行说明：\n \nApache Dubbo Dubbo 是阿里巴巴开源的高性能、轻量级的开源 Java 框架，目前被 Apache收录，官网是： http://dubbo.apache.org/\n \nDubbo 是典型的 RPC 框架的代表，通过客户端/服务端结构实现跨进程应用的高效二进制通信。\nApache Dubbo 提供了六大核心能力：\n面向接口代理的高性能 RPC 调用；\n智能容错和负载均衡；\n服务自动注册和发现；\n高度可扩展能力；\n运行期流量调度；\n可视化的服务治理与运维。\n下图引用 Dubbo 的官方架构图，讲解 ApacheDubbo 的组成。\n \nDubbo 架构中，包含 5 种角色。\n Provider：RPC服务提供者，Provider 是消息的最终处理者。 Container：容器，用于启动、停止 Provider 服务。这里的容器并非 Tomcat、Jetty 等 Web 容器，Dubbo 也并不强制要求 Provider 必须具备 Web 能力。Dubbo 的容器是指对象容器，例如 Dubbo 内置的 SpringContainer 容器就提供了利用 Spring IOC 容器管理 Provider 对象的职能。 Consumer：消费者，调用的发起者。Consumer 需要在客户端持有 Provider 的通信接口才能完成通信过程。 Registry：注册中心，Dubbo 架构中注册中心与微服务架构中的注册中心职责类似，提供了 Dubbo Provider 的注册与发现职能，Consumer通过 Registry 可以获取Provider 可用的节点实例的 IP、端口等，并产生直接通信。需要注意的是，前面我们讲解的 Alibaba Nacos 除了可以作为微服务架构中的注册中心外，同样对自家的 Dubbo 提供了 RPC 调用注册发现的职责，这是其他 Spring Cloud 注册中心所不具备的功能。 Monitor：监控器，监控器提供了Dubbo的监控职责。在 Dubbo 产生通信时，Monitor 进行收集、统计，并通过可视化 UI 界面帮助运维人员了解系统进程间的通信状况。Dubbo Monitor 主流产品有 Dubbo Admin、Dubbo Ops 等。  项目整合 服务提供者Provider  引入依赖  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.dubbo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dubbo-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 相比标准微服务，需要额外依赖 dubbo-spring-boot-starter 与 spring-boot-starter-actuator。其中 dubbo-spring-boot-starter 是 Dubbo 与 Spring Boot 整合最关键的组件，为 Spring Boot 提供了 Dubbo 的默认支持。而 spring-boot-starter-actuator则为微服务提供了监控指标接口，便于监控系统从应用收集各项运行指标。\n 配置文件  server:port:8000#服务端口spring:application:name:warehouse-service#微服务idcloud:nacos:#nacos注册地址discovery:server-addr:192.168.31.101:8848username:nacospassword:nacosdubbo:#dubbo与nacos的通信配置application:name:warehouse-dubbo#provider在Nacos中的应用idregistry:#Provider与Nacos通信地址，与spring.cloud.nacos地址一致address:nacos://192.168.31.101:8848protocol:name:dubbo#通信协议名port:20880#配置通信端口，默认为20880scan:base-packages:com.lagou.warehouseservice.dubboDubbo 需要依托 Container（容器）对外暴露服务，而这个容器配置与微服务配置是分开的，需要额外占用一个网络端口20880提供服务。\n \ndubbo.scan.base-packages 代表在 Dubbo 容器启动时自动扫描 com.lagou.warehouseservice.dubbo 包下的接口与实现类，并将这些接口信息在Nacos 进行登记，因此 Dubbo 对外暴露的接口必须放在该包下。\n 开发服务  实体类dto这里不做示例了\n下面是com.lagou.warehouseservice.dubbo包下创建的服务接口，包名要与 dubbo.scan.base-packages 保持一致\n//Provider接口 public interface WarehouseService { //查询库存  public Stock getStock(Long skuId); } 在 com.lagou.warehouseservice.dubbo.impl包下创建实现类\n@DubboService public class WarehouseServiceImpl implements WarehouseService { public Stock getStock(Long skuId){ /* code */ return stock; } } 需要额外增加 @DubboService注解。@DubboService 是 Provider 注解，说明该类所有方法都是服务提供者，加入该注解会自动将类与方法的信息在 Nacos中注册为 Provider。\n服务消费者Consumer  引入依赖和服务提供者一样 配置文件  spring:application:name:order-servicecloud:nacos:discovery:server-addr:192.168.31.101:8848username:nacospassword:nacosserver:port:9000dubbo:application:name:order-service-dubboregistry:address:nacos://192.168.31.101:8848 将处于服务提供方的服务接口和相关实体类复制到调用方   \n接口就行，接口的实现类不用。相当于声明了通信接口，注意要求包名、类名及代码保持完全一致。上面是在与原项目同级目录新建了一个和服务提供方一样的包路径。\n 消费者调用服务  @RestController public class OrderController { @DubboReference private WarehouseService warehouseService; @GetMapping(\u0026#34;/create_order\u0026#34;) public Map createOrder(Long skuId , Long salesQuantity){ // 查询商品库存，像调用本地方法一样完成业务逻辑。  Stock stock = warehouseService.getStock(skuId); // code\t return result; } } 关键点是 @DubboReference 注解。该注解用在 Consumer 端，Spring 会自动生成远程服务的接口的代理实现类，并隐藏远程通信细节。\n \n微服务启动后，在nacos的服务列表界面可以看到微服务和Dubbo的服务，表示注册成功了。\n \n小坑\n引入了spring-boot-starter-actuator 会与ShardingSphere检查数据库连接时产生冲突，抛出错误\norg.springframework.dao.InvalidDataAccessApiUsageException: ConnectionCallback; isValid; nested exception is java.sql.SQLFeatureNotSupportedException: isValid 解决办法：\n配置文件加上\nmanagement:health:db:enabled:false","date":"2021-07-22T02:26:29+08:00","image":"https://ccqstark.github.io/p/dubbo_nacos_rpc/cover_hu148189a32dd9592e6629114cd574d267_71263_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/dubbo_nacos_rpc/","title":"Dubbo+Nacos实现RPC"},{"content":"理论知识  \nRocketMQ 天然采用集群模式，常见的 RocketMQ 集群有三种形式：多 Master 模式、多 Master 多 Slave- 异步复制模式、多 Master 多 Slave- 同步双写模式，这三种模式各自的优缺点如下。\n 多 Master 模式是配置最简单的模式，同时也是使用最多的形式。优点是单个 Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复情况下，由于 RAID10 磁盘非常可靠，同步刷盘消息也不会丢失，性能也是最高的；缺点是单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。 多 Master 多 Slave 异步复制模式。每个 Master 配置一个 Slave，有多对 Master-Slave，HA 采用异步复制方式，主备有短暂消息毫秒级延迟，即使磁盘损坏只会丢失少量消息，且消息实时性不会受影响。同时 Master 宕机后，消费者仍然可以从 Slave 消费，而且此过程对应用透明，不需要人工干预，性能同多 Master 模式几乎一样；缺点是 Master 宕机，磁盘损坏情况下会丢失少量消息。 多 Master 多 Slave 同步双写模式，HA 采用同步双写方式，即只有主备都写成功，才向应用返回成功，该模式数据与服务都无单点故障，Master 宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；缺点是性能比异步复制模式低 10% 左右，发送单个消息的执行时间会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。   \n部署 部署 NameServer 集群 直接wget下载\nwget https://mirror-hk.koddos.net/apache/rocketmq/4.8.0/rocketmq-all-4.8.0-bin-release.zip unzip 解压后，我们进入bin目录修改runserver.sh文件的虚拟机内存配置（因为默认的太大了吃不消），根据自己服务器实际情况更改\nJAVA_OPT=\u0026#34;${JAVA_OPT}-server -Xms128m -Xmx128m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\u0026#34; 后台启动一下NameServer服务\nnohup sh mqnamesrv \u0026amp; NameServer 将占用 9876 端口提供服务，不要忘记在防火墙设置放行，另一台服务器也同样方式操作一波。\n部署 Broker 集群 同样改小JVM内存，这次改bin下的runbroker.sh文件\nJAVA_OPT=\u0026#34;${JAVA_OPT}-server -Xms128m -Xmx128m -Xmn128m\u0026#34; 然后我们要配置一下Broker，在 conf 目录下，RocketMQ 已经给我们贴心的准备好三组集群配置模板：\n 2m-2s-async 代表双主双从异步复制模式； 2m-2s-sync 代表双主双从同步双写模式； 2m-noslave 代表双主模式。  这里配置的是双主模式 ，所以去2m-noslave目录下，发现有broker-a.properties和broker-b.properties两个配置文件。\n第一台主机修改broker-a.properties作为broker-a，第二台修改broker-b.properties作为broker-b，都添加上NameServer集群的地址并配上自己的公网IP：\n#集群名称，同一个集群下的 broker 要求统一 brokerClusterName=DefaultCluster #broker 名称 brokerName=broker-a #broker 公网IP brokerIP1=49.234.82.226 #brokerId=0 代表主节点，大于零代表从节点 brokerId=0 #删除日志文件时间点，默认凌晨 4 点 deleteWhen=04 #日志文件保留时间，默认 48 小时 fileReservedTime=48 #Broker 的角色 #- ASYNC_MASTER 异步复制Master #- SYNC_MASTER 同步双写Master brokerRole=ASYNC_MASTER #刷盘方式 #- ASYNC_FLUSH 异步刷盘，性能好宕机会丢数 #- SYNC_FLUSH 同步刷盘，性能较差不会丢数 flushDiskType=ASYNC_FLUSH #末尾追加，NameServer 节点列表，使用分号分割 namesrvAddr=192.168.31.200:9876;192.168.31.201:9876 broker配置文件里一定要配个公网IP，否则默认是用内网的！\nbroker-b就只有brokerName和brokerIP1不同\n之后就可以运行了，到bin目录下\nnohup sh mqbroker -c ../conf/2m-noslave/broker-a.properties \u0026amp; broker-a就用broker-a.properties启动，broker-b就用broker-b.properties启动\nBroker 将占用 10911 端口提供服务，记得设置防火墙放行\n测试部署结果  修改bin下tools.sh的Djava.ext.dirs，添加jvm的ext绝对路径：  JAVA_OPT=\u0026#34;${JAVA_OPT}-Djava.ext.dirs=${BASE_DIR}/lib:${JAVA_HOME}/jre/lib/ext:${JAVA_HOME}/lib/ext:/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.282.b08-1.el7_9.x86_64/jre/lib/ext\u0026#34; 如上，在最后用冒号隔开加上自己的jre/lib/ext 绝对路径\n 使用 mqadmin 命令查看集群状态  sh mqadmin clusterList -n [NameServer服务器的IP]:9876 可以看到broker-a和broker-b的地址和端口\n \n 使用 tools.sh工具通过生成演示数据来测试 MQ 实际的运行情况  测试生产者发送消息\nexport NAMESRV_ADDR=[NameServer服务器的IP]:9876 sh tools.sh org.apache.rocketmq.example.quickstart.Producer 集群生效后，可以看到broker-a和broker-交替出现\n \n测试消费者接收消息\n# 设置环境变量 export NAMESRV_ADDR=[NameServer服务器的IP]:9876 # 运行测试程序 sh tools.sh org.apache.rocketmq.example.quickstart.Consumer  \n部署可视化界面 RocketMQ-Console 使用docker部署\n# 拉取镜像 docker pull apacherocketmq/rocketmq-console:2.0.0 # 运行容器 docker run -e \u0026#34;JAVA_OPTS=-Drocketmq.namesrv.addr=[NameServer服务器的IP]:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\u0026#34; -p 8080:8080 -t apacherocketmq/rocketmq-console:2.0.0 打开网址界面如下\n \n代码实践 生产者 Producer 发送消息 引入依赖\n\u0026lt;!-- RocketMQ客户端，版本与Broker保持一致 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 创建一个controller测试发送\n@RestController public class ProviderController { Logger logger = LoggerFactory.getLogger(ProviderController.class); @GetMapping(value = \u0026#34;/send_s1_tax\u0026#34;) public String send1() throws MQClientException { //创建DefaultMQProducer消息生产者对象  DefaultMQProducer producer = new DefaultMQProducer(\u0026#34;producer-group\u0026#34;); //设置NameServer节点地址，多个节点间用分号分割  producer.setNamesrvAddr(\u0026#34;192.168.31.200:9876;192.168.31.201:9876\u0026#34;); //与NameServer建立长连接  producer.start(); try { //发送一百条数据  for(int i = 0 ; i\u0026lt; 100 ; i++) { //数据正文  String data = \u0026#34;{\\\u0026#34;title\\\u0026#34;:\\\u0026#34;X市2021年度第一季度税务汇总数据\\\u0026#34;}\u0026#34;; /*创建消息 Message消息三个参数 topic 代表消息主题，自定义为tax-data-topic说明是税务数据 tags 代表标志，用于消费者接收数据时进行数据筛选。2021S1代表2021年第一季度数据 body 代表消息内容 */ Message message = new Message(\u0026#34;tax-data-topic\u0026#34;, \u0026#34;2021S1\u0026#34;, data.getBytes()); //发送消息，获取发送结果  SendResult result = producer.send(message); //将发送结果对象打印在控制台  logger.info(\u0026#34;消息已发送：MsgId:\u0026#34; + result.getMsgId() + \u0026#34;，发送状态:\u0026#34; + result.getSendStatus()); } } catch (RemotingException e) { e.printStackTrace(); } catch (MQBrokerException e) { e.printStackTrace(); } catch (InterruptedException e) { e.printStackTrace(); } finally { producer.shutdown(); } return \u0026#34;success\u0026#34;; } } 启动应用调用接口后，可以在控制台看到\n2021-04-19 19:06:16.630 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEA71024E，发送状态:SEND_OK 2021-04-19 19:06:16.697 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEAB6024F，发送状态:SEND_OK 2021-04-19 19:06:16.777 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEAFA0250，发送状态:SEND_OK 2021-04-19 19:06:16.847 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEB490251，发送状态:SEND_OK 2021-04-19 19:06:16.953 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEB8F0252，发送状态:SEND_OK 2021-04-19 19:06:17.050 INFO 51083 --- [nio-8000-exec-3] c.c.r.controller.ProviderController : 消息已发送：MsgId:20010DA820039217106D5F092230313AC78B18B4AAC260CBEBF90253，发送状态:SEND_OK 消费者 Consumer 接收消息 引入同样依赖\n\u0026lt;!-- RocketMQ客户端，版本与Broker保持一致 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.rocketmq\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rocketmq-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 创建一个controller测试接收\n@SpringBootApplication public class RocketmqConsumerApplication { private static Logger logger = LoggerFactory.getLogger(RocketmqConsumerApplication.class); public static void main(String[] args) throws MQClientException { SpringApplication.run(RocketmqConsumerApplication.class, args); //创建消费者对象  DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\u0026#34;consumer-group\u0026#34;); //设置NameServer节点  consumer.setNamesrvAddr(\u0026#34;192.168.31.200:9876;192.168.31.201:9876\u0026#34;); /*订阅主题， consumer.subscribe包含两个参数： topic: 说明消费者从Broker订阅哪一个主题，这一项要与Provider保持一致。 subExpression: 子表达式用于筛选tags。 同一个主题下可以包含很多不同的tags，subExpression用于筛选符合条件的tags进行接收。 例如：设置为*，则代表接收所有tags数据。 例如：设置为2020S1，则Broker中只有tags=2020S1的消息会被接收，而2020S2就会被排除在外。 */ consumer.subscribe(\u0026#34;tax-data-topic\u0026#34;, \u0026#34;*\u0026#34;); //创建监听，当有新的消息监听程序会及时捕捉并加以处理。  consumer.registerMessageListener(new MessageListenerConcurrently() { public ConsumeConcurrentlyStatus consumeMessage( List\u0026lt;MessageExt\u0026gt; msgs, ConsumeConcurrentlyContext context) { //批量数据处理  for (MessageExt msg : msgs) { logger.info(\u0026#34;消费者消费数据:\u0026#34;+new String(msg.getBody())); } //返回数据已接收标识  return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); //启动消费者，与Broker建立长连接，开始监听。  consumer.start(); } } 当应用启动后，Provider 产生新消息的同时，Consumer 端就会立即消费掉，控制台产生输出。\n2021-04-19 13:01:57.636 INFO 51389 --- [MessageThread_2] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 2021-04-19 13:01:57.692 INFO 51389 --- [MessageThread_1] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 2021-04-19 13:01:57.719 INFO 51389 --- [essageThread_18] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 2021-04-19 13:01:57.728 INFO 51389 --- [essageThread_10] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 2021-04-19 13:01:57.738 INFO 51389 --- [MessageThread_6] c.c.c.RocketmqConsumerApplication : 消费者消费数据:{\u0026#34;title\u0026#34;:\u0026#34;X市2021年度第一季度税务汇总数据\u0026#34;} 在可视化界面也可以看到变化。\nSpring Cloud 生态中还提供了 Spring Cloud Stream 模块，允许程序员采用“声明式”的开发方式实现与 MQ 更轻松的接入。\n","date":"2021-07-22T02:03:53+08:00","image":"https://ccqstark.github.io/p/rocketmq_startup/cover_hu9145d0cb10e9c56d586699b94d669fc3_38014_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/rocketmq_startup/","title":"RocketMQ入门"},{"content":"依赖 \u0026lt;!-- sleuth --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-sleuth\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- zipkin --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-zipkin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.6.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这里踩了大坑，不要用阿里的镜像，用Maven官方的，阿里的有问题！！\n配置文件 spring:sleuth:sampler:#采样器probability:1.0#采样率，采样率是采集Trace的比率，默认0.1rate:10000#每秒数据采集量，最多n条/秒Tracezipkin:#设置zipkin服务端地址base-url:http://49.234.82.226:9411然后去服务端部署zipkin的可视化监控程序，参照官网：\nhttps://zipkin.io/pages/quickstart.html\n推荐使用docker\ndocker run -d -p 9411:9411 openzipkin/zipkin 使用 之后调用的链路就可以在下面链接看到了\nhttp://49.234.82.226:9411/zipkin\n需要刷新和筛选一下\n \n点进去可以看到具体信息\n \n","date":"2021-07-22T01:56:55+08:00","image":"https://ccqstark.github.io/p/zipkin_startup/cover_hu6ef3ef375e80ecb9108b60353e3afbae_90400_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/zipkin_startup/","title":"Sleuth+Zipkin链路跟踪入门"},{"content":"建立数据库 建立个用于存放配置的数据库名为nacos-config，nacos/conf下有一个nacos-mysql.sql，运行一下便可获得存放配置信息的表\n \n配置数据源 修改nacos/conf/application.properties\n### If use MySQL as datasource: spring.datasource.platform=mysql ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://xxxxxxx:3306/nacos_config?characterEncoding=utf8\u0026amp;connectTimeout=1000\u0026amp;socketTimeout=3000\u0026amp;autoReconnect=true\u0026amp;useUnicode=true\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC db.user=root db.password=xxxxxxx 记得重启\n应用接入配置中心 依赖\n\u0026lt;!-- Spring Boot Web模块 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Nacos注册中心starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Nacos配置中心starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件，我们把原来的application.yml删除了，我们不再需要本地配置\n然后创建文件bootstrap.yml，注意名字要一模一样\nspring:application:name:order-service#微服务idprofiles:active:dev#环境名cloud:nacos:config:#Nacos配置中心配置file-extension:yml#文件扩展名server-addr:192.168.31.10:8848username:nacospassword:nacoslogging:#开启debug日志，仅为学习时使用level:root:debug定义一份配置文件是用微服务id-环境名.文件扩展名 三部分组合为有效的 data id，比如上面的就是order-service-dev.yml\n然后去Nacos把原来的那些应用配置给存到云端\n点击➕ 号新建配置\n \n注意data id 就是上面说的微服务id-环境名.文件扩展名 ，然后选择yaml格式，把我们以前写在本地的配置文件写到下面的配置内容中\n \n此时新建的配置信息其实就是用我们之前配置的MySQL存的，你会发现这些配置信息存在config-info表中了\n配置热加载技术 当我们突然修改配置文件后，为了生效我们必须重启一下应用，就有点麻烦，为了解决这个问题，我们用到了配置热加载技术\n为了支持热加载，服务的程序针对热加载需要作出如下变动：\n第一，配置数据必须被封装到单独的配置 Bean 中；\n第二，这个配置 Bean 需要被 @Configuration 与 @RefreshScope 两个注解描述。\n@Configuration @RefreshScope public class CustomConfig { @Value(\u0026#34;${custom.flag}\u0026#34;) private String flag; @Value(\u0026#34;${custom.database}\u0026#34;) private String database; public String getFlag() { return flag; } public void setFlag(String flag) { this.flag = flag; } public String getDatabase() { return database; } public void setDatabase(String database) { this.database = database; } } 在配置处用@Resource 注入即可\n@RestController public class TestController { @Resource private CustomConfig customConfig; @GetMapping(\u0026#34;/test\u0026#34;) public String test(){ return \u0026#34;flag:\u0026#34; + customConfig.getFlag() + \u0026#34;\u0026lt;br/\u0026gt; database:\u0026#34; + customConfig.getDatabase(); } } 现在我们需要变更配置文件时只需在Nacos中修改配置，它就会自动推送到应用而不需要每次都重启应用了。\n分环境配置 这个其实和原来没有用配置中心的差不多，生产环境的配置就在文件名后加-prod ，配置环境就加-dev ，共用的基础全局配置就直接application.yml 什么也不用加。\n对于现在微服务架构具体来说就是\n order-service-dev.yml 开发环境 order-service-prod.yml 生产环境 order-service.yml 共用  当然，如果要改变你要用的环境，还是需要改bootstrap.yml\nspring:profiles:active:prod#环境名","date":"2021-07-22T01:48:33+08:00","image":"https://ccqstark.github.io/p/nacos_config_startup/cover_hu2f85b5acfdf02eef7b8f3b3a65f67b73_18437_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/nacos_config_startup/","title":"Nacos配置中心入门"},{"content":"Feign 与 OpenFeign Spring Cloud OpenFeign 并不是独立的技术。它底层基于 Netflix Feign，Netflix Feign 是 Netflix 设计的开源的声明式 WebService 客户端，用于简化服务间通信。Netflix Feign 采用“接口+注解”的方式开发，通过模仿 RPC 的客户端与服务器模式（CS），采用接口方式开发来屏蔽网络通信的细节。OpenFeign 则是在 Netflix Feign 的基础上进行封装，结合原有 Spring MVC 的注解，对 Spring Cloud 微服务通信提供了良好的支持。使用 OpenFeign 开发的方式与开发 Spring MVC Controller 颇为相似。\n下面讲OpenFeign的使用方法。\n服务提供方 依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置 spring:application:name:warehouse-service#应用/微服务名字cloud:nacos:discovery:server-addr:192.168.31.102:8848#nacos服务器地址username:nacos#用户名密码password:nacosserver:port:80可被调用的服务 @RestController public class WarehouseController { @GetMapping(\u0026#34;/stock\u0026#34;) public Stock getStock(Long skuId){ /* code */ return stock; } } 服务调用方 依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- OpenFeign --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2.5.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; OpenFeign 为了保证通信高可用，底层也是采用 Ribbon 实现负载均衡，其原理与 Ribbon+RestTemplate 完全相同，只不过相较 RestTemplate，OpenFeign 封装度更高罢了。\n添加启用注解 @SpringBootApplication **@EnableFeignClients** //启用OpenFeign public class OrderServiceApplication { public static void main(String[] args) { SpringApplication.run(OrderServiceApplication.class, args); } } @EnableFeignClients用于启用OpenFeign\n配置 spring:application:name:order-servicecloud:nacos:discovery:server-addr:192.168.31.102:8848username:nacospassword:nacosserver:port:80这里只需配置Nacos即可\n创建OpenFeign的通信接口与响应对象 **@FeignClient(\u0026#34;warehouse-service\u0026#34;)** public interface WarehouseServiceFeignClient { @GetMapping(\u0026#34;/stock\u0026#34;) public Stock getStock(@RequestParam(\u0026#34;skuId\u0026#34;) Long skuId); } 这里就是定义我们要调用的服务的接口，方法名，参数，路由什么的都要对应。\n@FeignClient注解里面就填要调用的微服务名。参数值 warehouse-service 为服务提供者 ID，这一项必须与 Nacos 注册 ID 保持一致。在 OpenFeign 发送请求前会自动在 Nacos 查询 warehouse-service 所有可用实例信息，再通过内置的 Ribbon 负载均衡选择一个实例发起 RESTful 请求，进而保证通信高可用。\n这里的@GetMapping/@PostMapping和以前我们在写控制器时经常使用的 @GetMapping 或者 @ PostMapping 不同，OpenFeign 的客户端使用这些注解的含义是：OpenFeign 向服务提供者 warehouse-service 的 stock 接口**发起 Get 请求。**不得不说这个方式和Dubbo还是很像的，\n@RequestParam，该注解说明方法参数与请求参数之间的映射关系。\n消费者调用 @RestController public class OrderController { //利用@Resource将IOC容器中自动实例化的实现类对象进行注入  **@Resource private WarehouseServiceFeignClient warehouseServiceFeignClient;** @GetMapping(\u0026#34;/create_order\u0026#34;) public Map createOrder(Long skuId , Long salesQuantity){ //查询商品库存，像调用本地方法一样完成业务逻辑。  Stock stock = warehouseServiceFeignClient.getStock(skuId); /* code */ return result; } } @Resource注入被调用服务的接口就可以像调用本地方法一样使用了。\n完整过程 1.在第一次访问 WarehouseServiceFeignClient 接口时，Spring 自动生成接口的实现类并实例化对象。\n2.当调用 getStock() 方法时，Ribbon 获取 warehouse-service 可用实例信息，根据负载均衡策略选择合适实例。\n3.OpenFeign 根据方法上注解描述的映射关系生成完整的 URL 并发送 HTTP 请求，如果请求方法是 @PostMapping，则参数会附加在请求体中进行发送。\n4.warehouse-service 处理完毕返回 JSON 数据，消费者端 OpenFeign 接收 JSON 的同时反序列化到 Stock 对象，并将该对象返回。\n生产环境 OpenFeign 的配置事项 如何更改 OpenFeign 默认的负载均衡策略 前面提到在 OpenFeign 使用时默认引用 Ribbon 实现客户端负载均衡。如果设置 Ribbon 的负载均衡策略，其实配置方式其实与之前 Ribbon+RestTemplate 方案完全相同，只需在 application.yml 中调整微服务通信时使用的负载均衡类即可。\n复制代码\nwarehouse-service:#服务提供者的微服务IDribbon:#设置对应的负载均衡类NFLoadBalancerRuleClassName:com.netflix.loadbalancer.RandomRule开启默认的 OpenFeign 数据压缩功能 在 OpenFeign 中，默认并没有开启数据压缩功能。但如果服务间单次传递数据超过 1K 字节，强烈推荐开启数据压缩功能。默认 OpenFeign 使用 Gzip 方式压缩数据，对于大文本通常压缩后尺寸只相当于原始数据的 10%~30%，这会极大提高带宽利用率。但有一种情况除外，如果应用属于计算密集型，CPU 负载长期超过 70%，因数据压缩、解压缩都需要 CPU 运算，开启数据压缩功能反而会给 CPU 增加额外负担，导致系统性能降低，这是不可取的。\n复制代码\nfeign:compression:request:# 开启请求数据的压缩功能enabled:true# 压缩支持的MIME类型mime-types:text/xml,application/xml, application/json# 数据压缩下限 1024表示传输数据大于1024 才会进行数据压缩(最小压缩值标准)min-request-size:1024# 开启响应数据的压缩功能response:enabled:true替换默认通信组件 OpenFeign 默认使用 Java 自带的 URLConnection 对象创建 HTTP 请求，但接入生产时，如果能将底层通信组件更换为Apache HttpClient、OKHttp 这样的专用通信组件，基于这些组件自带的连接池，可以更好地对 HTTP 连接对象进行重用与管理。作为 OpenFeign 目前默认支持 Apache HttpClient 与 OKHttp 两款产品。这里以OKHttp配置方式为例。\n 引入 feign-okhttp 依赖包。  \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.github.openfeign\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;feign-okhttp\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;11.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在应用入口，利用 Java Config 形式初始化 OkHttpClient 对象。  @SpringBootApplication @EnableFeignClients public class OrderServiceApplication { //Spring IOC容器初始化时构建okHttpClient对象  @Bean public okhttp3.OkHttpClient okHttpClient(){ return new okhttp3.OkHttpClient.Builder() //读取超时时间  .readTimeout(10, TimeUnit.SECONDS) //连接超时时间  .connectTimeout(10, TimeUnit.SECONDS) //写超时时间  .writeTimeout(10, TimeUnit.SECONDS) //设置连接池  .connectionPool(new ConnectionPool()) .build(); } public static void main(String[] args) { SpringApplication.run(OrderServiceApplication.class, args); } } 在 application.yml 中启用 OkHttp。  feign:okhttp:enabled:true至此，我们已将OpenFeign的默认通信对象从URLConnection调整为OKHttp，至于替换为HttpClient组件的配置思路是基本相同的。\n如果需要了解OpenFeign更详细的配置选项，可以访问Spring Cloud OpenFeign的官方文档进行学习。\nhttps://docs.spring.io/spring-cloud-openfeign/docs/2.2.6.RELEASE/reference/html/\n","date":"2021-07-22T01:43:44+08:00","image":"https://ccqstark.github.io/p/openfeign_startup/cover_hu74c9fdd8cb819657fbdd849b196b87b5_65974_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/openfeign_startup/","title":"OpenFeign服务调用入门"},{"content":"客户端负载均衡 负载均衡顾名思义，是指通过软件或者硬件措施。它将来自客户端的请求按照某种策略平均的分配到集群的每一个节点上，保证这些节点的 CPU、内存等设备负载情况大致在一条水平线，避免由于局部节点负载过高产生宕机，再将这些处理压力传递到其他节点上产生系统性崩溃。\n负载均衡按实现方式分类可区分为：服务端负载均衡与客户端负载均衡。\n服务端负载均衡顾名思义，在架构中会提供专用的负载均衡器，由负载均衡器持有后端节点的信息，服务消费者发来的请求经由专用的负载均衡器分发给服务提供者，进而实现负载均衡的作用。目前常用的负载均衡器软硬件有：F5、Nginx、HaProxy 等。\n客户端负载均衡是指，在架构中不再部署额外的负载均衡器，在每个服务消费者内部持有客户端负载均衡器，由内置的负载均衡策略决定向哪个服务提供者发起请求。通俗来讲，就是客户端在发送请求之前就通过某种策略选定了要请求的服务提供者，而不是让一个中间件来帮忙决定。\nRibbon Netfilx Ribbon 是 Netflix 公司开源的一个负载均衡组件，是属于客户端负载均衡器。目前Ribbon 已被 Spring Cloud 官方技术生态整合，运行时以 SDK 形式内嵌到每一个微服务实例中，为微服务间通信提供负载均衡与高可用支持。\n \n过程如下：\n 订单服务（order-service）与商品服务（goods-service）实例在启动时向 Nacos 注册； 订单服务向商品服务发起通信前，Ribbon 向 Nacos 查询商品服务的可用实例列表； Ribbon 根据设置的负载策略从商品服务可用实例列表中选择实例； 订单服务实例向商品服务实例发起请求，完成 RESTful 通信；  下面用一个实例来演示：\n创建服务生产者 创建springboot项目模块，引入web和nacos客户端依赖\n配置文件 spring:application:name:provider-service#应用/微服务名字cloud:nacos:discovery:server-addr:49.234.82.226:8848#nacos服务器地址username:nacos#用户名密码password:nacosserver:port:8081创建示例服务 @RestController public class ProviderController { @GetMapping(\u0026#34;/provider/msg\u0026#34;) public String sendMessage(){ return \u0026#34;This is the message from provider service one!\u0026#34;; } } 连续创建3个provider，注意配置文件中的应用/微服务名要一致，代表同一种服务，为了直接了当地识别服务来自不同的微服务示例，可以在返回的字符串中添加自己的标示。启动后可以在nacos中看到健康示例数为3:\n \n创建服务消费者 引入web和nacos客户端依赖之外，还要引入ribbon\n\u0026lt;!-- Ribbon --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-netflix-ribbon\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud-alibaba.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件和服务提供者只有应用名和端口的区别。\n服务调用示例 首先是要添加RestTemplate对象\n@SpringBootApplication public class ConsumerServiceApplication { //Java Config声明RestTemplate对象  //在应用启动时自动执行restTemplate()方法创建RestTemplate对象，其BeanId为restTemplate。  @Bean public RestTemplate restTemplate(){ return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(ConsumerServiceApplication.class, args); } } 然后添加controller\n@RestController public class ConsumerController { private Logger logger = LoggerFactory.getLogger(ConsumerController.class); //注入 Ribbon 负载均衡器对象  //在引入 starter-netflix-ribbon 后在 SpringBoot 启动时会自动实例化 LoadBalancerClient 对象。  //在 Controller 使用 @Resource 注解进行注入即可。  @Resource private LoadBalancerClient loadBalancerClient; @Resource //将应用启动时创建的 RestTemplate 对象注入 ConsumerController  private RestTemplate restTemplate; @GetMapping(\u0026#34;/consumer/msg1\u0026#34;) public String getProviderMessage1() { //loadBalancerClient.choose()方法会从 Nacos 获取 provider-service 所有可用实例，  //并按负载均衡策略从中选择一个可用实例，封装为 ServiceInstance（服务实例）对象  //结合现有环境既是从三个实例中选择一个包装为ServiceInstance  ServiceInstance serviceInstance = loadBalancerClient.choose(\u0026#34;provider-service\u0026#34;); //获取服务实例的 IP 地址  String host = serviceInstance.getHost(); //获取服务实例的端口  int port = serviceInstance.getPort(); //在日志中打印服务实例信息  logger.info(\u0026#34;本次调用由provider-service的\u0026#34; + host + \u0026#34;:\u0026#34; + port + \u0026#34; 实例节点负责处理\u0026#34; ); //通过 RestTemplate 对象的 getForObject() 方法向指定 URL 发送请求，并接收响应。  //getForObject()方法有两个参数：  //1. 具体发送的 URL，结合当前环境发送地址为：http://[ip]:[port]/provider/msg  //2. String.class说明 URL 返回的是纯字符串，如果第二参数是实体类， RestTemplate 会自动进行反序列化，为实体属性赋值  String result = restTemplate.getForObject(\u0026#34;http://\u0026#34; + host + \u0026#34;:\u0026#34; + port + \u0026#34;/provider/msg\u0026#34;, String.class); //输出响应内容  logger.info(\u0026#34;provider-service 响应数据:\u0026#34; + result); //向浏览器返回响应  return \u0026#34;consumer-service 响应数据:\u0026#34; + result; } } 调用服务测试 发现每次刷新都是不一样的服务示例来服务的，这里默认采用了轮询机制来负载均衡\n \n@LoadBalanced 采用注解模式用@LoadBalanced 注解就可以很大程度上简化代码\n注解加在RestTemplate对象上\n@SpringBootApplication public class ConsumerServiceApplication { //Java Config声明RestTemplate对象  //在应用启动时自动执行restTemplate()方法创建RestTemplate对象，其BeanId为restTemplate。  @Bean @LoadBalanced //使RestTemplate对象自动支持Ribbon负载均衡  public RestTemplate restTemplate(){ return new RestTemplate(); } public static void main(String[] args) { SpringApplication.run(ConsumerServiceApplication.class, args); } } 添加服务\n@GetMapping(\u0026#34;/consumer/msg2\u0026#34;) public String getProviderMessage2() { //关键点：将原有IP:端口替换为服务名，RestTemplate便会在通信前自动利用Ribbon查询可用provider-service实例列表  //再根据负载均衡策略选择节点实例  String result = restTemplate.getForObject(\u0026#34;http://provider-service/provider/msg\u0026#34;, String.class); logger.info(\u0026#34;consumer-service获得数据:\u0026#34; + result); return \u0026#34;consumer-service获得数据:\u0026#34; + result; } 可以发现比第一种方式减少了很多的代码\n如何配置 Ribbon 负载均衡策略 Ribbon 内置多种负载均衡策略，常用的分为以下几种。\n RoundRobinRule：  轮询策略，Ribbon 默认策略。默认超过 10 次获取到的 server 都不可用，会返回⼀个空的 server。\n RandomRule：  随机策略，如果随机到的 server 为 null 或者不可用的话。会不停地循环选取。\n RetryRule：  重试策略，⼀定时限内循环重试。默认继承 RoundRobinRule，也⽀持自定义注⼊，RetryRule 会在每次选取之后，对选举的 server 进⾏判断，是否为 null，是否 alive，并且在 500ms 内会不停地选取判断。而 RoundRobinRule 失效的策略是超过 10 次，RandomRule 没有失效时间的概念，只要 serverList 没都挂。\n BestAvailableRule：  最小连接数策略，遍历 serverList，选取出可⽤的且连接数最小的⼀个 server。那么会调用 RoundRobinRule 重新选取。\n AvailabilityFilteringRule：  可用过滤策略。扩展了轮询策略，会先通过默认的轮询选取⼀个 server，再去判断该 server 是否超时可用、当前连接数是否超限，都成功再返回。\n ZoneAvoidanceRule：  区域权衡策略。扩展了轮询策略，除了过滤超时和链接数过多的 server，还会过滤掉不符合要求的 zone 区域⾥⾯的所有节点，始终保证在⼀个区域/机房内的服务实例进行轮询。\n这里所有负载均衡策略名本质都是 com.netflix.loadbalancer 包下的类：\n \n修改微服务的负载均衡规则 直接修改配置文件application.yml添加\nprovider-service:#服务提供者的微服务idribbon:NFLoadBalancerRuleClassName:com.netflix.loadbalancer.RandomRule#设置对应的负载均衡类这里采用随机算法，用上面的示例测试一下：\n2021-04-14 01:20:04.122 INFO 82083 --- [nio-8090-exec-1] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service two! 2021-04-14 01:20:06.694 INFO 82083 --- [nio-8090-exec-2] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service one! 2021-04-14 01:20:09.022 INFO 82083 --- [nio-8090-exec-3] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service one! 2021-04-14 01:20:09.989 INFO 82083 --- [nio-8090-exec-4] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service three! 2021-04-14 01:20:20.379 INFO 82083 --- [nio-8090-exec-5] c.c.c.controller.ConsumerController : consumer-service获得数据:This is the message from provider service two! 果然是随机的！\n","date":"2021-07-22T01:38:45+08:00","image":"https://ccqstark.github.io/p/ribbon_startup/cover_hu23ccbb911fabf1d5535c01685f315954_288884_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/ribbon_startup/","title":"Ribbon负载均衡入门"},{"content":"docker单点部署 clone项目 git clone https://github.com/nacos-group/nacos-docker.git cd nacos-docker 修改配置文件 如果单机主机内存较小，可以修改配置文件example/standalone-derby.yaml 修改JVM运行内存\n在nacos的environment 那里添加- JVM_XMS=256m和 - JVM_XMX=256m\nversion: \u0026#34;2\u0026#34;services: nacos: image: nacos/nacos-server:latest container_name: nacos-standalone environment: - PREFER_HOST_MODE=hostname - MODE=standalone - JVM_XMS=256m - JVM_XMX=256m volumes: - ./standalone-logs/:/home/nacos/logs - ./init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - \u0026#34;8848:8848\u0026#34; prometheus: container_name: prometheus image: prom/prometheus:latest volumes: - ./prometheus/prometheus-standalone.yaml:/etc/prometheus/prometheus.yml ports: - \u0026#34;9090:9090\u0026#34; depends_on: - nacos restart: on-failure grafana: container_name: grafana image: grafana/grafana:latest ports: - 3000:3000 restart: on-failuredocker-compose启动容器 最后加个-d后台运行\ndocker-compose -f example/standalone-derby.yaml up -d 访问 地址：http://[ip地址]:8848/nacos/\n8848是nacos的默认端口号\nweb界面如下：\n \n普通部署 到github: https://github.com/alibaba/nacos/releases/ 去获取Nacos的压缩包\n# 解压tar -xvf nacos-server-1.4.0.tar.gz解压后 Nacos 目录结构如下。\n bin：保存启用/关闭 Nacos Server 脚本； conf：Nacos Server 配置目录； data：Nacos 数据目录； logs：存放日志目录； target：Nacos Jar 包存放目录；  # 进入bin目录cd bin# 修改虚拟机内存vim startup.sh# 单机启动sh startup.sh -m standaloneSpringboot工程准备 创建 因为是微服务项目，一般是多个springboot项目的多模块项目，所以先建立一个大的空Maven项目，以备之后使用，再在下面建立Module（对父项目根目录右键new→Module）\nSpring Initializr选中 Custom，写入阿里云地址http://start.aliyun.com\n建立一个springboot项目，名字为nacos-sample-service，依赖除了spring-web之后记得一定还要选一个nacos-discovery\n \n修改配置文件application.properties # 应用名称 spring.application.name=nacos-sample-service # 应用服务 WEB 访问端口 server.port=9000 # Nacos帮助文档: https://nacos.io/zh-cn/docs/concepts.html # 连接 Nacos 服务器使用的用户名、密码，默认为 nacos spring.cloud.nacos.discovery.username=nacos spring.cloud.nacos.discovery.password=nacos # Nacos 服务发现与注册配置，其中子属性 server-addr 指定 Nacos 服务器主机和端口 spring.cloud.nacos.discovery.server-addr=49.234.82.226:8848 # 注册到 nacos 的指定 namespace，默认为 public spring.cloud.nacos.discovery.namespace=public 启动项目 启动后看到日志：\n2021-04-13 23:42:46.933 INFO 75033 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 9000 (http) with context path \u0026#39;\u0026#39; 2021-04-13 23:42:47.577 INFO 75033 --- [ main] c.a.c.n.registry.NacosServiceRegistry : nacos registry, DEFAULT_GROUP nacos-sample-service 10.173.110.92:9000 register finished 2021-04-13 23:42:47.590 INFO 75033 --- [ main] c.c.n.NacosSampleServiceApplication : Started NacosSampleServiceApplication in 16.484 seconds (JVM running for 24.374) 且在web界面看到服务已经被注册就证明已经成功了\n \nNacos 注册中心的心跳机制 下图阐述了微服务与 Nacos 服务器之间的通信过程。在微服务启动后每过5秒，会由微服务内置的 Nacos 客户端主动向 Nacos 服务器发起心跳包（HeartBeat）。心跳包会包含当前服务实例的名称、IP、端口、集群名、权重等信息。\n \nnaming 模块在接收到心跳包后，会按下图逻辑处理心跳包并返回响应：\n naming 模块收到心跳包，首先根据 IP 与端口判断 Nacos 是否存在该服务实例？如果实例信息不存在，在 Nacos 中注册登记该实例。而注册的本质是将新实例对象存储在“实例 Map”集合中； 如果实例信息已存在，记录本次心跳包发送时间； 设置实例状态为“健康”； 推送“微服务状态变更”消息； naming 模块返回心跳包时间间隔。  到这里一次完整的心跳包处理已完成。\n \nNacos Server 每过 20 秒对“实例 Map”中的所有“非健康”实例进行扫描，如发现“非健康”实例，随即从“实例 Map”中将该实例删除。\n集群部署 配置数据库 用于同步各集群之间的数据，同步端口为7848，所以也记得要打开\n修改nacos/conf/application.properties\n### If use MySQL as datasource: spring.datasource.platform=mysql ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://xxxxxx:3306/nacos_config?characterEncoding=utf8\u0026amp;connectTimeout=1000\u0026amp;socketTimeout=3000\u0026amp;autoReconnect=true\u0026amp;useUnicode=true\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC db.user=root db.password=xxxxxx 配置集群ip列表 复制一份样例的集群ip节点列表\ncp cluster.conf.example cluster.conf vim cluster.conf 添加所有集群的ip，一行一条\n192.168.163.131:8848 192.168.163.132:8848 192.168.163.133:8848 启动集群 不用-m ，默认就是集群方式启动\n# 启动 sh startup.sh # 查看启动日志 tail -f ../logs/start.out 看到日志出现大概以下信息就说明启动成功\n2021-04-17 17:20:44,801 INFO Nacos is starting... 2021-04-17 17:20:44,957 INFO Nacos Log files: /home/nacos/nacos/logs 2021-04-17 17:20:44,958 INFO Nacos Log files: /home/nacos/nacos/conf 2021-04-17 17:20:44,958 INFO Nacos Log files: /home/nacos/nacos/data 2021-04-17 17:20:44,958 INFO Nacos started successfully in cluster mode. use external storage 内存不够记得改下jvm启动内存（修改startup.sh文件）\n最后打开Nacos管理界面的集群管理的节点列表：\n \n","date":"2021-07-22T01:30:53+08:00","image":"https://ccqstark.github.io/p/nacos_startup/cover_hu3dcfa387b55d54e5becd295f3f353ebe_40548_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/nacos_startup/","title":"Nacos服务注册与发现入门"},{"content":"主从复制搭建 拉取镜像 用docker，mysql5.7\ndocker pull mysql:5.7 启动 主节点\ndocker run -p 3306:3306 --name mysql_master -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 从节点\ndocker run -p 3306:3306 --name mysql——slave -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 Master配置 通过docker exec -it [容器名] bash 进入容器内部\n安装vim\napt-get update apt-get install vim 编辑配置文件my.cnf\ncd /etc/mysql vim my.cnf 添加以下内容\n[mysqld] ## 同一局域网内注意要唯一 server-id=100 ## 开启二进制日志功能，可以随便取（关键） log-bin=mysql-bin 完成后重启服务，重启服务后需要重启容器\nservice mysql restart docker start mysql_master 再次进入容器，创建用于同步数据的用户\nmysql -hlocalhost -uroot -p CREATE USER \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO \u0026#39;slave\u0026#39;@\u0026#39;%\u0026#39;; flush privileges; Slave配置 和Master一样要安装vim，然后在my.cnf中添加\n[mysqld] ## 设置server_id,注意要唯一 server-id=101 ## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用 log-bin=mysql-slave-bin ## relay_log配置中继日志 relay_log=edu-mysql-relay-bin 然后也要经过一样的重启过程\n链接Master和Slave 先在master里mysql中执行\nshow master status;  \n其中File字段和Position字段待会要用到，此时开始master不要再做任何操作，保证Position字段的值不再改变\n然后进入salve的mysql中执行\nchange master to master_host=\u0026#39;172.17.0.2\u0026#39;, master_user=\u0026#39;slave\u0026#39;, master_password=\u0026#39;123456\u0026#39;, master_port=3306, master_log_file=\u0026#39;mysql-bin.000001\u0026#39;, master_log_pos= 769, master_connect_retry=30;  master_host ：Master的ip地址 master_port：Master的端口号 master_user：用于数据同步的用户 master_password：用于同步的用户的密码 master_log_file：指定 Slave 从哪个日志文件开始复制数据，即上文中提到的 File 字段的值 master_log_pos：从哪个 Position 开始读，即上文中提到的 Position 字段的值 master_connect_retry：如果连接失败，重试的时间间隔，单位是秒，默认是60秒  最后每台slave都执行\nstart slave; 查询主从复制状态\nshow slave status \\G;  \n有2个yes就成功了\n原理解析 基本过程  master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中； slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件 同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志（relay log）中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后 I/O Thread 和 SQL Thread 将进入睡眠状态，等待下一次被唤醒。   \n要点  从库会生成两个线程，一个I/O线程，一个SQL线程； I/O线程会去请求主库的binlog，并将得到的binlog写到本地的relay-log(中继日志)文件中； 主库会生成一个log dump线程，用来给从库I/O线程传binlog； SQL线程，会读取relay log文件中的日志,并解析成sql语句逐一执行；  注意  master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）。 slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和master数据保持一致了。 MySQL复制至少需要两个Mysql的服务，当然MySQL服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。 MySQL复制最好确保master和slave服务器上的MySQL版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本） master和slave两节点间时间需同步  ","date":"2021-07-22T01:00:48+08:00","image":"https://ccqstark.github.io/p/mysql_master_slave_replic/cover_huff5578d477b5a7be0373e736738479ea_238860_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/mysql_master_slave_replic/","title":"MySQL主从复制搭建与原理"},{"content":"题目 给你一个链表的头节点 head 和一个整数 val ，请你删除链表中所有满足 Node.val == val 的节点，并返回 新的头节点 。\n \n示例 1: 输入: head = [1,2,6,3,4,5,6], val = 6 输出: [1,2,3,4,5] 示例 2: 输入: head = [], val = 1 输出: [] 示例 3: 输入: head = [7,7,7,7], val = 7 输出: [] 分析 很普通的一道链表移除元素题目。这里我们主要考虑两种方式：\n 直接在原链表上删除节点操作 增加一个虚拟节点（也叫哨兵节点）来操作  第二种方法主要是为了统一所有的删除节点操作，而不用在遇到要删除头节点情况时要单独写一段代码来处理。\n而对于普通节点，删除这个节点的操作一般是把自己的前驱节点的next指针指向自己的后驱节点，如图：\n  由于是单链表，我们不能获得一个被删节点的前驱节点，所以一般是判断一个节点的next的值是否为被删值。\n 对于C/C++，不能自动释放内存我们就要手动释放被删除的节点的内存，但Java会帮我们做好这一切。\n 代码 ListNode节点类的代码：\npublic class ListNode { int val; ListNode next; ListNode() {} ListNode(int val) { this.val = val; } ListNode(int val, ListNode next) { this.val = val; this.next = next; } } 方法一：直接在原链表上操作 public ListNode removeElements1(ListNode head, int val) { ListNode ptr = head; while (ptr != null \u0026amp;\u0026amp; ptr.next != null) { if (ptr == head \u0026amp;\u0026amp; ptr.val == val) { // 删除头节点情况  head = head.next; ptr = head; } else if (ptr.next.val == val) { ptr.next = ptr.next.next; } else { ptr = ptr.next; } } // 处理只有一个节点的情况  if (head != null \u0026amp;\u0026amp; head.next == null \u0026amp;\u0026amp; head.val == val){ return null; } return head; } 这种方式对于要删除的点是头节点的情况就是把head节点往后移一位：\n \n方法二：虚拟头节点 public ListNode removeElements2(ListNode head, int val) { // 设置虚拟头节点 \tListNode virtualHead = new ListNode(0, head); ListNode ptr = virtualHead; while (ptr.next != null) { if (ptr.next.val == val) { ptr.next = ptr.next.next; } else { ptr = ptr.next; } } return virtualHead.next; } 下面是有了虚拟头节点之后删除头节点的操作，发现和其它的非头节点操作是可以统一的：\n \n复杂度分析  时间复杂度：O(N)，只遍历了一次。 空间复杂度：O(1)。  ","date":"2021-04-11T00:00:00+08:00","image":"https://ccqstark.github.io/p/remove_elements/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/remove_elements/","title":"[leetcode]203.移除链表元素"},{"content":"题目 给你一个正整数 n ，生成一个包含 1 到 n^2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵 matrix 。\n \n示例1: 输入:n = 3 输出:[[1,2,3],[8,9,4],[7,6,5]] 示例2: 输入: n = 1 输出: [[1]] 分析 第一次看到这道题感觉很懵很难，其实这道题也不涉及什么经典算法，就是考验你用代码复现这个过程道能力。\n我们可以把按照题目给的图的按顺序去填充矩阵中的值，从第一个位置开始先从左到右➡️ ，再从上到下⬇️ ，再从右到左⬅️ ，再从下到上⬆️ 。如此循环，直到填充完毕，当然如果n为奇数的话就要考虑中间那一格需要最后去单独填充，偶数的话就没有这个问题。\n当然每次循环还需要注意，每行/列都遵循的是左闭右开的原则，也就是说从头填到倒数第二个，最后一个就是下一行/列的，才能保证行/列填充行为的统一性。\n还有一点是每次循环之后，每行/列需要填充的个数就要少2，看下下面的图就可以很直观的理解了。\n下面就是n=5和n=4的例子：\n   \n代码 class Solution { public int[][] generateMatrix(int n) { // 矩阵本体  int[][] matrix = new int[n][n]; // 横行和纵向开始填充的起始点  int startx = 0, starty = 0; // 循环次数  int loop = n / 2; // n为奇数时矩阵的中间格  int mid = n / 2; // 用来填充的数字，从1开始  int count = 1; // 每列或每行在循环一次后，下一次循环时要填充的元素个数会减少2，用这个变量来记录当前减少的大小  int offset = 1; // 填充时用的指针，i为行，j为列  int i, j; while (loop-- != 0) { // 指针置于起始位置  i = startx; j = starty; // 上行，从左到右  for (j = starty; j \u0026lt; starty + n - offset; j++) { matrix[i][j] = count++; } // 右列，从上到下  for (i = startx; i \u0026lt; startx + n - offset; i++) { matrix[i][j] = count++; } // 下行，从右到左  for (; j \u0026gt; starty; j--) { matrix[i][j] = count++; } // 左列，从下到上  for (; i \u0026gt; startx; i--) { matrix[i][j] = count++; } // 循环一次后，下一次起始位置+1  startx++; starty++; // 下一次循环时，每行/列填充的个数要-2  offset += 2; } // n为奇数要填中间一格  if (n % 2 == 1) { matrix[mid][mid] = count; } return matrix; } } 复杂度分析  时间复杂度：O(n^2)，其中 nn 是给定的正整数。矩阵的大小是 n \\times nn×n，需要填入矩阵中的每个元素。 空间复杂度：O(1)。除了返回的矩阵以外，空间复杂度是常数。  ","date":"2021-04-07T21:07:00+08:00","image":"https://ccqstark.github.io/p/generate_matrix/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/generate_matrix/","title":"[leetcode]59.螺旋矩阵II"},{"content":"今天在看有关StringBuilder和StringBuffer的文章的时候看到里面提及了有关String中的final字段和不可变的性质，发现这个知识点不是很熟悉，去查了很多文章之后整理出这篇。\n新建字符串与缓冲池 新建一个String我们一般有下面2种方式：\nString a = \u0026#34;ok\u0026#34;; String b = new String(\u0026#34;ok\u0026#34;); 这两种写法都可以创建一个String对象。\n第一种用赋值运算符进行字符串初始化时，JVM自动为每个字符串生成一个String类的实例。\n第二种就是创建String类的对象，因为String本来就是一个类，而不是像int和double那样的基本数据类型。\nJava的字符串采用了缓冲池的技术，我们新建一个字符串的时候会去缓冲池寻找是否有已经存在的相同的字符串，如果有的话直接指向它即可；没有的话再创建，缓冲池是在堆里面的。\n如下图，是下面代码的结果：\n// one和two内容相同，指向同一String对象 String one = \u0026#34;someString\u0026#34;; String two = \u0026#34;someString\u0026#34;;   关于更深入的创建对象和之间的比较可以看下面这篇：\njava 字符串缓冲池 String缓冲池_天天的专栏-CSDN博客\n哪里不可变？ 那为什么说String不可变呢？我们明明可以通过给字符串变量赋一个新值来改变它的内容。\nString str = \u0026#34;aaaaaaa\u0026#34;; System.out.println(str); str = \u0026#34;bbbbbbbbb\u0026#34;; System.out.println(str); // 输出 //aaaaaaa //bbbbbbbbb 实际上，当我们给字符串重新赋值的时候，它并不是去改变这个String对象中的字符数组char[] value的值（下面会讲到），而是去缓冲池里寻找有没有已经存在这个值的String对象，有的话就直接指向它，没有的话创建一个对象再指向它。\n  str只是一个引用，指向的String对象是在堆中的。改变字符串的值其实只是改变整个对象的引用。\n而原来的String对象还是在那里没有被改变，之后要是有别的变量赋这个值可以继续指向它。\n为什么不可变？ 我们看下String的部分源码：\npublic final class String implements java.io.Serializable, Comparable\u0026lt;String\u0026gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 } 重点在这个字符数组value就是存放字符串内容的地方，注意它是被final 修饰的，也就是一旦初始化之后它的值就不能改变。\n不过它value也只是个引用，引用不可变，但是如果真的想改是可以改变数组中元素但值的，但由于String中没有setValue方法，我们要改的话就要通过反射了。\n利用反射改变 下面这段代码就利用了反射改变了value数组中的元素的值，但是数组的地址是没有改变的哦。\nString s=\u0026#34;123\u0026#34;; Field valueArray=String.class.getDeclaredField(\u0026#34;value\u0026#34;); valueArray.setAccessible(true); char[] array=(char[]) valueArray.get(s); array[0]=\u0026#39;2\u0026#39;; System.out.println(s);//223 设计成不可变的原因？ 代码安全 String类本身也是final 的，这样设计使得String不可被继承，不可扩展与重写方法，主要是为了安全。因为String作为一个比较底层的类使用得也比较频繁，而且很多实现是通过系统调用的，如果让开发者可以随意修改一些东西就很可能带来问题甚至注入病毒。\n为了实现字符串缓冲池 只有当字符串是不可变的，字符串池才有可能实现。字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那改变一个字符串的值就会导致其它指向这个String对象的字符串引用对应的值也会改变。\n作为HashMap的键 因为字符串是不可变的，所以在它创建的时候HashCode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。\n线程安全 因为字符串是不可变的，所以是多线程安全的，同一个字符串实例可以被多个线程共享。这样便不用因为线程安全问题而使用同步。字符串自己便是线程安全的。\n参考文章 Java String类为什么是final的？\n如何理解 String 类型值的不可变？\n","date":"2021-04-06T21:07:00+08:00","image":"https://ccqstark.github.io/p/string/java_hu4a52e4833b2d51fc82bb34a9877f5e42_192896_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/string/","title":"一次理解String的不可变性"},{"content":"题目 给定一个含有 n 个正整数的数组和一个正整数 target 。\n找出该数组中满足其和 ≥ target 的长度最小的 连续子数组 [numsl, numsl+1, \u0026hellip;, numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。\n示例 1: 输入: target = 7, nums = [2,3,1,2,4,3] 输出: 2 解释: 子数组 [4,3] 是该条件下的长度最小的子数组. 示例 2: 输入: target = 4, nums = [1,4,4] 输出: 1 示例 3: 输入: target = 11, nums = [1,1,1,1,1,1,1,1] 输出: 0 提示：\n 1 \u0026lt;= target \u0026lt;= 109 1 \u0026lt;= nums.length \u0026lt;= 105 1 \u0026lt;= nums[i] \u0026lt;= 105  分析 这道题一开始想到的是暴力解法，也就是把每种可能的子数组长度都试一遍，后来发现这是道典型的滑动窗口题目，用滑动窗口就解决了。之后看官方题解有前缀+二分搜索的方法作为扩展。\n代码 滑动窗口 public int minSubArrayLen(int target, int[] nums) { if (nums.length == 0) { return 0; } int left = 0, right = 0; int s = nums[0]; int windowLen = Integer.MAX_VALUE; while (right \u0026lt; nums.length - 1) { // 右指针移动  while (s \u0026lt; target \u0026amp;\u0026amp; right \u0026lt; nums.length - 1) { right++; s += nums[right]; } // 左指针移动  while (s \u0026gt;= target) { windowLen = Math.min(windowLen, right - left + 1); s -= nums[left]; left++; } } return windowLen == Integer.MAX_VALUE ? 0 : windowLen; } 方法很简单，就是一个左指针，一个右指针，窗口的范围就是2个指针之间的元素。\n一开始先移动右指针直到窗口内和大于等于target\n然后向右开始移动左指针，直到窗口内和小于target，由于每次就是一次满足s≥target的窗口，我们就要每次和当前的窗口长度进行比较从而找到最小的窗口长度，也就是最小的子数组长度。\n如果窗口长度为最大的int值说明没有找到任何一个满足s≥target的窗口，返回0。\n复杂度分析 时间复杂度：O(n)，其中 n 是数组的长度。指针最多各移动n次。\n空间复杂度：O(1)。\n前缀+二分搜索 public int minSubArrayLen(int target, int[] nums) { int n = nums.length; if (n == 0) { return 0; } int windowLen = Integer.MAX_VALUE; int[] sums = new int[n + 1]; // 前i个数之和  for (int i = 1; i \u0026lt;= n; i++) { sums[i] = sums[i - 1] + nums[i - 1]; } for (int i = 0; i \u0026lt; n; i++) { int s = target + sums[i]; // 二分搜索  int bound = Arrays.binarySearch(sums, s); // bound为负数表示找不到，返回的是插入位置，且从1开始  if (bound \u0026lt; 0) { bound = -bound - 1; } // 找到最小的  if (bound \u0026lt;= n) { windowLen = Math.min(windowLen, bound - i); } } return windowLen == Integer.MAX_VALUE ? 0 : windowLen; } 这个方法我们先计算出nums中不同长度的前i个数之和的数组sums，也就是sums[i]表示nums[0]到nums[i-1]中的所有数之和。\n然后我们用二分查找在sums数组中找到下标bound，使得sums[bound]-sums[i]\u0026gt;=target，且这个bound是所能找到的最小的。（由于nums都是正整数，sums一定是递增的，所以可以用二分搜索）\n最终bound-i就是我们要找的最小的窗口长度。\n  这里的二分搜索如果找不到的话要返回插入的位置，Java有个Arrays.binarySearch()工具类可以使用，返回值为：\n 如果找到关键字，则返回值为关键字在数组中的位置索引，且索引从0开始 如果没有找到关键字，返回值为负的插入点值，所谓插入点值就是第一个比关键字大的元素在数组中的位置索引，而且这个位置索引从1开始。  贴个这个工具类的源码：\nprivate static int binarySearch0(long[] a, int fromIndex, int toIndex, long key) { int low = fromIndex; int high = toIndex - 1; while (low \u0026lt;= high) { int mid = (low + high) \u0026gt;\u0026gt;\u0026gt; 1; long midVal = a[mid]; if (midVal \u0026lt; key) low = mid + 1; else if (midVal \u0026gt; key) high = mid - 1; else return mid; // key found  } return -(low + 1); // key not found. } 复杂度分析  时间复杂度：O(nlogn)，其中n是数组的长度。需要遍历每个下标作为子数组的开始下标，遍历的时间复杂度是 O(n)，对于每个开始下标，需要通过二分查找得到长度最小的子数组，二分查找得时间复杂度是 O(logn)，因此总时间复杂度是 O(nlogn)。 空间复杂度：O(n)，其中 n 是数组的长度。额外创建数组 sums 存储前缀和。  ","date":"2021-04-04T21:07:00+08:00","image":"https://ccqstark.github.io/p/min_sub_array_len/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/min_sub_array_len/","title":"[leetcode]209.长度最小的子数组"},{"content":"题目 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。\n不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。\n元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。\n分析 对于数组而言，我们原地移除元素的话就肯定要把被移除的元素后面的全部元素都往前挪一个位，这是最基本的操作。所以最普通的暴力解法就是删除一个，整体挪动一个位。优化一点的话就是当有几个需要删除的数连在一起时，我们找到边界后一起挪动n个位，减少整体挪动的次数。\n最优的是经常被用到的双指针法，下面再解释。\n代码 混合暴力法 public int removeElement(int[] nums, int val) { int len = nums.length; for (int left = 0; left \u0026lt; len; left++) { if (nums[left] == val) { // left位于最后一个元素时  if (left == len - 1) { return len - 1; } int right = left + 1; while (right \u0026lt;= len - 1 \u0026amp;\u0026amp; nums[right] == val) right++; if (right == len - 1 \u0026amp;\u0026amp; nums[right] == val) { // right超过长度时  return len - (right - left); } // 把元素right处整体前移到left  moveUp(left, right, nums, len); len = len - (right - left); } } return len; } // 该函数用于将right及后面的元素完前移到left位置 public void moveUp(int left, int right, int[] nums, int len) { int step = len - 1 - right; for (int i = 0; i \u0026lt;= step; i++) { nums[left + i] = nums[right + i]; } }   此方法其实是初步优化的暴力法，假设我们要移除值为2的元素，left指针找到第一被删除的元素，right指向left后第一个不等于2的元素，然后把从right开始的后面全部元素都往前挪至left位置。\n这种方法在被删除元素都是在连续位置时可以很好提高速度。但是会有一些边界条件需要考虑，在上面代码中用注释强调了。\n双指针法 public int removeElement(int[] nums, int val) { int slowIndex = 0; for (int fastIndex = 0; fastIndex \u0026lt; nums.length; fastIndex++) { if (nums[fastIndex] != val) { nums[slowIndex++] = nums[fastIndex]; } } return slowIndex; } 双指针法用一个快指针和一个慢指针，都是从0开始。\n当快指针遇到要被删除的元素时，让慢指针不动，自己继续往后走，直到遇到一个非被删元素。\n然后就把快指针所处位置的值覆盖慢指针所处位置的值，然后两个指针一起向后走。\n最终慢指针的位置就是去掉所有要删除的元素的数组的末端，当快指针移到原数组最后一个元素时结束整个流程。\n其实慢指针就是用来一点点构建最终数据的指针，快指针就是用来找那些存在于最终数组中的元素，慢指针停留在要被删除的元素的位置时，就把快指针位置的元素搬过去覆盖，本质就是把最终会存在于数组中的（没有被删的）元素移到一起连成数组。\n复杂度分析  时间复杂度：O(n)，假设数组总共有 n 个元素，i 和 j 至少遍历 2n 步。 空间复杂度：O(1)。  ","date":"2021-04-02T21:07:00+08:00","image":"https://ccqstark.github.io/p/remove_element/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/remove_element/","title":"[leetcode]27.移除元素"},{"content":"题目 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。\n你可以假设数组中无重复元素。\n示例 1: 输入: [1,3,5,6], 5 输出: 2 示例 2: 输入: [1,3,5,6], 2 输出: 1 示例 3: 输入: [1,3,5,6], 7 输出: 4 示例 4: 输入: [1,3,5,6], 0 输出: 0 分析 这道题就是找到数组中的数，遍历就不说了， 我们首先想到的比较好的解法当然是二分搜索\n需要注意的是当目标值不存在于数组中时，我们要如何去定位合适的插入点？先上代码再分析。\n代码 public int searchInsert(int[] nums, int target) { return binSearch(0,nums.length-1,target,nums); } public int binSearch(int left, int right, int x, int[] nums) { if (left \u0026gt; right) return left; int mid = (left + right) / 2; if (x \u0026lt; nums[mid]) return binSearch(left, mid - 1, x, nums); if (x \u0026gt; nums[mid]) return binSearch(mid + 1, right, x, nums); if (x == nums[mid]) return mid; return -1; } 这里是采用传统的递归来写二分，但其实这里可以不用，直接一个while循环就行\npublic int searchInsert(int[] nums, int target) { int left = 0; int right = nums.length - 1; while (left \u0026lt;= right) { // 防止溢出  int mid = left + ((right - left) \u0026gt;\u0026gt; 1); if (target == nums[mid]) { return mid; } else if (target \u0026lt; nums[mid]) { right = mid - 1; } else if (target \u0026gt; nums[mid]) { left = mid + 1; } } return left; } 二分搜索在目标值大于或小于mid位置的值时要如何改变left和right 就不说了，关键是为什么最后我们把left 作为插入位置呢？\n我们可以拿奇数个或偶数个元素的数组试一下，发现如果目标值不在数组中，那么它们最后都会面临这样一种情况：left和right相邻，而目标值就介于两者之间。\n举个例子，数组[0,2,4,5,6]，目标值3，如下图：\n  而下一个状态也是肯定的，因为此时mid和left相等，target\u0026gt;nums[mid]，则left = mid + 1 ，呈现下面的状态：left和right重叠，且在目标值的大一位\n  再下一个状态同样是一定的，mid此时就是left和right的位置，则target\u0026lt;nums[mid]，即right = mid - 1 ，right左移一位，达到while循环结束条件left\u0026gt;right\n  那很明显的，目标插入的位置就一定是最后这里left的位置。不管数组元素是奇数个还是偶数个，最终就会是这个情形，所以最后我们选择left 作为插入不存在目标值的位置。当然也可以提前一步，当left == right 时那个位置也是一样的，leetcode官方就是这么选择的。\n复杂度分析  时间复杂度：O(log n)，其中 n 为数组的长度。二分查找所需的时间复杂度为 O(log n)。 空间复杂度：O(1)。我们只需要常数空间存放若干变量。  这道题主要考察二分搜索，难点在于插入位置的选择。\n","date":"2021-04-01T21:07:00+08:00","image":"https://ccqstark.github.io/p/search_insert/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/search_insert/","title":"[leetcode]35.搜索插入位置"},{"content":"题目 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n你可以按任意顺序返回答案。\n示例 1: 输入: nums = [2,7,11,15], target = 9 输出: [0,1] 解释: 因为 nums[0] + nums[1] == 9, 返回 [0, 1]. 示例 2: 输入: nums = [3,2,4], target = 6 输出: [1,2] 示例 3: 输入: nums = [3,3], target = 6 输出: [0,1] 提示：\n 2 \u0026lt;= nums.length \u0026lt;= 103 -109 \u0026lt;= nums[i] \u0026lt;= 109 -109 \u0026lt;= target \u0026lt;= 109 只会存在一个有效答案  分析 这道题比较容易，就是在数组中找到数值x和target-x\n直接上代码\n代码 方法一：暴力枚举 public int[] twoSum(int[] nums, int target) { for (int i = 0; i \u0026lt; nums.length - 1; i++) { for (int j = i + 1; j \u0026lt; nums.length; j++) { if (nums[i] + nums[j] == target) { return new int[]{i, j}; } } } return null; } 这里我们只需关注一个点就是j = i + 1 ，我们是选中其中一个数作为x，再去找target-x的，所谓为了避免重复组合，我们从x的下一个开始找，保证每个组合只试一遍，同时避免了x和找自己。\n复杂度分析  时间复杂度：O(N^2)，其中N是数组中的元素数量。最坏情况下数组中任意两个数都要被匹配一次。 空间复杂度：O(1)。  方法二：哈希表 public int[] twoSum(int[] nums, int target) { Map\u0026lt;Integer, Integer\u0026gt; hashtable = new HashMap\u0026lt;Integer, Integer\u0026gt;(); for (int i = 0; i \u0026lt; nums.length; ++i) { if (hashtable.containsKey(target - nums[i])) { return new int[] { hashtable.get(target - nums[i]), i } ; } hashtable.put(nums[i], i); } return new int[0]; } 利用哈希表我们可以提高找target-x的速度，从头到尾拿出一个数x，查看target-x是否存在于哈希表中，如果不存在就把自己也加入哈希表（x作为key，下标作为value）。这样就可以快速找到我们要的组合。\n复杂度分析  时间复杂度：O(N)，其中N是数组中的元素数量。对于每一个元素 x，我们可以 O(1)地寻找target - x。 空间复杂度：O(N)，其中 N 是数组中的元素数量。主要为哈希表的开销。  ","date":"2021-03-31T21:07:00+08:00","image":"https://ccqstark.github.io/p/two_sum/leetcode_hua465350402cd0ec3eacd50007e571132_103033_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/two_sum/","title":"[leetcode]1.两数之和"},{"content":"项目中用到了之前说的日志门面slf4j+log4j，但是之后遇到了一些问题。比如程序报错没有记录在日志，记录的时间也和服务器的不一致（服务器是东八区时间），或者记录一些不需要的信息，此篇就来解决这些问题。\nslf4j与log4j 之前有一篇文章介绍了slf4j怎么整合进Springboot，slf4j是一个日志门面，和我们所用的logback、log4j这些日志框架不同，它是为这些日志框架统一调用的API，通过api来调用具体的日志实现，简化了日志的配置与使用。slf4j要与具体的日志框架搭配，我用的是log4j。\n\u0026lt;!-- SLF4j - log4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8.0-alpha2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 使用时只要用注解@Slf4j ，然后直接用log.info() 方法就可以记录日志了。\n日志等级 日志分为以下几个等级：\nOFF：最高等级的，用于关闭所有日志记录。\nFATAL：会导致应用程序推出的严重错误。\nERROR：虽然发生错误事件，但仍然不影响系统的继续运行，一般也是程序的各种Exception，但要注意的是并不是所有异常都会导致Error，这就是下面的要说的异常捕获。打印错误和异常信息，如果不想输出太多的日志，可以使用这个级别。\nWARN：警告，表明会出现潜在错误的情形，有些信息不是错误信息，只是一些提示。\nINFO：消息在粗粒度级别上突出强调应用程序的运行过程。打印一些你感兴趣的或者重要的信息，这个可以用于生产环境中输出程序运行的一些重要信息，但是不能滥用，避免打印过多的日志。\nDEBUG：主要用于开发过程中打印一些运行信息。但是打印但信息量过多，项目上线后不要用。\nTRACE：跟踪日志，日志消息的粒度太细，很低的日志级别，一般不会使用。\nALL：最低等级的，用于打开所有日志记录。\n通过修改日志配置文件log4j.properties来改变日志等级：\nlog4j.rootLogger = ERROR,stdout,log //第一个参数是日志等级 错误捕获 在SpringBoot我们希望有统一的操作来捕获系统运行过程中参数的所有错误，对未预测到对错误设置友好的返回值给用户，避免返回500状态码。甚至可以将系统产生的报错通过邮件发送给开发者，让生产环境中的错误能得到快速直接的监测和解决。\n我们用到@RestControllerAdvice和@ExceptionHandler 这两个注解\n@Slf4j @RestControllerAdvice // 用于拦截异常的注解 public class ExceptionProcesser extends ResponseEntityExceptionHandler { @Autowired private MailService mailService; /** * 全局异常捕获入日志 */ // 此注解用来标示处理哪个类的异常 \t@ExceptionHandler(value = Exception.class) // 表示所有的异常都会处理 \tpublic CommonResult\u0026lt;String\u0026gt; defaultErrorHandler(Exception e) { // slf4j下的日志用法，简洁易用 \tlog.error(\u0026#34;defaultErrorHandler:\u0026#34;, e); // 将报错栈的信息转为字符串 \tStringWriter errors = new StringWriter(); e.printStackTrace(new PrintWriter(errors)); // 发送邮件给开发者 \tmailService.sendSimpleMail(\u0026#34;xxxxx@qq.com\u0026#34;, \u0026#34;项目报错\u0026#34;, errors.toString()); return CommonResult.failed(\u0026#34;这里可能有bug，报错信息发给ccq了，找他改bug去\u0026#34;); } /** * 对一些无法try/catch的具体错误还可以专门处理 */ @ExceptionHandler(MultipartException.class) // 表示只处理MultipartException这个类相关的异常  public CommonResult\u0026lt;String\u0026gt; handleUploadFileTooLargeError() { return CommonResult.failed(ResultCode.FILE_TOO_BIG); } } 日志时差 应用部署到线上的时候可能会遇到日志的记录时间和我们的东八区时间有时差，那就是经典时区问题了，可以通过启动jar包时设置参数来解决\njava -jar -Duser.timezone=GMT+08 xxx.jar ","date":"2021-03-18T23:01:00+08:00","image":"https://ccqstark.github.io/p/log_catch_error/cover_hud62bf8010474cbdcf139a7fd30aacc5c_25975_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/log_catch_error/","title":"[SpringBoot]日志与异常捕获"},{"content":"简介 引入 对于搜索功能，大家以前都是怎么做的呢？我相信很多人一开始也是用SQL的LIKE关键字加上%来匹配关键字的吧，为了实现更好的模糊效果就再加一个分词器来拆分关键词。但是，一旦被搜索的数据量一大，这种方式就显得效率低下。为了实现更好的效果，我们可以使用当前最流行的分布式搜索引擎——ElasticSearch 。\n基本介绍 Elasticsearch 是一个分布式的免费开源搜索和分析引擎，适用于包括文本、数字、地理空间、结构化和非结构化数据等在内的所有类型的数据，基于著名的Lucene库进行开发，并以简单的RESTful风格的API进行调用，支持Java、JavaScript(Node)、Go、 C#(.NET)、PHP、Python、Ruby等多种语言。ElasticSearch已经成为非常流行的搜索引擎，一些著名厂商例如京东、滴滴、携程、Stack Overflow、GitHub等都在使用。\n官网地址：https://www.elastic.co/cn/elasticsearch/\n \n应用场景  应用程序搜索 网站搜索 企业搜索 日志处理和分析 基础设施指标和容器监测 应用程序性能监测 地理空间数据分析和可视化 安全分析 业务分析  ELK ELK，即ElasticSearch + logstash + Kibana ，是一套开源的日志收集与分析解决方案。利用ElasticSearch对数据进行快速的复杂条件检索，用logstash则作为数据管道从多个来源进行数据的采集、转换和传输，Kibana则通过生成多种可视化报表方便用户进行日志监控。\n一般小型系统我们分析日志可以直接在用grep、awk等命令进行过滤与检索，或者拉到本地用LogViewer等专门的日志工具打开查看。但是当系统体量一大，采用的是分布式架构，集群中的日志管理就成为一个难题。ELK目的就是为了解决大型系统中的日志收集、存储与分析问题，方便将节点中的日志统一管理从而提高效率。\n \n概念介绍 基本概念 ElasticSearch（简称es）搜索的时候不是去数据库里拿数据，它有自己的一套存储与索引体系。数据库中的数据需要同步到es中，通过索引的形式来存储数据才能实现高效检索。\nes索引体系的基本概念和关系型数据库中的有些类似，我们可以对比着来看\n   Index 索引 Database 数据库     Type 文档类型 Table 表   Document 文档 Row 记录   Field 字段 Column 属性   Mapping 映射 Schema 模型   Query DSL SQL    es的层次组织结构类似于MySQL这样的关系型数据库，index就像database那样存储着不同的type，也就是数据库中的table；再下一级就是document，类似于数据库中的一条条记录；每条记录的字段field就对应表中的column；mapping就如schema那样表示着库表的架构；es中的查询语言Query DSL则对标我们熟悉的SQL。通过类比可以更快地认识es的结构组成。\n⚠️ 注意：从6.x开始es慢慢放弃type，并统一默认type为_doc，预计在8.x正式将其移除。\n其它概念   Node 节点\n实际项目中我们往往不会只用一台服务器来部署elasticsearch，那样的话能够承载的用户数就非常少。因为es是一个分布式的搜索引擎，那我们完全可以部署一个es集群，而其中的一个服务器实例就叫做node(节点)。\n  Cluster 集群\n一个cluster是有多个node组成的，es集群可以扩大单个节点的数据存储量以及承载的搜索请求。在其中一个节点挂掉的情况下不影响其他节点的正常工作。es集群也可以设置或选举master node来负责创建索引、删除索引、分配分片、追踪集群中的节点状态等，当然也可能存在脑裂问题。其它普通节点称为data node，用来接受用户的搜索请求返回搜索结果。\n  Shard 分片\n上面说到集群可以扩大单机存储空间过小的问题，而其中实现的原理就是通过分片。es通过对数据进行水平拆分成多个部分，然后分发到多台物理机上，这个过程叫做索引分片(Sharding)，每个部分就是一个分片(Shard)。创建索引时可以指定分片数量，一旦指定就不可更改。sharding的过程是es自动完成的，数据被写入时会被指定写入的分片。es的分片是Lucene实现的。\n  Replica 索引副本\n索引副本就是对分片进行的拷贝。在某一分片请求负载导致阻塞时，replica同样可以处理用户的请求。而且不仅可以提高流量承载能力，同时数据也有了一份备份，即使主分片数据丢掉也可以用副本恢复。\n  安装与基本使用 容器部署 云原生时代推荐使用容器，这里以docker单机部署为例简单讲下。\n# 拉取镜像，这里是7.10.1，注意es版本间兼容性较差 docker pull elasticsearch:7.10.1 # 启动容器，配置文件和数据挂载出来 docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \\ -e ES_JAVA_OPTS=\u0026#34;-Xms256m -Xmx256m\u0026#34; -d \\ -v [主机挂载目录]/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ -v [主机挂载目录]/data:/usr/share/elasticsearch/data elasticsearch:7.10.1 es容器是比较占内存的，毕竟一开就是一个JVM，单节点内存较小可以通过设置ES_JAVA_OPTS 来调小JVM的内存占用，例如上面例子中都参数就是设置为256M。\n其他可能出现的问题以及更多相关组件安装如Kibana或ik分词器可以参看我的另一篇博客，这里不再赘述。\n[Elastic]使用docker安装ElasticSearch + Kibana\nRESTful风格操作 es使用RESTful风格的API进行CRUD，存储与传输使用的数据形式也是使用常见的JSON，常用的method和对应的功能如下：\n  其中查询支持多种类型的复杂查询，如match解析查询、排序查询、分页查询、bool查询、fileter查询、多关键字查询、term精确查询、高亮查询等等。详细可以查看我博客的另一篇文章。\n[ElasticSearch]REST风格操作\n客户端 es提供了多种语言的client，各种API文档都在官网可以找到。对于Java推荐使用Java High Level REST Client，与SpringBoot的整合可以看我另一篇博客。\n[SpringBoot]整合ElasticSearch\n官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html\nMySQL的LIKE探究 索引使用 我们习惯用LIKE进行模糊查询，但是当数据量很大时耗时就会比较久，也许你会想到用索引来实现优化，但是模糊查询使用索引是要满足一定条件的。\n 单%模糊，且查询字段加了索引 使用双%进行全模糊查询，且把主键作为结果集，因为覆盖索引所以查询会走索引 使用全文索引  为了探究在大量数据情况下LIKE+%方案的效果，下面用个例子来实践一下。\n数据准备 建一张简单的表供查询，引擎是InnoDB\nCREATETABLE`test_like`(`id`int(11)UNSIGNEDNOTNULLAUTO_INCREMENT,`name`varchar(20)NOTNULLDEFAULT\u0026#39;\u0026#39;,`student_number`varchar(11)NOTNULLDEFAULT\u0026#39;\u0026#39;,PRIMARYKEY(`id`));准备多点数据，这里我准备了10万条。\n注意这里一次性插入太多数据可能会出现PacketTooBigException，可以分批插入或者设置max_allowed_packet\n\u0026lt;insert id=\u0026#34;insertLikeTestData\u0026#34;\u0026gt; insert into test_like (`name`,`student_number`) VALUES \u0026lt;foreach collection=\u0026#34;list\u0026#34; item=\u0026#34;item\u0026#34; index=\u0026#34;index\u0026#34; separator=\u0026#34;,\u0026#34;\u0026gt; (\u0026#39;ccq\u0026#39;,\u0026#39;50377880000\u0026#39;+#{item}) \u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt; 然后给我们用来查询的student_number加个索引\nALTERTABLE`test_like`ADDINDEX`idx_student_number`(`student_number`)USINGBTREE;查看执行计划 首先我们执行select * 的全模糊查询\nexplainselect*fromtest_likewherestudent_numberlike\u0026#39;%503%\u0026#39;\\G发现并没有使用索引并进行了全表扫描\nid:1select_type:SIMPLEtable:test_likepartitions:NULLtype:ALLpossible_keys:NULLkey:NULLkey_len:NULLref:NULLrows:100076filtered:11.11Extra:Usingwhere1rowinset,1warning(0.00sec)然后我们执行select id 的单%查询，也就是将主键作为结果集\nexplainselectidfromtest_likewherestudent_numberlike\u0026#39;503%\u0026#39;\\G发现的确使用了索引进行了优化，扫描行数只有一半\nid:1select_type:SIMPLEtable:test_likepartitions:NULLtype:rangepossible_keys:idx_student_numberkey:idx_student_numberkey_len:46ref:NULLrows:50038filtered:100.00Extra:Usingwhere;Usingindex1rowinset,1warning(0.00sec)最后我们select id 的双%查询\nexplainselectidfromtest_likewherestudent_numberlike\u0026#39;%503%\u0026#39;\\G这个时候我们发现确实使用我们创建的idx_student_number ，但是possible_keys居然是NULL\n而且还发现，使用索引与不使用索引，扫描行数都是一样的，而且都是全表扫描\nid:1select_type:SIMPLEtable:test_likepartitions:NULLtype:indexpossible_keys:NULLkey:idx_student_numberkey_len:46ref:NULLrows:100076filtered:11.11Extra:Usingwhere;Usingindex1rowinset,1warning(0.00sec)使用Trace查看优化器 我们跟踪一下MySQL的优化器是怎么做选择的\n-- 开启优化器跟踪 setsessionoptimizer_trace=\u0026#39;enabled=on\u0026#39;;select*fromtest_likewherestudent_numberlike\u0026#39;%503%\u0026#39;;-- 查看优化器追踪内容 select*frominformation_schema.optimizer_trace;找到查询路径的选择\n\u0026#34;best_access_path\u0026#34;: { \u0026#34;considered_access_paths\u0026#34;: [ { \u0026#34;rows_to_scan\u0026#34;: 100076, \u0026#34;access_type\u0026#34;: \u0026#34;scan\u0026#34;, \u0026#34;resulting_rows\u0026#34;: 100076, \u0026#34;cost\u0026#34;: 20304, \u0026#34;chosen\u0026#34;: true } ] } 然后对选择主键的双%查询也进行同样的跟踪，发现两者同样都是用了顺序扫描，而没有用上B+Tree来优化。\n结论 从上面我们也可以看到，没有做其它的优化而只用索引来使用MySQL的LIKE进行全模糊查询，在数据量大的时候，性能还是不尽人意的，这也说明了使用ES的必要性。\n索引原理 这一部分我们来说说ES的一些原理，看看为什么ES在查询上能更胜MySQL一筹。\n倒排索引 es是通过Lucene的倒排索引Inverted Index技术来实现比普通关系型数据库更快的查询的，特别对多条件的复杂查询，这一点能更好地体现。\n那什么是倒排索引呢？引用维基上的定义：\n倒排索引是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。\n有两种不同的反向索引形式：\n 一条记录的水平反向索引（或者反向档案索引）包含每个引用单词的文档的列表。 一个单词的水平反向索引（或者完全反向索引）又包含每个单词在一个文档中的位置。  其实很好理解，就是把我们以前设计表的那种把文章对应里面有哪些单词的结构，倒过来，变成一个单词与被包含在哪些文章中的对应关系，当我们搜索一个单词的时候就能快速得到包含这个单词的文章列表来。\n举个例子：\n比方说下面这张表\n  对direct字段利用倒排索引，变成：\n  那只要我们想查frontend对应有哪些人，就可以直接获得他们的id列表[21,16,54]，如果想查boss有哪些人，就可以得到[67,98]。这样就可以很快检索到我们想要到结果，而不用进行全表的搜索。\n对于上面的倒排表，我们把其中每一项称为Term，被索引的那一列也就是实例的direct字段为Term Dictionary ，对应被检索出来的id_list字段为Posting List。\n被检索的direct如果按顺序排列的话就可以用二分搜索快速找出，或者也可以在其上再加一层BTree来索引，提高关键词本身的搜索速度。\nTerm Index 当数据量很大的时候，Term Dictionary也会变得很大，无法完全放入内存（es本身运行已经占用非常大的内存了），这个时候我们再加一层索引叫Term Index。\nes使用 Burst-Trie 结构来实现，它是字典树（前缀树）Trie 的一种变种，它主要是将后缀进行了压缩，降低了Trie的高度，从而获取更好查询性能。\n  可以看到这棵树的根节点为空，接下来每一层是单词的从头到位的顺序的字母，某一节点的子节点连接所有单词中可能出现的下一个字母，根据下一个字母的可能的情况来分叉，同时多余的后缀也被省略。查询时可以先将Term Index缓存到内存中，据此找到我们要的Term Dictionary再去读磁盘，可以减少磁盘I/O次数。\n联合查询合并 当我们用es进行联合查询时，比如查找方向为backend且年份等于2019的人，我们只需要对direct和year字段分别用倒排索引查找出结果集，最后对结果集进行合并就行了。\n在关系型数据库中我们一般会用join来合并两表，这里再次鞭尸一下MySQL，它的join实现性能也很差。比如下面这样的SQL：\nselect*fromt2straight_joint1on(t2.a=t1.a);straight_join 保证优化器不改变驱动表，用Index Nested-Loop Join 算法执行流程如下：\n 从 t2 表中读取一行数据 L2 使用L2的 a 字段，去 t1 表中作为条件进行查询 取出 t1 中满足条件的行， 跟 L2组成相应的行，成为结果集的一部分 重复执行，直到扫描完 t2 表  所以阿里开发者规范禁止三张表以上的 join 操作，是有原因滴。\n而Elasticsearch使用跳表Skip List和位图Bitset来合并结果集，下面介绍一下这两种方法。\nSkip List合并策略 说到跳表，我们首先讲一下普通的链表，如下图：\n  图中的链表除了首位节点之外，其它节点都有一个指针指向下一个节点，但是由于不是顺序存储，我们无法从其中任意一个节点推算出其它任意一个节点的位置（除非是它指向的下一节点）。因此用这个数据结构来寻找某一节点效率偏低。\n然后说跳表Skip List，实际上是在链表的基础上多加了几层索引，使得查询效率加快，如图：\n  我们在原来的链表上多加了三层，而上面的每一层各节点之间的距离都在逐级递增，也就是说每次跨到本层的下一个节点，中间跳跃的相对与底层的节点数越来越多，所以叫跳表。利用这种数据结构的特性，我们在遍历原链表的时候就可以利用上面的索引来每次多跳几个节点，从而加快速度。\nES利用Skip List进行合并结果集的时候就是从上往下，找到节点值大于等于目标值的最小节点，如果还是大于目标值，那就往下一层，相当于增加查找精度。例如我现在要找的目标值为2，从最上一层开始找，这层是0—\u0026gt;6，6明显大于2了，到下一层；这一层是0—\u0026gt;4—\u0026gt;6，找到4还是大于2，那继续下一层；这时是0—\u0026gt;2—\u0026gt;4—\u0026gt;6，我们就可以找到目标值2了。\n利用跳表，ES在找两个结果集的交集的时候就会快很多。\nRoaring Bitset合并策略 除了用Skip List来加快合并之外，ES还会把不同条件查询的结果集Posting List放到内存中缓存。如果直接用普通的数据结构，比如数组这样的，就其实很消耗空间；如果用Bitset，可能会有过于稀疏而导致的空间浪费。所以ES采用压缩效率更高的Roaring Bitmap来存储。\n 这里插播一道面试题：给定含有40亿个不重复的位于[0, 2^32 - 1]区间内的整数的集合，如何快速判定某个数是否在该集合内？\n  如果我们要使用 unsigned long 数组来存储它的话，也就需要消耗 40亿 * 32 位 =160亿Byte，大约是 16000 MB。 如果使用位图 Bitset 来存储的话，即某个数如果存在的话，就将它对应的位图内的比特置为1，否则保持为0。这样多少个树就只需要消耗多少bit来存，这里是 2 ^ 32 位 = 512 MB，这可只有原来的 3.2 % 左右。\n Roaring Bitmap又是如何来解决稀疏的问题的呢？直接上图：\n  如图中所示，我们把待存数除以65535，并根据所得商和余数分组。然后把相同商的组分到同一个存储单元，这个存储单元称为container，最后只需要存各container中的余数即可。\n所以RoaringBitmap其实就是很多container的集合，如果是一个32位unsigned long的话，那最多就有2^32 / 65535 = 65535个container。\n对于其中的余数的存储（低16位），则是以下的存储规则：\n 余数小于 2 ^ 12 次方（4096）时，使用unsigned short类型的有序数组来存储，最大消耗空间为 8 KB。 余数大于 4096 时，则使用大小为 2 ^ 16 次方的普通 bitset 来存储，固定消耗 8 KB。有些时候也会对 bitset 进行run-length encoding压缩，进一步缩小占用内存。  ES利用Roaring Bitset缓存不同条件查出来的Posting List，最后通过与操作合并出最终结果集。\n小结  ElasticSearch是一个分布式开源搜索引擎，支持多种语言客户端，拥有丰富的应用场景，受到许多企业的青睐。 ElasticSearch方便部署集群，使用RESTful风格等API进行调用。 MySQL的LIKE字句只在特定情况下才使用索引，且性能不高，无法应对大数据亮搜索任务。 ElasticSearch使用倒排索引与Term Index来提高搜索效率，减少磁盘I/O。 ElasticSearch使用Skip List和Roaring Bitset来合并复杂条件查询的结果集。  参考文章  https://mp.weixin.qq.com/s/LU77ToU4b7O8WqjRRf1AqA https://www.cnblogs.com/Howinfun/p/12449975.html?spm=a2c6h.12873639.0.0.7b354fc6zDKM52 https://ccqstark.github.io/p/es_docker/ https://arxiv.org/pdf/1402.6407.pdf  ","date":"2021-03-13T23:01:00+08:00","image":"https://ccqstark.github.io/p/es_principle/es_hu709c9dbb1dd93df65cfe69a9e6744979_88514_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/es_principle/","title":"[ElasticSearch]ElasticSearch入门与原理浅析"},{"content":"简介 Dubbo原本是阿里的开源框架，有很多著名厂商都在用。但在14年停更，之后Spring Cloud大红大紫，Dubbo终于在17年再度更新，并在18年合并当当网的基于它开发出的DubboX推出了2.6版本。之后在18年除夕夜，阿里正式将Dubbo捐献给了著名开源组织Apache，成为Apache众多开源项目之一。\nApache Dubbo\nZooKeeper 也是 Apache 软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。\nZooKeeper 的架构通过冗余服务实现高可用性。\nZookeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。\n一个典型的分布式数据一致性的解决方案，分布式应用程序可以基于它实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。\nApache ZooKeeper\n安装 使用Dubbo引入相关依赖即可，下面具体实践会涉及。\nZooKeeper可以去官网下载安装，这里我还是用docker在Linux服务器上安装。\n# 拉取镜像 docker pull zookeeper # 启动 docker run -d \\ -p 2181:2181 \\ -v /home/zookeeper/data/:/data/ \\ --name=zookeeper \\ --privileged zookeeper # 如果想运行自带的客户端可以： docker exec -it zookeeper bash cd bin ./zkCli.sh # 之后就可以使用相关命令了 安装ZooInspector来可视化查看zookeeper\n\n# 下载后进入build目录运行jar包，输入zookeeper的地址即可连接 java -jar zookeeper-dev-ZooInspector.jar  \n使用dubbo-admin可视化监控服务 dubbo-admin是一个Springboot项目，可以监控我们注册到注册中心到服务。\n到github上下载\napache/dubbo-admin\n解压后在application.properties中修改zookeeper地址\ndubbo.registry.address=zookeeper://[ip]:2181 之后用mvn命令打包再运行jar包即可，也可以直接在idea里打包\n运行后浏览器 打开localhost:7001 ，输入账号密码默认都为root，来到主页\n  中间的搜索框可以搜索服务、应用、ip，菜单栏上也有各种监控服务的方式。\nSpringBoot Demo 用idea建立一个空项目，然后添加两个Modules，都为Springboot项目。\n一个作为服务提供者provider，一个作为服务消费者consumer\n两者都添加以下maven依赖\n\u0026lt;!-- https://mvnrepository.com/artifact/org.apache.dubbo/dubbo-spring-boot-starter --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.dubbo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;dubbo-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.8\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/com.github.sgroschupf/zkclient --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.sgroschupf\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zkclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.1\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-framework --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-framework\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.0\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.apache.curator/curator-recipes --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.2\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; 其中Curator是zookeeper分布式协调服务的java客户端库，它包装了一系列操作zk的高级API和实用库，是的操作zk变得更加容易和可靠。\n在provider项目中创建并注册服务 包目录都是就直接com.xxx，不要多一级，然后在provider项目的com.xxx路径下创建一个service目录，写一个简单的服务接口\npackage com.ccqstark.service; public interface TicketService { String getTicket(); } 然后是其实现\nimport com.ccqstark.service.TicketService; import org.apache.dubbo.config.annotation.DubboService; import org.springframework.stereotype.Component; @DubboService // 服务注册注解 @Component public class TicketServiceImpl implements TicketService { @Override public String getTicket(){ return \u0026#34;dubbo+zookeeper!\u0026#34;; } } 其中注解@DubboService 用来把该服务注册到zookeeper中\n修改provider项目的application.properties\n# 服务应用名称 dubbo.application.name=provider-server # 注册中心地址 dubbo.registry.address=zookeeper://[ip]:2181 # 被注册的服务 dubbo.scan.base-packages=com.ccqstark.service 然后启动项目，就可以在之前安装的dubbo中发现该服务了\n \n在consumer项目中调用服务 配置文件中增加配置\n# 消费者暴露的服务应用名称 dubbo.application.name=consumer-server # 注册中心地址 dubbo.registry.address=zookeeper://[ip]:2181 同样创建com.xxx.service包，把provider里的TicketService的接口文件复制过来\n创建一个调用此服务的例子\nimport org.apache.dubbo.config.annotation.DubboReference; import org.springframework.stereotype.Service; @Service public class UserService { @DubboReference // 获取注册中心中的服务  TicketService ticketService; public void buyTicket() { String ticket = ticketService.getTicket(); System.out.println(\u0026#34;调用provider的服务：\u0026#34; + ticket); } } 注解@DubboReference 用于获取注册中心的服务\n写个单元测试\n@SpringBootTest class ConsumerServerApplicationTests { @Autowired UserService userService; @Test void contextLoads() { userService.buyTicket(); } } 运行之后就可以发现consumer项目调用provider的服务成功！\n  最基本的服务注册发现与rpc调用大概是demo这样。\n参考自： bilibili\n","date":"2021-02-24T23:01:00+08:00","image":"https://ccqstark.github.io/p/dubbo_zookeeper/dubbo-zookeeper_huceb4a22a384e0271fe532efed4b00fee_48645_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/dubbo_zookeeper/","title":"Dubbo + ZooKeeper 基础入门"},{"content":"随着互联网的发展，Web应用与服务的规模不断扩大，才能满足不断增加的用户和需求。而原来只用一台服务器来部署的单机应用的方式已经满足不了如此大的需求。为了提高性能，单机发展为分布式架构，简单来说就是通过增加服务器的数量来弥补性能上的不足，当然同时也带来了一些问题。\n分布式系统 分布式系统（distributed system）是由一组网络进行通信，为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统是为了用单体性能普通的机器完成单个计算机无法完成的计算、存储任务，通过合理调度各台计算机共同合作来提高性能，完成数量更多、体量更大的任务。\n  比如百度或淘宝这样体量规模都十分大的应用，为了满足如此大的用户数量和请求压力，背后肯定不止一台计算机在提供服务，而是部署了计算机集群，通过提升计算机的数量来提高处理数据的能力。在流量高峰时，大量的请求可以被均匀地分配给各台服务器去处理，从而避免其中一台服务器由于压力过大而宕机，这就是负载均衡，也就是nginx可以做的事情。\n  同时应用的各个模块也可以分别部署在不同的服务器上，比如淘宝这样的电商项目可以把服务拆分成商品、支付、订单、物流等不同的模块，不同模块可以部署在不同的服务器上。当一个模块部署到多台服务器上时，其中一台崩了，还有其他的服务器可以提供服务，提高了服务的稳定性与高可用。\n  而对于用户来说，他们都是访问一个域名来获取服务的，所以对于用户来说服务还是一个整体，而不需要知道是哪台服务器为他们提供了服务。\nRPC 下图是Dubbo官方文档中的一张图，说明了网站应用的架构演变\n  原来应用是单体应用，程序如果要调用一个函数或方法就直接调用就行了，因为都是在本地。\n现在应用采用分布式架构，服务被分散到不同的服务器上，一台服务器上的程序就会遇到需要调用另一台服务器上的某个方法的情况，这个时候就叫RPC(远程过程调用)(Remote Procedure call)\nRPC的调用过程如下图：\n  通过网络发送调用消息就需要先序列化，到目标服务器后成功调用对应的服务后返回，反序列化得到结果。\nDubbo就是一个流行的RPC框架，提供面向接口代理的高性能RPC调用、智能负载均衡、服务自动注册与发现、高度可扩展能力、运行期流量调度（灰度发布）、可视化工具等功能。\n流动计算架构 当服务增多时，服务的管理与资源的分配成为亟待解决的问题，此时，需要增加一个调度中心基于访问压力实时管理集群容量，提高集群的利用率。用于提高机器利用率的资源调度和治理中心(SOA)(Service Oriented Architecture)就十分重要。\n服务通过在注册中心进行注册，被统一的管理起来并可被发现，并对用户开放。当用户需要用到某一服务时，就去注册中心拿，注册中心就会将对应的服务提供给他。\n  注册中心用的比较多的是Zookeeper\n","date":"2021-02-24T23:01:00+08:00","image":"https://ccqstark.github.io/p/distributed_rpc/dis-rpc_hueac48662f0ecf63cc9ad2fc947cb2254_27950_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/distributed_rpc/","title":"浅谈分布式系统与RPC"},{"content":"导入依赖 我们使用springboot操作es要用到对应的data相关starter\n\u0026lt;!-- elasticsearch的starter依赖 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-elasticsearch\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 将对象转为json传入source时要用 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.75\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt;  ⚠️ 各springboot的版本对应特定的elasticsearch版本，引入上面的依赖时会自动下载对应版本的rest-high-level-client，使用时尽量使得版本对应，避免潜在问题。\n 版本对应表如下：\n  我使用的这里用Springboot2.4.1，所以对应的elasticsearch是7.9.3版本\n配置类 config目录下新建es的配置类ElasticSearchClientConfig.java\n@Configuration public class ElasticSearchClientConfig { @Bean public RestHighLevelClient restHighLevelClient() { final CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(\u0026#34;elastic\u0026#34;, \u0026#34;[密码]\u0026#34;)); RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026#34;[ip]\u0026#34;, 9200, \u0026#34;http\u0026#34;)) .setHttpClientConfigCallback(httpClientBuilder -\u0026gt; { httpClientBuilder.disableAuthCaching(); return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); })); return client; } } 这里有用到x-pack基础安全功能，所以配置了用户和密码。如果没有用户和密码，参照官方文档连接代码如下：\nRestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026#34;localhost\u0026#34;, 9200, \u0026#34;http\u0026#34;), new HttpHost(\u0026#34;localhost\u0026#34;, 9201, \u0026#34;http\u0026#34;))); 使用客户端连接 使用时@Autowired一下，用自定义名字时就@Qualifier一下，不然就得对应上面的方法名\n@Autowired @Qualifier(\u0026#34;restHighLevelClient\u0026#34;) private RestHighLevelClient client; 索引相关操作 创建索引 void testCreateIndex() throws IOException { // 1. 创建索引请求  CreateIndexRequest request = new CreateIndexRequest(\u0026#34;test\u0026#34;); // 2. 执行请求  CreateIndexResponse createIndexResponse = client.indices().create(request, RequestOptions.DEFAULT); System.out.println(createIndexResponse); } 判断索引是否存在 void testExistIndex() throws IOException { GetIndexRequest request = new GetIndexRequest(\u0026#34;test2\u0026#34;); boolean exists = client.indices().exists(request, RequestOptions.DEFAULT); System.out.println(exists); } 删除索引 void testDeleteIndex() throws IOException { DeleteIndexRequest request = new DeleteIndexRequest(\u0026#34;test\u0026#34;); AcknowledgedResponse delete = client.indices().delete(request, RequestOptions.DEFAULT); System.out.println(delete.isAcknowledged()); } 文档相关操作 添加文档 void testAddDocument() throws IOException { // 创建对象  User user = new User(\u0026#34;ccqstark\u0026#34;, 20); // 创建请求  IndexRequest request = new IndexRequest(\u0026#34;test\u0026#34;); // 规则 put /test/_doc/1  request.id(\u0026#34;1\u0026#34;); // 设置超时时间，可以不写，有默认参数  request.timeout(TimeValue.timeValueSeconds(1)); request.timeout(\u0026#34;1s\u0026#34;); // 将数据放入请求  request.source(JSON.toJSONString(user), XContentType.JSON); // 客户端发送请求  IndexResponse indexResponse = client.index(request, RequestOptions.DEFAULT); System.out.println(indexResponse.toString()); System.out.println(indexResponse.status()); // 对应返回的状态 } 批量插入文档 void testBulkRequest() throws IOException { BulkRequest bulkRequest = new BulkRequest(); // 数据量多的话超时时间可以设置长一点  bulkRequest.timeout(\u0026#34;10s\u0026#34;); List\u0026lt;User\u0026gt; userList = new ArrayList\u0026lt;\u0026gt;(); userList.add(new User(\u0026#34;ccq1\u0026#34;, 1)); userList.add(new User(\u0026#34;ccq2\u0026#34;, 2)); userList.add(new User(\u0026#34;ccq3\u0026#34;, 3)); userList.add(new User(\u0026#34;ccq4\u0026#34;, 4)); userList.add(new User(\u0026#34;ccq5\u0026#34;, 5)); // 批处理请求  for (int i = 0; i \u0026lt; userList.size(); i++) { bulkRequest.add( // 批量更新或批量删除，就在这里修改对应的请求即可. 不指定id会自动生成随机不重复id  new IndexRequest(\u0026#34;test\u0026#34;) .id(\u0026#34;\u0026#34; + (i + 1)) .source(JSON.toJSONString(userList.get(i)), XContentType.JSON)); } BulkResponse bulkResponse = client.bulk(bulkRequest, RequestOptions.DEFAULT); // 是否失败，false代表成功  System.out.println(bulkResponse.hasFailures()); } 判断文档是否存在 void testIsExists() throws IOException { GetRequest getRequest = new GetRequest(\u0026#34;test\u0026#34;, \u0026#34;1\u0026#34;); // 不获取返回的_source上下文了  getRequest.fetchSourceContext(new FetchSourceContext(false)); // 排序的字段  getRequest.storedFields(\u0026#34;_none_\u0026#34;); boolean exist = client.exists(getRequest, RequestOptions.DEFAULT); System.out.println(exist); } 获取文档信息 void testGetDocument() throws IOException { // index id  GetRequest getRequest = new GetRequest(\u0026#34;test\u0026#34;, \u0026#34;1\u0026#34;); GetResponse getResponse = client.get(getRequest, RequestOptions.DEFAULT); // 返回的全部内容，和用命令获取的结果一样  System.out.println(getResponse); // 以map获取结果的source  System.out.println(getResponse.getSourceAsMap()); // 以string获取结果source  System.out.println(getResponse.getSourceAsString()); } 更新文档 void testUpdateDocument() throws IOException { UpdateRequest updateRequest = new UpdateRequest(\u0026#34;test\u0026#34;, \u0026#34;1\u0026#34;); updateRequest.timeout(\u0026#34;1s\u0026#34;); User user = new User(\u0026#34;ccq java\u0026#34;, 18); updateRequest.doc(JSON.toJSONString(user), XContentType.JSON); UpdateResponse updateResponse = client.update(updateRequest, RequestOptions.DEFAULT); System.out.println(updateResponse.status()); } 删除文档 void deleteDocument() throws IOException { DeleteRequest deleteRequest = new DeleteRequest(\u0026#34;test\u0026#34;, \u0026#34;3\u0026#34;); DeleteResponse deleteResponse = client.delete(deleteRequest, RequestOptions.DEFAULT); System.out.println(deleteResponse.status()); } 高级查询 void testSearch() throws IOException { // SearchRequest 搜索请求  // SearchSourceBuilder 搜索条件构造  SearchRequest searchRequest = new SearchRequest(\u0026#34;test\u0026#34;); SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); // 不同查询方式都在这里设置  // QueryBuilders.termQuery() 精确查询  // QueryBuilders.matchAllQuery() 匹配所有  TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\u0026#34;name\u0026#34;, \u0026#34;ccq\u0026#34;); sourceBuilder.query(termQueryBuilder); sourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); // 分页  sourceBuilder.from(0); sourceBuilder.size(10); // 高亮  HighlightBuilder highlightBuilder = new HighlightBuilder(); // 设置高亮的字段  highlightBuilder.field(\u0026#34;name\u0026#34;); // 多个匹配字高亮  highlightBuilder.requireFieldMatch(true); // 设置高亮标签  highlightBuilder.preTags(\u0026#34;\u0026lt;span style=\\\u0026#34;color:#ffd73b\\\u0026#34;\u0026gt;\u0026#34;); highlightBuilder.postTags(\u0026#34;\u0026lt;/span\u0026gt;\u0026#34;); sourceBuilder.highlighter(highlightBuilder); // 执行搜索  searchRequest.source(sourceBuilder); SearchResponse searchResponse = client.search(searchRequest, RequestOptions.DEFAULT); System.out.println(JSON.toJSONString(searchResponse.getHits())); System.out.println(\u0026#34;=========================================\u0026#34;); for (SearchHit hit : searchResponse.getHits()) { // 获取高亮字段  Map\u0026lt;String, HighlightField\u0026gt; highlightFields = hit.getHighlightFields(); HighlightField highlightName = highlightFields.get(\u0026#34;name\u0026#34;); // 原来的结果  Map\u0026lt;String, Object\u0026gt; sourceAsMap = hit.getSourceAsMap(); // 用高亮替换原来的，这里要判断一个是否为空，因为有可能没有高亮结果  if (highlightName != null) { Text[] fragments = highlightName.fragments(); // 只有当要高亮搜索当字段是数组类型fragments才会有多个元素，如果是单字段就去第0个就行  sourceAsMap.put(\u0026#34;name\u0026#34;, fragments[0]); } System.out.println(sourceAsMap); } } 参考自狂神的ElasticSearch教程： 【狂神说Java】ElasticSearch7.6.x最新完整教程通俗易懂\n","date":"2021-02-04T23:01:00+08:00","image":"https://ccqstark.github.io/p/springboot_es/springboot-es_hu5dbd9828aef42d61c56fd952a73b2be9_64126_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/springboot_es/","title":"[SpringBoot]整合ElasticSearch"},{"content":"基本的rest命令    method url 功能     PUT localhost:9200/索引名称/类型名称/文档id 创建文档（指定文档id)   POST localhost:9200/索引名称/类型名称 创建文档（随机文档id）   POST localhost:9200/索引名称/类型名称/文档id/_update 修改文档   DELETE localhost:9200/索引名称/类型名称/文档id 删除文档   GET localhost:9200/索引名称/类型名称/文档id 查询文档，通过文档id   POST localhost:9200/索引名称/类型名称/_search 查询所有数据     ⚠️ 自定义类型将在以后的版本中弃用，规范起见一律使用_doc 类型\n 文档字段的数据类型   字符串类型\ntext keyword\n  数值类型\nlong integer short byte double float half float scaled float\n  日期类型\ndate\n  布尔类型\nboolean\n  二进制类型\nbinary\n等等\u0026hellip;..\n  基本操作  创建一个文档，如果索引不存在也会一起创建  PUT /test/_doc/1 { \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34;, \u0026#34;age\u0026#34;:3 } 没有指定字段的数据类型，es会默认配置\n 指定字段数据类型创建索引  PUT /test2 { \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;age\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, \u0026#34;birthday\u0026#34;:{ \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; } } } }  基本查询  # 查询索引库信息 GET /{index} # 查询具体某一文档 GET /{index}/_doc/{id}  查询es参数  GET _cat/[参数项]  PUT更新  PUT /{index}/_doc/{id} { \u0026#34;name\u0026#34;:\u0026#34;ccqstark666\u0026#34;, \u0026#34;age\u0026#34;:3 } 直接在对应字段写上更新后的信息，会覆盖旧的值\n如果漏了原来有的字段，那么这些字段会被删除，所以不推荐使用\n POST更新**（推荐）**  POST **/{index}/_update/{id}** { \u0026#34;doc\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark555\u0026#34; } } 被修改的文档的\u0026quot;_version\u0026quot;会递增1\n 删除  # 删除索引库 DELETE /{index} # 删除文档 DELETE /{index}/_doc/{id}  简单条件查询  GET /test/_doc/_search?q=name:ccqstark  ⚠️ 如果字段类型是keyword ，说明不可分割，查询的时候分词器不会分割这个词来搜索，而是当成一个整体，而text 类型可以被分词器解析\n  😮 查询出来的\u0026quot;hits\u0026quot;里有\u0026quot;_score\u0026quot;是说明匹配度的分数值，匹配度越高，分数越高\n 复杂(花式)搜索  match 查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34; } } } match不是精确搜索，会使用分词器解析再搜索（默认自带分词器把英文按空格分词，中文是每一个字都分开）\n使用json构建查询参数体\n\u0026#34;hits\u0026#34; : { \u0026#34;total\u0026#34; : { \u0026#34;value\u0026#34; : 3, \u0026#34;relation\u0026#34; : \u0026#34;eq\u0026#34; } 查询结果中的 hits里有个total的value，为查询结果的总数量\n 过滤查询结果的字段  GET /test/_doc/_search { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34; } }, \u0026#34;_source\u0026#34;:[\u0026#34;name\u0026#34;,\u0026#34;age\u0026#34;] } \u0026quot;_source\u0026quot; 可以用来指定查询结果中的字段，相当于select xxx,xxx\n 结果排序  GET /test/_doc/_search { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34; } }, \u0026#34;sort\u0026#34;:{ \u0026#34;age\u0026#34;:{ \u0026#34;order\u0026#34;:\u0026#34;desc\u0026#34; } } } 这里 \u0026quot;sort\u0026quot; 指定age为用来排序的字段，\u0026quot;order\u0026quot; 为排序方式\n升序：asc\n降序：desc\n 分页查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;:{ \u0026#34;match\u0026#34;:{ \u0026#34;name\u0026#34;:\u0026#34;ccqstark\u0026#34; } }, \u0026#34;from\u0026#34;:0, \u0026#34;size\u0026#34;:2 } “from”是从第几页开始，第一页为0\n“size”是每页多少条数据\n bool查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ccqstark\u0026#34; } }, { \u0026#34;match\u0026#34;: { \u0026#34;age\u0026#34;: 100 } } ] } } } 用bool可以实现多条件查询\n这里的must相当于and，也就是所有条件都要符合\n也可以用should ，相当于or\n还有must_not ，相当于not\n bool嵌套  GET /my_store/products/_search { \u0026#34;query\u0026#34; : { \u0026#34;filtered\u0026#34; : { \u0026#34;filter\u0026#34; : { \u0026#34;bool\u0026#34; : { \u0026#34;should\u0026#34; : [ { \u0026#34;term\u0026#34; : {\u0026#34;productID\u0026#34; : \u0026#34;KDKE-B-9947-#kL5\u0026#34;}}, { \u0026#34;bool\u0026#34; : { \u0026#34;must\u0026#34; : [ { \u0026#34;term\u0026#34; : {\u0026#34;productID\u0026#34; : \u0026#34;JODL-X-1937-#pV7\u0026#34;}}, { \u0026#34;term\u0026#34; : {\u0026#34;price\u0026#34; : 30}} ] }} ] } } } } } bool查询里再套一个bool，就相当于加了个括号：( A or ( B and C ))\n filter 查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must_not\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;陈楚权\u0026#34; } } ], \u0026#34;filter\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;age\u0026#34;: { \u0026#34;gte\u0026#34;: 66, \u0026#34;lte\u0026#34;: 100 } } } } } } range 表示范围查询，age 指定了字段\n范围查询表达式\n   表达式 表示     gt \u0026gt;   gte \u0026gt;=   lt \u0026lt;   lte \u0026lt;=     多关键词查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ccq java\u0026#34; } } ] } } } 用空格隔开关键词就行\n term精确查询  GET /test3/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;should\u0026#34;: [ { \u0026#34;term\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ccq说java\u0026#34; } } ] } } }  ⚠️ 使用term查询要求字段为keyword类型才能匹配出来\n term是精确查询，于match会用分词器解析不同，term是直接通过倒排索引指定的词条进行精确查找\n \n 高亮查询  GET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;java\u0026#34; } }, \u0026#34;highlight\u0026#34;: { \u0026#34;fields\u0026#34;: { \u0026#34;name\u0026#34;: {} } } } 返回值中的highlight字段里会有带高亮标签的搜索结果，默认标签为\u0026lt;em\u0026gt;，效果如下\n{ \u0026#34;_index\u0026#34; : \u0026#34;test\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;_doc\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;6\u0026#34;, \u0026#34;_score\u0026#34; : 1.1631508, \u0026#34;_source\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;ccq说java\u0026#34;, \u0026#34;age\u0026#34; : 100 }, \u0026#34;highlight\u0026#34; : { \u0026#34;name\u0026#34; : [ \u0026#34;ccq说\u0026lt;em\u0026gt;java\u0026lt;/em\u0026gt;\u0026#34; ] } } 高亮标签可以自定义，用前标签pre_tags和后标签post_tags 来指定\nGET /test/_doc/_search { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;java\u0026#34; } }, \u0026#34;highlight\u0026#34;: { \u0026#34;pre_tags\u0026#34;: \u0026#34;\u0026lt;p class=\u0026#39;key\u0026#39; style=\u0026#39;color:red\u0026#39;\u0026gt;\u0026#34;, \u0026#34;post_tags\u0026#34;: \u0026#34;\u0026lt;/p\u0026gt;\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;name\u0026#34;: {} } } } 参考自狂神的ElasticSearch教程： 【狂神说Java】ElasticSearch7.6.x最新完整教程通俗易懂\n","date":"2021-02-03T23:01:00+08:00","image":"https://ccqstark.github.io/p/es_rest/restful_hud0b30a641456616a14ef2ef618957a76_22844_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/es_rest/","title":"[ElasticSearch]REST风格操作"},{"content":"由于这几天开始看《CS:APP》，我就开始寻求一款Mac上的轻量的C语言编辑器。找来找去，无非是VSCode、CLion和大名鼎鼎的Vim。\n为了减少磁盘占用同时让自己更接近于底层，我还是硬着头皮折腾起了Vim，这个上古神器之前就一直让我望而却步，我对它的掌握程度也差不多是会退出的程度，这一次就打算好好来折腾下。\n安装NeoVim Vim其实到目前为止，不同的分支版本还是很多的，比较流行的现代版本就要属NeoVim了，所以我在终端安装了它，用iTerm2运行着。\nbrew install neovim 安装完成后用nvim命令就可以打开\nnvim 配置文件路径\n传统的vim的配置配置文件为~/.vimrc\n而nvim的配置文件为/.config/nvim/init.vim ，之后修改nvim配置文件就用这个，以下简称为init.vim\n安装SpaceVim 作为小白，快速搭建一个好看实用的Vim开发环境那最好的选择就是SpaceVim 了，下面是官方的介绍：\n SpaceVim 是一个社区驱动的模块化的 Vim IDE，以模块的方式组织管理插件以及相关配置， 为不同的语言开发量身定制了相关的开发模块，该模块提供代码自动补全， 语法检查、格式化、调试、REPL 等特性。用户仅需载入相关语言的模块即可得到一个开箱即用的 Vim IDE。\n 官网地址：\n主页 | SpaceVim\n官网的文档还是很全的，按官方文档就可以快速搭建出来了。以MacOS为例：\n安装spacevim\ncurl -sLf https://spacevim.org/cn/install.sh | bash 完成后重新打开nvim就会自动下载相关插件。\n然后就是主界面：\n  主题的修改可以参考官方文档\nSpaceVim colorscheme 模块 | SpaceVim\n快捷键符号说明\nSPC 代表空格\n\u0026lt;Leader\u0026gt; 默认为\\\n以下一些功能需要对mac进行一定的设置才能正常使用。\n打开系统偏好设置 → 键盘\n勾选将F1、F2等键用作标准功能键\n这同时也解决了Chrome的F12 不能打开控制台的问题\n  文件目录树\n按F3 可以打开或关闭\n语法函数树\n按F2可以打开或关闭\nmac下可能会出现错误，解决方案：\nbrew install ctags-exuberant 然后init.vim里添加下面这行即可\nlet g:Tlist_Ctags_Cmd=\u0026#39;/usr/local/Cellar/ctags/5.8_1/bin/ctags\u0026#39; shell终端\nSPC ' 即可打开系统shell，如果用了oh-my-zsh主题什么的也会保留的\n配置C/C++环境 spacevim对大部分语言都有相关支持，文档也齐全，比如我需要的C语言环境：\n使用 Vim 搭建 C/C++ 开发环境 | SpaceVim\n按照官方文档修改spacevim的配置文件~/.SpaceVim.d/init.toml 即可，以下简称init.toml\n对于自带的模块基本只需要添加[[layers]]\n# 语法高亮 [[layers]] name = \u0026#39;lang#c\u0026#39; enable_clang_syntax_highlight = true # 代码格式化 [[layers]] name = \u0026#34;format\u0026#34; # 语法检查 [[layers]] name = \u0026#34;checkers\u0026#34; spacevim内置的模块还是很多的，但是很多功能相对简陋，为了实现更好的效果，我们还需要安装其他的插件。\n安装插件管理器vim-plug 虽然SpaceVim已经自带插件管理工具，在init.toml 里添加\n[[custom_plugins]] repo = \u0026#34;插件的github地址\u0026#34; 重启后即可自动下载\n用spacevim管理的这些从github上下载的插件存储在~/.cache/vimfiles/repos/github.com/\n这个自带的插件管理器大部分情况下还可以，但是有时不太好使，所以我选择多下载一个vim的主流插件管理器vim-plug\n使用curl安装，下面一条命令就够\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\  https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 如果遇到了Connection refused的错误，使用SwitchHosts! ，添加以下的host：\n199.232.68.133 raw.githubusercontent.com 199.232.68.133 user-images.githubusercontent.com 199.232.68.133 avatars2.githubusercontent.com 199.232.68.133 avatars1.githubusercontent.com 使用插件管理器安装新的插件的方法是，在init.vim 配置文件里添加：\ncall plug#begin() call plug#end() 然后把要安装的插件添加到这两行代码中间，以Plug 'xxx/xxx' 的格式，如：\ncall plug#begin() Plug \u0026#39;junegunn/vim-easy-align\u0026#39; call plug#end() 之后重启nvim，使用命令:PlugInstall 就可以安装了。\n若要卸载插件，就从配置文件中去除相应的那一行，然后使用命令:PlugClean 就可以卸载了。\n安装Coc.nvim SpaceVim自带的补全还行，但是为了达到效果更好的补全和语法检查，我选择安装插件coc.nvim\nneoclide/coc.nvim\n这可以说是神器了，除了基本的补全之外，还提供了众多扩展来支持不同的语言和不同的特性。\n用之前下的vim-plug 来安装\nPlug \u0026#39;neoclide/coc.nvim\u0026#39;, {\u0026#39;branch\u0026#39;: \u0026#39;release\u0026#39;} 安装完后可以先直接把官方的示例配置文件粘贴进init.vim，示例配置文件在github的readme里有。\n为了C语言更好的补全支持，我下载相关的coc扩展——coc-clangd\nneoclide/coc.nvim\n首先保证有node环境，然后运行以下命令安装coc-clangd\n:CocInstall coc-clangd 完成后打开一个c语言文件，若提示找不到clangd，则自己手动下载。\n进入github release页面下载clangd-mac-11.0.0.zip\nRelease 11.0.0 · clangd/clangd\n解压后目录下有一个bin文件夹和一个lib文件夹\n将bin下的clangd文件移动至/usr/local/bin/目录下\n将lib目录下的clang文件夹移动至~/Library/目录下\n再次打开即可正常使用，注意把spacevim自带的补全给禁用\n[[layers]] name = \u0026#39;autocomplete\u0026#39; enable = false 效果如下：\n  可以看到代码提示效果是非常好的\n当然，里面还有很多很实用的扩展也可以根据需要下\n括号引号自动补全 coc.nvim插件对于括号和引号还是没有自动补成一对的功能，可以在init.vim里添加\ninoremap ( ()\u0026lt;Esc\u0026gt;i inoremap [ []\u0026lt;Esc\u0026gt;i inoremap { {\u0026lt;CR\u0026gt;}\u0026lt;Esc\u0026gt;O autocmd Syntax html,vim inoremap \u0026lt; \u0026lt;lt\u0026gt;\u0026gt;\u0026lt;Esc\u0026gt;i| inoremap \u0026gt; \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;\u0026gt;\u0026#39;)\u0026lt;CR\u0026gt; inoremap ) \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;)\u0026#39;)\u0026lt;CR\u0026gt; inoremap ] \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;]\u0026#39;)\u0026lt;CR\u0026gt; inoremap } \u0026lt;c-r\u0026gt;=CloseBracket()\u0026lt;CR\u0026gt; inoremap \u0026#34; \u0026lt;c-r\u0026gt;=QuoteDelim(\u0026#39;\u0026#34;\u0026#39;)\u0026lt;CR\u0026gt; inoremap \u0026#39; \u0026lt;c-r\u0026gt;=QuoteDelim(\u0026#34;\u0026#39;\u0026#34;)\u0026lt;CR\u0026gt; function ClosePair(char) if getline(\u0026#39;.\u0026#39;)[col(\u0026#39;.\u0026#39;) - 1] == a:char return \u0026#34;\\\u0026lt;Right\u0026gt;\u0026#34; else return a:char endif endf function CloseBracket() if match(getline(line(\u0026#39;.\u0026#39;) + 1), \u0026#39;\\s*}\u0026#39;) \u0026lt; 0 return \u0026#34;\\\u0026lt;CR\u0026gt;}\u0026#34; else return \u0026#34;\\\u0026lt;Esc\u0026gt;j0f}a\u0026#34; endif endf function QuoteDelim(char) let line = getline(\u0026#39;.\u0026#39;) let col = col(\u0026#39;.\u0026#39;) if line[col - 2] == \u0026#34;\\\\\u0026#34; return a:char elseif line[col - 1] == a:char return \u0026#34;\\\u0026lt;Right\u0026gt;\u0026#34; else return a:char.a:char.\u0026#34;\\\u0026lt;Esc\u0026gt;i\u0026#34; endif endf 彩虹括号 vim里也有类似vscode或IDEA那样的彩虹括号插件\nPlug \u0026#39;luochen1990/rainbow\u0026#39; #或 repo = \u0026#39;luochen1990/rainbow\u0026#39; init.vim 添加\nlet g:rainbow_active = 1 let g:rainbow_conf = { \\  \u0026#39;guifgs\u0026#39;: [\u0026#39;darkorange3\u0026#39;, \u0026#39;seagreen3\u0026#39;, \u0026#39;royalblue3\u0026#39;, \u0026#39;firebrick\u0026#39;], \\  \u0026#39;ctermfgs\u0026#39;: [\u0026#39;lightyellow\u0026#39;, \u0026#39;lightcyan\u0026#39;,\u0026#39;lightblue\u0026#39;, \u0026#39;lightmagenta\u0026#39;], \\  \u0026#39;operators\u0026#39;: \u0026#39;_,_\u0026#39;, \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/ fold\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/ fold\u0026#39;, \u0026#39;start=/{/ end=/}/ fold\u0026#39;], \\  \u0026#39;separately\u0026#39;: { \\  \u0026#39;*\u0026#39;: {}, \\  \u0026#39;tex\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/\u0026#39;], \\  }, \\  \u0026#39;lisp\u0026#39;: { \\  \u0026#39;guifgs\u0026#39;: [\u0026#39;darkorange3\u0026#39;, \u0026#39;seagreen3\u0026#39;, \u0026#39;royalblue3\u0026#39;, \u0026#39;firebrick\u0026#39;], \\  }, \\  \u0026#39;vim\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/\u0026#39;, \u0026#39;start=/{/ end=/}/ fold\u0026#39;, \u0026#39;start=/(/ end=/)/ containedin=vimFuncBody\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/ containedin=vimFuncBody\u0026#39;, \u0026#39;start=/{/ end=/}/ fold containedin=vimFuncBody\u0026#39;], \\  }, \\  \u0026#39;html\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/\\v\\\u0026lt;((area|base|br|col|embed|hr|img|input|keygen|link|menuitem|meta|param|source|track|wbr)[ \u0026gt;])@!\\z([-_:a-zA-Z0-9]+)(\\s+[-_:a-zA-Z0-9]+(\\=(\u0026#34;[^\u0026#34;]*\u0026#34;|\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;[^\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;]*\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;|[^ \u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;\u0026#34;\u0026gt;\u0026lt;=`]*))?)*\\\u0026gt;/ end=#\u0026lt;/\\z1\u0026gt;# fold\u0026#39;], \\  }, \\  \u0026#39;css\u0026#39;: 0, \\  } \\} 安装CtrlP CtrlP是vim下一款很好的文件模糊搜索跳转插件\nkien/ctrlp.vim\n安装\nrepo = \u0026#39;kien/ctrlp.vim\u0026#39; 使用\n:CtrlP [要搜索的目录] 如果目录下的文件过多，比如系统根目录，就会花比较多的时间去索引。所以建议尽量缩小范围。\n之后便可以输入关键字进行搜索了\n \n其他插件 比如更好的代码格式化vim-clang-format和代码时间记录wakatime\nrhysd/vim-clang-format\nwakatime/vim-wakatime\n基本上想要的插件都可以在github上找到，根据官方文档使用即可\n常用快捷键 SPC 1/2/3 切换不同窗口，数字为窗口编号\nSPC l r 运行代码\nSPC b f 代码格式化\ng d 函数跳转\n\u0026lt;c-o\u0026gt; 回调到上次的位置（这个写法表示ctrl+o）\n更多功能可以SPC空格键唤出菜单查看\n尾声 到此一个基本的vim编程环境已经搭好了，用来写点小东西还是够用的。\n这一套折腾下来最大的感受是曾经觉得vim好难学好难用，但是通过这几天捣鼓之后发现只要熟练了其实效率还是很高的。难怪至今还有很多vim的使用者和爱好者。同时自己安装各种插件，修改配置文件，通过自定义来获得一款完全属于自己的编辑器的过程也是充满乐趣的，我很享受这个过程。\n","date":"2021-01-31T21:26:00+08:00","image":"https://ccqstark.github.io/p/vim/vim_hu721b1231aff42422e86b1dd0b5ea6e91_94583_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/vim/","title":"我的vim入门配置折腾"},{"content":"ElacticSearch索引中有大量的数据，如果没有一些安全措施的话会让系统处于一个十分危险的处境，引发的相关安全事件可以看看这篇文章。\n你的Elasticsearch在\u0026quot;裸奔\u0026quot;吗？\n而ElaticSearch官方的高级安全服务是收费的，主要给企业提供。但是从6.8和7.1版本开始，基础安全功能就免费了，而且已经集成在里面不用额外安装。\n除此之外诸如Search Guard、ReadonlyREST、Nginx 等开源免费等方法来达到安全的目的，这里介绍的是使用官方的x-pack的基础安全功能，对于小项目来说够用了。\n本文版本为7.10.1\n修改配置文件 在elasticsearch.yml里新增\nxpack.security.enabled:truexpack.security.transport.ssl.enabled:true之后重启 es\n在es目录下执行 elasticsearch-setup-passwords interactive 然后输入多个用户的密码\nInitiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: Reenter password for [elastic]: Passwords do not match. Try again. Enter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana]: Reenter password for [kibana]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: Changed password for user [apm_system] Changed password for user [kibana] Changed password for user [logstash_system] Changed password for user [beats_system] Changed password for user [remote_monitoring_user] Changed password for user [elastic] 其中elastic用户相当与es的root用户，之后使用es和kibana需要这个用户的密码\n设置完重启一下es\n测试 curl -GET -u elastic http://[ip]:9200/ 发现提示输入elastic用户的密码\nEnter host password for user \u0026#39;elastic\u0026#39;: 基本的安全就实现了，之后进一步防止暴力破解密码可以再使用iptables\nKibana设置 修改kibana.yml\nelasticsearch.username:\u0026#34;elastic\u0026#34;elasticsearch.password:\u0026#34;[密码]\u0026#34;xpack:apm.ui.enabled:falsegraph.enabled:falseml.enabled:falsemonitoring.enabled:falsereporting.enabled:falsesecurity.enabled:true# 这里要打开grokdebugger.enabled:falsesearchprofiler.enabled:false之后进入kibana进入登陆界面\n  用elastic用户和密码登陆即可\n代码中配置 Java High Level REST Client中配置账户和密码\nfinal CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(\u0026#34;elastic\u0026#34;, \u0026#34;123456\u0026#34;)); //es账号密码（默认用户名为elastic）  RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026#34;localhost\u0026#34;, 9200, \u0026#34;http\u0026#34;)) .setHttpClientConfigCallback(new RestClientBuilder.HttpClientConfigCallback() { public HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpClientBuilder) { httpClientBuilder.disableAuthCaching(); return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); } })); SpringBoot的配置文件\nspring.elasticsearch.rest.username=elasticspring.elasticsearch.rest.password=123456修改密码 curl -H \u0026#34;Content-Type:application/json\u0026#34; -XPOST -u elastic \u0026#39;http://127.0.0.1:9200/_xpack/security/user/elastic/_password\u0026#39; -d \u0026#39;{ \u0026#34;password\u0026#34; : \u0026#34;123456\u0026#34; }\u0026#39; 结尾 这里只是单节点示例，集群以及证书相关可以参看官方文档\n通过 TLS 加密和基于角色的访问控制确保 Elasticsearch 的安全\n","date":"2021-01-29T21:26:00+08:00","image":"https://ccqstark.github.io/p/x_pack/x-pack_huc4207ebc9b333ece948f0ec8e981e0d7_15854_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/x_pack/","title":"[Elastic]ElasticSearch 安全"},{"content":"安装logstash 在实际项目中使用es进行搜索，我们就要把mysql数据库中的数据同步到es索引库中。进行这项过程的工具很多，比如go-mysql-elasticsearch，canal等等，当然也可以使用ELK组合中的logsatsh 来完成。这里同样用docker来部署logstash容器。\n拉取镜像 docker pull logstash:7.10.1 启动容器 启动后进入容器内，修改jvm启动的内存设置，地址为/usr/share/logstash/config/jvm.options\n# 修改jvm内存分配 vi jvm.options # 修改下面的参数，单位可以为g和m -Xms256m -Xmx256m 修改后重启容器即可\n下载插件与依赖包 docker exec -it logstash bash 安装logstash-input-jdbc插件\nbin/logstash-plugin install logstash-input-jdbc 如果出现以下ERROR，说明logstash里本身已经包含有这个插件了，就无需安装。7.10.1的版本是已经自带了。\nERROR: Installation aborted, plugin \u0026#39;logstash-input-jdbc\u0026#39; is already provided by \u0026#39;logstash-integration-jdbc\u0026#39; 下载mysql-connector-java，也就是jdbc驱动\nMySQL官方下载地址：https://downloads.mysql.com/archives/c-j/\n下载对应版本后本地解压，上传到服务器，然后用docker cp命令复制到logstash容器中\n只需要其中的jar包即可\n# 把文件复制到容器内 docker cp [jar包路径] logstash:[容器内路径] 在/usr/share/logstash目录下新建mysql/目录，把jar包复制到这里\n同步配置文件 在刚刚的mysql目录下新建jdbc.conf 文件，来配置同步操作\n 单表同步  input { jdbc { # jar包的绝对路径 jdbc_driver_library =\u0026gt; \u0026#34;/usr/share/logstash/mysql/mysql-connector-java-5.1.48.jar\u0026#34; jdbc_driver_class =\u0026gt; \u0026#34;com.mysql.jdbc.Driver\u0026#34; # 数据库连接信息 jdbc_connection_string =\u0026gt; \u0026#34;jdbc:mysql://[ip]:3306/[库名]?characterEncoding=UTF-8\u0026amp;autoReconnect=true\u0026#34; jdbc_user =\u0026gt; \u0026#34;[mysql用户]\u0026#34; jdbc_password =\u0026gt; \u0026#34;[密码]\u0026#34; # cron的定时执行语法一样，默认每分钟同步一次 schedule =\u0026gt; \u0026#34;* * * * *\u0026#34; # 执行的sql语句语法，这里是通过将主键大于最后一次同步所记录的值来实现增量同步的 statement =\u0026gt; \u0026#34;SELECT * FROM activity WHERE activity_id \u0026gt; :sql_last_value order by activity_id asc\u0026#34; use_column_value =\u0026gt; true # 用来作为增量同步的判断字段，最好为表的主键 tracking_column =\u0026gt; \u0026#34;activity_id\u0026#34; # 是否记录上次执行结果，true表示会将上次执行结果的tracking_column字段的值保存到last_run_metadata_path指定的文件中； record_last_run =\u0026gt; true # record_last_run上次数据存放位置 last_run_metadata_path =\u0026gt; \u0026#34;/usr/share/logstash/mysql/last_id.txt\u0026#34; # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false clean_run =\u0026gt; false } } output{ elasticsearch{ hosts =\u0026gt; [\u0026#34;[ip]:9200\u0026#34;] index =\u0026gt; \u0026#34;[索引名]\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{activity_id}\u0026#34; } stdout { codec =\u0026gt; rubydebug } }  多表同步  多表配置和单表配置的区别在于input模块的jdbc模块有几个type，output模块就需对应有几个type\ninput { stdin {} jdbc { # 多表同步时，表类型区分，建议命名为“库名_表名”，每个jdbc模块需对应一个type； type =\u0026gt; \u0026#34;TestDB_DetailTab\u0026#34; # 其他配置此处省略，参考单表配置 # ... # ... # record_last_run上次数据存放位置； last_run_metadata_path =\u0026gt; \u0026#34;mysql\\last_id.txt\u0026#34; # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false； clean_run =\u0026gt; false # # 同步频率(分 时 天 月 年)，默认每分钟同步一次； schedule =\u0026gt; \u0026#34;* * * * *\u0026#34; } jdbc { # 多表同步时，表类型区分，建议命名为“库名_表名”，每个jdbc模块需对应一个type； type =\u0026gt; \u0026#34;TestDB_Tab2\u0026#34; # 多表同步时，last_run_metadata_path配置的路径应不一致，避免有影响； # 其他配置此处省略 # ... # ... } } filter { json { source =\u0026gt; \u0026#34;message\u0026#34; remove_field =\u0026gt; [\u0026#34;message\u0026#34;] } } output { # output模块的type需和jdbc模块的type一致 if [type] == \u0026#34;TestDB_DetailTab\u0026#34; { elasticsearch { # host =\u0026gt; \u0026#34;192.168.1.1\u0026#34; # port =\u0026gt; \u0026#34;9200\u0026#34; # 配置ES集群地址 hosts =\u0026gt; [\u0026#34;192.168.1.1:9200\u0026#34;, \u0026#34;192.168.1.2:9200\u0026#34;, \u0026#34;192.168.1.3:9200\u0026#34;] # 索引名字，必须小写 index =\u0026gt; \u0026#34;detailtab1\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{KeyId}\u0026#34; } } if [type] == \u0026#34;TestDB_Tab2\u0026#34; { elasticsearch { # host =\u0026gt; \u0026#34;192.168.1.1\u0026#34; # port =\u0026gt; \u0026#34;9200\u0026#34; # 配置ES集群地址 hosts =\u0026gt; [\u0026#34;192.168.1.1:9200\u0026#34;, \u0026#34;192.168.1.2:9200\u0026#34;, \u0026#34;192.168.1.3:9200\u0026#34;] # 索引名字，必须小写 index =\u0026gt; \u0026#34;detailtab2\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{KeyId}\u0026#34; } } stdout { codec =\u0026gt; json_lines } } 为了统一，把数据也放这个目录下，在mysql目录下再新建目录data\nmkdir data 启动logstash同步 cd回到/usr/share/logstash目录，启动同步\n./bin/logstash -f mysql/jdbc.conf --path.data=/usr/share/logstash/mysql/data/ 注意，要保证给elasticsearch的分配的内存足够大才行，测试用的256m是不够的，会导致es容器退出，至少给个1g\n—-path.data参数用来设置同步数据存放的位置\n启动之后控制台会打印出大概以下信息\nUsing bundled JDK: /usr/share/logstash/jdk OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. WARNING: An illegal reflective access operation has occurred WARNING: Illegal reflective access by org.jruby.ext.openssl.SecurityHelper (file:/tmp/jruby-423/jruby7667758569951782495jopenssl.jar) to field java.security.MessageDigest.provider WARNING: Please consider reporting this to the maintainers of org.jruby.ext.openssl.SecurityHelper WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations WARNING: All illegal access operations will be denied in a future release 开始同步会打印出从数据库读取的，插入到elasticsearch的信息\n实际使用中用nohup 来保持后台运行\n缺点 logstash的缺点很明显，就是只能同步mysql中新增的数据，对于更改的、删除的就无能为力了。这其实也很好理解，ELK其实本来就是用来收集与分析日志的，而同步增加的数据已经足够了。\n我觉得es与mysql最好的同步工具其实是阿里的开源的canal\nalibaba/canal\n","date":"2021-01-28T21:26:00+08:00","image":"https://ccqstark.github.io/p/logstash_mysql/logstash-mysql_hubd922da79b2e986df34a25cd755e9ffb_77309_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/logstash_mysql/","title":"[Elastic]使用logstash同步MySQL数据"},{"content":"安装ElasticSearch 拉取镜像 docker pull elasticsearch:7.10.1 启动容器 同时挂载目录（包括配置文件和data）（挂载出来的位置自己定义）\ndocker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=\u0026#34;-Xms256m -Xmx256m\u0026#34; -d \\ -v /home/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ -v /home/es/data:/usr/share/elasticsearch/data elasticsearch:7.10.1 注意这里还设置了JVM的内存大小，默认为2G，有点大，很可能会因为内存不够而无法正常启动。可以像我这里改为256m或者其他值。\n可能出现的错误 查看容器日志\ndocker logs elasticsearch 如果出现以下错误\nmax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 则要修改服务器配置\nvim /etc/sysctl.conf 添加这行\nvm.max_map_count=262144 立即生效, 执行：\n/sbin/sysctl -p 对挂载的宿主机data目录可能出现权限不足问题\nchmod 777 [宿主机data目录] 配置跨域 到挂载出来到位置编辑配置文件\nvim elasticsearch.yml 添加以下几行\nnetwork.host:0.0.0.0discovery.type:single-nodehttp.cors.enabled:truehttp.cors.allow-origin:\u0026#34;*\u0026#34;同时安全组和防火墙记得打开对应端口\n记得每次修改完配置都要重启 docker restart elasticsearch 浏览器访问测试 http://[IP]:9200 看到类似以下的json就成功了\n{ \u0026#34;name\u0026#34;: \u0026#34;8c819d377714\u0026#34;, \u0026#34;cluster_name\u0026#34;: \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34;: \u0026#34;-AkgwTlbS1SsjvzNtG45nw\u0026#34;, \u0026#34;version\u0026#34;: { \u0026#34;number\u0026#34;: \u0026#34;7.10.1\u0026#34;, \u0026#34;build_flavor\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;build_hash\u0026#34;: \u0026#34;1c34507e66d7db1211f66f3513706fdf548736aa\u0026#34;, \u0026#34;build_date\u0026#34;: \u0026#34;2020-12-05T01:00:33.671820Z\u0026#34;, \u0026#34;build_snapshot\u0026#34;: false, \u0026#34;lucene_version\u0026#34;: \u0026#34;8.7.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34;: \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34;: \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; }  如果无法访问到\n 如果开了安全组和防火墙的话还是无法访问到的话，看看在容器启动时是否有如下警告：\nWARNING: IPv4 forwarding is disabled. Networking will not work. 按如下步骤操作再访问即可\nvim /etc/sysctl.conf #添加如下代码： net.ipv4.ip_forward=1 #重启network服务 systemctl restart network #查看是否修改成功 sysctl net.ipv4.ip_forward #如果返回为“net.ipv4.ip_forward = 1”则表示成功了 #这时，重启容器即可。 安装elasticsearch-head 拉取镜像 docker pull mobz/elasticsearch-head:5 启动容器 docker run -it -d --name head -p 9100:9100 mobz/elasticsearch-head:5 浏览器打开\nhttp://[ip]:9100/ 在上面集群连接处的输入框输入elasticsearch的地址\nhttp://[IP]:9200 之后点击连接，右边的集群健康值字样出现绿色背景代表成功连接\n安装Kibana 拉取镜像 docker pull kibana:7.10.1 注意版本和ES的要对应\n配置文件kibana.yml 为了挂载配置文件，我们先在本机创建一个配置文件，这里以/home/kibana/config/kibana.yml 为例\n配置文件中写入\nserver.host:\u0026#39;0.0.0.0\u0026#39;elasticsearch.hosts:[\u0026#34;http://[ip地址]:9200/\u0026#34;]xpack:apm.ui.enabled:falsegraph.enabled:falseml.enabled:falsemonitoring.enabled:falsereporting.enabled:falsesecurity.enabled:falsegrokdebugger.enabled:falsesearchprofiler.enabled:false启动容器 docker run -d -it \\ --name kibana -p 5601:5601 \\ -v /home/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:7.10.1 浏览器打开\nhttp://[ip]:5601/ 安装ik分词器 首先进入es的容器内\ndocker exec -it elasticsearch /bin/bash 使用bin目录下的elasticsearch-plugin install安装ik分词器插件（注意版本要对应）\n# github官方 bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.10.1/elasticsearch-analysis-ik-7.10.1.zip 这里可能会很慢，可以用镜像加速\n# 镜像加速 bin/elasticsearch-plugin install https://github.91chifun.workers.dev//https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.10.1/elasticsearch-analysis-ik-7.10.1.zip 也可以选择本地下载解压完再上传到服务器，再把它移动到容器内的plugins文件夹里\n然后重启容器\ndocker restart elasticsearch 在kibana中测试 GET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;各地校车将享最高路权\u0026#34; } 有ik_smart 和 ik_max_word 两种模式，分别是最粗粒度的拆分和最细粒度的拆分\n","date":"2021-01-27T21:26:00+08:00","image":"https://ccqstark.github.io/p/es_docker/elastic-docker_hu1fc05f09d19ffda9f7576c23f66afe5c_19136_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/es_docker/","title":"[Elastic]使用docker安装ElasticSearch + Kibana"},{"content":"随着移动互联网发展，用户和数据量越来越多，对应用系统提出了更高的要求，系统必须支持高并发访问和海量数据处理。\n分布式系统技术就是用来解决集中式架构的性能瓶颈问题。一般来说，分布式系统是建立在网络之上的硬件或者软件系统，彼此之间通过消息等方式进行通信和协调。\n分布式系统的核心是可扩展性，通过对服务、存储的扩展，来提高系统的处理能力，通过对多台服务器协同工作，来完成单台服务器无法处理的任务，尤其是高并发或者大数据量的任务。\n单点故障（Single Point Failure）是指在系统中某个组件一旦失效，这会让整个系统无法工作。而分布式系统的设计就是为了避免出现单点故障问题，为了实现一个节点的失效不影响整个系统的运行。\n无状态，是因为无状态的服务才能满足部分机器宕机不影响全部，可以随时进行扩展的需求。\n由于分布式系统的特点，在分布式环境中更容易出现问题，比如节点之间通信失败、网络分区故障、多个副本的数据不一致等，为了更好地在分布式系统下进行开发，学者们提出了一系列的理论，其中具有代表性的就是 CAP 理论。\n  一致性是指“所有节点同时看到相同的数据”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，等同于所有节点拥有数据的最新版本。\n可用性是指“任何时候，读写都是成功的”，即服务一直可用，而且是正常响应时间。平时会看到一些 IT 公司说系统稳定性已经做到 3 个 9、4 个 9，即 99.9%、99.99%，这里的 n 个 9 就是对可用性的一个描述，叫做 SLA，即服务水平协议。比如我们说月度 99.95% 的 SLA，则意味着每个月服务出现故障的时间只能占总时间的 0.05%，如果这个月是 30 天，那么就是 21.6 分钟。\n分区容忍性具体是指“当部分节点出现消息丢失或者分区故障的时候，分布式系统仍然能够继续运行”，即系统容忍网络出现分区，并且在遇到某节点或网络分区之间网络不可达的情况下，仍然能够对外提供满足一致性和可用性的服务。\n在分布式系统中，由于系统的各层拆分，P 是确定的，CAP 的应用模型就是 CP 架构和 AP 架构。分布式系统所关注的，就是在 Partition Tolerance 的前提下，如何实现更好的 A 和更稳定的 C。\nCAP 理论说明在架构设计中，不要把精力浪费在如何设计能满足三者的完美分布式系统上，而要合理进行取舍，因为三者无法完全兼得。\n不同业务对于一致性的要求是不同的。例如，在微博上发表评论和点赞，用户对不一致是不敏感的，可以容忍相对较长时间的不一致，只要做好本地的交互，并不会影响用户体验；而我们在电商购物时，产品价格数据则是要求强一致性的，如果商家更改价格不能实时生效，则会对交易成功率有非常大的影响。\n需要注意的是，CAP 理论中是忽略网络延迟的，也就是当事务提交时，节点间的数据复制一定是需要花费时间的。即使是同一个机房，从节点 A 复制到节点 B，由于现实中网络请求总是需要一定时间的，所以总会有一段时间不一致。\n CP 架构：对于 CP 来说，放弃可用性，追求一致性和分区容错性。\n🔧 ZooKeeper就是采用了 CP 一致性，ZooKeeper 是一个分布式的服务框架，主要用来解决分布式集群中应用系统的协调和一致性问题。其核心算法是 Zab，所有设计都是为了一致性。在 CAP 模型中，ZooKeeper 是 CP，这意味着面对网络分区时，为了保持一致性，它是不可用的。\n AP 架构：对于 AP 来说，放弃强一致性，追求分区容错性和可用性，这是很多分布式系统设计时的选择，后面的 Base 也是根据 AP 来扩展的。\n📦 和 ZooKeeper 相对的是 Eureka，Eureka 是 Spring Cloud 微服务技术栈中的服务发现组件，Eureka 的各个节点都是平等的，几个节点挂掉不影响正常节点的工作，剩余的节点依然可以提供注册和查询服务，只要有一台 Eureka 还在，就能保证注册服务可用，只不过查到的信息可能不是最新的版本，不保证一致性。\n","date":"2021-01-21T23:01:00+08:00","image":"https://ccqstark.github.io/p/cap/cover_huf47dfa8462eb5615bceb79738fdfbc2b_351372_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/cap/","title":"什么是CAP理论？"},{"content":"为了提高在mac下连接ssh的效率，我们可以用alfred和iTerm配合，达到只要在输入框中输入ssh [主机名] 就可以快速连上了，效果如下图：\n \n使用ssh config 在~/.ssh/config文件里添加服务器信息，没有的话就新建一个\nvim ~/.ssh/config然后在文件中输入主机的信息，有多个主机就追加在后面就行\nHost [主机名] HostName [ip] User root Port [端口]使用密钥登陆 如果本地的~/.ssh 目录下没有id_rsa 私钥文件，可以是使用下面这个目录生成，一路回车即可，如果已经有了就可以跳过这步\nssh-keygen然后将私钥复制到远程服务器\nssh-copy-id -i -p[端口号] root@ip按提示输入一次密码，就会自动将刚才生成的公钥id_rsa.pub追加到远程主机的~/.ssh/authorized_keys后面了，这样以后的 ssh 连接都不用输入密码了\n安装alfred-ssh插件 https://github.com/deanishe/alfred-ssh\n到上面github链接下载最新版：Secure-SHell的alfredworkflow，双击自动添加到alfred的workflow\n添加后打开alfred的偏好设置可以看到效果如下：\n  测试用alfred输入ssh+主机名就可以连上服务器了，但是默认是用mac自带但终端，想用好看的iTrem2还需要进一步操作\n安装alfred集成iTerm2配置 如下图，打开iTrem2的偏好设置，如下图设置默认方式为ssh\n  进入下面github链接，按说明操作\nhttps://github.com/vitorgalvao/custom-alfred-iterm-scripts\n  按上面要求运行命令并粘贴到对应地方就完成了！\n参考文章： 开发效率神器之alfred集成ssh+iTerm2实现一步登录服务器\n","date":"2021-01-10T16:35:00+08:00","image":"https://ccqstark.github.io/p/alfred_iterm/ssh_hu16ae618dcf0f79ca9c769a7fb0762a5e_66847_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/alfred_iterm/","title":"Alfred + iTerm2 快速ssh连接服务器"},{"content":"DevOps现在非常流行，CI/CD持续集成、持续部署也大火，而Jenkins就是自动化部署主要的工具之一。\n这篇博客就来详细介绍用jenkins来实现自动化部署springboot项目的docker容器，堪称保姆级教学了。\n用docker拉取jenkins镜像，启动Jenkins容器 这里采用的jenkins本身也是用docker容器部署的，不得不说docker确实好用，当然也可以直接运行在主机上\n首先拉取Jenkins镜像 docker pull jenkins/jenkins ⚠️注意：切勿docker pull jenkins，已经废弃\n启动Jenkins容器 docker run -u root -itd --name jenkins \\ -p 6001:8080 \\ -v $(which docker):/usr/bin/docker \\ -v /var/run/docker.sock:/var/run/docker.sock -e TZ=\u0026#34;Asia/Shanghai\u0026#34; \\ -v /etc/localtime:/etc/localtime:ro \\ -v /volume1/docker/jenkins:/var/jenkins_home \\ jenkins/jenkins  -p 6001:8080Jenkins默认网页访问端口为8080，将端口映射到外部主机6001端口 -v $(which docker):/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock使Jenkins内部可以使用docker命令 -e TZ=\u0026quot;Asia/Shanghai\u0026quot; -v /etc/localtime:/etc/localtime:ro配置Jenkins容器的时区 -v /volume1/docker/jenkins:/var/jenkins_home 将Jenkins的配置映射到外部主机卷，容器删除仍可保留配置  测试Jenkins容器内部 # 进入Jenkins的容器内部 docker exec -it jenkins bash # 判断docker命令是否正常执行 docker info 访问Jenkins网页端 用http://主机IP:6001 就可以访问Jenkins的网页端了\nJenkins初始化 访问页面后需要输入初始密码，用cat 命令查看一下页面上给出的路径就可以获得初始密码，复制进去后就可以成功进入\n  到插件这里就选择安装推荐插件即可，等待安装完毕，速度稍慢。如果很多插件一直安装失败可以等下一步配置国内源之后再安装\n  然后按提示创建一个自己的管理员账户\n如果想重启Jenkins：\n在jenkins主页网址后加上/restart 后回车，点击确定即可\n安装插件和必要配置 修改插件国内源并安装其它插件 点击侧边栏系统管理→插件管理→高级\n  将图中所示URL的输入中的链接改为阿里的：\nhttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json 安装一些插件 在插件管理中选择可选插件\n安装Maven Integration和Docker的插件，安装完重启\n全局工具配置 点击系统管理→全局工具配置\nJDK\n  用docker inspect jenkins 查看JAVA_HOME 路径后填入即可，这是个openjdk1.8，刚好用于项目，因为jenkins就是Java开发的\nGit\n  用默认即可\nMaven\n  可以用外部安装的，这里因为下了插件就用Jenkins里的插件就行，点击自动安装\nDocker\n  都好了之后点应用在点保存\nJenkins容器内使用vim 进入Jenkins容器内部后想使用vim的话还需要额外安装，后面需要用到vim\n# 更新一下软件源 apt-get update # 安装vim apt-get install vim 这里可能比较慢，就等一下，但只需用一次就不额外换源了\n修改maven插件的镜像源 因为jenkins在容器内，所以要进入容器内\ncd到目录~/.m2 下，ls 一下发现只有一个repository 目录，这个就是默认的maven仓库目录，然后就vim settings.xml 新建一个配置文件\n在命令模式下用:set paste 开启粘贴模式，然后把下面内容粘贴进去，记得检查一下内容和编码是不是utf-8\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;settings xmlns=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\u0026#34;\u0026gt; \u0026lt;localRepository\u0026gt;~/.m2/repository\u0026lt;/localRepository\u0026gt; \u0026lt;pluginGroups\u0026gt; \u0026lt;/pluginGroups\u0026gt; \u0026lt;proxies\u0026gt; \u0026lt;/proxies\u0026gt; \u0026lt;servers\u0026gt; \u0026lt;/servers\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;nexus-aliyun\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;*\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;Nexus aliyun\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt; 重启jenkins，之后下载包时发现已经更改为阿里源了\n创建项目准备自动化部署 左侧边栏新建一个任务，选择maven项目\n   \n添加GitHub仓库源码 这里用GitHub做代码仓库，也可以gitlab\n有2种方式：https和ssh\n  如果是https的话添加Credentials 的时候就直接配置自己的GitHub用户名和密码，仓库的URL填写github仓库的url就行\n如果是ssh的话要配置密钥，点击系统管理→Manage Credentials →全局 ,点击左侧边栏添加凭据\n  如果之前生成过，在自己机器上的~/.ssh 下cat一下就行，没有的话就ssh-keygen 生成\n注意此时url就要用ssh://git@github.com/[用户名]/[项目名].git 的格式\n加快代码拉取速度 为了加快构建速度，勾选此选项可以使jenkins不拉取代码的历史版本，从而加快构建速度\n  勾选浅克隆\n  初次之外，不要在本地打出jar包，不然这么大一个文件上传到仓库再被拉取很费时间\n构建触发器  \n添加maven构建步骤  ### 构建脚本\n这里是运行一些shell脚本来构建docker镜像和运行容器的\n  脚本如下，记得在项目目录下写好一个Dockerfile\n# 进入项目目录 cd /var/jenkins_home/workspace/[项目名] # 执行构建Dockerfile命令 docker build -f Dockerfile -t [镜像名]:[tag] . # 停止之前的容器运行 docker stop [容器名] # 删除之前的容器 docker rm [容器名] #运行刚刚创建的容器 docker run -d --name [容器名] -p [映射端口]:8080 [镜像名]:[tag] echo \u0026#34;构建完成\u0026#34; Dockerfile参考：\nFROMopenjdk:8MAINTAINER[作者]ADD /target/[项目名]-0.0.1-SNAPSHOT.jar [项目名].jarEXPOSE8080ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/[项目名].jar\u0026#34;]push触发构建 为了实现只要我们一向代码仓库push就可以自动进行构建，我们需要配置webhook\n点击系统管理→系统配置 ，找到GitHub选项，点击高级\n按下图操作：\n  打开自己GitHub项目页面\n  粘贴刚刚复制的地址\n  下面勾选Pushes和Active ，最后点击添加即可\n点击项目内左侧栏的立即构建 可以手动开始构建\n在进程中点击控制台输出 看到构建过程中的日志信息，这些信息很重要我们经常要看，用来发现构建过程中的错误\n清除无用的镜像 docker image prune 在多次构建之后可能会发现一些为none的镜像，用此命令清除\n配置邮箱通知 在这之前保证安装了相关插件，如果一开始是选安装推荐插件那应该都安装了\n点击系统管理→系统配置\n先配一下管理员邮箱\n  然后拉到下面，按图中配置，这个邮箱要填刚刚上面的管理员邮箱\n注意里面的密码是开启SMTP的密码，不是邮箱的密码\n然后可以点击发送测试邮件试试\n  上面还有一个Extended E-mail Notification 也配一下，也按这些信息填写\nDefault Recipients 是默认接收通知的邮箱，可以填写多个，用英文半角逗号隔开\nDefault Triggers 也可以配置一下，是触发邮件的事件\n  这里有个坑，在系统设置配置完之后，在项目里面的设置记得也要配置完整\n进入要发送邮箱功能的项目的配置\n  再点击增加构建后操作步骤\n    点击高级设置后设置触发条件\n  其他的诸如Content Type和Default Content 之类的就按需求配就行\n之后在控制台输出就可以看到构建项目到最后有发邮件的步骤日志\n主题美化 可以参考下面这篇文章，个人觉得还是习惯于原版\nJenkins自定义主题教程_FlyWine的博客-CSDN博客_jenkins自定义界面\n参考文章：\n最优雅的Docker+Jenkins pipeline部署Spring boot项目\nJenkins+Docker+github+Spring Boot自动化部署_linfen1520的博客-CSDN博客\njenkins+git+maven+docker持续集成部署_自动化_运维开发网_运维开发技术经验分享\nJenkins - SSH认证方式拉取Git代码\ncentos7的Jenkins的maven插件的settings.xml配置文件路径在哪里_festone000的专栏-CSDN博客\n","date":"2021-01-09T23:01:00+08:00","image":"https://ccqstark.github.io/p/jenkins_docker_springboot/jenkins-cicd_huac9b8bcc40d9704ef8edb1ad38827231_44206_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/jenkins_docker_springboot/","title":"Jenkins + docker + springboot 完美配合全流程教程"},{"content":"如果是单体应用的话nginx用docker部署其实是更麻烦的，不过既然操作过就记录一下。\n拉取nginx镜像 docker pull nginx 还是一样，默认是拉取latest版本，也可以选择想要的特定版本\n启动并挂载html目录 docker container run \\  -d \\  -p 80:80 \\  --name mynginx \\  --v [本机挂载目录]:/usr/share/nginx/html \\  nginx 复制出配置文件 docker container cp mynginx:/etc/nginx . 将复制出来的文件夹改名并移动到你想要的目录下，然后把容器停止并删除\n挂载配置文件目录 最后一步就是重新启动一个容器并把html和配置文件目录都挂载了\ndocker run \\  --name test-nginx \\  -v [本机挂载html目录]:/usr/share/nginx/html \\  -v [本机挂载nginx目录]:/etc/nginx \\  -p 80:80 \\  -d \\  nginx 访问一下试试就可以了！\n参考：\nNginx 容器教程\n","date":"2021-01-08T15:46:00+08:00","image":"https://ccqstark.github.io/p/docker_nginx/nginx-docker_hu2ff739cd1ceaefb705a9e30c4218e66c_86441_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/docker_nginx/","title":"[docker]用docker部署nginx"},{"content":"这篇文章介绍的是把整个Springboot后端项目部署到docker容器中，当然包括mysql和redis\n按下面步骤一步步来\n本地打出jar包 以Maven的话直接就IDEA里打出jar包到target目录下，这一步和以前一样\n编写Dockerfile 可以用IDEA里的插件来写，也可以自己写dockerfile\n在项目文件夹下新建一个文件Dockerfile\nFROMopenjdk:8MAINTAINERccqstarkADD /target/[项目jar包名].jar app.jarEXPOSE8080ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/app.jar\u0026#34;]⚠️注意：ADD后两个参数，第一个是项目jar包的相对路径，第二是把jar包在容器内重新命的名\n构建镜像 在Dockerfile所在文件夹下运行build 命令，注意最后有一个.\ndocker build -f Dockerfile -t [镜像名]:[版本tag] .构建之后用docker images 查看一下自己构架的镜像\n构建完之后本地run一下容器测试下\npush上传到镜像仓库 其实也可以把jar包上传服务器后用服务器的docker来构建和运行\n但这里采用的是把本地构建的镜像上传到repository，相当于镜像仓库，其他人想用这个镜像就可以从那拉取下来使用。\nrepository可以是官方的Docker Hub，但是比较慢，也可以花钱上传到阿里云的容器镜像服务就会快很多\n这里是上传到docker hub，首先要登陆自己到docker账号，没有的话可以去官网注册一个\ndocker login -u [账户名] 输入密码成功后登陆\n在push之前要给镜像打个tag，这样才能上传到自己账号对应的仓库下\ndocker tag [镜像名] [账户名]/[镜像仓库名]:latest 之后就可以上传了\ndocker push [账户名]/[镜像仓库名]:latest pull拉取镜像 docker pull [账户名]/[镜像仓库名]:[tag] 在服务器上拉取到镜像后就可以启动容器了\ndocker run -it -d -p [对外暴露端口]:8080 app:[tag] 部署MySQL容器 # 拉取mysql镜像 docker pull mysql:5.7 # 跑起来 docker run \\ -d \\ -p 3306:3306 \\ -v /home/mysql/conf:/etc/mysql/conf.d \\ -v /home/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=[设置mysql到root密码] \\  --name [容器名] \\ mysql:5.7 mysql容器到暴露端口要和代码中配到一样就行\n这里还把配置目录和数据目录挂载了出来，避免容器停止后数据丢失\n部署redis容器 # 拉取redis镜像 docker pull redis # 运行，这个时候指定密码，不指定默认为空 docker run -d --name myredis -p 6379:6379 redis --requirepass \u0026#34;mypassword\u0026#34; ⚠️注意：建议先把mysql和redis都部署好后再去启动jar包都镜像，防止应用启动时连不到它们而报错\n所有容器都成功启动起来之后就把整个后端部署到docker完毕了\n","date":"2021-01-07T21:39:00+08:00","image":"https://ccqstark.github.io/p/docker_springboot/docker-springboot_hu705e70abdc72815dabd2267940e19d94_40186_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/docker_springboot/","title":"[docker]用docker部署SpringBoot项目"},{"content":"Dockerfile介绍 dockfile是用来构建docker镜像的文件，命令参数脚本\n💡构建步骤：\n 编写dockerfile脚本 用docker build命令构建一个镜像 用docker run运行镜像 用docker push发布镜像（DockerHub、阿里云仓库）  在官网点击镜像会跳转到github对应的dockerfile\n可以发现这些镜像也是通过dockerfile来构建的\n  上图是centos的dockerfile，其中scratch是最基本的，90%都是基于这个镜像。\n然后ADD 就是添加来一层centos相关的镜像文件\n官方很多镜像都是基础包，功能很少，很多我们需要的都没有，所以我们通常都会构建自己的镜像。\n比如我们可以直接构建一个centos+jdk+tomcat+mysql的镜像，不就直接有来一个可以运行javaweb项目的环境镜像了吗？\nDockerfile构建过程 基本规则  每个关键字（保留字）都是大写的 执行顺序是从上到下的 \u0026ldquo;#\u0026rdquo; 表示注释 每一个指令都会创建一个新的镜像层，并提交    以前开发交付都是用jar包或war包，现在云原生时代交付的就是docker镜像，docker镜像也逐渐成为企业交付标准，而构建docker镜像就需要学会编写dockerfile\n什么是云原生？聊聊云原生的今生_阿里云开发者-CSDN博客\nDockerfile常用指令    指令关键字 作用     FROM 构建镜像所用的基础镜像   MAINTAINER 镜像作者，一般是姓名+邮箱   RUN 镜像构建时运行的命令   ADD 为镜像添加内容   WORKDIR 镜像的工作目录   VOLUME 挂载目录   EXPOSE 暴露的端口   CMD 容器启动时需要运行的命令，只有最后一个会生效，可被替代   ENTRYPOINT 也是指定启动时需要运行的命令，但是可以追加   ONBUILD 构建一个被继承的dockerfile时会运行ONBUILD的指令。触发指令   COPY 类似ADD，将文件拷贝到镜像中   ENV 构建时设置的环境变量    实践：构建自己的centos 举个例子：\nFROMcentos # centos为基础镜像MAINTAINERccqstark\u0026lt;xxxxxx@qq.com\u0026gt; # 作者名和邮箱ENV MYPATH /usr/local # 环境变量WORKDIR$MYPATH # 工作目录# 安装vim和ifconfig命令RUN yum -y install vim RUN yum -y install net-toolsEXPOSE80CMD echo $MYPATHCMD echo \u0026#34;---end---\u0026#34;CMD /bin/bashdocker build 之后 run 起来就可以使用了！\n还可以使用下面命令查看镜像构建的过程\ndocker history [镜像id] 参考自狂神的docker教程\n","date":"2021-01-06T21:13:00+08:00","image":"https://ccqstark.github.io/p/dockerfile/dockerfile_hua2299a9fb0d8a75d7ada60f608a774d6_160236_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/dockerfile/","title":"[docker]初识Dockerfile"},{"content":"把容器内的目录挂载到宿主机的某一个目录下，实现双向同步。\n也就是说两者都指向了同一文件目录下，在其中一端所做的修改都会同步。\n好处：\n MySQL数据持久化，不会因为删了容器就没了 方便修改文件，比如nginx的配置文件  基本使用 bind mounts 以启动一个centos容器为例\ndocker run -it -v [宿主机目录]:[容器内目录] centos /bin/bash -it ：-t选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开，通常写成-it\n-v ：挂载卷所需参数，后面的映射是[宿主机目录]:[容器内目录]\n用此命令查看容器参数\ndocker inspect [容器id]   如上图，在Mounts 字段中可以看到：\nSource 表示宿主机中被映射的目录\nDestination 表示容器内要映射的目录\n这种挂载方式称为bind mounts\n实践：MySQL挂载 拉取mysql镜像 docker search mysql docker pull mysql:5.7 启动容器 -d 后台运行\n-p 端口映射\n-v 数据卷挂载\n—name 容器名字\ndocker run \\ -d \\ -p 3310:3306 \\ -v /home/mysql/conf:/etc/mysql/conf.d \\ -v /home/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=[你配置的mysql密码] \\ --name [容器名] \\ mysql:5.7 -v可以一次写多个来多次挂载\n连接测试 运行成功后用navicat连接下试试\n 主机地址还是服务器公网ip 端口是映射出来的暴露端口，比如上面命令中的3310 密码就是-e MYSQL_ROOT_PASSWORD设置的密码  可以创建新的数据库看看宿主机对应映射目录下有没有同步出现新数据库的文件\n删除测试 docker rm -f [mysql容器名] 运行上面的指令删除掉容器，再在主机下查看/home/mysql/data 目录发现数据依旧都还在\n如果再次启动一个容器数据就还是和删除前一样，从而保证了数据安全，这就是MySQL数据卷挂载\n匿名挂载和具名挂载 volumes 匿名挂载 -P 随机映射端口\ndocker run -d -P --name nginx01 -v /etc/nginx nginx 如上图的命令，-v 是没有指定外部目录的，只写了内部目录，所以是匿名挂载，使用下面命令查看挂载的卷\ndocker volume ls 发现卷名是随机生成的字符串，所以是匿名的\n \n具名挂载 docker run -d -P --name nginx01 -v [自己起的卷名]:/etc/nginx nginx [卷名]:[目录名] 这样指定了卷名的形式就是具名挂载\n这样再用docker volume ls 看到的卷名就是自己指定的了\n查看挂载的目录 docker volume inspect [卷名] 用这条命令就可以查看卷的一些信息，其中Mountpoint 就是所挂载的外部目录\n  所以这种在没有指定目录的情况下（具名或匿名）都是挂载在/var/lib/docker/volumes/[卷名]/_data这个目录的\n大多数情况下都是用具名挂载\n这两种挂载方式统称volumes\n总结 -v [内路径] 匿名挂载 -v 卷名:内路径 具名挂载 -v 宿主机路径:容器内路径 指定路径挂载\n扩展 可以用参数改变读写权限\nro 只读，容器内不可修改，容器外可以\nre 可读可写\ndocker run -d -P --name nginx02 -v ccq-nginx:/etc/nginx:ro nginx docker run -d -P --name nginx02 -v ccq-nginx:/etc/nginx:rw nginx 使用Dockerfile来构建和挂载 Dockerfile是用来构建docker镜像的构建文件，里面就是构建的脚本\n这个文件可以用来生成镜像，由于镜像是一层一层的，所以脚本命令也是一句句对应一层层的\n以centos来举个例子，在dockerfile里写下下面这些内容：\nFROMcentos # 由哪个原始镜像构建VOLUME [\u0026#34;volume01\u0026#34;,\u0026#34;volume02\u0026#34;] # 挂载，此处匿名CMD echo \u0026#34;---end---\u0026#34;CMD /bin/bash运行构建命令如下：\ndocker build -f [dockerfile路径] -t [镜像名]:[版本tag] [生成目录] 然后用命令docker images 就可以看到自己刚刚构建的镜像了，docker run 就可以跑起来\n之后也可以docker inspect 查看挂载情况，挂载同样是数据内外目录同步的\n数据卷容器 之前是容器内的目录挂载到容器外到到目录，现在是一个容器挂载到另一个容器\n这样就实现了容器之间到数据同步\n—-volumes-from 使用此参数开启一个容器挂载到另一个容器\n被挂载的称为父容器\ndocker run -it --name [名字] --volumes-from [父容器名] [镜像名]:[版本tag] 测试一下，开两个容器，进入挂载到一起的目录创建文件试试，发现数据是同步的\n多重挂载 可以开启第三个容器挂载到第一或第二个容器，发现现在这3个容器对应到目录的数据都是同步的\n所以挂载其实是可以套娃的\n卷的挂载机制 不同容器的挂载机制并不是映射到单一到文件夹下的，如果这样的话其中一个容器被删除的话，其它所有容器对应都数据都会消失。\n实际上挂载是一种拷贝的机制，数据是有多份相同的备份的，删除一种一份其它的都还在，不会消失的，只是会占用更多的存储空间\n  只有把挂载这一卷的所有的容器都删除，这个卷才会消失\n当然，如果是bind到本地的目录那就删除全部容器数据也仍然在本地\n参考自狂神的docker教程\n","date":"2021-01-06T16:51:00+08:00","image":"https://ccqstark.github.io/p/docker_volumes/docker_hu22e70eb00a1bc79d3e2af88d0f9ef83b_73329_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/docker_volumes/","title":"[docker]容器数据卷"},{"content":"终于从Windows转到心心念念的macOS上进行开发，虽然是黑苹果但是软件层面上没有太大的区别，程序员还是得用mac啊这终端上真的比windows好用无数倍，那终端到手后还是要折腾美化的，那就开始吧。 先看下我，还可以吧？  1 \n准备工作 先保证自己下载homebrew和wget，安装软件或下载包很多情况下要用到它们，特别homebrew是mac下最好用的包管理器一定要有。下载方法网上也很多的，建议先下homebrew再用它下wget。\niTerm2 首先是下载第三方终端iTerm2，mac自带的终端用的比较少，大家用的最多还是这个。 官网下载\nzsh zsh是shell的一种，mac默认的shell是bash，一般来说我们也是用zsh比较多，因为命令更多更好用。\n下载zsh brew install zsh 切换shell为zsh # 查看当前使用的shell echo $SHELL # 切换为zsh chsh -s /bin/zsh 运行完上面命令后重启一下即可\noh-my-zsh oh-my-zsh用于美化终端，可以让你拥有很多好看的主题。\n安装 wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh sh install.sh\r运行上面的命令来下载安装脚本并运行脚本，成功后会有如下画面\n 2 \n更换主题 oh-my-zsh有很多默认的主题，可以在~/.zshrc中修改ZSH_THEME来切换不同主题。 这里我推荐powerlever10k，它集合了很多不同主题风格的样式，支持自定义，如果默认主题中没有你满意的那推荐就用它。下面就讲powerlevel10k的安装方法。\n下载 git clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\r安装所需字体 # 安装 nerd-font 字体 brew tap homebrew/cask-fonts # 其他所需字体 cd ~ git clone https://github.com/powerline/fonts.git --depth=1 # 到目录下执行安装脚本 cd fonts ./install.sh # 删除刚刚下载的 cd .. rm -rf fonts 配置 vim ~/.zshrc 进入zsh配置文件中修改并增加\nZSH_THEME = \u0026#34;powerlevel10k/powerlevel10k\u0026#34; [[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh 之后启动向导\np10k configure 可以用下面命令查看颜色代号\nfor i in {0..255}; do print -Pn \u0026#34;%K{$i} %k%F{$i}${(l:3::0:)i}%f \u0026#34; ${${(M)$((i%6)):#3}:+$\u0026#39;\\n\u0026#39;}; done 接下来需要下载一些必要的字体或样式，在此之前需要先改host以正常下载 下载软件SwitchHosts! 之后如图加上\n199.232.68.133 raw.githubusercontent.com 199.232.68.133 user-images.githubusercontent.com 199.232.68.133 avatars2.githubusercontent.com 199.232.68.133 avatars1.githubusercontent.com  3 \n开启My hosts后重启终端，就会自动提示下载所需字体，耐心等待它下载完（有点慢）后，就可以根据引导一步步自定义属于自己的主题了！从图标到字体颜色风格到显示信息都可以自定义！\n背景透明+毛玻璃 打开iTerm2的偏好设置按下图即可调节背景透明和毛玻璃，下面还可以设置默认窗口大小。\n 4 \n快捷键唤醒 如何让切出终端更快捷？可以设置Hotkey 按下图操作\n 5   6 \n尾声 至此，一个好用又好看的mac终端基本配置完毕啦\n其他有趣的可以看下这篇博客讲的\n","date":"2021-01-06T02:07:00+08:00","image":"https://ccqstark.github.io/p/mac_terminal/Mojave-desktop_hu0caf60027e85952cdd6ae94392d12e9b_35582_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/mac_terminal/","title":"macOS终端美化指北"},{"content":"事情经过 11月17号这天早上上着课，突然有用户反馈应用卡顿，使用不了。我感觉上去看了果然是这样，有时数据加载很慢甚至加载不出来，我感到焦虑与害怕，害怕数据库和别人一样被黑了然后删光要钱，课都没心情听了。然后手机下了个Termius，先把服务关了。\n中午回到宿舍后看了数据库发现数据完好无损，赶紧备份了一波，然后寻找问题。\n内存和CPU和磁盘都挺正常，看了服务器的安全日志，那登录记录刷刷的，有人在暴力破解我的root密码！\n由于下午还有体育课，就先直接关了服务器，然后上课去了。\n下午来到实验室，重新打开服务器，又开始攻击了，气死了。用脚本封了攻击者一百多个肉鸡ip，以为可以了之后，把服务开启，通知用户可以用了。\n结果用户又说太卡了，我又检查了一波，CPU、内存、磁盘正常，然后这个带宽就不太正常了，我学生机的1M/s都超了，应该是这个原因导致卡的。\n用命令找了进程发现好像也没哪个占用很多呀，弄了很久还是很迷惑，攻击者的ip也明明被我加入黑名单了呀，之后还开了腾讯云的专业机阻断，还是很卡，卡到我ssh都连不太上。然后有个办法叫我改ssh的22端口，我怕操作失误连自己都直接连不上就GG了，然后就算了不这样搞了。\n最后只能屁颠屁颠去找客服，他跟我说也是其他正常带宽跑满，叫我看有没有什么进程占用很多，主要是建议我临时升级带宽。\n我想着：啊好家伙，开始了。但是也没啥其他办法，就去买了3天升级到3M/s的带宽，不贵，结果也是真香。\n后来最多手动在安全组加了几个奇怪ip封掉，服务就完成稳定下来了，看来没有什么是加钱不能解决的。\n后来过了两天攻击者还在继续冲，除了影响我带宽之外其实也没太大问题反正他进不来的，问了师兄建议说改22端口，反正重要使用期也过了，我就试试改下，还真有用，安全日志也没攻击者那些破解记录了，带宽也占用也再降了，说明攻击者也是冲22，这下直接完全被挡住，带宽也不占了。\n第一次与黑客对线还是学到了很多的，也加强了我的安全防范意识\n查看系统状态命令 下面有些命令工具需要额外安装的，直接yum install xxx安装就行\n查看服务器安全日志(动态实时)(CentOS) tail -f /var/log/secure 查看CPU等的使用情况(按进程) top 查看内存使用情况 free -h 查看磁盘使用情况 df -hl 查看网络带宽占用(按ip) iftop -i eth0 jnettop 按Q退出\n查看网络带宽占用(按进程) nethogs 还有防火墙工具iptables和firewall-cmd\nhttps://wangchujiang.com/linux-command/c/iptables.html\nhttps://wangchujiang.com/linux-command/c/firewall-cmd.html\n编写自动化脚本封禁暴力破解登录的ip 从安全日志中读取记录，把那些多次登录失败的ip写进请求黑名单中（hosts.deny），但是这种办法只是拒绝连接，如果黑客继续攻击还是会占用带宽\n先找个目录，vim建立一个脚本文件\nvim /usr/local/secure_ssh.sh 然后编写脚本\n#! /bin/bash cat /var/log/secure|awk \u0026#39;/Failed/{print $(NF-3)}\u0026#39;|sort|uniq -c|awk \u0026#39;{print $2\u0026#34;=\u0026#34;$1;}\u0026#39; \u0026gt; /usr/local/bin/black.txt for i in `cat /usr/local/bin/black.txt` do IP=`echo $i |awk -F= \u0026#39;{print $1}\u0026#39;` NUM=`echo $i|awk -F= \u0026#39;{print $2}\u0026#39;` result=$(cat /etc/hosts.deny | grep $IP) if [[ $NUM -gt 10 ]];then if [[ $result = \u0026#34;\u0026#34; ]];then echo \u0026#34;sshd: $IP\u0026#34; \u0026gt;\u0026gt; /etc/hosts.deny fi fi done 设置定时任务\n#首先打开定时任务列表 crontab -e #添加下面这行，表示每十分钟 */10 * * * * bash /usr/local/secure_ssh.sh #保存退出后重启下 service crond restart 修改sshd的22端口 这个方法可以完全把对22端口的攻击直接拒之门外，安全日志都没记录破解登录事件，带宽也不会影响，但操作过程要小心一点点\n修改sshd配置文件\nvim /etc/ssh/sshd_config #Port 22 //这行去掉#号，然后在下面增加自己要新开的端口，保证新端口能用再去掉这行 下面新增端口\nPort xxxxx 防火墙开启对应端口，安全组也记得开，或者先把防火墙关了，之后试了新端口能用再开\nfirewall-cmd --zone=public --add-port=xxxxx/tcp --permanent\r重启sshd\n/etc/init.d/sshd restart #或者 service sshd restart 然后重新连服务器终端试试，没问题之后可以把22直接禁掉，防火墙和安全组也封了22，对新端口放行就行\n其他 使用强密码或者只用密钥登录\n数据库多做备份\n建立快照\n关键数据加密\n要增强安全意识呀！\n","date":"2020-11-22T22:10:00+08:00","image":"https://ccqstark.github.io/p/first_attack/cover_hu15cb69af2a51eec4fc95f50c41859b41_1403865_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/first_attack/","title":"记一次服务器被攻击"},{"content":"问题引入与研究目标 目标检测的数据集的收集往往是在现实场景中进行的，因此数据中目标的外观、背景、光照、图像质量等方面的巨大差异会导致训练数据和测试数据之间出现巨大的领域偏移。比如汽车在不同天气条件下驾驶收集到的数据，或者是相机的类型和设置的不同也会导致数据的领域偏移。这样的偏移会导致性能显著下降，尽管收集尽可能多的数据集可以降低这种影响，但是注释边界框也是一个费时费力的过程，因此开发一个新的算法来应对跨领域目标检测问题就尤为重要。\n论文中方法适用于无监督场景，在源域有完整的监督，而在目标域没有监督。这样就可以不增加人工标注成本的前提下减少跨域对目标检测效率的影响。\n关键术语介绍 目标检测 Object Detection 目标检测，也叫目标提取，是一种基于目标几何和统计特征的图像分割，它将目标的分割和识别合二为一，其准确性和实时性是整个系统的一项重要能力。尤其是在复杂场景中，需要对多个目标进行实时处理时，目标自动提取和识别就显得特别重要。目标检测主要有三个层次：\n一是分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其他任务提供了基础。在应用领域，人脸、场景的识别等都可以归为分类任务。\n二是检测（Detection）。分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置），因而，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。\n三是分割（Segmentation）。分割包括语义分割（semantic segmentation）和实例分割（instance segmentation），前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。\n领域自适应 Domain Adaptation 领域自适应（Domain Adaptation）是迁移学习中的一种代表性方法，指的是利用信息丰富的源域样本来提升目标域模型的性能。 领域自适应问题中两个至关重要的概念：\n源域（source domain）表示与测试样本不同的领域，但是有丰富的监督信息\n目标域（target domain）表示测试样本所在的领域，无标签或者只有少量标签。源域和目标域往往属于同一类任务，但是分布不同\n根据目标域和源域的不同类型，领域自适应问题有四类不同的场景：无监督的，有监督的，异构分布和多个源域问题。 通过在不同阶段进行领域自适应，研究者提出了三种不同的领域自适应方法：\n1）样本自适应，对源域样本进行加权重采样，从而逼近目标域的分布。\n2）特征层面自适应，将源域和目标域投影到公共特征子空间。\n3）模型层面自适应，对源域误差函数进行修改，考虑目标域的误差。\n散度 Divergence 在机器学习中，我们常常需要用一个分布Q去逼近一个目标分布P，我们希望能够找到一个目标函数D ( Q , P ) D( Q,P)D(Q,P)，计算Q到P的距离。而这一个目标函数，正是Divergence(散度)，比如常见的KL-Divergence，JS-Divergence等等。通过这个散度的计算我们就能不断地去优化我们的Q，寻找一个最优的参数去逼近真实的分布P。\nFaster R-CNN Faster R-CNN是何凯明等大神在2015年提出目标检测算法，该算法在2015年的ILSVRV和COCO竞赛中获得多项第一。该算法在Fast R-CNN基础上提出了RPN候选框生成算法，使得目标检测速度大大提高。\n \n \nFaster-RCNN由下面几部分组成：\n  数据集，image input\n  卷积层CNN等基础网络，提取特征得到feature map\n  RPN层，再在经过卷积层提取到的feature map上用一个3x3的slide window，去遍历整个feature map,在遍历过程中每个window中心按rate，scale（1:2,1:1,2:1）生成9个anchors，然后再利用全连接对每个anchors做二分类（是前景还是背景）和初步bbox regression，最后输出比较精确的300个ROIs。 把经过卷积层feature map用ROI pooling固定全连接层的输入维度。\n  然后把经过RPN输出的rois映射到ROIpooling的feature map上进行bbox回归和分类。\n  交叉熵 cross entropy 交叉熵描述了两个概率分布之间的距离，当交叉熵越小说明二者之间越接近。\n在信息论中，基于相同事件测度的两个概率分布的交叉熵是指，当基于一个“非自然”（相对于“真实”分布而言）的概率分布进行编码时，在事件集合中唯一标识一个事件所需要的平均比特数。\n梯度下降 gradient descent 在机器学习算法中，在最小化损失函数时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。\n梯度下降在机器学习中应用十分的广泛，不论是在线性回归还是Logistic回归中，它的主要目的是通过迭代找到目标函数的最小值，或者收敛到最小值。\n \n基本思路 论文中为了解决域偏移问题，在Faster R-CNN模型中加入了图像级和实例级的两个域适应组件，从而来最小化两个域之间的h散度。在每个组件中，训练一个领域分类器，并使用对抗性训练策略来学习领域不变量的鲁棒特征。并且进一步整合不同层次的域分类器之间的一致性规则，在Faster R-CNN模型中学习一个域不变区域建议网络(RPN)。\n研究成果   从概率的角度对跨域目标检测的域移问题进行了理论分析。\n  设计了两个域自适应组件，以缓解图像级和实例级的域差异。\n  进一步提出了一致性正则化，以促进RPN变成领域不变的。\n  将提出的组件集成到Faster R-CNN模型中，得到的系统可以以端到端的方式进行训练。\n  与用于分类的领域适应研究相比，其他计算机视觉任务的领域适应研究较少。近年来在语义分割、精细识别等方面进行了研究。对于检测任务，提出通过引入自适应支持向量机来缓解可变形零件模型(DPM)的域漂移问题。在近期的研究中，其他研究者使用R-CNN模型作为特征提取器，然后用子空间对齐方法对特征进行对齐。也有从其他来源学习探测器的工作，例如从图像到视频，从3D模型，或者从合成模型。以前的工作要么不能以端到端的方式进行培训，要么侧重于特定的案例。在这项工作中，论文作者建立了一个用于目标检测的端到端的可训练模型，也是世界上第一个。\n领域适应组件 Domain Adaptation Components 映像级别适应 Image-Level Adaptation 在Faster R-CNN模型中，指的功能映射输出映像级别表示基本卷积的层。消除域分布不匹配在图像层次,采用patch-based域分类器。\n这种选择的好处:\n 对齐图像级表示通常有助于减少由全局图像差异引起的位移，如图像风格、图像尺度、光照等。类似的基于块的损失在最近的关于style transfer的工作中也被证明是有效的，它也处理全局变换 由于使用了高分辨率的输入，对于训练一个目标检测网络来说，批处理的大小通常非常小。这种基于块的设计有助于增加训练领域分类器的训练样本的数量。  用Di表示第i个训练图像的定义域标签，源域的Di= 0，目标域的Di= 1。将经过基卷积层后的第i幅图像的feature map位于(u, v)处的激活表示为φu,v(Ii)。将域分类器的输出表示为pi(u,v)，利用交叉熵损失，图像级自适应损失可表示为:\n \n实例级适应 Instance-Level Adaptation 实例级表示是指在输入到最终的类别分类器之前基于ROI的特征向量\n对齐实例级表示有助于减少本地实例差异，如对象外观、大小、视点等。与图像级自适应相似，研究者训练了一个针对特征向量的领域分类器来对齐实例级分布。\n将第i幅图像中第j个区域建议的实例级域分类器的输出表示为pi,j。实例级适应损失现在可以写成:\n \n一致性正规化 Consistency Regularization 加强不同层次的域分类器之间的一致性有助于学习边界盒预测器(即Faster R-CNN模型中的RPN)的跨域鲁棒性。因此，研究者进一步设置了一个一致性规则。由于图像级域分类器会为图像级表示的每次激活生成一个输出，因此取图像中所有激活的平均值作为其图像级概率。一致性调节器可以写成:\n \n网络概述 Faster R-CNN与2个组件之间的整合关系如下图：\n \n在每一层上构建一个领域分类器，以一种对抗性的训练方式进行训练。在这两个分类器中加入了一致性规则器，以学习用于Faster R-CNN模型的领域不变RPN。\n左边部分是原始的Faster R-CNN模型。底层的卷积层在所有组件之间共享。然后在其上构建RPN和ROI池化层，然后构建两个完全连接的层来提取实例级特征。\n从合成数据中学习 随着计算机图形技术的发展，利用合成数据训练CNN变得越来越流行。尽管如此，合成的数据与真实世界的图像仍然有明显的视觉差异，并且通常与在真实数据上训练的模型存在性能差距。研究者用不同于真实世界的合成数据进行试验。\n数据集:是SIM 10k由10000张由侠盗猎车手(GTA5)渲染的图像组成，在SIM 10k中，10000张训练图像中提供了58,701辆车的包围框。所有的图像都在训练中使用。Cityscapes数据集是一个城市场景数据集为驾驶场景。这些图像是由车载摄像机拍摄的。2975图像训练集,500图像验证集。使用的标记图像训练集作为目标域适应我们的检测器, 并报告结果验证集。\n结果：不同方法的结果如下表所示。具体来说，与Faster R-CNN相比，仅使用图像级自适应组件获得+2.9%的性能提升，而仅使用实例级对齐组件获得+5.6%的性能提升。这表明，图像级适应和实例级适应组件可以有效地减少各层次上的域漂移。将这两个部分结合在一起可以得到7.7%的改进，这验证了关于减少两层域移位的必要性的猜想。通过进一步应用一致性正则化，域自适应Faster R-CNN模型将更快的R-CNN模型提高了+8.8%。\n \n其它 为了验证模型的效果，研究者还通过恶劣天气中收集的图像数据、不同摄像机拍摄出来的图像数据对算法进行测试，结果都显示出不错的结果\n还进一步分析了图像级和实例级适应的影响，做了有关于图像级和实例级对齐的实验，验证了模型可以从更高分辨率的图像输入中获得更好的性能结果。实验结论是从200像素增加到1000像素。\n还做了实验研究了使用一致性正则化前后RPN的性能，发现RPN的性能可以进一步提高到30.3%，说明一致性调节器提高了RPN的鲁棒性。\n","date":"2020-11-22T22:07:00+08:00","image":"https://ccqstark.github.io/p/ml_domain_adaptation/cover_hu1c6885273cd613b163ce1e850e631c7c_545173_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/ml_domain_adaptation/","title":"[机器学习论文]Domain Adaptive Faster R-CNN for Object Detection in the Wild"},{"content":"问题 设A和B是2个字符串。要用最少的字符操作将字符串A转换为字符串B。这里所说的字符操作包括 (1)删除一个字符； (2)插入一个字符； (3)将一个字符改为另一个字符。 将字符串A变换为字符串B所用的最少字符操作数称为字符串A到 B的编辑距离，记为d(A,B)。 对于给定的字符串A和字符串B，计算其编辑距离 d(A,B)。\n输入格式: 第一行是字符串A，文件的第二行是字符串B。\n提示：字符串长度不超过2000个字符。\n输出格式: 输出编辑距离d(A,B)\n输入样例: 在这里给出一组输入。例如：\nfxpimu\rxwrs 输出样例: 在这里给出相应的输出。例如：\n5\r思路 用动态规划算法可以将问题分解出最优子结构。\n设dp[i][j]表示把A字符串前i个字符组成的字符串转变为B字符串前j个字符组成的字符串所需的最少的字符操作数\n如果A字符串的第i个字符与B字符串的第j个字符串相同，则这个位置不需要操作，所需的操作等于dp[i-1][j-1]，否则需要进行修改，操作数就要+1\n由于每个位置都可以进行修改、删除、插入三种操作，因此需要把这三种操作中编辑距离最小的作为dp[i][j]的值\n递推公式(代码表示)：\nif (A[i - 1] == B[j - 1]) // dp矩阵以1开始，字符数组是0开始，因此对应的话要-1 \tdp[i][j] = dp[i - 1][j - 1]; // 如果对应的位置相同就不用操作，否则要修改所以要+1 else dp[i][j] = dp[i - 1][j - 1] + 1; // 修改 删除 插入 dp[i][j] = min(dp[i][j], min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); 表的维度：二维\n填表的范围：（len_A和len_B分别为字符串A、B的长度）\ni：1 ~ len_A\nj：1 ~ len_B\n填表顺序：从左至右，自顶向下（i与j的递增方向）\n时间复杂度：由于填写的是二维表，需要二重循环，所以时间复杂度是O(n^2)\n空间复杂度：需要一个二维数组，因而是O(n^2)\n代码 // 编辑距离问题 #include \u0026lt;iostream\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 2002 char A[MAX]; char B[MAX]; int dp[MAX][MAX]; int calculate_distance() { // a、b字符串的长度  int len_a = strlen(A); int len_b = strlen(B); // 边界初始化  for (int i = 0; i \u0026lt;= len_a; i++) dp[i][0] = i; for (int j = 0; j \u0026lt;= len_b; j++) dp[0][j] = j; for (int i = 1; i \u0026lt;= len_a; i++) { for (int j = 1; j \u0026lt;= len_b; j++) { // dp矩阵以1开始，字符数组是0开始，因此对应的话要-1  if (A[i - 1] == B[j - 1]) // 如果对应的位置相同就不用操作，否则要修改所以要+1  dp[i][j] = dp[i - 1][j - 1]; else dp[i][j] = dp[i - 1][j - 1] + 1; // 修改 删除 插入  dp[i][j] = min(dp[i][j], min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); } } return dp[len_a][len_b]; } int main() { cin \u0026gt;\u0026gt; A \u0026gt;\u0026gt; B; cout \u0026lt;\u0026lt; calculate_distance(); } ","date":"2020-10-31T17:03:00+08:00","image":"https://ccqstark.github.io/p/dp_edit_distance/cover_hua1161b2ae5e85a208ecc4f734dd7884a_242133_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/dp_edit_distance/","title":"DP动态规划——编辑距离问题"},{"content":"题目 假设要在足够多的会场里安排一批活动，并希望使用尽可能少的会场。设计一个有效的 贪心算法进行安排。（这个问题实际上是著名的图着色问题。若将每一个活动作为图的一个 顶点，不相容活动间用边相连。使相邻顶点着有不同颜色的最小着色数，相应于要找的最小 会场数。）\n输入格式: 第一行有 1 个正整数k，表示有 k个待安排的活动。 接下来的 k行中，每行有 2个正整数，分别表示 k个待安排的活动开始时间和结束时间。时间 以 0 点开始的分钟计。\n输出格式: 输出最少会场数。\n输入样例: 5\r1 23\r12 28\r25 35\r27 80\r36 50 输出样例: 在这里给出相应的输出。例如：\n3\r思路 首先这道题就很像书中那道在一个会场中安排尽可能多的活动，但是，不能完全按之前那个思路来做！\n这里是要用尽可能少的会场，而且从题中可以看出会场的结束时间没有限制，只要活动的开始时间比上一场要晚就行。如果我们按书中的办法把活动先按结束时间从小到大排序，然后对当前未安排的活动用一个会场进行尽可能多的安排，之后若还每安排完在开辟一个新的会场继续之前的操作。这样的算法是有问题的，因为这样的在一个会场中尽可能多的安排活动，而从全局来看（还有这道题的特点：会场结束时间无限制），这种策略并不能保证把所有活动安排在最少的会场，所以两个问题并不能完全等同，这就是我一开始犯的错误。\n其实原因就在于：会场结束时间无限制，要用最少的会场。\n正确解法有2种：\n 把活动按开始时间从小到大排，当开始时间相同则结束时间早的优先。遍历活动再用之前的那种在一个会场安排尽可能多的活动，完了之后开辟一个新的会场继续安排，直到全部活动安排完毕。 把活动按结束时间从小到大排，当结束时间相同则开始时间早的优先。遍历活动，每次再遍历一次所有会场看结束时间是否满足可以安排下，都不能安排下就新开一个会场，然后每次还要对所有已经开辟的会场按结束时间进行从大到小再次排序，这样直到所有活动遍历安排完毕。  所以这道题是要把有限的活动尽量塞在最少的会场中，要从所有会场全局去考虑，而且这道题的特点是单个会场的结束时间没有限制，所以第一种解法是按开始时间排的而不用按结束时间。第二种按结束时间的话就需要每次重新遍历所有会场，每次还重排，保证从全局去考虑。\n代码 解法1： // 按开始时间排序 #include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 666  struct activity { int start; int end; int arrage; } activities[MAX]; int n; bool struct_compare(activity a, activity b) { if (a.start != b.start) return a.start \u0026lt; b.start; //优先进行最先开始的活动  else return a.end \u0026lt; b.end; //当开始时间相同时,优先进行最早结束的活动 } int main() { cin \u0026gt;\u0026gt; n; for (int i = 0; i \u0026lt; n; i++) { cin \u0026gt;\u0026gt; activities[i].start; cin \u0026gt;\u0026gt; activities[i].end; activities[i].arrage = 0; } // 初始化会场数  int room = 0; // 对活动\u0026#39;开始时间\u0026#39;进行从小到大排序  sort(activities, activities + n, struct_compare); // 记录当前安排会场的结束时间，被安排的会场数  int lastest = 0, arrage_num = 0; // 如果会场还没有被全部安排完  while (arrage_num != n) { // 新增一个会场  room++; for (int i = 0; i \u0026lt; n; i++) { // 在一个会场中安排尽可能多的活动  if (activities[i].arrage == 0 \u0026amp;\u0026amp; activities[i].start \u0026gt;= lastest) { activities[i].arrage = 1; // 标记活动为已被安排  arrage_num++; lastest = activities[i].end; // 更新当前会场的结束时间  } } lastest = 0; } //另外一种写法，效果一样  /* for (int i = 0; i \u0026lt; n; i++) { if (activities[i].arrage == 0) { room++; activities[i].arrage = 1; lastest = activities[i].end; for (int j = i + 1; j \u0026lt; n; j++) { if (activities[j].arrage == 0 \u0026amp;\u0026amp; activities[j].start \u0026gt;= lastest) { activities[j].arrage = 1; lastest = activities[j].end; } } } } */ cout \u0026lt;\u0026lt; room; return 0; } 解法2： //按结束时间排序 #include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 666  struct activity { int start; int end; } activities[MAX]; int n; int end_time[MAX] = {0}; // 记录每个会场的结束时间 int room = 1; // 会场数  bool struct_compare(activity a, activity b) { if (a.end != b.end) return a.end \u0026lt; b.end; //优先进行最早结束的活动  else return a.start \u0026lt; b.start; //当结束时间相同时,优先进行最早开始的活动 } bool dcmp(int a, int b) { return a \u0026gt; b; // 从大到小排序 } int main() { cin \u0026gt;\u0026gt; n; for (int i = 0; i \u0026lt; n; i++) { cin \u0026gt;\u0026gt; activities[i].start; cin \u0026gt;\u0026gt; activities[i].end; } // 对活动按\u0026#39;结束时间\u0026#39;进行排序  sort(activities, activities + n, struct_compare); // 遍历活动  for (int i = 0; i \u0026lt; n; i++) { int flag = 0; // 标记是否在已开辟的会场中被安排  for (int j = 1; j \u0026lt;= room; j++) // 遍历已有会场寻找合适的  { if (activities[i].start \u0026gt;= end_time[j]) { end_time[j] = activities[i].end; flag = 1; break; } } // 已有会场找不到合适的就开辟一个新的  if (!flag) { room++; end_time[room] = activities[i].end; } // 每次安排完一个活动都要对会场们按结束时间从大到小重排  sort(end_time + 1, end_time + room + 1, dcmp); } cout \u0026lt;\u0026lt; room; return 0; } 参考博文\n","date":"2020-10-31T09:45:00+08:00","image":"https://ccqstark.github.io/p/greedy_activity/cover_hud37e3ca5fae84e51507ebf04bd20edfb_89681_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/greedy_activity/","title":"贪心算法——会场安排问题"},{"content":"题目 在一个地图上有n个地窖（n≤200）,每个地窖中埋有一定数量的地雷。同时，给出地窖之间的连接路径，并规定路径都是单向的,且保证都是小序号地窖指向大序号地窖，也不存在可以从一个地窖出发经过若干地窖后又回到原来地窖的路径。某人可以从任意一处开始挖地雷，然后沿着指出的连接往下挖（仅能选择一条路径），当无连接时挖地雷工作结束。设计一个挖地雷的方案，使他能挖到最多的地雷。\n输入格式: 第一行：地窖的个数；\n第二行：为依次每个地窖地雷的个数；\n下面若干行：\nxi yi //表示从xi可到yi，xi\u0026lt;yi。\n最后一行为\u0026quot;0 0\u0026quot;表示结束。\n输出格式: k1-k2−…−kv //挖地雷的顺序 挖到最多的雷。\n输入样例: 6\r5 10 20 5 4 5\r1 2\r1 4\r2 4\r3 4\r4 5\r4 6\r5 6\r0 0\r输出样例: 3-4-5-6\r34\r代码 #include \u0026lt;iostream\u0026gt;using namespace std; #define MAX 203 int matrix[MAX][MAX]; // 存放通路情况 int mines[MAX]; // 存放各坑地雷数 int dp_mat[MAX][MAX]; // 存放子问题最优解 int path[MAX]; // 存放路径 int n, ans, last_update; // last_update是最后一个更新最大值的点  void dig() { // 一行行扫  for (int i = 1; i \u0026lt;= n; i++) { // max_last是此点之前所有点可以挖到的最大地雷数  int max_last = 0; for (int k = 1; k \u0026lt;= i - 1; k++) { // 判断之前所有可以通向现在的点中，可以挖到最大的地雷数的路径的最后一点  if (matrix[k][i] == 1) { // 按列方向扫，可以通向本点的点  if (dp_mat[k][i] \u0026gt; max_last) { max_last = dp_mat[k][i]; path[i] = k; // 路径是所连接的上一点  } } } for (int j = i; j \u0026lt;= n; j++) { // max_last + 本点地雷数 = 以本点作为路径末点可以挖到的最大地雷数  dp_mat[i][j] = max_last + mines[i]; if (dp_mat[i][j] \u0026gt; ans) { // 更新最终答案的最大地雷数  ans = dp_mat[i][j]; // 记录最后更新最终答案的那个点，作为答案路径的末尾点，用数组回溯可以打印出完整路径  last_update = i; } } } } // 递归回溯打印完整路径 void print_path(int point) { if (point == 0) return; print_path(path[point]); if (point == last_update) { cout \u0026lt;\u0026lt; point \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; point \u0026lt;\u0026lt; \u0026#34;-\u0026#34;; } } int main() { cin \u0026gt;\u0026gt; n; for (int i = 1; i \u0026lt;= n; i++) { cin \u0026gt;\u0026gt; mines[i]; } int a, b; while (cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b) { if (a == 0 \u0026amp;\u0026amp; b == 0) break; matrix[a][b] = 1; } dig(); print_path(last_update); cout \u0026lt;\u0026lt; ans; } ","date":"2020-10-22T01:05:00+08:00","image":"https://ccqstark.github.io/p/dp_digmines/cover_hua1161b2ae5e85a208ecc4f734dd7884a_242133_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/dp_digmines/","title":"DP动态规划——挖地雷"},{"content":"题目 设计一个O(n2)时间的算法，找出由n个数组成的序列的最长单调递增子序列。\n输入格式: 输入有两行： 第一行：n，代表要输入的数列的个数 第二行：n个数，数字之间用空格格开\n输出格式: 最长单调递增子序列的长度\n输入样例: 在这里给出一组输入。例如：\n5\r1 3 5 2 9\r输出样例: 在这里给出相应的输出。例如：\n4\r思路 用动态规划的思想，利用子问题的最优解求更大一点的子问题。\n设一个数组dp[i]用于存放数组中从0到i下标的序列中，最长的递增子序列的长度\n双重遍历，如果arr[j]小于arr[i]，则dp[i]为dp[j]+1和dp[i]中较大的那个。即\ndp[i] = max{ dp[j]+1, dp[i] }\n由于每次重头又遍历了一次，并每次都分析最优解，避免了1 2 3 9 6 7 这样在最大数后面还有2个较小的数可以产生更长递增子序列的情况可能犯的错误。\n这也说明这个算法的时间复杂度只能是O(n2)\n代码 // 单调递增最长子序列 #include \u0026lt;iostream\u0026gt;using namespace std; #define MAX 666 int arr[MAX]; int dp[MAX]; int n; int longest_increasing(){ // 初始化第一个  dp[0] = 1; // 双重遍历  for (int i = 0;i\u0026lt;n;i++){ for (int j = 0;j\u0026lt;i;j++){ // 利用子问题最优解  if(arr[i]\u0026gt;arr[j]){ dp[i] = (dp[j]+1\u0026gt;dp[i])?dp[j]+1:dp[i]; } } } // 找出dp[]中最大的那个作为答案  int max_len = 1; for (int i = 0;i\u0026lt;n;i++){ max_len = (dp[i]\u0026gt;max_len)?dp[i]:max_len; } return max_len; } int main() { cin\u0026gt;\u0026gt;n; for (int i = 0;i\u0026lt;n;i++){ cin\u0026gt;\u0026gt;arr[i]; } cout\u0026lt;\u0026lt;longest_increasing(); } ","date":"2020-10-21T21:07:00+08:00","image":"https://ccqstark.github.io/p/dp_increasing/cover_hua1161b2ae5e85a208ecc4f734dd7884a_242133_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/dp_increasing/","title":"DP动态规划——单调递增最长子序列"},{"content":"添加依赖 \u0026lt;!-- shiro --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- JWT --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.auth0\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;java-jwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.11.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; JWT加密解密验证工具类 package com.ccqstark.springbootquick.util; import com.auth0.jwt.JWT; import com.auth0.jwt.JWTVerifier; import com.auth0.jwt.algorithms.Algorithm; import io.jsonwebtoken.Claims; import io.jsonwebtoken.JwtBuilder; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import org.apache.commons.codec.binary.Base64; import java.util.Date; import java.util.HashMap; import java.util.Map; import java.util.UUID; /* * 总的来说，工具类中有三个方法 * 获取JwtToken，获取JwtToken中封装的信息，判断JwtToken是否存在 * 1. encode()，参数是=签发人，存在时间，一些其他的信息=。返回值是JwtToken对应的字符串 * 2. decode()，参数是=JwtToken=。返回值是荷载部分的键值对 * 3. isVerify()，参数是=JwtToken=。返回值是这个JwtToken是否存在 * */ public class JwtUtil { // 创建默认的秘钥和算法，供无参的构造方法使用  private static final String defaultbase64EncodedSecretKey = \u0026#34;wdnmd\u0026#34;; private static final SignatureAlgorithm defaultsignatureAlgorithm = SignatureAlgorithm.HS256; // 无参构造，使用默认  public JwtUtil() { this(defaultbase64EncodedSecretKey, defaultsignatureAlgorithm); } private final String base64EncodedSecretKey; private final SignatureAlgorithm signatureAlgorithm; // 有参构造  public JwtUtil(String secretKey, SignatureAlgorithm signatureAlgorithm) { this.base64EncodedSecretKey = Base64.encodeBase64String(secretKey.getBytes()); this.signatureAlgorithm = signatureAlgorithm; } /* *这里就是产生jwt字符串的地方 * jwt字符串包括三个部分 * 1. header * -当前字符串的类型，一般都是“JWT” * -哪种算法加密，“HS256”或者其他的加密算法 * 所以一般都是固定的，没有什么变化 * 2. payload * 一般有四个最常见的标准字段（下面有） * iat：签发时间，也就是这个jwt什么时候生成的 * jti：JWT的唯一标识 * iss：签发人，一般都是username或者userId * exp：过期时间 * * */ public String encode(String iss, long ttlMillis, Map\u0026lt;String, Object\u0026gt; claims) { //iss签发人，ttlMillis生存时间，claims是指还想要在jwt中存储的一些非隐私信息  if (claims == null) { claims = new HashMap\u0026lt;\u0026gt;(); } long nowMillis = System.currentTimeMillis(); JwtBuilder builder = Jwts.builder() .setClaims(claims) .setId(UUID.randomUUID().toString())// 这个是JWT的唯一标识，一般设置成唯一的，这个方法可以生成唯一标识  .setIssuedAt(new Date(nowMillis))// 这个地方就是以毫秒为单位，换算当前系统时间生成的iat  .setIssuer(iss)// 签发人，也就是JWT是给谁的（逻辑上一般都是username或者userId）  .signWith(signatureAlgorithm, base64EncodedSecretKey);//这个地方是生成jwt使用的算法和秘钥  if (ttlMillis \u0026gt;= 0) { // 过期时间 = 当前时间 + 生存时间  long expMillis = nowMillis + ttlMillis; Date exp = new Date(expMillis);// 过期时间，这个也是使用毫秒生成的  builder.setExpiration(exp); } return builder.compact(); } //相当于encode的逆向，传入jwtToken生成对应的username和password等字段。Claim就是一个map  //也就是拿到荷载部分所有的键值对  public Claims decode(String jwtToken) { // 得到 DefaultJwtParser  return Jwts.parser() // 设置签名的秘钥  .setSigningKey(base64EncodedSecretKey) // 设置需要解析的 jwt  .parseClaimsJws(jwtToken) .getBody(); } //判断jwtToken是否合法  public boolean isVerify(String jwtToken) { //这个是官方的校验规则，这里只写了一个\u0026#34;校验算法\u0026#34;，可以自己加  Algorithm algorithm = null; switch (signatureAlgorithm) { case HS256: algorithm = Algorithm.HMAC256(Base64.decodeBase64(base64EncodedSecretKey)); break; default: throw new RuntimeException(\u0026#34;不支持该算法\u0026#34;); } JWTVerifier verifier = JWT.require(algorithm).build(); verifier.verify(jwtToken); // 校验不通过会抛出异常  //判断合法的标准：1. 头部和荷载部分没有篡改过。2. 没有过期  return true; } public static void main(String[] args) { JwtUtil util = new JwtUtil(\u0026#34;wdnmd\u0026#34;, SignatureAlgorithm.HS256); //以tom作为秘钥，以HS256加密  Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;username\u0026#34;, \u0026#34;ccq\u0026#34;); map.put(\u0026#34;password\u0026#34;, \u0026#34;1428\u0026#34;); map.put(\u0026#34;age\u0026#34;, 20); String jwtToken = util.encode(\u0026#34;ccqstark\u0026#34;, 30000, map); System.out.println(jwtToken); util.decode(jwtToken).entrySet().forEach((entry) -\u0026gt; { System.out.println(entry.getKey() + \u0026#34;: \u0026#34; + entry.getValue()); }); } } 关闭shiro的session package com.ccqstark.springbootquick.auth; import org.apache.shiro.subject.Subject; import org.apache.shiro.subject.SubjectContext; import org.apache.shiro.web.mgt.DefaultWebSubjectFactory; // 关闭shiro的session public class JwtDefaultSubjectFactory extends DefaultWebSubjectFactory { @Override public Subject createSubject(SubjectContext context) { // 不创建 session  context.setSessionCreationEnabled(false); return super.createSubject(context); } } 使用UsernamePasswordToken package com.ccqstark.springbootquick.auth; import org.apache.shiro.authc.AuthenticationToken; //这个就类似UsernamePasswordToken public class JwtToken implements AuthenticationToken { private String jwt; public JwtToken(String jwt) { this.jwt = jwt; } @Override//类似是用户名  public Object getPrincipal() { return jwt; } @Override//类似密码  public Object getCredentials() { return jwt; } //返回的都是jwt } Realm验证类 package com.ccqstark.springbootquick.auth; import com.ccqstark.springbootquick.util.JwtUtil; import lombok.extern.slf4j.Slf4j; import org.apache.shiro.authc.*; import org.apache.shiro.authz.AuthorizationInfo; import org.apache.shiro.realm.AuthorizingRealm; import org.apache.shiro.subject.PrincipalCollection; @Slf4j public class JwtRealm extends AuthorizingRealm { /* * 多重写一个support * 标识这个Realm是专门用来验证JwtToken * 不负责验证其他的token（UsernamePasswordToken） * */ @Override public boolean supports(AuthenticationToken token) { //这个token就是从过滤器中传入的jwtToken  return token instanceof JwtToken; } //授权  @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { return null; } //认证  //这个token就是从过滤器中传入的jwtToken  @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { String jwt = (String) token.getPrincipal(); if (jwt == null) { throw new NullPointerException(\u0026#34;jwtToken 不允许为空\u0026#34;); } //判断  JwtUtil jwtUtil = new JwtUtil(); if (!jwtUtil.isVerify(jwt)) { throw new UnknownAccountException(); } //下面是验证这个user是否是真实存在的  String username = (String) jwtUtil.decode(jwt).get(\u0026#34;username\u0026#34;);//判断数据库中username是否存在  log.info(\u0026#34;在使用token登录\u0026#34;+username); return new SimpleAuthenticationInfo(jwt,jwt,\u0026#34;JwtRealm\u0026#34;); //这里返回的是类似账号密码的东西，但是jwtToken都是jwt字符串。还需要一个该Realm的类名  } } Filter过滤器 package com.ccqstark.springbootquick.auth; import lombok.extern.slf4j.Slf4j; import org.apache.shiro.web.filter.AccessControlFilter; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /* * 自定义一个Filter，用来拦截所有的请求判断是否携带Token * isAccessAllowed()判断是否携带了有效的JwtToken * onAccessDenied()是没有携带JwtToken的时候进行账号密码登录，登录成功允许访问，登录失败拒绝访问 * */ @Slf4j public class JwtFilter extends AccessControlFilter { /* * 1. 返回true，shiro就直接允许访问url * 2. 返回false，shiro才会根据onAccessDenied的方法的返回值决定是否允许访问url * */ @Override protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception { log.warn(\u0026#34;isAccessAllowed 方法被调用\u0026#34;); //这里先让它始终返回false来使用onAccessDenied()方法  return false; } /** * 返回结果为true表明登录通过 */ @Override protected boolean onAccessDenied(ServletRequest servletRequest, ServletResponse servletResponse) throws Exception { log.warn(\u0026#34;onAccessDenied 方法被调用\u0026#34;); //这个地方和前端约定，要求前端将jwtToken放在请求的Header部分  //所以以后发起请求的时候就需要在Header中放一个Authorization，值就是对应的Token  HttpServletRequest request = (HttpServletRequest) servletRequest; String jwt = request.getHeader(\u0026#34;Authorization\u0026#34;); log.info(\u0026#34;请求的 Header 中藏有 jwtToken {}\u0026#34;, jwt); JwtToken jwtToken = new JwtToken(jwt); /* * 下面就是固定写法 * */ try { // 委托 realm 进行登录认证  //所以这个地方最终还是调用JwtRealm进行的认证  getSubject(servletRequest, servletResponse).login(jwtToken); //也就是subject.login(token)  } catch (Exception e) { e.printStackTrace(); onLoginFail(servletResponse); //调用下面的方法向客户端返回错误信息  return false; } return true; //执行方法中没有抛出异常就表示登录成功  } //登录失败时默认返回 401 状态码  private void onLoginFail(ServletResponse response) throws IOException { HttpServletResponse httpResponse = (HttpServletResponse) response; httpResponse.setStatus(HttpServletResponse.SC_UNAUTHORIZED); httpResponse.getWriter().write(\u0026#34;login error\u0026#34;); } } shiro配置 package com.ccqstark.springbootquick.config; import com.ccqstark.springbootquick.auth.*; import org.apache.shiro.mgt.DefaultSessionStorageEvaluator; import org.apache.shiro.mgt.DefaultSubjectDAO; import org.apache.shiro.mgt.SubjectFactory; import org.apache.shiro.realm.Realm; import org.apache.shiro.spring.web.ShiroFilterFactoryBean; import org.apache.shiro.web.filter.authc.AnonymousFilter; import org.apache.shiro.web.filter.authc.LogoutFilter; import org.apache.shiro.web.mgt.DefaultWebSecurityManager; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import javax.servlet.Filter; import java.util.HashMap; import java.util.LinkedHashMap; import java.util.Map; //springBoot整合jwt实现认证有三个不一样的地方，对应下面abc @Configuration public class ShiroConfig { /* * a. 告诉shiro不要使用默认的DefaultSubject创建对象，因为不能创建Session * */ @Bean public SubjectFactory subjectFactory() { return new JwtDefaultSubjectFactory(); } @Bean public Realm realm() { return new JwtRealm(); } @Bean public DefaultWebSecurityManager securityManager() { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(realm()); /* * b * */ // 关闭 ShiroDAO 功能  DefaultSubjectDAO subjectDAO = new DefaultSubjectDAO(); DefaultSessionStorageEvaluator defaultSessionStorageEvaluator = new DefaultSessionStorageEvaluator(); // 不需要将 Shiro Session 中的东西存到任何地方（包括 Http Session 中）  defaultSessionStorageEvaluator.setSessionStorageEnabled(false); subjectDAO.setSessionStorageEvaluator(defaultSessionStorageEvaluator); securityManager.setSubjectDAO(subjectDAO); //禁止Subject的getSession方法  securityManager.setSubjectFactory(subjectFactory()); return securityManager; } @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean() { ShiroFilterFactoryBean shiroFilter = new ShiroFilterFactoryBean(); shiroFilter.setSecurityManager(securityManager()); shiroFilter.setLoginUrl(\u0026#34;/unauthenticated\u0026#34;); shiroFilter.setUnauthorizedUrl(\u0026#34;/unauthorized\u0026#34;); /* * c. 添加jwt过滤器，并在下面注册 * 也就是将jwtFilter注册到shiro的Filter中 * 指定除了login和logout之外的请求都先经过jwtFilter * */ Map\u0026lt;String, Filter\u0026gt; filterMap = new HashMap\u0026lt;\u0026gt;(); //这个地方其实另外两个filter可以不设置，默认就是  filterMap.put(\u0026#34;anon\u0026#34;, new AnonymousFilter()); filterMap.put(\u0026#34;jwt\u0026#34;, new JwtFilter()); filterMap.put(\u0026#34;logout\u0026#34;, new LogoutFilter()); shiroFilter.setFilters(filterMap); // 拦截器  Map\u0026lt;String, String\u0026gt; filterRuleMap = new LinkedHashMap\u0026lt;\u0026gt;(); filterRuleMap.put(\u0026#34;/login\u0026#34;, \u0026#34;anon\u0026#34;); filterRuleMap.put(\u0026#34;/logout\u0026#34;, \u0026#34;logout\u0026#34;); filterRuleMap.put(\u0026#34;/**\u0026#34;, \u0026#34;jwt\u0026#34;); shiroFilter.setFilterChainDefinitionMap(filterRuleMap); return shiroFilter; } } 测试Controller package com.ccqstark.springbootquick.controller; import com.ccqstark.springbootquick.util.JwtUtil; import io.jsonwebtoken.SignatureAlgorithm; import lombok.extern.slf4j.Slf4j; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; import java.util.HashMap; import java.util.Map; @Slf4j @Controller public class LoginController { @RequestMapping(\u0026#34;/login\u0026#34;) public ResponseEntity\u0026lt;Map\u0026lt;String, String\u0026gt;\u0026gt; login(String username, String password) { log.info(\u0026#34;username:{},password:{}\u0026#34;,username,password); Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); if (!\u0026#34;tom\u0026#34;.equals(username) || !\u0026#34;123\u0026#34;.equals(password)) { map.put(\u0026#34;msg\u0026#34;, \u0026#34;用户名密码错误\u0026#34;); return ResponseEntity.ok(map); } JwtUtil jwtUtil = new JwtUtil(\u0026#34;wdnmd\u0026#34;, SignatureAlgorithm.HS256); Map\u0026lt;String, Object\u0026gt; chaim = new HashMap\u0026lt;\u0026gt;(); chaim.put(\u0026#34;username\u0026#34;, username); // 生存时间在这里设置  String jwtToken = jwtUtil.encode(username, 20*1000, chaim); map.put(\u0026#34;msg\u0026#34;, \u0026#34;登录成功\u0026#34;); map.put(\u0026#34;token\u0026#34;, jwtToken); return ResponseEntity.ok(map); } @RequestMapping(\u0026#34;/testdemo\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; testdemo() { return ResponseEntity.ok(\u0026#34;我爱蛋炒饭\u0026#34;); } } 请求登录接口，密码正确后返回一个token，以后每次请求带上这个token以header里的Authorization字段的形式\n之后的页面都会经过拦截器分配到对应的过滤器进行验证token是否有效，实现了鉴权。\n","date":"2020-10-17T16:52:00+08:00","image":"https://ccqstark.github.io/p/springboot_shiro_jwt/cover_hud62bf8010474cbdcf139a7fd30aacc5c_25975_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/springboot_shiro_jwt/","title":"[SpringBoot]整合shiro+JWT做鉴权"},{"content":"开通服务 登录阿里云，开通OSS服务，默认按量计费，为了业务稳定可以购买包月包年的资源包。\n准备工作 创建Bucket，如果是为了作为网站的静态资源存储供用户访问的话把权限设为公共读，填写信息后创建成功，可以在Bucket下新建目录什么的。\n单独创建一个RAM子用户用来调用API，选择编程访问，创建成功后一定要把AccessKeyID和AccessKeySecret等重要信息记下来，后面配置文件要用到。\n然后要给这个子用户添加权限AliyunOSSFullAccess\nMaven依赖 \u0026lt;!-- OSS --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-sdk-oss\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.2\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件 endpoint就是在存储桶的概览里地域节点，填外网访问那个就行\nurl填资源访问的URL的前面部分（填到.com/）\naccessKeyId和accessKeySecret就是创建子用户时那个\nbucketName就是存储桶的名字\n# 阿里云ossoss:endpoint:*url:*accessKeyId:*accessKeySecret:*bucketName:*配置类 项目的config目录下新建OSS的配置类\npackage com.ccqstark.springbootquick.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import java.io.Serializable; /** * @Description: 阿里云 OSS 配置信息 * @Author: ccq * @Date: 2020/10/16 */ @Component //注册bean @Data @Configuration @ConfigurationProperties(prefix = \u0026#34;oss\u0026#34;) public class OSSConfig implements Serializable { private String endpoint; private String url; private String accessKeyId; private String accessKeySecret; private String bucketName; } 上传文件工具类 项目的util目录下新建这上传工具类\npackage com.ccqstark.springbootquick.util; import com.aliyun.oss.ClientConfiguration; import com.aliyun.oss.OSSClient; import com.aliyun.oss.common.auth.DefaultCredentialProvider; import com.ccqstark.springbootquick.config.OSSConfig; import org.springframework.web.multipart.MultipartFile; import java.io.IOException; import java.util.UUID; /** * @Description: 阿里云 oss 上传工具类(高依赖版) * @Author: ccq * @Date: 2020/10/17 */ public class OSSBootUtil { private OSSBootUtil(){} /** * oss 工具客户端 */ private volatile static OSSClient ossClient = null; /** * 上传文件至阿里云 OSS * 文件上传成功,返回文件完整访问路径 * 文件上传失败,返回 null * * @param ossConfig oss 配置信息 * @param file 待上传文件 * @param fileDir 文件保存目录 * @return oss 中的相对文件路径 */ public static String upload(OSSConfig ossConfig, MultipartFile file, String fileDir){ // 初始化客户端  initOSS(ossConfig); // 文件URL  StringBuilder fileUrl = new StringBuilder(); try { String suffix = file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf(\u0026#39;.\u0026#39;)); String fileName = System.currentTimeMillis() + \u0026#34;-\u0026#34; + UUID.randomUUID().toString().substring(0,18) + suffix; if (!fileDir.endsWith(\u0026#34;/\u0026#34;)) { fileDir = fileDir.concat(\u0026#34;/\u0026#34;); } fileUrl = fileUrl.append(fileDir + fileName); // 上传文件到指定的存储空间，并将其保存为指定的文件名称  ossClient.putObject(ossConfig.getBucketName(), fileUrl.toString(), file.getInputStream()); } catch (IOException e) { e.printStackTrace(); return null; } fileUrl = fileUrl.insert(0,ossConfig.getUrl()); return fileUrl.toString(); } /** * 初始化 oss 客户端 * @param ossConfig * @return */ private static OSSClient initOSS(OSSConfig ossConfig) { if (ossClient == null ) { synchronized (OSSBootUtil.class) { if (ossClient == null) { ossClient = new OSSClient(ossConfig.getEndpoint(), new DefaultCredentialProvider(ossConfig.getAccessKeyId(), ossConfig.getAccessKeySecret()), new ClientConfiguration()); } } } return ossClient; } } 服务层 在项目的service目录下新建服务层接口\npackage com.ccqstark.springbootquick.service; import com.ccqstark.springbootquick.model.ApiResult; import org.springframework.web.multipart.MultipartFile; /** * @Description: 公共业务 * @Author: ccq * @Date: 2020/10/17 */ public interface CommonService { /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ ApiResult uploadOSS(MultipartFile file, String uploadKey) throws Exception; } 新建实现类\npackage com.ccqstark.springbootquick.service; import com.ccqstark.springbootquick.config.OSSConfig; import com.ccqstark.springbootquick.model.ApiResult; import com.ccqstark.springbootquick.util.OSSBootUtil; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.web.multipart.MultipartFile; import java.util.HashMap; import java.util.Map; /** * @Description: 公共业务具体实现类 * @Author: ccq * @Date: 2020/10/17 */ @Service(\u0026#34;commonService\u0026#34;) public class CommonServiceImpl implements CommonService { @Autowired private OSSConfig ossConfig; /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ @Override public ApiResult uploadOSS(MultipartFile file, String uploadKey) throws Exception { // 高依赖版本 oss 上传工具  String ossFileUrlBoot = null; ossFileUrlBoot = OSSBootUtil.upload(ossConfig, file, \u0026#34;image/\u0026#34;); // 注意这里填写的是存储桶中你要存放文件的目录  Map\u0026lt;String, Object\u0026gt; resultMap = new HashMap\u0026lt;\u0026gt;(16); resultMap.put(\u0026#34;ossFileUrlBoot\u0026#34;, ossFileUrlBoot); return new ApiResult(200, resultMap); } } Controller上传测试 package com.ccqstark.springbootquick.controller; import com.ccqstark.springbootquick.model.ApiResult; import com.ccqstark.springbootquick.service.CommonService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpHeaders; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.multipart.MultipartFile; /** * @Description: 上传文件 * @Author: ccq * @Date: 2020/10/17 */ @Slf4j @RestController @RequestMapping(\u0026#34;/upload\u0026#34;) public class UploadController { @Autowired private CommonService commonService; /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ @RequestMapping(value = \u0026#34;/oss\u0026#34;, method = {RequestMethod.POST}, produces = {MediaType.APPLICATION_JSON_VALUE}) public ResponseEntity\u0026lt;?\u0026gt; uploadOSS(@RequestParam(value = \u0026#34;file\u0026#34;) MultipartFile file, String uploadKey) throws Exception { ApiResult apiResult = commonService.uploadOSS(file, uploadKey); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return new ResponseEntity\u0026lt;\u0026gt;(apiResult, headers, HttpStatus.CREATED); } } Postman工具，用POST请求，在form-data中用file字段对应图片或其他类型的文件，然后请求接口\n返回的URL在浏览器中可以用公网访问说明成功了！\n","date":"2020-10-17T10:54:00+08:00","image":"https://ccqstark.github.io/p/springboot_oss/cover_hud62bf8010474cbdcf139a7fd30aacc5c_25975_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/springboot_oss/","title":"[SpringBoot]使用阿里云OSS上传文件"},{"content":"添加依赖 \u0026lt;!-- druid数据库连接池 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.21\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySql数据库驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- log4j日志 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 添加配置 spring:datasource:username:rootpassword:root#serverTimezone=UTC解决时区的报错url:jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf-8driver-class-name:com.mysql.cj.jdbc.Drivertype:com.alibaba.druid.pool.DruidDataSource#Spring Boot 默认是不注入这些属性值的，需要自己绑定#druid 数据源专有配置initialSize:5minIdle:5maxActive:20maxWait:60000timeBetweenEvictionRunsMillis:60000minEvictableIdleTimeMillis:300000validationQuery:SELECT 1 FROM DUALtestWhileIdle:truetestOnBorrow:falsetestOnReturn:falsepoolPreparedStatements:true#配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入#如果允许时报错 java.lang.ClassNotFoundException: org.apache.log4j.Priority#则导入 log4j 依赖即可，Maven 地址：https://mvnrepository.com/artifact/log4j/log4jfilters:stat,wall,log4jmaxPoolPreparedStatementPerConnectionSize:20useGlobalDataSourceStat:trueconnectionProperties:druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500测试 编写测试类\n@SpringBootTest class SpringbootQuickApplicationTests { @Autowired DataSource dataSource; @Test void contextLoads() throws SQLException { System.out.println(dataSource.getClass()); Connection connection = dataSource.getConnection(); System.out.println(connection); connection.close(); } } 运行后控制台出现如下druid连接池相关字样说明成功\n2020-10-15 10:40:34.179 INFO 11352 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} inited\rDEBUG [main] - {conn-10005} pool-connect\rcom.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@31db34da\rDEBUG [main] - {conn-10005} pool-recycle\r添加后台监控 项目应用目录下的cofig目录添加\n@Configuration public class DruidConfig { @ConfigurationProperties(prefix = \u0026#34;spring.datasource\u0026#34;) @Bean public DataSource druidDataSource(){ return new DruidDataSource(); } @Bean // 后台监控  public ServletRegistrationBean statViewServlet(){ ServletRegistrationBean\u0026lt;StatViewServlet\u0026gt; bean = new ServletRegistrationBean\u0026lt;\u0026gt;(new StatViewServlet(),\u0026#34;/druid/*\u0026#34;); // 存储账号密码  HashMap\u0026lt;String,String\u0026gt; initParameters = new HashMap\u0026lt;\u0026gt;(); // 设置后台登录账号密码  initParameters.put(\u0026#34;loginUsername\u0026#34;,\u0026#34;admin\u0026#34;); initParameters.put(\u0026#34;loginPassword\u0026#34;,\u0026#34;123456\u0026#34;); // 谁都可以访问  initParameters.put(\u0026#34;allow\u0026#34;,\u0026#34;\u0026#34;); bean.setInitParameters(initParameters); // 设置初始化参数  return bean; } // filter  public FilterRegistrationBean webStatFilter(){ FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); // 被过滤的请求  Map\u0026lt;String,String\u0026gt; initParameters = new HashMap\u0026lt;\u0026gt;(); initParameters.put(\u0026#34;exclusions\u0026#34;,\u0026#34;*.js,*.css,/druid/*\u0026#34;); bean.setInitParameters(initParameters); return bean; } } 运行项目后打开localhost:8080/druid/出现后台监控登录页面说明成功\n","date":"2020-10-17T10:54:00+08:00","image":"https://ccqstark.github.io/p/springboot_druid/cover_hud62bf8010474cbdcf139a7fd30aacc5c_25975_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/springboot_druid/","title":"[SpringBoot]整合Druid数据源"},{"content":"以我的项目目录结构为例: com.ccqstark.springbootquick\n导入依赖 \u0026lt;!-- springboot的mybatis --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置 #整合mybatismybatis:type-aliases-package:com.ccqstark.springbootquick.pojomapper-locations:classpath:mybatis/mapper/*.xml编写POJO(用了Lombok) 在com.ccqstark.springbootquick下新建目录pojo，然后新建类User.java，用于存储数据的对象（与数据库中的表对应）\npackage com.ccqstark.springbootquick.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class User { private int id; private String name; private String pwd; } 编写Mapper 在com.ccqstark.springbootquick下新建目录mapper，然后新建UserMapper.java，用于写接口，CRUD函数\npackage com.ccqstark.springbootquick.mapper; import com.ccqstark.springbootquick.pojo.User; import org.apache.ibatis.annotations.Mapper; import org.springframework.stereotype.Repository; import java.util.List; // Mapper注解说明这是一个mybatis的mapper类 //@Mapper //如果有扫描的话这里可以不用写这个注解了 @Repository public interface UserMapper { List\u0026lt;User\u0026gt; queryUserList(); User queryByUserId(int id); int addUser(User user); int updateUser(User user); int deleteUser(int id); } 如果是以扫描的形式，就是在项目的app启动类加上注解**@MapperScan**\n@SpringBootApplication // 也可以用着方式扫描，就不用一个个写@Mapper了 @MapperScan(\u0026#34;com.ccqstark.springbootquick.mapper\u0026#34;) public class SpringbootQuickApplication { public static void main(String[] args) { SpringApplication.run(SpringbootQuickApplication.class, args); } } 在XML里编写SQL语句 在resources目录下新建mybatis/mapper目录，再在下面新建xml文件，如这里的UserMapper.xml，在里面记得配好namespace，然后就可以写自定义SQL语句啦\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.ccqstark.springbootquick.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;!-- namespace要配好，如上面的格式，对应源码目录中的mapper接口 --\u0026gt; \u0026lt;!-- 下面就是CRUD的SQL语句 --\u0026gt; \u0026lt;!-- id对应的就是接口定义的函数名 --\u0026gt; \u0026lt;select id=\u0026#34;queryUserList\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; // id对现有 SELECT * FROM user \u0026lt;/select\u0026gt; \u0026lt;!-- #{id}就是模板待填空位--\u0026gt; \u0026lt;select id=\u0026#34;queryByUserId\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; SELECT * FROM user WHERE id = #{id} \u0026lt;/select\u0026gt; \u0026lt;insert id=\u0026#34;addUser\u0026#34; parameterType=\u0026#34;User\u0026#34;\u0026gt; INSERT into user (id,name,pwd) values (#{id},#{name},#{pwd}) \u0026lt;/insert\u0026gt; \u0026lt;update id=\u0026#34;updateUser\u0026#34; parameterType=\u0026#34;User\u0026#34;\u0026gt; UPDATE user SET name=#{name},pwd=#{pwd} where id = #{id} \u0026lt;/update\u0026gt; \u0026lt;delete id=\u0026#34;deleteUser\u0026#34; parameterType=\u0026#34;int\u0026#34;\u0026gt; DELETE FROM user WHERE id = #{id} \u0026lt;/delete\u0026gt; \u0026lt;/mapper\u0026gt; 调用来进行CRUD 在Controller或者Service里调用Mybatis进行CRUD，先@Autowired注入一个Mapper，然后利用这个接口类型指向的对象就可以调用接口里面的方法了。这些方法对应的sql语句操作就是在xml中定义的。\n@RestController @RequestMapping(\u0026#34;/mybatis\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @PostMapping(\u0026#34;/query\u0026#34;) public List\u0026lt;User\u0026gt; queryUserList(){ List\u0026lt;User\u0026gt; userList = userMapper.queryUserList(); return userList; } @PostMapping(\u0026#34;/create\u0026#34;) public String createUser(){ userMapper.addUser(new User(4,\u0026#34;wuhu\u0026#34;,\u0026#34;5555\u0026#34;)); return \u0026#34;ok\u0026#34;; } @PostMapping(\u0026#34;/update\u0026#34;) public String updateUser(){ userMapper.updateUser(new User(1,\u0026#34;qqq\u0026#34;,\u0026#34;33\u0026#34;)); return \u0026#34;ok\u0026#34;; } @PostMapping(\u0026#34;/delete\u0026#34;) public String deleteUser(){ userMapper.deleteUser(4); return \u0026#34;ok\u0026#34;; } } ","date":"2020-10-17T10:54:00+08:00","image":"https://ccqstark.github.io/p/springboot_mybatis/cover_hud62bf8010474cbdcf139a7fd30aacc5c_25975_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/springboot_mybatis/","title":"[SpringBoot]整合Mybatis"},{"content":"导入依赖 \u0026lt;!-- SLF4j - log4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8.0-alpha2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 然后要在IDEA下载插件Maven Helper中把logback相关的包给Exclude，否则会出现冲突\n配置 log4j.properties中配置\n# rootLogger参数分别为：根Logger级别，输出器stdout，输出器log\rlog4j.rootLogger = info,stdout,log\r# 输出信息到控制台\rlog4j.appender.stdout = org.apache.log4j.ConsoleAppender\rlog4j.appender.stdout.layout = org.apache.log4j.PatternLayout\rlog4j.appender.stdout.layout.ConversionPattern = %d [%-5p] %l %rms: %m%n\r# 输出DEBUG级别以上的日志到D://log/debug.log，这个是日志文件存放的路径，根据时间情况进行设置\rlog4j.appender.log = org.apache.log4j.DailyRollingFileAppender\rlog4j.appender.log.DatePattern = '.'yyyy-MM-dd\rlog4j.appender.log.File = D://log/debug.log\rlog4j.appender.log.Encoding = UTF-8\r#log4j.appender.log.Threshold = INFO\rlog4j.appender.log.layout = org.apache.log4j.PatternLayout\rlog4j.appender.log.layout.ConversionPattern = %d [%-5p] (%c.%t): %m%n\r测试 编写测试类，使用@Slf4j注解之前确保使用了lombok\npackage com.ccqstark.springbootquick; import lombok.extern.slf4j.Slf4j; import org.junit.Test; @Slf4j public class LoggerTest { // private static final Logger log = LoggerFactory.getLogger(LoggerTest.class);  @Test public void TestSLF4j(){ log.info(\u0026#34;Current Time: {}\u0026#34;, System.currentTimeMillis()); log.info(\u0026#34;Current Time: \u0026#34; + System.currentTimeMillis()); log.info(\u0026#34;Current Time: {}\u0026#34;, System.currentTimeMillis()); log.trace(\u0026#34;trace log\u0026#34;); log.warn(\u0026#34;warn log\u0026#34;); log.debug(\u0026#34;debug log\u0026#34;); log.info(\u0026#34;info log\u0026#34;); log.error(\u0026#34;error log\u0026#34;); } } 运行后输出以下说明成功\n2020-10-15 16:36:45,459 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:13) 0ms: Current Time: 1602751005450\r2020-10-15 16:36:45,464 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:14) 5ms: Current Time: 1602751005464\r2020-10-15 16:36:45,465 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:15) 6ms: Current Time: 1602751005465\r2020-10-15 16:36:45,466 [WARN ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:17) 7ms: warn log\r2020-10-15 16:36:45,466 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:19) 7ms: info log\r2020-10-15 16:36:45,468 [ERROR] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:20) 9ms: error log\r用法 添加注解@Slf4j（确保使用了lombok）\n然后如测试类中log.info或其他类型的日志便可以使用了\n","date":"2020-10-17T10:54:00+08:00","image":"https://ccqstark.github.io/p/springboot_slf4j-log4j/cover_hud62bf8010474cbdcf139a7fd30aacc5c_25975_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/springboot_slf4j-log4j/","title":"[SpringBoot]整合SLF4J-log4j"},{"content":"问题引入 学过线性代数都知道矩阵的乘法，比如说矩阵A×B，就是A的每一行上的元素分别和B的每一列上对应位置的元素相乘再总体相加，每次得到一个位置上的元素的值。\n假设A是p × q，B是q × r，那结果矩阵就是p × r，当然，能够相乘的条件是A的列数等于B的行数。\n而A×B总共需要做的乘法数是p × q × r，由矩阵乘法的过程可知。\n可以发现，当至少3个矩阵相乘时，比如ABC，(AB)C和(A)BC两种计算顺序所需做的乘法数是不同的。\n现在的问题是一个矩阵链，比如A × B × C × D × E × F × G，要以什么样的顺序相乘才能得使得所需做的乘法数最小呢？\n题目 输入格式: 每个输入文件为一个测试用例，每个测试用例的第一行给出一个正整数(1≤n≤100)，表示一共有n个矩阵A​1​​ ,A​2​​ ,…,A​n​​ ，第二行给出n+1个整数P​0​​ ,P​1​​ …P​n​​ ，以空格分隔，其中1≤P​i​​ ≤100(0≤i≤n)，第i个矩阵A​i​​ 是阶为P​i−1​​ ∗P​i​​ 的矩阵。\n输出格式: 获得上述矩阵的乘积，所需的最少乘法次数。\n输入样例: 在这里给出一组输入。例如：\n 5\n30 35 15 5 10 20\n 输出样例: 在这里给出相应的输出。例如：\n 11875\n 思路 可以先求2个2个相邻相乘的值，然后用他们求3个3个相乘的，再4个\u0026hellip;依照此规律直到n个\n当前个数阶段也需要把每种划分方案进行尝试，并得出最小的那种。比如我在算4个4个相乘的，那划分位置就有3个，每个都要遍历算一次，最后选最小那个，为下一阶段使用。\n我们利用二维数组m[i][j]表示第i个到第j个矩阵连乘的最优解，有如下公式。\n就是每次划分为2部分，整体最优解=左部分最优解+右部分的最优解+两者相乘所需乘法数\n矩阵i的行数为p[i-1]，列数为p[i]\n \n我们用一个二维矩阵来存储各阶段结果，数据就一步步往右上角填上去，最终答案就在最右上角。\n \n代码 // 矩阵链相乘问题 #include \u0026lt;iostream\u0026gt;#include \u0026lt;string.h\u0026gt;using namespace std; const int MAX = 1000; int p[MAX]; // 存放行列数，就是题目输入的序列 int m[MAX][MAX]; // 存放局部和最终结果的矩阵 int n; // 需要相乘的矩阵个数  void matrix() { memset(m, 0, sizeof(m)); // 初始化矩阵为0  // 同时连续相乘的个数  for (int r = 2; r \u0026lt;= n; r++) { // 从第几个开始(到第几组了)  for (int i = 1; i \u0026lt;= n - r + 1; i++) { // 相乘链的最后一个  int j = i + r - 1; // 为了通过比较从而得出最小的那个，要有一个比较的初值，这里是划分第一个和其余的为2组  m[i][j] = m[i + 1][j] + p[i - 1] * p[i] * p[j]; // 一步步移动划分点  for (int k = i + 1; k \u0026lt; j; k++) { // 以k位置为划分点，划分i到j的相乘链  int t = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j]; // 比较找出最小的那个  if (t \u0026lt; m[i][j]) { m[i][j] = t; } } } } } int main() { cin \u0026gt;\u0026gt; n; // 输入的数字总数比矩阵个数多1  for (int i = 0; i \u0026lt; n + 1; i++) { cin \u0026gt;\u0026gt; p[i]; } matrix(); // 最后答案会在右上角出现  cout \u0026lt;\u0026lt; m[1][n]; } 参考博文\n","date":"2020-10-12T21:07:00+08:00","image":"https://ccqstark.github.io/p/dp_matrix/cover_hua1161b2ae5e85a208ecc4f734dd7884a_242133_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/dp_matrix/","title":"DP动态规划——矩阵链相乘问题"},{"content":"“工欲善其事，必先利其器”，作为后端搬砖工，我们敲代码之前需要给我们的电脑配上所需的软件环境，这样我们写的代码才能跑起来，原地起飞！\n下载集成环境工具 可以选择xampp或phpenv（二选一就行）\nxampp xampp = Apache + MySQL(MariaDB) + PHP + Perl，是一个集成环境软件，装了一个就可以轻松获得服务器，数据库和php语言的环境，轻松快捷而且免费，唯一的缺点可能是因为是外网所以速度稍慢或者可能需要科学上网\n官网下载：https://www.apachefriends.org/zh_cn/index.html\n选择自己的平台，然后点击下载，完成后运行exe\n按普通安装步骤来就好，下面这个界面也默认选择就好，有些环境之后会用到\n \n安装路径建议安装在D盘，然后等待安装完成就可以了，打开软件看到主面板\n \n点击Apache和start按钮，等待图标变绿后再点击admin按钮或者浏览器地址栏输入localhost进行访问\n如果可以看到服务器主页面说明成功\n然后点击MySQL的start和admin，或者地址栏输入localhost/phpmyadmin/\n出现一个登录界面，账号填写root，密码为空不用填，直接点击登录，出现下面画面说明成功\n \nphpEnv 如果xampp实在太慢或者根本无法下载，也可以用phpEnv\n官网下载：https://www.phpenv.cn/\n根据你电脑是64位或者32位进行选择对应版本下载，如果不知道自己电脑是几位的可以点击教程查看\n同样建议放在D盘，其它的默认就行，运行后出现下面界面\n \n点击启动服务上面的图标，再点击打开主页的图标，看到phpEnv的主页面就说明成功了\n页面拉到最下面如下\n \n数据库端口填3306\n用户名填root\n密码也填root（注意：这里和xampp不一样）\n点击连接按钮后再把页面拉到最下面显示连接成功就行啦\n点击顶部菜单栏的开始，再点击phpMyAdmin，然后按上面xampp的对应内容操作就行\n安装IDE IDE(Integrated Development Environment)，集成开发环境，为开发者提供了基本的代码编辑器的同时还提供了许多适用工具，功能强大，是码农开发的利器。\nphp语言我们使用的比较多的是JetBrains公司出的PhpStorm\n官网下载：https://www.jetbrains.com/phpstorm/\n软件体积较大，如果你不想装它的话可以自己下载VSCode然后下载相应插件（自己查）\n由于软件是收费的，但是我们是学生，可以用学校给的邮箱进行学生认证就可以在毕业前都免费使用\n学生认证地址：https://www.jetbrains.com/community/education/#students\n学校邮箱获取方法 进入学校官网，进入智慧广外，\t在个人事务中可以看到自己的邮箱地址，一般是学号@gdufs.edu.cn\n \n下载破解版也可以，但可能比较花时间\n按步骤完成后打开phpstorm，进行下面的配置流程\n1. 新建一个项目  \n2. 选择创建路径 建议把目录建在集成环境指定的网络根目录下，目录路径如下（以安装在D盘为例）：\nxampp：D:\\xampp\\htdocs\nphpEnv：D:\\phpEnv\\www\\localhost\n \n路径最后自定义一个项目名，比如我这里叫test，然后点击creat\n3. 修改运行目录  \n如图打开设置\n \n选择Deployment，点击顶部+号，选择Local or mounted folder\n \nFolder就填写自己安装的集成环境软件的网络根目录\nWeb server URL记得要在最后补上斜杆和当前项目名\n点击右下角的Apply和OK\n4. Hello World!  \n对项目文件夹右键新建一个php文件，自定义命名，然后开始写下第一行php代码吧：\n\u0026lt;?php echo \u0026#34;hello world!\u0026#34;; 鼠标移到右上角选择一个浏览器运行，或者右键并选择run，或者快捷键Ctrl+Shift+F10\n \n如果出现了提醒你选择php解释器的情况\n \n就选择一个已有的版本就行，在settings -\u0026gt; Languages\u0026amp;Frameworks -\u0026gt; PHP也可以设置\n点击运行后出现\n \n或者是\n \n大功告成！现在可以愉快地敲代码了！\n当然，这是为了方便本地开发而安装的集成环境，有兴趣的小朋友可以自己尝试分别安装每个环境或者在Linux上进行编译安装\nPHPer现在可以带着世界上最好的语言开冲了！\n \n","date":"2020-10-10T11:39:00+08:00","image":"https://ccqstark.github.io/p/php_env/php_hu30aa9710d612d752c63ae5cdcfcf5665_61468_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/php_env/","title":"php后台开发基础环境搭建教程"},{"content":"基本操作 下载hugo 首先要有Golang的环境\n然后在GitHub上选择对应平台下载\nhttps://github.com/gohugoio/hugo/releases\nWindows下载完要设置环境变量\n创建新的站点 hugo new site \u0026lt;path\u0026gt; \n在指定路径下创建博客站点目录，目录最后是博客站点名\n找到心仪主题 在下面这个网站上找到喜欢的主题，按照各自的文档进行设置\nhttps://themes.gohugo.io/\n本地预览 hugo server -t hugo-theme-stack --buildDrafts \u0026lt;theme\u0026gt;的位置填写主题的名称\n创建博客 hugo new post/blog.md 博客的markdown文件一开始都是放在\\content\\post目录下\n创建GitHub/Gitee仓库 Github把仓库命名为\u0026lt;name\u0026gt;.github.io即可开启博客托管服务\nGitee直接命名为自己的用户名，一字不差，同时需要手动开启Gitee Page服务\n部署到远端仓库  生成\\public目录  hugo --theme=hugo-theme-stack --baseUrl=\u0026#34;https://ccqstark.github.io/\u0026#34; --buildDrafts 根据具体仓库修改，也可以是\u0026quot;https://ccqstark.gitee.io/\u0026quot; 然后cd进public目录 在这个目录下创建git仓库，部署也是部署这个目录中的内容\n 三部曲  git add . git commit -m \u0026#39;...\u0026#39; git push github master 更新博客 要新增一篇博客就继续按下面这个步骤走\nhugo new post/name.md hugo --theme=hugo-theme-stack --baseUrl=\u0026#34;https://ccqstark.github.io/\u0026#34; --buildDrafts cd public git add . git commit -m \u0026#39;...\u0026#39; git push github master 如果只是更新就重新运行生成\\public目录的命令，再重新部署即可\n主题Stack配置 此博客的主题用的是Stack，下面是主题地址，可以找到文档和Demo\nhttps://themes.gohugo.io/hugo-theme-stack/\nicon设置 使用.ico文件类型的图标，并将其放置在\\public目录下\n\\layouts\\partials\\head下新建一个custom.html，写上\n\u0026lt;link rel=\u0026#34;shortcut icon\u0026#34; href=\u0026#34;https://ccqstark.github.io/icon.ico\u0026#34;/\u0026gt; 为了访问稳定也可以改为gitee\n文章外部展示图 在\\content\\post目录下创建博客时，先创建博客标题命名的文件夹，再在其下创建md文件index.md\n图片也是放在其下，在md文件开头的设置中添加image: \u0026quot;image.jpg\u0026quot;即可\nTags和分类 文章开头设置\ntags: - Spring categories: - Tech 一个是打标签，一个是分类\nAbout和Archives 在\\content\\page目录下创建about.md和archives.md\nabout.md用于写个人信息页面，需要文章顶部的设置写法改为字段加冒号的形式，配置slug为about\narchives.md用于分类和归档页面，用exampleSite的就行，不用做任何修改\nCategories 在\\content\\categories目录下创建以各分类命名的文件夹\n各分类的文件夹下放置_index.md和分类的展示图\n_index.md中的内容就是普通文章顶部的配置项，注意图片名配置对了就行\n","date":"2020-10-04T02:44:33+08:00","image":"https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/hugo_hu8b6407a07803ab5ecf8133363f04b00e_28892_120x120_fill_box_smart1_3.png","permalink":"https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","title":"使用Hugo+github/gitee搭建个人博客"}]