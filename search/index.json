[{"content":"由于这几天开始看《CS:APP》，我就开始寻求一款Mac上的轻量的C语言编辑器。找来找去，无非是VSCode、CLion和大名鼎鼎的Vim。\n为了减少磁盘占用同时让自己更接近于底层，我还是硬着头皮折腾起了Vim，这个上古神器之前就一直让我望而却步，我对它的掌握程度也差不多是会退出的程度，这一次就打算好好来折腾下。\n安装NeoVim Vim其实到目前为止，不同的分支版本还是很多的，比较流行的现代版本就要属NeoVim了，所以我在终端安装了它，用iTerm2运行着。\nbrew install neovim 安装完成后用nvim命令就可以打开\nnvim 配置文件路径\n传统的vim的配置配置文件为~/.vimrc\n而nvim的配置文件为/.config/nvim/init.vim ，之后修改nvim配置文件就用这个，以下简称为init.vim\n安装SpaceVim 作为小白，快速搭建一个好看实用的Vim开发环境那最好的选择就是SpaceVim 了，下面是官方的介绍：\n SpaceVim 是一个社区驱动的模块化的 Vim IDE，以模块的方式组织管理插件以及相关配置， 为不同的语言开发量身定制了相关的开发模块，该模块提供代码自动补全， 语法检查、格式化、调试、REPL 等特性。用户仅需载入相关语言的模块即可得到一个开箱即用的 Vim IDE。\n 官网地址：\n主页 | SpaceVim\n官网的文档还是很全的，按官方文档就可以快速搭建出来了。以MacOS为例：\n安装spacevim\ncurl -sLf https://spacevim.org/cn/install.sh | bash 完成后重新打开nvim就会自动下载相关插件。\n然后就是主界面：\n主题的修改可以参考官方文档\nSpaceVim colorscheme 模块 | SpaceVim\n快捷键符号说明\nSPC 代表空格\n\u0026lt;Leader\u0026gt; 默认为\\\n以下一些功能需要对mac进行一定的设置才能正常使用。\n打开系统偏好设置 → 键盘\n勾选将F1、F2等键用作标准功能键\n这同时也解决了Chrome的F12 不能打开控制台的问题\n文件目录树\n按F3 可以打开或关闭\n语法函数树\n按F2可以打开或关闭\nmac下可能会出现错误，解决方案：\nbrew install ctags-exuberant 然后init.vim里添加下面这行即可\nlet g:Tlist_Ctags_Cmd=\u0026#39;/usr/local/Cellar/ctags/5.8_1/bin/ctags\u0026#39; shell终端\nSPC ' 即可打开系统shell，如果用了oh-my-zsh主题什么的也会保留的\n配置C/C++环境 spacevim对大部分语言都有相关支持，文档也齐全，比如我需要的C语言环境：\n使用 Vim 搭建 C/C++ 开发环境 | SpaceVim\n按照官方文档修改spacevim的配置文件~/.SpaceVim.d/init.toml 即可，以下简称init.toml\n对于自带的模块基本只需要添加[[layers]]\n# 语法高亮 [[layers]] name = \u0026#39;lang#c\u0026#39; enable_clang_syntax_highlight = true # 代码格式化 [[layers]] name = \u0026#34;format\u0026#34; # 语法检查 [[layers]] name = \u0026#34;checkers\u0026#34; spacevim内置的模块还是很多的，但是很多功能相对简陋，为了实现更好的效果，我们还需要安装其他的插件。\n安装插件管理器vim-plug 虽然SpaceVim已经自带插件管理工具，在init.toml 里添加\n[[custom_plugins]] repo = \u0026#34;插件的github地址\u0026#34; 重启后即可自动下载\n用spacevim管理的这些从github上下载的插件存储在~/.cache/vimfiles/repos/github.com/\n这个自带的插件管理器大部分情况下还可以，但是有时不太好使，所以我选择多下载一个vim的主流插件管理器vim-plug\n使用curl安装，下面一条命令就够\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\  https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 如果遇到了Connection refused的错误，使用SwitchHosts! ，添加以下的host：\n199.232.68.133 raw.githubusercontent.com 199.232.68.133 user-images.githubusercontent.com 199.232.68.133 avatars2.githubusercontent.com 199.232.68.133 avatars1.githubusercontent.com 使用插件管理器安装新的插件的方法是，在init.vim 配置文件里添加：\ncall plug#begin() call plug#end() 然后把要安装的插件添加到这两行代码中间，以Plug 'xxx/xxx' 的格式，如：\ncall plug#begin() Plug \u0026#39;junegunn/vim-easy-align\u0026#39; call plug#end() 之后重启nvim，使用命令:PlugInstall 就可以安装了。\n若要卸载插件，就从配置文件中去除相应的那一行，然后使用命令:PlugClean 就可以卸载了。\n安装Coc.nvim SpaceVim自带的补全还行，但是为了达到效果更好的补全和语法检查，我选择安装插件coc.nvim\nneoclide/coc.nvim\n这可以说是神器了，除了基本的补全之外，还提供了众多扩展来支持不同的语言和不同的特性。\n用之前下的vim-plug 来安装\nPlug \u0026#39;neoclide/coc.nvim\u0026#39;, {\u0026#39;branch\u0026#39;: \u0026#39;release\u0026#39;} 安装完后可以先直接把官方的示例配置文件粘贴进init.vim，示例配置文件在github的readme里有。\n为了C语言更好的补全支持，我下载相关的coc扩展——coc-clangd\nneoclide/coc.nvim\n首先保证有node环境，然后运行以下命令安装coc-clangd\n:CocInstall coc-clangd 完成后打开一个c语言文件，若提示找不到clangd，则自己手动下载。\n进入github release页面下载clangd-mac-11.0.0.zip\nRelease 11.0.0 · clangd/clangd\n解压后目录下有一个bin文件夹和一个lib文件夹\n将bin下的clangd文件移动至/usr/local/bin/目录下\n将lib目录下的clang文件夹移动至~/Library/目录下\n再次打开即可正常使用，注意把spacevim自带的补全给禁用\n[[layers]] name = \u0026#39;autocomplete\u0026#39; enable = false 效果如下：\n可以看到代码提示效果是非常好的\n当然，里面还有很多很实用的扩展也可以根据需要下\n括号引号自动补全 coc.nvim插件对于括号和引号还是没有自动补成一对的功能，可以在init.vim里添加\ninoremap ( ()\u0026lt;Esc\u0026gt;i inoremap [ []\u0026lt;Esc\u0026gt;i inoremap { {\u0026lt;CR\u0026gt;}\u0026lt;Esc\u0026gt;O autocmd Syntax html,vim inoremap \u0026lt; \u0026lt;lt\u0026gt;\u0026gt;\u0026lt;Esc\u0026gt;i| inoremap \u0026gt; \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;\u0026gt;\u0026#39;)\u0026lt;CR\u0026gt; inoremap ) \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;)\u0026#39;)\u0026lt;CR\u0026gt; inoremap ] \u0026lt;c-r\u0026gt;=ClosePair(\u0026#39;]\u0026#39;)\u0026lt;CR\u0026gt; inoremap } \u0026lt;c-r\u0026gt;=CloseBracket()\u0026lt;CR\u0026gt; inoremap \u0026#34; \u0026lt;c-r\u0026gt;=QuoteDelim(\u0026#39;\u0026#34;\u0026#39;)\u0026lt;CR\u0026gt; inoremap \u0026#39; \u0026lt;c-r\u0026gt;=QuoteDelim(\u0026#34;\u0026#39;\u0026#34;)\u0026lt;CR\u0026gt; function ClosePair(char) if getline(\u0026#39;.\u0026#39;)[col(\u0026#39;.\u0026#39;) - 1] == a:char return \u0026#34;\\\u0026lt;Right\u0026gt;\u0026#34; else return a:char endif endf function CloseBracket() if match(getline(line(\u0026#39;.\u0026#39;) + 1), \u0026#39;\\s*}\u0026#39;) \u0026lt; 0 return \u0026#34;\\\u0026lt;CR\u0026gt;}\u0026#34; else return \u0026#34;\\\u0026lt;Esc\u0026gt;j0f}a\u0026#34; endif endf function QuoteDelim(char) let line = getline(\u0026#39;.\u0026#39;) let col = col(\u0026#39;.\u0026#39;) if line[col - 2] == \u0026#34;\\\\\u0026#34; return a:char elseif line[col - 1] == a:char return \u0026#34;\\\u0026lt;Right\u0026gt;\u0026#34; else return a:char.a:char.\u0026#34;\\\u0026lt;Esc\u0026gt;i\u0026#34; endif endf 彩虹括号 vim里也有类似vscode或IDEA那样的彩虹括号插件\nPlug \u0026#39;luochen1990/rainbow\u0026#39; #或 repo = \u0026#39;luochen1990/rainbow\u0026#39; init.vim 添加\nlet g:rainbow_active = 1 let g:rainbow_conf = { \\  \u0026#39;guifgs\u0026#39;: [\u0026#39;darkorange3\u0026#39;, \u0026#39;seagreen3\u0026#39;, \u0026#39;royalblue3\u0026#39;, \u0026#39;firebrick\u0026#39;], \\  \u0026#39;ctermfgs\u0026#39;: [\u0026#39;lightyellow\u0026#39;, \u0026#39;lightcyan\u0026#39;,\u0026#39;lightblue\u0026#39;, \u0026#39;lightmagenta\u0026#39;], \\  \u0026#39;operators\u0026#39;: \u0026#39;_,_\u0026#39;, \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/ fold\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/ fold\u0026#39;, \u0026#39;start=/{/ end=/}/ fold\u0026#39;], \\  \u0026#39;separately\u0026#39;: { \\  \u0026#39;*\u0026#39;: {}, \\  \u0026#39;tex\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/\u0026#39;], \\  }, \\  \u0026#39;lisp\u0026#39;: { \\  \u0026#39;guifgs\u0026#39;: [\u0026#39;darkorange3\u0026#39;, \u0026#39;seagreen3\u0026#39;, \u0026#39;royalblue3\u0026#39;, \u0026#39;firebrick\u0026#39;], \\  }, \\  \u0026#39;vim\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/(/ end=/)/\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/\u0026#39;, \u0026#39;start=/{/ end=/}/ fold\u0026#39;, \u0026#39;start=/(/ end=/)/ containedin=vimFuncBody\u0026#39;, \u0026#39;start=/\\[/ end=/\\]/ containedin=vimFuncBody\u0026#39;, \u0026#39;start=/{/ end=/}/ fold containedin=vimFuncBody\u0026#39;], \\  }, \\  \u0026#39;html\u0026#39;: { \\  \u0026#39;parentheses\u0026#39;: [\u0026#39;start=/\\v\\\u0026lt;((area|base|br|col|embed|hr|img|input|keygen|link|menuitem|meta|param|source|track|wbr)[ \u0026gt;])@!\\z([-_:a-zA-Z0-9]+)(\\s+[-_:a-zA-Z0-9]+(\\=(\u0026#34;[^\u0026#34;]*\u0026#34;|\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;[^\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;]*\u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;|[^ \u0026#39;.\u0026#34;\u0026#39;\u0026#34;.\u0026#39;\u0026#34;\u0026gt;\u0026lt;=`]*))?)*\\\u0026gt;/ end=#\u0026lt;/\\z1\u0026gt;# fold\u0026#39;], \\  }, \\  \u0026#39;css\u0026#39;: 0, \\  } \\} 安装CtrlP CtrlP是vim下一款很好的文件模糊搜索跳转插件\nkien/ctrlp.vim\n安装\nrepo = \u0026#39;kien/ctrlp.vim\u0026#39; 使用\n:CtrlP [要搜索的目录] 如果目录下的文件过多，比如系统根目录，就会花比较多的时间去索引。所以建议尽量缩小范围。\n之后便可以输入关键字进行搜索了\n其他插件 比如更好的代码格式化vim-clang-format和代码时间记录wakatime\nrhysd/vim-clang-format\nwakatime/vim-wakatime\n基本上想要的插件都可以在github上找到，根据官方文档使用即可\n常用快捷键 SPC 1/2/3 切换不同窗口，数字为窗口编号\nSPC l r 运行代码\nSPC b f 代码格式化\ng d 函数跳转\n\u0026lt;c-o\u0026gt; 回调到上次的位置（这个写法表示ctrl+o）\n更多功能可以SPC空格键唤出菜单查看\n尾声 到此一个基本的vim编程环境已经搭好了，用来写点小东西还是够用的。\n这一套折腾下来最大的感受是曾经觉得vim好难学好难用，但是通过这几天捣鼓之后发现只要熟练了其实效率还是很高的。难怪至今还有很多vim的使用者和爱好者。同时自己安装各种插件，修改配置文件，通过自定义来获得一款完全属于自己的编辑器的过程也是充满乐趣的，我很享受这个过程。\n","date":"2021-01-31T21:26:00+08:00","image":"https://ccqstark.github.io/p/vim/vim_hu721b1231aff42422e86b1dd0b5ea6e91_94583_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/vim/","title":"我的vim入门配置折腾"},{"content":"ElacticSearch索引中有大量的数据，如果没有一些安全措施的话会让系统处于一个十分危险的处境，引发的相关安全事件可以看看这篇文章。\n你的Elasticsearch在\u0026quot;裸奔\u0026quot;吗？\n而ElaticSearch官方的高级安全服务是收费的，主要给企业提供。但是从6.8和7.1版本开始，基础安全功能就免费了，而且已经集成在里面不用额外安装。\n除此之外诸如Search Guard、ReadonlyREST、Nginx 等开源免费等方法来达到安全的目的，这里介绍的是使用官方的x-pack的基础安全功能，对于小项目来说够用了。\n本文版本为7.10.1\n修改配置文件 在elasticsearch.yml里新增\nxpack.security.enabled:truexpack.security.transport.ssl.enabled:true之后重启 es\n在es目录下执行 elasticsearch-setup-passwords interactive 然后输入多个用户的密码\nInitiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: Reenter password for [elastic]: Passwords do not match. Try again. Enter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana]: Reenter password for [kibana]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: Changed password for user [apm_system] Changed password for user [kibana] Changed password for user [logstash_system] Changed password for user [beats_system] Changed password for user [remote_monitoring_user] Changed password for user [elastic] 其中elastic用户相当与es的root用户，之后使用es和kibana需要这个用户的密码\n设置完重启一下es\n测试 curl -GET -u elastic http://[ip]:9200/ 发现提示输入elastic用户的密码\nEnter host password for user \u0026#39;elastic\u0026#39;: 基本的安全就实现了，之后进一步防止暴力破解密码可以再使用iptables\nKibana设置 修改kibana.yml\nelasticsearch.username:\u0026#34;elastic\u0026#34;elasticsearch.password:\u0026#34;[密码]\u0026#34;xpack:apm.ui.enabled:falsegraph.enabled:falseml.enabled:falsemonitoring.enabled:falsereporting.enabled:falsesecurity.enabled:true# 这里要打开grokdebugger.enabled:falsesearchprofiler.enabled:false之后进入kibana进入登陆界面\n用elastic用户和密码登陆即可\n代码中配置 Java High Level REST Client中配置账户和密码\nfinal CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(\u0026#34;elastic\u0026#34;, \u0026#34;123456\u0026#34;)); //es账号密码（默认用户名为elastic）  RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(\u0026#34;localhost\u0026#34;, 9200, \u0026#34;http\u0026#34;)) .setHttpClientConfigCallback(new RestClientBuilder.HttpClientConfigCallback() { public HttpAsyncClientBuilder customizeHttpClient(HttpAsyncClientBuilder httpClientBuilder) { httpClientBuilder.disableAuthCaching(); return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); } })); SpringBoot的配置文件\nspring.elasticsearch.rest.username=elasticspring.elasticsearch.rest.password=123456修改密码 curl -H \u0026#34;Content-Type:application/json\u0026#34; -XPOST -u elastic \u0026#39;http://127.0.0.1:9200/_xpack/security/user/elastic/_password\u0026#39; -d \u0026#39;{ \u0026#34;password\u0026#34; : \u0026#34;123456\u0026#34; }\u0026#39; 结尾 这里只是单节点示例，集群以及证书相关可以参看官方文档\n通过 TLS 加密和基于角色的访问控制确保 Elasticsearch 的安全\n","date":"2021-01-29T21:26:00+08:00","image":"https://ccqstark.github.io/p/x_pack/x-pack_huc4207ebc9b333ece948f0ec8e981e0d7_15854_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/x_pack/","title":"[Elastic]ElasticSearch 安全"},{"content":"安装logstash 在实际项目中使用es进行搜索，我们就要把mysql数据库中的数据同步到es索引库中。进行这项过程的工具很多，比如go-mysql-elasticsearch，canal等等，当然也可以使用ELK组合中的logsatsh 来完成。这里同样用docker来部署logstash容器。\n拉取镜像 docker pull logstash:7.10.1 启动容器 启动后进入容器内，修改jvm启动的内存设置，地址为/usr/share/logstash/config/jvm.options\n# 修改jvm内存分配 vi jvm.options # 修改下面的参数，单位可以为g和m -Xms256m -Xmx256m 修改后重启容器即可\n下载插件与依赖包 docker exec -it logstash bash 安装logstash-input-jdbc插件\nbin/logstash-plugin install logstash-input-jdbc 如果出现以下ERROR，说明logstash里本身已经包含有这个插件了，就无需安装。7.10.1的版本是已经自带了。\nERROR: Installation aborted, plugin \u0026#39;logstash-input-jdbc\u0026#39; is already provided by \u0026#39;logstash-integration-jdbc\u0026#39; 下载mysql-connector-java，也就是jdbc驱动\nMySQL官方下载地址：https://downloads.mysql.com/archives/c-j/\n下载对应版本后本地解压，上传到服务器，然后用docker cp命令复制到logstash容器中\n只需要其中的jar包即可\n# 把文件复制到容器内 docker cp [jar包路径] logstash:[容器内路径] 在/usr/share/logstash目录下新建mysql/目录，把jar包复制到这里\n同步配置文件 在刚刚的mysql目录下新建jdbc.conf 文件，来配置同步操作\n 单表同步  input { jdbc { # jar包的绝对路径 jdbc_driver_library =\u0026gt; \u0026#34;/usr/share/logstash/mysql/mysql-connector-java-5.1.48.jar\u0026#34; jdbc_driver_class =\u0026gt; \u0026#34;com.mysql.jdbc.Driver\u0026#34; # 数据库连接信息 jdbc_connection_string =\u0026gt; \u0026#34;jdbc:mysql://[ip]:3306/[库名]?characterEncoding=UTF-8\u0026amp;autoReconnect=true\u0026#34; jdbc_user =\u0026gt; \u0026#34;[mysql用户]\u0026#34; jdbc_password =\u0026gt; \u0026#34;[密码]\u0026#34; # cron的定时执行语法一样，默认每分钟同步一次 schedule =\u0026gt; \u0026#34;* * * * *\u0026#34; # 执行的sql语句语法，这里是通过将主键大于最后一次同步所记录的值来实现增量同步的 statement =\u0026gt; \u0026#34;SELECT * FROM activity WHERE activity_id \u0026gt; :sql_last_value order by activity_id asc\u0026#34; use_column_value =\u0026gt; true # 用来作为增量同步的判断字段，最好为表的主键 tracking_column =\u0026gt; \u0026#34;activity_id\u0026#34; # 是否记录上次执行结果，true表示会将上次执行结果的tracking_column字段的值保存到last_run_metadata_path指定的文件中； record_last_run =\u0026gt; true # record_last_run上次数据存放位置 last_run_metadata_path =\u0026gt; \u0026#34;/usr/share/logstash/mysql/last_id.txt\u0026#34; # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false clean_run =\u0026gt; false } } output{ elasticsearch{ hosts =\u0026gt; [\u0026#34;[ip]:9200\u0026#34;] index =\u0026gt; \u0026#34;[索引名]\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{activity_id}\u0026#34; } stdout { codec =\u0026gt; rubydebug } }  多表同步  多表配置和单表配置的区别在于input模块的jdbc模块有几个type，output模块就需对应有几个type\ninput { stdin {} jdbc { # 多表同步时，表类型区分，建议命名为“库名_表名”，每个jdbc模块需对应一个type； type =\u0026gt; \u0026#34;TestDB_DetailTab\u0026#34; # 其他配置此处省略，参考单表配置 # ... # ... # record_last_run上次数据存放位置； last_run_metadata_path =\u0026gt; \u0026#34;mysql\\last_id.txt\u0026#34; # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false； clean_run =\u0026gt; false # # 同步频率(分 时 天 月 年)，默认每分钟同步一次； schedule =\u0026gt; \u0026#34;* * * * *\u0026#34; } jdbc { # 多表同步时，表类型区分，建议命名为“库名_表名”，每个jdbc模块需对应一个type； type =\u0026gt; \u0026#34;TestDB_Tab2\u0026#34; # 多表同步时，last_run_metadata_path配置的路径应不一致，避免有影响； # 其他配置此处省略 # ... # ... } } filter { json { source =\u0026gt; \u0026#34;message\u0026#34; remove_field =\u0026gt; [\u0026#34;message\u0026#34;] } } output { # output模块的type需和jdbc模块的type一致 if [type] == \u0026#34;TestDB_DetailTab\u0026#34; { elasticsearch { # host =\u0026gt; \u0026#34;192.168.1.1\u0026#34; # port =\u0026gt; \u0026#34;9200\u0026#34; # 配置ES集群地址 hosts =\u0026gt; [\u0026#34;192.168.1.1:9200\u0026#34;, \u0026#34;192.168.1.2:9200\u0026#34;, \u0026#34;192.168.1.3:9200\u0026#34;] # 索引名字，必须小写 index =\u0026gt; \u0026#34;detailtab1\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{KeyId}\u0026#34; } } if [type] == \u0026#34;TestDB_Tab2\u0026#34; { elasticsearch { # host =\u0026gt; \u0026#34;192.168.1.1\u0026#34; # port =\u0026gt; \u0026#34;9200\u0026#34; # 配置ES集群地址 hosts =\u0026gt; [\u0026#34;192.168.1.1:9200\u0026#34;, \u0026#34;192.168.1.2:9200\u0026#34;, \u0026#34;192.168.1.3:9200\u0026#34;] # 索引名字，必须小写 index =\u0026gt; \u0026#34;detailtab2\u0026#34; # 数据唯一索引（建议使用数据库KeyID） document_id =\u0026gt; \u0026#34;%{KeyId}\u0026#34; } } stdout { codec =\u0026gt; json_lines } } 为了统一，把数据也放这个目录下，在mysql目录下再新建目录data\nmkdir data 启动logstash同步 cd回到/usr/share/logstash目录，启动同步\n./bin/logstash -f mysql/jdbc.conf --path.data=/usr/share/logstash/mysql/data/ 注意，要保证给elasticsearch的分配的内存足够大才行，测试用的256m是不够的，会导致es容器退出，至少给个1g\n—-path.data参数用来设置同步数据存放的位置\n启动之后控制台会打印出大概以下信息\nUsing bundled JDK: /usr/share/logstash/jdk OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. WARNING: An illegal reflective access operation has occurred WARNING: Illegal reflective access by org.jruby.ext.openssl.SecurityHelper (file:/tmp/jruby-423/jruby7667758569951782495jopenssl.jar) to field java.security.MessageDigest.provider WARNING: Please consider reporting this to the maintainers of org.jruby.ext.openssl.SecurityHelper WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations WARNING: All illegal access operations will be denied in a future release 开始同步会打印出从数据库读取的，插入到elasticsearch的信息\n实际使用中用nohup 来保持后台运行\n缺点 logstash的缺点很明显，就是只能同步mysql中新增的数据，对于更改的、删除的就无能为力了。这其实也很好理解，ELK其实本来就是用来收集与分析日志的，而同步增加的数据已经足够了。\n我觉得es与mysql最好的同步工具其实是阿里的开源的canal\nalibaba/canal\n","date":"2021-01-28T21:26:00+08:00","image":"https://ccqstark.github.io/p/logstash_mysql/logstash-mysql_hubd922da79b2e986df34a25cd755e9ffb_77309_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/logstash_mysql/","title":"[Elastic]使用logstash同步MySQL数据"},{"content":"安装ElasticSearch 拉取镜像 docker pull elasticsearch:7.10.1 启动容器 同时挂载目录（包括配置文件和data）（挂载出来的位置自己定义）\ndocker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=\u0026#34;-Xms256m -Xmx256m\u0026#34; -d \\ -v /home/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\ -v /home/es/data:/usr/share/elasticsearch/data elasticsearch:7.10.1 注意这里还设置了JVM的内存大小，默认为2G，有点大，很可能会因为内存不够而无法正常启动。可以像我这里改为256m或者其他值。\n可能出现的错误 查看容器日志\ndocker logs elasticsearch 如果出现以下错误\nmax virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 则要修改服务器配置\nvim /etc/sysctl.conf 添加这行\nvm.max_map_count=262144 立即生效, 执行：\n/sbin/sysctl -p 对挂载的宿主机data目录可能出现权限不足问题\nchmod 777 [宿主机data目录] 配置跨域 到挂载出来到位置编辑配置文件\nvim elasticsearch.yml 添加以下几行\nnetwork.host:0.0.0.0discovery.type:single-nodehttp.cors.enabled:truehttp.cors.allow-origin:\u0026#34;*\u0026#34;同时安全组和防火墙记得打开对应端口\n记得每次修改完配置都要重启 docker restart elasticsearch 浏览器访问测试 http://[IP]:9200 看到类似以下的json就成功了\n{ \u0026#34;name\u0026#34;: \u0026#34;8c819d377714\u0026#34;, \u0026#34;cluster_name\u0026#34;: \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34;: \u0026#34;-AkgwTlbS1SsjvzNtG45nw\u0026#34;, \u0026#34;version\u0026#34;: { \u0026#34;number\u0026#34;: \u0026#34;7.10.1\u0026#34;, \u0026#34;build_flavor\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34;: \u0026#34;docker\u0026#34;, \u0026#34;build_hash\u0026#34;: \u0026#34;1c34507e66d7db1211f66f3513706fdf548736aa\u0026#34;, \u0026#34;build_date\u0026#34;: \u0026#34;2020-12-05T01:00:33.671820Z\u0026#34;, \u0026#34;build_snapshot\u0026#34;: false, \u0026#34;lucene_version\u0026#34;: \u0026#34;8.7.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34;: \u0026#34;6.8.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34;: \u0026#34;6.0.0-beta1\u0026#34; }, \u0026#34;tagline\u0026#34;: \u0026#34;You Know, for Search\u0026#34; } 安装elasticsearch-head 拉取镜像 docker pull mobz/elasticsearch-head:5 启动容器 docker run -it -d --name head -p 9100:9100 mobz/elasticsearch-head:5 浏览器打开\nhttp://[ip]:9100/ 在上面集群连接处的输入框输入elasticsearch的地址\nhttp://[IP]:9200 之后点击连接，右边的集群健康值字样出现绿色背景代表成功连接\n安装Kibana 拉取镜像 docker pull kibana:7.10.1 注意版本和ES的要对应\n配置文件kibana.yml 为了挂载配置文件，我们先在本机创建一个配置文件，这里以/home/kibana/config/kibana.yml 为例\n配置文件中写入\nserver.host:\u0026#39;0.0.0.0\u0026#39;elasticsearch.hosts:[\u0026#34;http://[ip地址]:9200/\u0026#34;]xpack:apm.ui.enabled:falsegraph.enabled:falseml.enabled:falsemonitoring.enabled:falsereporting.enabled:falsesecurity.enabled:falsegrokdebugger.enabled:falsesearchprofiler.enabled:false启动容器 docker run -d -it \\ --name kibana -p 5601:5601 \\ -v /home/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:7.10.1 浏览器打开\nhttp://[ip]:5601/ 安装ik分词器 首先进入es的容器内\ndocker exec -it elasticsearch /bin/bash 使用bin目录下的elasticsearch-plugin install安装ik分词器插件（注意版本要对应）\n# github官方 bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.10.1/elasticsearch-analysis-ik-7.10.1.zip 这里可能会很慢，可以用镜像加速\n# 镜像加速 bin/elasticsearch-plugin install https://github.91chifun.workers.dev//https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.10.1/elasticsearch-analysis-ik-7.10.1.zip 也可以选择本地下载解压完再上传到服务器，再把它移动到容器内的plugins文件夹里\n然后重启容器\ndocker restart elasticsearch 在kibana中测试 GET _analyze { \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;各地校车将享最高路权\u0026#34; } 有ik_smart 和 ik_max_word 两种模式，分别是最粗粒度的拆分和最细粒度的拆分\n","date":"2021-01-27T21:26:00+08:00","image":"https://ccqstark.github.io/p/es_docker/elastic-docker_hu1fc05f09d19ffda9f7576c23f66afe5c_19136_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/es_docker/","title":"[Elastic]使用docker安装ElasticSearch + Kibana"},{"content":"为了提高在mac下连接ssh的效率，我们可以用alfred和iTerm配合，达到只要在输入框中输入ssh [主机名] 就可以快速连上了，效果如下图：\n使用ssh config 在~/.ssh/config文件里添加服务器信息，没有的话就新建一个\nvim ~/.ssh/config然后在文件中输入主机的信息，有多个主机就追加在后面就行\nHost [主机名] HostName [ip] User root Port [端口]使用密钥登陆 如果本地的~/.ssh 目录下没有id_rsa 私钥文件，可以是使用下面这个目录生成，一路回车即可，如果已经有了就可以跳过这步\nssh-keygen然后将私钥复制到远程服务器\nssh-copy-id -i -p[端口号] root@ip按提示输入一次密码，就会自动将刚才生成的公钥id_rsa.pub追加到远程主机的~/.ssh/authorized_keys后面了，这样以后的 ssh 连接都不用输入密码了\n安装alfred-ssh插件 https://github.com/deanishe/alfred-ssh\n到上面github链接下载最新版：Secure-SHell的alfredworkflow，双击自动添加到alfred的workflow\n添加后打开alfred的偏好设置可以看到效果如下：\n测试用alfred输入ssh+主机名就可以连上服务器了，但是默认是用mac自带但终端，想用好看的iTrem2还需要进一步操作\n安装alfred集成iTerm2配置 如下图，打开iTrem2的偏好设置，如下图设置默认方式为ssh\n进入下面github链接，按说明操作\nhttps://github.com/vitorgalvao/custom-alfred-iterm-scripts\n按上面要求运行命令并粘贴到对应地方就完成了！\n参考文章： 开发效率神器之alfred集成ssh+iTerm2实现一步登录服务器\n","date":"2021-01-10T16:35:00+08:00","image":"https://ccqstark.github.io/p/alfred_iterm/ssh_hu16ae618dcf0f79ca9c769a7fb0762a5e_66847_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/alfred_iterm/","title":"Alfred + iTerm2 快速ssh连接服务器"},{"content":"DevOps现在非常流行，CI/CD持续集成、持续部署也大火，而Jenkins就是自动化部署主要的工具之一。\n这篇博客就来详细介绍用jenkins来实现自动化部署springboot项目的docker容器，堪称保姆级教学了。\n用docker拉取jenkins镜像，启动Jenkins容器 这里采用的jenkins本身也是用docker容器部署的，不得不说docker确实好用，当然也可以直接运行在主机上\n首先拉取Jenkins镜像 docker pull jenkins/jenkins ⚠️注意：切勿docker pull jenkins，已经废弃\n启动Jenkins容器 docker run -u root -itd --name jenkins \\ -p 6001:8080 \\ -v $(which docker):/usr/bin/docker \\ -v /var/run/docker.sock:/var/run/docker.sock -e TZ=\u0026#34;Asia/Shanghai\u0026#34; \\ -v /etc/localtime:/etc/localtime:ro \\ -v /volume1/docker/jenkins:/var/jenkins_home \\ jenkins/jenkins  -p 6001:8080Jenkins默认网页访问端口为8080，将端口映射到外部主机6001端口 -v $(which docker):/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock使Jenkins内部可以使用docker命令 -e TZ=\u0026quot;Asia/Shanghai\u0026quot; -v /etc/localtime:/etc/localtime:ro配置Jenkins容器的时区 -v /volume1/docker/jenkins:/var/jenkins_home 将Jenkins的配置映射到外部主机卷，容器删除仍可保留配置  测试Jenkins容器内部 # 进入Jenkins的容器内部 docker exec -it jenkins bash # 判断docker命令是否正常执行 docker info 访问Jenkins网页端 用http://主机IP:6001 就可以访问Jenkins的网页端了\nJenkins初始化 访问页面后需要输入初始密码，用cat 命令查看一下页面上给出的路径就可以获得初始密码，复制进去后就可以成功进入\n到插件这里就选择安装推荐插件即可，等待安装完毕，速度稍慢。如果很多插件一直安装失败可以等下一步配置国内源之后再安装\n然后按提示创建一个自己的管理员账户\n如果想重启Jenkins：\n在jenkins主页网址后加上/restart 后回车，点击确定即可\n安装插件和必要配置 修改插件国内源并安装其它插件 点击侧边栏系统管理→插件管理→高级\n将图中所示URL的输入中的链接改为阿里的：\nhttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json 安装一些插件 在插件管理中选择可选插件\n安装Maven Integration和Docker的插件，安装完重启\n全局工具配置 点击系统管理→全局工具配置\nJDK\n用docker inspect jenkins 查看JAVA_HOME 路径后填入即可，这是个openjdk1.8，刚好用于项目，因为jenkins就是Java开发的\nGit\n用默认即可\nMaven\n可以用外部安装的，这里因为下了插件就用Jenkins里的插件就行，点击自动安装\nDocker\n都好了之后点应用在点保存\nJenkins容器内使用vim 进入Jenkins容器内部后想使用vim的话还需要额外安装，后面需要用到vim\n# 更新一下软件源 apt-get update # 安装vim apt-get install vim 这里可能比较慢，就等一下，但只需用一次就不额外换源了\n修改maven插件的镜像源 因为jenkins在容器内，所以要进入容器内\ncd到目录~/.m2 下，ls 一下发现只有一个repository 目录，这个就是默认的maven仓库目录，然后就vim settings.xml 新建一个配置文件\n在命令模式下用:set paste 开启粘贴模式，然后把下面内容粘贴进去，记得检查一下内容和编码是不是utf-8\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;settings xmlns=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\u0026#34;\u0026gt; \u0026lt;localRepository\u0026gt;~/.m2/repository\u0026lt;/localRepository\u0026gt; \u0026lt;pluginGroups\u0026gt; \u0026lt;/pluginGroups\u0026gt; \u0026lt;proxies\u0026gt; \u0026lt;/proxies\u0026gt; \u0026lt;servers\u0026gt; \u0026lt;/servers\u0026gt; \u0026lt;mirrors\u0026gt; \u0026lt;mirror\u0026gt; \u0026lt;id\u0026gt;nexus-aliyun\u0026lt;/id\u0026gt; \u0026lt;mirrorOf\u0026gt;*\u0026lt;/mirrorOf\u0026gt; \u0026lt;name\u0026gt;Nexus aliyun\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.aliyun.com/nexus/content/groups/public\u0026lt;/url\u0026gt; \u0026lt;/mirror\u0026gt; \u0026lt;/mirrors\u0026gt; \u0026lt;profiles\u0026gt; \u0026lt;/profiles\u0026gt; \u0026lt;/settings\u0026gt; 重启jenkins，之后下载包时发现已经更改为阿里源了\n创建项目准备自动化部署 左侧边栏新建一个任务，选择maven项目\n添加GitHub仓库源码 这里用GitHub做代码仓库，也可以gitlab\n有2种方式：https和ssh\n如果是https的话添加Credentials 的时候就直接配置自己的GitHub用户名和密码，仓库的URL填写github仓库的url就行\n如果是ssh的话要配置密钥，点击系统管理→Manage Credentials →全局 ,点击左侧边栏添加凭据\n如果之前生成过，在自己机器上的~/.ssh 下cat一下就行，没有的话就ssh-keygen 生成\n注意此时url就要用ssh://git@github.com/[用户名]/[项目名].git 的格式\n加快代码拉取速度 为了加快构建速度，勾选此选项可以使jenkins不拉取代码的历史版本，从而加快构建速度\n勾选浅克隆\n初次之外，不要在本地打出jar包，不然这么大一个文件上传到仓库再被拉取很费时间\n构建触发器 添加maven构建步骤 构建脚本 这里是运行一些shell脚本来构建docker镜像和运行容器的\n脚本如下，记得在项目目录下写好一个Dockerfile\n# 进入项目目录 cd /var/jenkins_home/workspace/[项目名] # 执行构建Dockerfile命令 docker build -f Dockerfile -t [镜像名]:[tag] . # 停止之前的容器运行 docker stop [容器名] # 删除之前的容器 docker rm [容器名] #运行刚刚创建的容器 docker run -d --name [容器名] -p [映射端口]:8080 [镜像名]:[tag] echo \u0026#34;构建完成\u0026#34; Dockerfile参考：\nFROMopenjdk:8MAINTAINER[作者]ADD /target/[项目名]-0.0.1-SNAPSHOT.jar [项目名].jarEXPOSE8080ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/[项目名].jar\u0026#34;]push触发构建 为了实现只要我们一向代码仓库push就可以自动进行构建，我们需要配置webhook\n点击系统管理→系统配置 ，找到GitHub选项，点击高级\n按下图操作：\n打开自己GitHub项目页面\n粘贴刚刚复制的地址\n下面勾选Pushes和Active ，最后点击添加即可\n点击项目内左侧栏的立即构建 可以手动开始构建\n在进程中点击控制台输出 看到构建过程中的日志信息，这些信息很重要我们经常要看，用来发现构建过程中的错误\n清除无用的镜像 docker image prune 在多次构建之后可能会发现一些为none的镜像，用此命令清除\n配置邮箱通知 在这之前保证安装了相关插件，如果一开始是选安装推荐插件那应该都安装了\n点击系统管理→系统配置\n先配一下管理员邮箱\n然后拉到下面，按图中配置，这个邮箱要填刚刚上面的管理员邮箱\n注意里面的密码是开启SMTP的密码，不是邮箱的密码\n然后可以点击发送测试邮件试试\n上面还有一个Extended E-mail Notification 也配一下，也按这些信息填写\nDefault Recipients 是默认接收通知的邮箱，可以填写多个，用英文半角逗号隔开\nDefault Triggers 也可以配置一下，是触发邮件的事件\n这里有个坑，在系统设置配置完之后，在项目里面的设置记得也要配置完整\n进入要发送邮箱功能的项目的配置\n再点击增加构建后操作步骤\n点击高级设置后设置触发条件\n其他的诸如Content Type和Default Content 之类的就按需求配就行\n之后在控制台输出就可以看到构建项目到最后有发邮件的步骤日志\n主题美化 可以参考下面这篇文章，个人觉得还是习惯于原版\nJenkins自定义主题教程_FlyWine的博客-CSDN博客_jenkins自定义界面\n参考文章：\n最优雅的Docker+Jenkins pipeline部署Spring boot项目\nJenkins+Docker+github+Spring Boot自动化部署_linfen1520的博客-CSDN博客\njenkins+git+maven+docker持续集成部署_自动化_运维开发网_运维开发技术经验分享\nJenkins - SSH认证方式拉取Git代码\ncentos7的Jenkins的maven插件的settings.xml配置文件路径在哪里_festone000的专栏-CSDN博客\n","date":"2021-01-09T23:01:00+08:00","image":"https://ccqstark.github.io/p/jenkins_docker_springboot/jenkins-docker-springboot_huac9b8bcc40d9704ef8edb1ad38827231_44206_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/jenkins_docker_springboot/","title":"Jenkins + docker + springboot 完美配合全流程教程"},{"content":"如果是单体应用的话nginx用docker部署其实是更麻烦的，不过既然操作过就记录一下。\n拉取nginx镜像 docker pull nginx 还是一样，默认是拉取latest版本，也可以选择想要的特定版本\n启动并挂载html目录 docker container run \\  -d \\  -p 80:80 \\  --name mynginx \\  --v [本机挂载目录]:/usr/share/nginx/html \\  nginx 复制出配置文件 docker container cp mynginx:/etc/nginx . 将复制出来的文件夹改名并移动到你想要的目录下，然后把容器停止并删除\n挂载配置文件目录 最后一步就是重新启动一个容器并把html和配置文件目录都挂载了\ndocker run \\  --name test-nginx \\  -v [本机挂载html目录]:/usr/share/nginx/html \\  -v [本机挂载nginx目录]:/etc/nginx \\  -p 80:80 \\  -d \\  nginx 访问一下试试就可以了！\n参考：\nNginx 容器教程\n","date":"2021-01-08T15:46:00+08:00","image":"https://ccqstark.github.io/p/docker_nginx/nginx-docker_hu2ff739cd1ceaefb705a9e30c4218e66c_86441_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/docker_nginx/","title":"[docker]用docker部署nginx"},{"content":"这篇文章介绍的是把整个Springboot后端项目部署到docker容器中，当然包括mysql和redis\n按下面步骤一步步来\n本地打出jar包 以Maven的话直接就IDEA里打出jar包到target目录下，这一步和以前一样\n编写Dockerfile 可以用IDEA里的插件来写，也可以自己写dockerfile\n在项目文件夹下新建一个文件Dockerfile\nFROMopenjdk:8MAINTAINERccqstarkADD /target/[项目jar包名].jar app.jarEXPOSE8080ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/app.jar\u0026#34;]⚠️注意：ADD后两个参数，第一个是项目jar包的相对路径，第二是把jar包在容器内重新命的名\n构建镜像 在Dockerfile所在文件夹下运行build 命令，注意最后有一个.\ndocker build -f Dockerfile -t [镜像名]:[版本tag] .构建之后用docker images 查看一下自己构架的镜像\n构建完之后本地run一下容器测试下\npush上传到镜像仓库 其实也可以把jar包上传服务器后用服务器的docker来构建和运行\n但这里采用的是把本地构建的镜像上传到repository，相当于镜像仓库，其他人想用这个镜像就可以从那拉取下来使用。\nrepository可以是官方的Docker Hub，但是比较慢，也可以花钱上传到阿里云的容器镜像服务就会快很多\n这里是上传到docker hub，首先要登陆自己到docker账号，没有的话可以去官网注册一个\ndocker login -u [账户名] 输入密码成功后登陆\n在push之前要给镜像打个tag，这样才能上传到自己账号对应的仓库下\ndocker tag [镜像名] [账户名]/[镜像仓库名]:latest 之后就可以上传了\ndocker push [账户名]/[镜像仓库名]:latest pull拉取镜像 docker pull [账户名]/[镜像仓库名]:[tag] 在服务器上拉取到镜像后就可以启动容器了\ndocker run -it -d -p [对外暴露端口]:8080 app:[tag] 部署MySQL容器 # 拉取mysql镜像 docker pull mysql:5.7 # 跑起来 docker run \\ -d \\ -p 3306:3306 \\ -v /home/mysql/conf:/etc/mysql/conf.d \\ -v /home/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=[设置mysql到root密码] \\  --name [容器名] \\ mysql:5.7 mysql容器到暴露端口要和代码中配到一样就行\n这里还把配置目录和数据目录挂载了出来，避免容器停止后数据丢失\n部署redis容器 # 拉取redis镜像 docker pull redis # 运行，这个时候指定密码，不指定默认为空 docker run -d --name myredis -p 6379:6379 redis --requirepass \u0026#34;mypassword\u0026#34; ⚠️注意：建议先把mysql和redis都部署好后再去启动jar包都镜像，防止应用启动时连不到它们而报错\n所有容器都成功启动起来之后就把整个后端部署到docker完毕了\n","date":"2021-01-07T21:39:00+08:00","image":"https://ccqstark.github.io/p/docker_springboot/docker-springboot_hu705e70abdc72815dabd2267940e19d94_40186_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/docker_springboot/","title":"[docker]用docker部署SpringBoot项目"},{"content":"Dockerfile介绍 dockfile是用来构建docker镜像的文件，命令参数脚本\n💡构建步骤：\n 编写dockerfile脚本 用docker build命令构建一个镜像 用docker run运行镜像 用docker push发布镜像（DockerHub、阿里云仓库）  在官网点击镜像会跳转到github对应的dockerfile\n可以发现这些镜像也是通过dockerfile来构建的\n上图是centos的dockerfile，其中scratch是最基本的，90%都是基于这个镜像。\n然后ADD 就是添加来一层centos相关的镜像文件\n官方很多镜像都是基础包，功能很少，很多我们需要的都没有，所以我们通常都会构建自己的镜像。\n比如我们可以直接构建一个centos+jdk+tomcat+mysql的镜像，不就直接有来一个可以运行javaweb项目的环境镜像了吗？\nDockerfile构建过程 基本规则  每个关键字（保留字）都是大写的 执行顺序是从上到下的 \u0026ldquo;#\u0026rdquo; 表示注释 每一个指令都会创建一个新的镜像层，并提交  以前开发交付都是用jar包或war包，现在云原生时代交付的就是docker镜像，docker镜像也逐渐成为企业交付标准，而构建docker镜像就需要学会编写dockerfile\n什么是云原生？聊聊云原生的今生_阿里云开发者-CSDN博客\nDockerfile常用指令    指令关键字 作用     FROM 构建镜像所用的基础镜像   MAINTAINER 镜像作者，一般是姓名+邮箱   RUN 镜像构建时运行的命令   ADD 为镜像添加内容   WORKDIR 镜像的工作目录   VOLUME 挂载目录   EXPOSE 暴露的端口   CMD 容器启动时需要运行的命令，只有最后一个会生效，可被替代   ENTRYPOINT 也是指定启动时需要运行的命令，但是可以追加   ONBUILD 构建一个被继承的dockerfile时会运行ONBUILD的指令。触发指令   COPY 类似ADD，将文件拷贝到镜像中   ENV 构建时设置的环境变量    实践：构建自己的centos 举个例子：\nFROMcentos # centos为基础镜像MAINTAINERccqstark\u0026lt;xxxxxx@qq.com\u0026gt; # 作者名和邮箱ENV MYPATH /usr/local # 环境变量WORKDIR$MYPATH # 工作目录# 安装vim和ifconfig命令RUN yum -y install vim RUN yum -y install net-toolsEXPOSE80CMD echo $MYPATHCMD echo \u0026#34;---end---\u0026#34;CMD /bin/bashdocker build 之后 run 起来就可以使用了！\n还可以使用下面命令查看镜像构建的过程\ndocker history [镜像id] 参考自狂神的docker教程\n","date":"2021-01-06T21:13:00+08:00","image":"https://ccqstark.github.io/p/dockerfile/dockerfile_hua2299a9fb0d8a75d7ada60f608a774d6_160236_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/dockerfile/","title":"[docker]初识Dockerfile"},{"content":"把容器内的目录挂载到宿主机的某一个目录下，实现双向同步。\n也就是说两者都指向了同一文件目录下，在其中一端所做的修改都会同步。\n好处：\n MySQL数据持久化，不会因为删了容器就没了 方便修改文件，比如nginx的配置文件  基本使用 bind mounts 以启动一个centos容器为例\ndocker run -it -v [宿主机目录]:[容器内目录] centos /bin/bash -it ：-t选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开，通常写成-it\n-v ：挂载卷所需参数，后面的映射是[宿主机目录]:[容器内目录]\n用此命令查看容器参数\ndocker inspect [容器id] 如上图，在Mounts 字段中可以看到：\nSource 表示宿主机中被映射的目录\nDestination 表示容器内要映射的目录\n这种挂载方式称为bind mounts\n实践：MySQL挂载 拉取mysql镜像 docker search mysql docker pull mysql:5.7 启动容器 -d 后台运行\n-p 端口映射\n-v 数据卷挂载\n—name 容器名字\ndocker run \\ -d \\ -p 3310:3306 \\  -v /home/mysql/conf:/etc/mysql/conf.d \\  -v /home/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=[你配置的mysql密码] \\  --name [容器名] \\ mysql:5.7 -v可以一次写多个来多次挂载\n连接测试 运行成功后用navicat连接下试试\n 主机地址还是服务器公网ip 端口是映射出来的暴露端口，比如上面命令中的3310 密码就是-e MYSQL_ROOT_PASSWORD设置的密码  可以创建新的数据库看看宿主机对应映射目录下有没有同步出现新数据库的文件\n删除测试 docker rm -f [mysql容器名] 运行上面的指令删除掉容器，再在主机下查看/home/mysql/data 目录发现数据依旧都还在\n如果再次启动一个容器数据就还是和删除前一样，从而保证了数据安全，这就是MySQL数据卷挂载\n匿名挂载和具名挂载 volumes 匿名挂载 -P 随机映射端口\ndocker run -d -P --name nginx01 -v /etc/nginx nginx 如上图的命令，-v 是没有指定外部目录的，只写了内部目录，所以是匿名挂载，使用下面命令查看挂载的卷\ndocker volume ls 发现卷名是随机生成的字符串，所以是匿名的\n具名挂载 docker run -d -P --name nginx01 -v [自己起的卷名]:/etc/nginx nginx [卷名]:[目录名] 这样指定了卷名的形式就是具名挂载\n这样再用docker volume ls 看到的卷名就是自己指定的了\n查看挂载的目录 docker volume inspect [卷名] 用这条命令就可以查看卷的一些信息，其中Mountpoint 就是所挂载的外部目录\n所以这种在没有指定目录的情况下（具名或匿名）都是挂载在/var/lib/docker/volumes/[卷名]/_data这个目录的\n大多数情况下都是用具名挂载\n这两种挂载方式统称volumes\n总结 -v [内路径] 匿名挂载 -v 卷名:内路径 具名挂载 -v 宿主机路径:容器内路径 指定路径挂载\n扩展 可以用参数改变读写权限\nro 只读，容器内不可修改，容器外可以\nre 可读可写\ndocker run -d -P --name nginx02 -v ccq-nginx:/etc/nginx:ro nginx docker run -d -P --name nginx02 -v ccq-nginx:/etc/nginx:rw nginx 使用Dockerfile来构建和挂载 Dockerfile是用来构建docker镜像的构建文件，里面就是构建的脚本\n这个文件可以用来生成镜像，由于镜像是一层一层的，所以脚本命令也是一句句对应一层层的\n以centos来举个例子，在dockerfile里写下下面这些内容：\nFROMcentos # 由哪个原始镜像构建VOLUME [\u0026#34;volume01\u0026#34;,\u0026#34;volume02\u0026#34;] # 挂载，此处匿名CMD echo \u0026#34;---end---\u0026#34;CMD /bin/bash运行构建命令如下：\ndocker build -f [dockerfile路径] -t [镜像名]:[版本tag] [生成目录] 然后用命令docker images 就可以看到自己刚刚构建的镜像了，docker run 就可以跑起来\n之后也可以docker inspect 查看挂载情况，挂载同样是数据内外目录同步的\n数据卷容器 之前是容器内的目录挂载到容器外到到目录，现在是一个容器挂载到另一个容器\n这样就实现了容器之间到数据同步\n—-volumes-from 使用此参数开启一个容器挂载到另一个容器\n被挂载的称为父容器\ndocker run -it --name [名字] --volumes-from [父容器名] [镜像名]:[版本tag] 测试一下，开两个容器，进入挂载到一起的目录创建文件试试，发现数据是同步的\n多重挂载 可以开启第三个容器挂载到第一或第二个容器，发现现在这3个容器对应到目录的数据都是同步的\n所以挂载其实是可以套娃的\n卷的挂载机制 不同容器的挂载机制并不是映射到单一到文件夹下的，如果这样的话其中一个容器被删除的话，其它所有容器对应都数据都会消失。\n实际上挂载是一种拷贝的机制，数据是有多份相同的备份的，删除一种一份其它的都还在，不会消失的，只是会占用更多的存储空间\n只有把挂载这一卷的所有的容器都删除，这个卷才会消失\n当然，如果是bind到本地的目录那就删除全部容器数据也仍然在本地\n参考自狂神的docker教程\n","date":"2021-01-06T16:51:00+08:00","image":"https://ccqstark.github.io/p/docker_volumes/docker_hu22e70eb00a1bc79d3e2af88d0f9ef83b_73329_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/docker_volumes/","title":"[docker]容器数据卷"},{"content":"终于从Windows转到心心念念的MacOS上进行开发，虽然是黑苹果但是软件层面上没有太大的区别，程序员还是得用mac啊这终端上真的比windows好用无数倍，那终端到手后还是要折腾美化的，那就开始吧。 先看下我，还可以吧？ 准备工作 先保证自己下载homebrew和wget，安装软件或下载包很多情况下要用到它们，特别homebrew是mac下最好用的包管理器一定要有。下载方法网上也很多的，建议先下homebrew再用它下wget。\niTerm2 首先是下载第三方终端iTerm2，mac自带的终端用的比较少，大家用的最多还是这个。 官网下载\nzsh zsh是shell的一种，mac默认的shell是bash，一般来说我们也是用zsh比较多，因为命令更多更好用。\n下载zsh brew install zsh 切换shell为zsh # 查看当前使用的shell echo $SHELL # 切换为zsh chsh -s /bin/zsh 运行完上面命令后重启一下即可\noh-my-zsh oh-my-zsh用于美化终端，可以让你拥有很多好看的主题。\n安装 wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh sh install.sh 运行上面的命令来下载安装脚本并运行脚本，成功后会有如下画面\n更换主题 oh-my-zsh有很多默认的主题，可以在~/.zshrc中修改ZSH_THEME来切换不同主题。 这里我推荐powerlever10k，它集合了很多不同主题风格的样式，支持自定义，如果默认主题中没有你满意的那推荐就用它。下面就讲powerlevel10k的安装方法。\n下载 git clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 安装所需字体 # 安装 nerd-font 字体 brew tap homebrew/cask-fonts # 其他所需字体 cd ~ git clone https://github.com/powerline/fonts.git --depth=1 # 到目录下执行安装脚本 cd fonts ./install.sh # 删除刚刚下载的 cd .. rm -rf fonts 配置 vim ~/.zshrc 进入zsh配置文件中修改并增加\nZSH_THEME = \u0026#34;powerlevel10k/powerlevel10k\u0026#34; [[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh 之后启动向导\np10k configure 可以用下面命令查看颜色代号\nfor i in {0..255}; do print -Pn \u0026#34;%K{$i} %k%F{$i}${(l:3::0:)i}%f \u0026#34; ${${(M)$((i%6)):#3}:+$\u0026#39;\\n\u0026#39;}; done 接下来需要下载一些必要的字体或样式，在此之前需要先改host以正常下载 下载软件SwitchHosts! 之后如图加上\n199.232.68.133 raw.githubusercontent.com 199.232.68.133 user-images.githubusercontent.com 199.232.68.133 avatars2.githubusercontent.com 199.232.68.133 avatars1.githubusercontent.com 开启My hosts后重启终端，就会自动提示下载所需字体，耐心等待它下载完（有点慢）后，就可以根据引导一步步自定义属于自己的主题了！从图标到字体颜色风格到显示信息都可以自定义！\n背景透明+毛玻璃 打开iTerm2的偏好设置按下图即可调节背景透明和毛玻璃，下面还可以设置默认窗口大小。\n快捷键唤醒 如何让切出终端更快捷？可以设置Hotkey 按下图操作\n尾声 至此，一个好用又好看的mac终端基本配置完毕啦\n其他有趣的可以看下这篇博客讲的\n","date":"2021-01-06T02:07:00+08:00","image":"https://ccqstark.github.io/p/mac_terminal/Mojave-desktop_hu0caf60027e85952cdd6ae94392d12e9b_35582_120x120_fill_q75_box_smart1.jpg","permalink":"https://ccqstark.github.io/p/mac_terminal/","title":"MacOS终端美化指北"},{"content":"事情经过 11月17号这天早上上着课，突然有用户反馈应用卡顿，使用不了。我感觉上去看了果然是这样，有时数据加载很慢甚至加载不出来，我感到焦虑与害怕，害怕数据库和别人一样被黑了然后删光要钱，课都没心情听了。然后手机下了个Termius，先把服务关了。\n中午回到宿舍后看了数据库发现数据完好无损，赶紧备份了一波，然后寻找问题。\n内存和CPU和磁盘都挺正常，看了服务器的安全日志，那登录记录刷刷的，有人在暴力破解我的root密码！\n由于下午还有体育课，就先直接关了服务器，然后上课去了。\n下午来到实验室，重新打开服务器，又开始攻击了，气死了。用脚本封了攻击者一百多个肉鸡ip，以为可以了之后，把服务开启，通知用户可以用了。\n结果用户又说太卡了，我又检查了一波，CPU、内存、磁盘正常，然后这个带宽就不太正常了，我学生机的1M/s都超了，应该是这个原因导致卡的。\n用命令找了进程发现好像也没哪个占用很多呀，弄了很久还是很迷惑，攻击者的ip也明明被我加入黑名单了呀，之后还开了腾讯云的专业机阻断，还是很卡，卡到我ssh都连不太上。然后有个办法叫我改ssh的22端口，我怕操作失误连自己都直接连不上就GG了，然后就算了不这样搞了。\n最后只能屁颠屁颠去找客服，他跟我说也是其他正常带宽跑满，叫我看有没有什么进程占用很多，主要是建议我临时升级带宽。\n我想着：啊好家伙，开始了。但是也没啥其他办法，就去买了3天升级到3M/s的带宽，不贵，结果也是真香。\n后来最多手动在安全组加了几个奇怪ip封掉，服务就完成稳定下来了，看来没有什么是加钱不能解决的。\n后来过了两天攻击者还在继续冲，除了影响我带宽之外其实也没太大问题反正他进不来的，问了师兄建议说改22端口，反正重要使用期也过了，我就试试改下，还真有用，安全日志也没攻击者那些破解记录了，带宽也占用也再降了，说明攻击者也是冲22，这下直接完全被挡住，带宽也不占了。\n第一次与黑客对线还是学到了很多的，也加强了我的安全防范意识\n查看系统状态命令 下面有些命令工具需要额外安装的，直接yum install xxx安装就行\n查看服务器安全日志(动态实时)(CentOS) tail -f /var/log/secure 查看CPU等的使用情况(按进程) top 查看内存使用情况 free -h 查看磁盘使用情况 df -hl 查看网络带宽占用(按ip) iftop -i eth0 jnettop 按Q退出\n查看网络带宽占用(按进程) nethogs 还有防火墙工具iptables和firewall-cmd\nhttps://wangchujiang.com/linux-command/c/iptables.html\nhttps://wangchujiang.com/linux-command/c/firewall-cmd.html\n编写自动化脚本封禁暴力破解登录的ip 从安全日志中读取记录，把那些多次登录失败的ip写进请求黑名单中（hosts.deny），但是这种办法只是拒绝连接，如果黑客继续攻击还是会占用带宽\n先找个目录，vim建立一个脚本文件\nvim /usr/local/secure_ssh.sh 然后编写脚本\n#! /bin/bash cat /var/log/secure|awk \u0026#39;/Failed/{print $(NF-3)}\u0026#39;|sort|uniq -c|awk \u0026#39;{print $2\u0026#34;=\u0026#34;$1;}\u0026#39; \u0026gt; /usr/local/bin/black.txt for i in `cat /usr/local/bin/black.txt` do IP=`echo $i |awk -F= \u0026#39;{print $1}\u0026#39;` NUM=`echo $i|awk -F= \u0026#39;{print $2}\u0026#39;` result=$(cat /etc/hosts.deny | grep $IP) if [[ $NUM -gt 10 ]];then if [[ $result = \u0026#34;\u0026#34; ]];then echo \u0026#34;sshd: $IP\u0026#34; \u0026gt;\u0026gt; /etc/hosts.deny fi fi done 设置定时任务\n#首先打开定时任务列表 crontab -e #添加下面这行，表示每十分钟 */10 * * * * bash /usr/local/secure_ssh.sh #保存退出后重启下 service crond restart 修改sshd的22端口 这个方法可以完全把对22端口的攻击直接拒之门外，安全日志都没记录破解登录事件，带宽也不会影响，但操作过程要小心一点点\n修改sshd配置文件\nvim /etc/ssh/sshd_config #Port 22 //这行去掉#号，然后在下面增加自己要新开的端口，保证新端口能用再去掉这行 下面新增端口\nPort xxxxx 防火墙开启对应端口，安全组也记得开，或者先把防火墙关了，之后试了新端口能用再开\nfirewall-cmd --zone=public --add-port=xxxxx/tcp --permanent\r重启sshd\n/etc/init.d/sshd restart #或者 service sshd restart 然后重新连服务器终端试试，没问题之后可以把22直接禁掉，防火墙和安全组也封了22，对新端口放行就行\n其他 使用强密码或者只用密钥登录\n数据库多做备份\n建立快照\n关键数据加密\n要增强安全意识呀！\n","date":"2020-11-22T22:10:00+08:00","permalink":"https://ccqstark.github.io/p/first_attack/","title":"记一次服务器被攻击"},{"content":"问题引入与研究目标 目标检测的数据集的收集往往是在现实场景中进行的，因此数据中目标的外观、背景、光照、图像质量等方面的巨大差异会导致训练数据和测试数据之间出现巨大的领域偏移。比如汽车在不同天气条件下驾驶收集到的数据，或者是相机的类型和设置的不同也会导致数据的领域偏移。这样的偏移会导致性能显著下降，尽管收集尽可能多的数据集可以降低这种影响，但是注释边界框也是一个费时费力的过程，因此开发一个新的算法来应对跨领域目标检测问题就尤为重要。\n论文中方法适用于无监督场景，在源域有完整的监督，而在目标域没有监督。这样就可以不增加人工标注成本的前提下减少跨域对目标检测效率的影响。\n关键术语介绍 目标检测 Object Detection 目标检测，也叫目标提取，是一种基于目标几何和统计特征的图像分割，它将目标的分割和识别合二为一，其准确性和实时性是整个系统的一项重要能力。尤其是在复杂场景中，需要对多个目标进行实时处理时，目标自动提取和识别就显得特别重要。目标检测主要有三个层次：\n一是分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其他任务提供了基础。在应用领域，人脸、场景的识别等都可以归为分类任务。\n二是检测（Detection）。分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置），因而，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。\n三是分割（Segmentation）。分割包括语义分割（semantic segmentation）和实例分割（instance segmentation），前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。\n领域自适应 Domain Adaptation 领域自适应（Domain Adaptation）是迁移学习中的一种代表性方法，指的是利用信息丰富的源域样本来提升目标域模型的性能。 领域自适应问题中两个至关重要的概念：\n源域（source domain）表示与测试样本不同的领域，但是有丰富的监督信息\n目标域（target domain）表示测试样本所在的领域，无标签或者只有少量标签。源域和目标域往往属于同一类任务，但是分布不同\n根据目标域和源域的不同类型，领域自适应问题有四类不同的场景：无监督的，有监督的，异构分布和多个源域问题。 通过在不同阶段进行领域自适应，研究者提出了三种不同的领域自适应方法：\n1）样本自适应，对源域样本进行加权重采样，从而逼近目标域的分布。\n2）特征层面自适应，将源域和目标域投影到公共特征子空间。\n3）模型层面自适应，对源域误差函数进行修改，考虑目标域的误差。\n散度 Divergence 在机器学习中，我们常常需要用一个分布Q去逼近一个目标分布P，我们希望能够找到一个目标函数D ( Q , P ) D( Q,P)D(Q,P)，计算Q到P的距离。而这一个目标函数，正是Divergence(散度)，比如常见的KL-Divergence，JS-Divergence等等。通过这个散度的计算我们就能不断地去优化我们的Q，寻找一个最优的参数去逼近真实的分布P。\nFaster R-CNN Faster R-CNN是何凯明等大神在2015年提出目标检测算法，该算法在2015年的ILSVRV和COCO竞赛中获得多项第一。该算法在Fast R-CNN基础上提出了RPN候选框生成算法，使得目标检测速度大大提高。\n \n \nFaster-RCNN由下面几部分组成：\n  数据集，image input\n  卷积层CNN等基础网络，提取特征得到feature map\n  RPN层，再在经过卷积层提取到的feature map上用一个3x3的slide window，去遍历整个feature map,在遍历过程中每个window中心按rate，scale（1:2,1:1,2:1）生成9个anchors，然后再利用全连接对每个anchors做二分类（是前景还是背景）和初步bbox regression，最后输出比较精确的300个ROIs。 把经过卷积层feature map用ROI pooling固定全连接层的输入维度。\n  然后把经过RPN输出的rois映射到ROIpooling的feature map上进行bbox回归和分类。\n  交叉熵 cross entropy 交叉熵描述了两个概率分布之间的距离，当交叉熵越小说明二者之间越接近。\n在信息论中，基于相同事件测度的两个概率分布的交叉熵是指，当基于一个“非自然”（相对于“真实”分布而言）的概率分布进行编码时，在事件集合中唯一标识一个事件所需要的平均比特数。\n梯度下降 gradient descent 在机器学习算法中，在最小化损失函数时，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。\n梯度下降在机器学习中应用十分的广泛，不论是在线性回归还是Logistic回归中，它的主要目的是通过迭代找到目标函数的最小值，或者收敛到最小值。\n \n基本思路 论文中为了解决域偏移问题，在Faster R-CNN模型中加入了图像级和实例级的两个域适应组件，从而来最小化两个域之间的h散度。在每个组件中，训练一个领域分类器，并使用对抗性训练策略来学习领域不变量的鲁棒特征。并且进一步整合不同层次的域分类器之间的一致性规则，在Faster R-CNN模型中学习一个域不变区域建议网络(RPN)。\n研究成果   从概率的角度对跨域目标检测的域移问题进行了理论分析。\n  设计了两个域自适应组件，以缓解图像级和实例级的域差异。\n  进一步提出了一致性正则化，以促进RPN变成领域不变的。\n  将提出的组件集成到Faster R-CNN模型中，得到的系统可以以端到端的方式进行训练。\n  与用于分类的领域适应研究相比，其他计算机视觉任务的领域适应研究较少。近年来在语义分割、精细识别等方面进行了研究。对于检测任务，提出通过引入自适应支持向量机来缓解可变形零件模型(DPM)的域漂移问题。在近期的研究中，其他研究者使用R-CNN模型作为特征提取器，然后用子空间对齐方法对特征进行对齐。也有从其他来源学习探测器的工作，例如从图像到视频，从3D模型，或者从合成模型。以前的工作要么不能以端到端的方式进行培训，要么侧重于特定的案例。在这项工作中，论文作者建立了一个用于目标检测的端到端的可训练模型，也是世界上第一个。\n领域适应组件 Domain Adaptation Components 映像级别适应 Image-Level Adaptation 在Faster R-CNN模型中，指的功能映射输出映像级别表示基本卷积的层。消除域分布不匹配在图像层次,采用patch-based域分类器。\n这种选择的好处:\n 对齐图像级表示通常有助于减少由全局图像差异引起的位移，如图像风格、图像尺度、光照等。类似的基于块的损失在最近的关于style transfer的工作中也被证明是有效的，它也处理全局变换 由于使用了高分辨率的输入，对于训练一个目标检测网络来说，批处理的大小通常非常小。这种基于块的设计有助于增加训练领域分类器的训练样本的数量。  用Di表示第i个训练图像的定义域标签，源域的Di= 0，目标域的Di= 1。将经过基卷积层后的第i幅图像的feature map位于(u, v)处的激活表示为φu,v(Ii)。将域分类器的输出表示为pi(u,v)，利用交叉熵损失，图像级自适应损失可表示为:\n \n实例级适应 Instance-Level Adaptation 实例级表示是指在输入到最终的类别分类器之前基于ROI的特征向量\n对齐实例级表示有助于减少本地实例差异，如对象外观、大小、视点等。与图像级自适应相似，研究者训练了一个针对特征向量的领域分类器来对齐实例级分布。\n将第i幅图像中第j个区域建议的实例级域分类器的输出表示为pi,j。实例级适应损失现在可以写成:\n \n一致性正规化 Consistency Regularization 加强不同层次的域分类器之间的一致性有助于学习边界盒预测器(即Faster R-CNN模型中的RPN)的跨域鲁棒性。因此，研究者进一步设置了一个一致性规则。由于图像级域分类器会为图像级表示的每次激活生成一个输出，因此取图像中所有激活的平均值作为其图像级概率。一致性调节器可以写成:\n \n网络概述 Faster R-CNN与2个组件之间的整合关系如下图：\n \n在每一层上构建一个领域分类器，以一种对抗性的训练方式进行训练。在这两个分类器中加入了一致性规则器，以学习用于Faster R-CNN模型的领域不变RPN。\n左边部分是原始的Faster R-CNN模型。底层的卷积层在所有组件之间共享。然后在其上构建RPN和ROI池化层，然后构建两个完全连接的层来提取实例级特征。\n从合成数据中学习 随着计算机图形技术的发展，利用合成数据训练CNN变得越来越流行。尽管如此，合成的数据与真实世界的图像仍然有明显的视觉差异，并且通常与在真实数据上训练的模型存在性能差距。研究者用不同于真实世界的合成数据进行试验。\n数据集:是SIM 10k由10000张由侠盗猎车手(GTA5)渲染的图像组成，在SIM 10k中，10000张训练图像中提供了58,701辆车的包围框。所有的图像都在训练中使用。Cityscapes数据集是一个城市场景数据集为驾驶场景。这些图像是由车载摄像机拍摄的。2975图像训练集,500图像验证集。使用的标记图像训练集作为目标域适应我们的检测器, 并报告结果验证集。\n结果：不同方法的结果如下表所示。具体来说，与Faster R-CNN相比，仅使用图像级自适应组件获得+2.9%的性能提升，而仅使用实例级对齐组件获得+5.6%的性能提升。这表明，图像级适应和实例级适应组件可以有效地减少各层次上的域漂移。将这两个部分结合在一起可以得到7.7%的改进，这验证了关于减少两层域移位的必要性的猜想。通过进一步应用一致性正则化，域自适应Faster R-CNN模型将更快的R-CNN模型提高了+8.8%。\n \n其它 为了验证模型的效果，研究者还通过恶劣天气中收集的图像数据、不同摄像机拍摄出来的图像数据对算法进行测试，结果都显示出不错的结果\n还进一步分析了图像级和实例级适应的影响，做了有关于图像级和实例级对齐的实验，验证了模型可以从更高分辨率的图像输入中获得更好的性能结果。实验结论是从200像素增加到1000像素。\n还做了实验研究了使用一致性正则化前后RPN的性能，发现RPN的性能可以进一步提高到30.3%，说明一致性调节器提高了RPN的鲁棒性。\n","date":"2020-11-22T22:07:00+08:00","permalink":"https://ccqstark.github.io/p/ml_domain_adaptation/","title":"[机器学习论文]Domain Adaptive Faster R-CNN for Object Detection in the Wild"},{"content":"问题 设A和B是2个字符串。要用最少的字符操作将字符串A转换为字符串B。这里所说的字符操作包括 (1)删除一个字符； (2)插入一个字符； (3)将一个字符改为另一个字符。 将字符串A变换为字符串B所用的最少字符操作数称为字符串A到 B的编辑距离，记为d(A,B)。 对于给定的字符串A和字符串B，计算其编辑距离 d(A,B)。\n输入格式: 第一行是字符串A，文件的第二行是字符串B。\n提示：字符串长度不超过2000个字符。\n输出格式: 输出编辑距离d(A,B)\n输入样例: 在这里给出一组输入。例如：\nfxpimu\rxwrs 输出样例: 在这里给出相应的输出。例如：\n5\r思路 用动态规划算法可以将问题分解出最优子结构。\n设dp[i][j]表示把A字符串前i个字符组成的字符串转变为B字符串前j个字符组成的字符串所需的最少的字符操作数\n如果A字符串的第i个字符与B字符串的第j个字符串相同，则这个位置不需要操作，所需的操作等于dp[i-1][j-1]，否则需要进行修改，操作数就要+1\n由于每个位置都可以进行修改、删除、插入三种操作，因此需要把这三种操作中编辑距离最小的作为dp[i][j]的值\n递推公式(代码表示)：\nif (A[i - 1] == B[j - 1]) // dp矩阵以1开始，字符数组是0开始，因此对应的话要-1 \tdp[i][j] = dp[i - 1][j - 1]; // 如果对应的位置相同就不用操作，否则要修改所以要+1 else dp[i][j] = dp[i - 1][j - 1] + 1; // 修改 删除 插入 dp[i][j] = min(dp[i][j], min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); 表的维度：二维\n填表的范围：（len_A和len_B分别为字符串A、B的长度）\ni：1 ~ len_A\nj：1 ~ len_B\n填表顺序：从左至右，自顶向下（i与j的递增方向）\n时间复杂度：由于填写的是二维表，需要二重循环，所以时间复杂度是O(n^2)\n空间复杂度：需要一个二维数组，因而是O(n^2)\n代码 // 编辑距离问题 #include \u0026lt;iostream\u0026gt;#include \u0026lt;cstring\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 2002 char A[MAX]; char B[MAX]; int dp[MAX][MAX]; int calculate_distance() { // a、b字符串的长度  int len_a = strlen(A); int len_b = strlen(B); // 边界初始化  for (int i = 0; i \u0026lt;= len_a; i++) dp[i][0] = i; for (int j = 0; j \u0026lt;= len_b; j++) dp[0][j] = j; for (int i = 1; i \u0026lt;= len_a; i++) { for (int j = 1; j \u0026lt;= len_b; j++) { // dp矩阵以1开始，字符数组是0开始，因此对应的话要-1  if (A[i - 1] == B[j - 1]) // 如果对应的位置相同就不用操作，否则要修改所以要+1  dp[i][j] = dp[i - 1][j - 1]; else dp[i][j] = dp[i - 1][j - 1] + 1; // 修改 删除 插入  dp[i][j] = min(dp[i][j], min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); } } return dp[len_a][len_b]; } int main() { cin \u0026gt;\u0026gt; A \u0026gt;\u0026gt; B; cout \u0026lt;\u0026lt; calculate_distance(); } ","date":"2020-10-31T17:03:00+08:00","permalink":"https://ccqstark.github.io/p/dp_edit_distance/","title":"DP动态规划——编辑距离问题"},{"content":"题目 假设要在足够多的会场里安排一批活动，并希望使用尽可能少的会场。设计一个有效的 贪心算法进行安排。（这个问题实际上是著名的图着色问题。若将每一个活动作为图的一个 顶点，不相容活动间用边相连。使相邻顶点着有不同颜色的最小着色数，相应于要找的最小 会场数。）\n输入格式: 第一行有 1 个正整数k，表示有 k个待安排的活动。 接下来的 k行中，每行有 2个正整数，分别表示 k个待安排的活动开始时间和结束时间。时间 以 0 点开始的分钟计。\n输出格式: 输出最少会场数。\n输入样例: 5\r1 23\r12 28\r25 35\r27 80\r36 50 输出样例: 在这里给出相应的输出。例如：\n3\r思路 首先这道题就很像书中那道在一个会场中安排尽可能多的活动，但是，不能完全按之前那个思路来做！\n这里是要用尽可能少的会场，而且从题中可以看出会场的结束时间没有限制，只要活动的开始时间比上一场要晚就行。如果我们按书中的办法把活动先按结束时间从小到大排序，然后对当前未安排的活动用一个会场进行尽可能多的安排，之后若还每安排完在开辟一个新的会场继续之前的操作。这样的算法是有问题的，因为这样的在一个会场中尽可能多的安排活动，而从全局来看（还有这道题的特点：会场结束时间无限制），这种策略并不能保证把所有活动安排在最少的会场，所以两个问题并不能完全等同，这就是我一开始犯的错误。\n其实原因就在于：会场结束时间无限制，要用最少的会场。\n正确解法有2种：\n 把活动按开始时间从小到大排，当开始时间相同则结束时间早的优先。遍历活动再用之前的那种在一个会场安排尽可能多的活动，完了之后开辟一个新的会场继续安排，直到全部活动安排完毕。 把活动按结束时间从小到大排，当结束时间相同则开始时间早的优先。遍历活动，每次再遍历一次所有会场看结束时间是否满足可以安排下，都不能安排下就新开一个会场，然后每次还要对所有已经开辟的会场按结束时间进行从大到小再次排序，这样直到所有活动遍历安排完毕。  所以这道题是要把有限的活动尽量塞在最少的会场中，要从所有会场全局去考虑，而且这道题的特点是单个会场的结束时间没有限制，所以第一种解法是按开始时间排的而不用按结束时间。第二种按结束时间的话就需要每次重新遍历所有会场，每次还重排，保证从全局去考虑。\n代码 解法1： // 按开始时间排序 #include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 666  struct activity { int start; int end; int arrage; } activities[MAX]; int n; bool struct_compare(activity a, activity b) { if (a.start != b.start) return a.start \u0026lt; b.start; //优先进行最先开始的活动  else return a.end \u0026lt; b.end; //当开始时间相同时,优先进行最早结束的活动 } int main() { cin \u0026gt;\u0026gt; n; for (int i = 0; i \u0026lt; n; i++) { cin \u0026gt;\u0026gt; activities[i].start; cin \u0026gt;\u0026gt; activities[i].end; activities[i].arrage = 0; } // 初始化会场数  int room = 0; // 对活动\u0026#39;开始时间\u0026#39;进行从小到大排序  sort(activities, activities + n, struct_compare); // 记录当前安排会场的结束时间，被安排的会场数  int lastest = 0, arrage_num = 0; // 如果会场还没有被全部安排完  while (arrage_num != n) { // 新增一个会场  room++; for (int i = 0; i \u0026lt; n; i++) { // 在一个会场中安排尽可能多的活动  if (activities[i].arrage == 0 \u0026amp;\u0026amp; activities[i].start \u0026gt;= lastest) { activities[i].arrage = 1; // 标记活动为已被安排  arrage_num++; lastest = activities[i].end; // 更新当前会场的结束时间  } } lastest = 0; } //另外一种写法，效果一样  /* for (int i = 0; i \u0026lt; n; i++) { if (activities[i].arrage == 0) { room++; activities[i].arrage = 1; lastest = activities[i].end; for (int j = i + 1; j \u0026lt; n; j++) { if (activities[j].arrage == 0 \u0026amp;\u0026amp; activities[j].start \u0026gt;= lastest) { activities[j].arrage = 1; lastest = activities[j].end; } } } } */ cout \u0026lt;\u0026lt; room; return 0; } 解法2： //按结束时间排序 #include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; #define MAX 666  struct activity { int start; int end; } activities[MAX]; int n; int end_time[MAX] = {0}; // 记录每个会场的结束时间 int room = 1; // 会场数  bool struct_compare(activity a, activity b) { if (a.end != b.end) return a.end \u0026lt; b.end; //优先进行最早结束的活动  else return a.start \u0026lt; b.start; //当结束时间相同时,优先进行最早开始的活动 } bool dcmp(int a, int b) { return a \u0026gt; b; // 从大到小排序 } int main() { cin \u0026gt;\u0026gt; n; for (int i = 0; i \u0026lt; n; i++) { cin \u0026gt;\u0026gt; activities[i].start; cin \u0026gt;\u0026gt; activities[i].end; } // 对活动按\u0026#39;结束时间\u0026#39;进行排序  sort(activities, activities + n, struct_compare); // 遍历活动  for (int i = 0; i \u0026lt; n; i++) { int flag = 0; // 标记是否在已开辟的会场中被安排  for (int j = 1; j \u0026lt;= room; j++) // 遍历已有会场寻找合适的  { if (activities[i].start \u0026gt;= end_time[j]) { end_time[j] = activities[i].end; flag = 1; break; } } // 已有会场找不到合适的就开辟一个新的  if (!flag) { room++; end_time[room] = activities[i].end; } // 每次安排完一个活动都要对会场们按结束时间从大到小重排  sort(end_time + 1, end_time + room + 1, dcmp); } cout \u0026lt;\u0026lt; room; return 0; } 参考博文\n","date":"2020-10-31T09:45:00+08:00","permalink":"https://ccqstark.github.io/p/greedy_activity/","title":"贪心算法——会场安排问题"},{"content":"题目 在一个地图上有n个地窖（n≤200）,每个地窖中埋有一定数量的地雷。同时，给出地窖之间的连接路径，并规定路径都是单向的,且保证都是小序号地窖指向大序号地窖，也不存在可以从一个地窖出发经过若干地窖后又回到原来地窖的路径。某人可以从任意一处开始挖地雷，然后沿着指出的连接往下挖（仅能选择一条路径），当无连接时挖地雷工作结束。设计一个挖地雷的方案，使他能挖到最多的地雷。\n输入格式: 第一行：地窖的个数；\n第二行：为依次每个地窖地雷的个数；\n下面若干行：\nxi yi //表示从xi可到yi，xi\u0026lt;yi。\n最后一行为\u0026quot;0 0\u0026quot;表示结束。\n输出格式: k1-k2−…−kv //挖地雷的顺序 挖到最多的雷。\n输入样例: 6\r5 10 20 5 4 5\r1 2\r1 4\r2 4\r3 4\r4 5\r4 6\r5 6\r0 0\r输出样例: 3-4-5-6\r34\r代码 #include \u0026lt;iostream\u0026gt;using namespace std; #define MAX 203 int matrix[MAX][MAX]; // 存放通路情况 int mines[MAX]; // 存放各坑地雷数 int dp_mat[MAX][MAX]; // 存放子问题最优解 int path[MAX]; // 存放路径 int n, ans, last_update; // last_update是最后一个更新最大值的点  void dig() { // 一行行扫  for (int i = 1; i \u0026lt;= n; i++) { // max_last是此点之前所有点可以挖到的最大地雷数  int max_last = 0; for (int k = 1; k \u0026lt;= i - 1; k++) { // 判断之前所有可以通向现在的点中，可以挖到最大的地雷数的路径的最后一点  if (matrix[k][i] == 1) { // 按列方向扫，可以通向本点的点  if (dp_mat[k][i] \u0026gt; max_last) { max_last = dp_mat[k][i]; path[i] = k; // 路径是所连接的上一点  } } } for (int j = i; j \u0026lt;= n; j++) { // max_last + 本点地雷数 = 以本点作为路径末点可以挖到的最大地雷数  dp_mat[i][j] = max_last + mines[i]; if (dp_mat[i][j] \u0026gt; ans) { // 更新最终答案的最大地雷数  ans = dp_mat[i][j]; // 记录最后更新最终答案的那个点，作为答案路径的末尾点，用数组回溯可以打印出完整路径  last_update = i; } } } } // 递归回溯打印完整路径 void print_path(int point) { if (point == 0) return; print_path(path[point]); if (point == last_update) { cout \u0026lt;\u0026lt; point \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; point \u0026lt;\u0026lt; \u0026#34;-\u0026#34;; } } int main() { cin \u0026gt;\u0026gt; n; for (int i = 1; i \u0026lt;= n; i++) { cin \u0026gt;\u0026gt; mines[i]; } int a, b; while (cin \u0026gt;\u0026gt; a \u0026gt;\u0026gt; b) { if (a == 0 \u0026amp;\u0026amp; b == 0) break; matrix[a][b] = 1; } dig(); print_path(last_update); cout \u0026lt;\u0026lt; ans; } ","date":"2020-10-22T01:05:00+08:00","permalink":"https://ccqstark.github.io/p/dp_digmines/","title":"DP动态规划——挖地雷"},{"content":"题目 设计一个O(n2)时间的算法，找出由n个数组成的序列的最长单调递增子序列。\n输入格式: 输入有两行： 第一行：n，代表要输入的数列的个数 第二行：n个数，数字之间用空格格开\n输出格式: 最长单调递增子序列的长度\n输入样例: 在这里给出一组输入。例如：\n5\r1 3 5 2 9\r输出样例: 在这里给出相应的输出。例如：\n4\r思路 用动态规划的思想，利用子问题的最优解求更大一点的子问题。\n设一个数组dp[i]用于存放数组中从0到i下标的序列中，最长的递增子序列的长度\n双重遍历，如果arr[j]小于arr[i]，则dp[i]为dp[j]+1和dp[i]中较大的那个。即\ndp[i] = max{ dp[j]+1, dp[i] }\n由于每次重头又遍历了一次，并每次都分析最优解，避免了1 2 3 9 6 7 这样在最大数后面还有2个较小的数可以产生更长递增子序列的情况可能犯的错误。\n这也说明这个算法的时间复杂度只能是O(n2)\n代码 // 单调递增最长子序列 #include \u0026lt;iostream\u0026gt;using namespace std; #define MAX 666 int arr[MAX]; int dp[MAX]; int n; int longest_increasing(){ // 初始化第一个  dp[0] = 1; // 双重遍历  for (int i = 0;i\u0026lt;n;i++){ for (int j = 0;j\u0026lt;i;j++){ // 利用子问题最优解  if(arr[i]\u0026gt;arr[j]){ dp[i] = (dp[j]+1\u0026gt;dp[i])?dp[j]+1:dp[i]; } } } // 找出dp[]中最大的那个作为答案  int max_len = 1; for (int i = 0;i\u0026lt;n;i++){ max_len = (dp[i]\u0026gt;max_len)?dp[i]:max_len; } return max_len; } int main() { cin\u0026gt;\u0026gt;n; for (int i = 0;i\u0026lt;n;i++){ cin\u0026gt;\u0026gt;arr[i]; } cout\u0026lt;\u0026lt;longest_increasing(); } ","date":"2020-10-21T21:07:00+08:00","permalink":"https://ccqstark.github.io/p/dp_increasing/","title":"DP动态规划——单调递增最长子序列"},{"content":"添加依赖 \u0026lt;!-- shiro --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.shiro\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;shiro-spring\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- JWT --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.auth0\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;java-jwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.11.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; JWT加密解密验证工具类 package com.ccqstark.springbootquick.util; import com.auth0.jwt.JWT; import com.auth0.jwt.JWTVerifier; import com.auth0.jwt.algorithms.Algorithm; import io.jsonwebtoken.Claims; import io.jsonwebtoken.JwtBuilder; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import org.apache.commons.codec.binary.Base64; import java.util.Date; import java.util.HashMap; import java.util.Map; import java.util.UUID; /* * 总的来说，工具类中有三个方法 * 获取JwtToken，获取JwtToken中封装的信息，判断JwtToken是否存在 * 1. encode()，参数是=签发人，存在时间，一些其他的信息=。返回值是JwtToken对应的字符串 * 2. decode()，参数是=JwtToken=。返回值是荷载部分的键值对 * 3. isVerify()，参数是=JwtToken=。返回值是这个JwtToken是否存在 * */ public class JwtUtil { // 创建默认的秘钥和算法，供无参的构造方法使用  private static final String defaultbase64EncodedSecretKey = \u0026#34;wdnmd\u0026#34;; private static final SignatureAlgorithm defaultsignatureAlgorithm = SignatureAlgorithm.HS256; // 无参构造，使用默认  public JwtUtil() { this(defaultbase64EncodedSecretKey, defaultsignatureAlgorithm); } private final String base64EncodedSecretKey; private final SignatureAlgorithm signatureAlgorithm; // 有参构造  public JwtUtil(String secretKey, SignatureAlgorithm signatureAlgorithm) { this.base64EncodedSecretKey = Base64.encodeBase64String(secretKey.getBytes()); this.signatureAlgorithm = signatureAlgorithm; } /* *这里就是产生jwt字符串的地方 * jwt字符串包括三个部分 * 1. header * -当前字符串的类型，一般都是“JWT” * -哪种算法加密，“HS256”或者其他的加密算法 * 所以一般都是固定的，没有什么变化 * 2. payload * 一般有四个最常见的标准字段（下面有） * iat：签发时间，也就是这个jwt什么时候生成的 * jti：JWT的唯一标识 * iss：签发人，一般都是username或者userId * exp：过期时间 * * */ public String encode(String iss, long ttlMillis, Map\u0026lt;String, Object\u0026gt; claims) { //iss签发人，ttlMillis生存时间，claims是指还想要在jwt中存储的一些非隐私信息  if (claims == null) { claims = new HashMap\u0026lt;\u0026gt;(); } long nowMillis = System.currentTimeMillis(); JwtBuilder builder = Jwts.builder() .setClaims(claims) .setId(UUID.randomUUID().toString())// 这个是JWT的唯一标识，一般设置成唯一的，这个方法可以生成唯一标识  .setIssuedAt(new Date(nowMillis))// 这个地方就是以毫秒为单位，换算当前系统时间生成的iat  .setIssuer(iss)// 签发人，也就是JWT是给谁的（逻辑上一般都是username或者userId）  .signWith(signatureAlgorithm, base64EncodedSecretKey);//这个地方是生成jwt使用的算法和秘钥  if (ttlMillis \u0026gt;= 0) { // 过期时间 = 当前时间 + 生存时间  long expMillis = nowMillis + ttlMillis; Date exp = new Date(expMillis);// 过期时间，这个也是使用毫秒生成的  builder.setExpiration(exp); } return builder.compact(); } //相当于encode的逆向，传入jwtToken生成对应的username和password等字段。Claim就是一个map  //也就是拿到荷载部分所有的键值对  public Claims decode(String jwtToken) { // 得到 DefaultJwtParser  return Jwts.parser() // 设置签名的秘钥  .setSigningKey(base64EncodedSecretKey) // 设置需要解析的 jwt  .parseClaimsJws(jwtToken) .getBody(); } //判断jwtToken是否合法  public boolean isVerify(String jwtToken) { //这个是官方的校验规则，这里只写了一个\u0026#34;校验算法\u0026#34;，可以自己加  Algorithm algorithm = null; switch (signatureAlgorithm) { case HS256: algorithm = Algorithm.HMAC256(Base64.decodeBase64(base64EncodedSecretKey)); break; default: throw new RuntimeException(\u0026#34;不支持该算法\u0026#34;); } JWTVerifier verifier = JWT.require(algorithm).build(); verifier.verify(jwtToken); // 校验不通过会抛出异常  //判断合法的标准：1. 头部和荷载部分没有篡改过。2. 没有过期  return true; } public static void main(String[] args) { JwtUtil util = new JwtUtil(\u0026#34;wdnmd\u0026#34;, SignatureAlgorithm.HS256); //以tom作为秘钥，以HS256加密  Map\u0026lt;String, Object\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(\u0026#34;username\u0026#34;, \u0026#34;ccq\u0026#34;); map.put(\u0026#34;password\u0026#34;, \u0026#34;1428\u0026#34;); map.put(\u0026#34;age\u0026#34;, 20); String jwtToken = util.encode(\u0026#34;ccqstark\u0026#34;, 30000, map); System.out.println(jwtToken); util.decode(jwtToken).entrySet().forEach((entry) -\u0026gt; { System.out.println(entry.getKey() + \u0026#34;: \u0026#34; + entry.getValue()); }); } } 关闭shiro的session package com.ccqstark.springbootquick.auth; import org.apache.shiro.subject.Subject; import org.apache.shiro.subject.SubjectContext; import org.apache.shiro.web.mgt.DefaultWebSubjectFactory; // 关闭shiro的session public class JwtDefaultSubjectFactory extends DefaultWebSubjectFactory { @Override public Subject createSubject(SubjectContext context) { // 不创建 session  context.setSessionCreationEnabled(false); return super.createSubject(context); } } 使用UsernamePasswordToken package com.ccqstark.springbootquick.auth; import org.apache.shiro.authc.AuthenticationToken; //这个就类似UsernamePasswordToken public class JwtToken implements AuthenticationToken { private String jwt; public JwtToken(String jwt) { this.jwt = jwt; } @Override//类似是用户名  public Object getPrincipal() { return jwt; } @Override//类似密码  public Object getCredentials() { return jwt; } //返回的都是jwt } Realm验证类 package com.ccqstark.springbootquick.auth; import com.ccqstark.springbootquick.util.JwtUtil; import lombok.extern.slf4j.Slf4j; import org.apache.shiro.authc.*; import org.apache.shiro.authz.AuthorizationInfo; import org.apache.shiro.realm.AuthorizingRealm; import org.apache.shiro.subject.PrincipalCollection; @Slf4j public class JwtRealm extends AuthorizingRealm { /* * 多重写一个support * 标识这个Realm是专门用来验证JwtToken * 不负责验证其他的token（UsernamePasswordToken） * */ @Override public boolean supports(AuthenticationToken token) { //这个token就是从过滤器中传入的jwtToken  return token instanceof JwtToken; } //授权  @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) { return null; } //认证  //这个token就是从过滤器中传入的jwtToken  @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException { String jwt = (String) token.getPrincipal(); if (jwt == null) { throw new NullPointerException(\u0026#34;jwtToken 不允许为空\u0026#34;); } //判断  JwtUtil jwtUtil = new JwtUtil(); if (!jwtUtil.isVerify(jwt)) { throw new UnknownAccountException(); } //下面是验证这个user是否是真实存在的  String username = (String) jwtUtil.decode(jwt).get(\u0026#34;username\u0026#34;);//判断数据库中username是否存在  log.info(\u0026#34;在使用token登录\u0026#34;+username); return new SimpleAuthenticationInfo(jwt,jwt,\u0026#34;JwtRealm\u0026#34;); //这里返回的是类似账号密码的东西，但是jwtToken都是jwt字符串。还需要一个该Realm的类名  } } Filter过滤器 package com.ccqstark.springbootquick.auth; import lombok.extern.slf4j.Slf4j; import org.apache.shiro.web.filter.AccessControlFilter; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /* * 自定义一个Filter，用来拦截所有的请求判断是否携带Token * isAccessAllowed()判断是否携带了有效的JwtToken * onAccessDenied()是没有携带JwtToken的时候进行账号密码登录，登录成功允许访问，登录失败拒绝访问 * */ @Slf4j public class JwtFilter extends AccessControlFilter { /* * 1. 返回true，shiro就直接允许访问url * 2. 返回false，shiro才会根据onAccessDenied的方法的返回值决定是否允许访问url * */ @Override protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) throws Exception { log.warn(\u0026#34;isAccessAllowed 方法被调用\u0026#34;); //这里先让它始终返回false来使用onAccessDenied()方法  return false; } /** * 返回结果为true表明登录通过 */ @Override protected boolean onAccessDenied(ServletRequest servletRequest, ServletResponse servletResponse) throws Exception { log.warn(\u0026#34;onAccessDenied 方法被调用\u0026#34;); //这个地方和前端约定，要求前端将jwtToken放在请求的Header部分  //所以以后发起请求的时候就需要在Header中放一个Authorization，值就是对应的Token  HttpServletRequest request = (HttpServletRequest) servletRequest; String jwt = request.getHeader(\u0026#34;Authorization\u0026#34;); log.info(\u0026#34;请求的 Header 中藏有 jwtToken {}\u0026#34;, jwt); JwtToken jwtToken = new JwtToken(jwt); /* * 下面就是固定写法 * */ try { // 委托 realm 进行登录认证  //所以这个地方最终还是调用JwtRealm进行的认证  getSubject(servletRequest, servletResponse).login(jwtToken); //也就是subject.login(token)  } catch (Exception e) { e.printStackTrace(); onLoginFail(servletResponse); //调用下面的方法向客户端返回错误信息  return false; } return true; //执行方法中没有抛出异常就表示登录成功  } //登录失败时默认返回 401 状态码  private void onLoginFail(ServletResponse response) throws IOException { HttpServletResponse httpResponse = (HttpServletResponse) response; httpResponse.setStatus(HttpServletResponse.SC_UNAUTHORIZED); httpResponse.getWriter().write(\u0026#34;login error\u0026#34;); } } shiro配置 package com.ccqstark.springbootquick.config; import com.ccqstark.springbootquick.auth.*; import org.apache.shiro.mgt.DefaultSessionStorageEvaluator; import org.apache.shiro.mgt.DefaultSubjectDAO; import org.apache.shiro.mgt.SubjectFactory; import org.apache.shiro.realm.Realm; import org.apache.shiro.spring.web.ShiroFilterFactoryBean; import org.apache.shiro.web.filter.authc.AnonymousFilter; import org.apache.shiro.web.filter.authc.LogoutFilter; import org.apache.shiro.web.mgt.DefaultWebSecurityManager; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import javax.servlet.Filter; import java.util.HashMap; import java.util.LinkedHashMap; import java.util.Map; //springBoot整合jwt实现认证有三个不一样的地方，对应下面abc @Configuration public class ShiroConfig { /* * a. 告诉shiro不要使用默认的DefaultSubject创建对象，因为不能创建Session * */ @Bean public SubjectFactory subjectFactory() { return new JwtDefaultSubjectFactory(); } @Bean public Realm realm() { return new JwtRealm(); } @Bean public DefaultWebSecurityManager securityManager() { DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(realm()); /* * b * */ // 关闭 ShiroDAO 功能  DefaultSubjectDAO subjectDAO = new DefaultSubjectDAO(); DefaultSessionStorageEvaluator defaultSessionStorageEvaluator = new DefaultSessionStorageEvaluator(); // 不需要将 Shiro Session 中的东西存到任何地方（包括 Http Session 中）  defaultSessionStorageEvaluator.setSessionStorageEnabled(false); subjectDAO.setSessionStorageEvaluator(defaultSessionStorageEvaluator); securityManager.setSubjectDAO(subjectDAO); //禁止Subject的getSession方法  securityManager.setSubjectFactory(subjectFactory()); return securityManager; } @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean() { ShiroFilterFactoryBean shiroFilter = new ShiroFilterFactoryBean(); shiroFilter.setSecurityManager(securityManager()); shiroFilter.setLoginUrl(\u0026#34;/unauthenticated\u0026#34;); shiroFilter.setUnauthorizedUrl(\u0026#34;/unauthorized\u0026#34;); /* * c. 添加jwt过滤器，并在下面注册 * 也就是将jwtFilter注册到shiro的Filter中 * 指定除了login和logout之外的请求都先经过jwtFilter * */ Map\u0026lt;String, Filter\u0026gt; filterMap = new HashMap\u0026lt;\u0026gt;(); //这个地方其实另外两个filter可以不设置，默认就是  filterMap.put(\u0026#34;anon\u0026#34;, new AnonymousFilter()); filterMap.put(\u0026#34;jwt\u0026#34;, new JwtFilter()); filterMap.put(\u0026#34;logout\u0026#34;, new LogoutFilter()); shiroFilter.setFilters(filterMap); // 拦截器  Map\u0026lt;String, String\u0026gt; filterRuleMap = new LinkedHashMap\u0026lt;\u0026gt;(); filterRuleMap.put(\u0026#34;/login\u0026#34;, \u0026#34;anon\u0026#34;); filterRuleMap.put(\u0026#34;/logout\u0026#34;, \u0026#34;logout\u0026#34;); filterRuleMap.put(\u0026#34;/**\u0026#34;, \u0026#34;jwt\u0026#34;); shiroFilter.setFilterChainDefinitionMap(filterRuleMap); return shiroFilter; } } 测试Controller package com.ccqstark.springbootquick.controller; import com.ccqstark.springbootquick.util.JwtUtil; import io.jsonwebtoken.SignatureAlgorithm; import lombok.extern.slf4j.Slf4j; import org.springframework.http.ResponseEntity; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; import java.util.HashMap; import java.util.Map; @Slf4j @Controller public class LoginController { @RequestMapping(\u0026#34;/login\u0026#34;) public ResponseEntity\u0026lt;Map\u0026lt;String, String\u0026gt;\u0026gt; login(String username, String password) { log.info(\u0026#34;username:{},password:{}\u0026#34;,username,password); Map\u0026lt;String, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); if (!\u0026#34;tom\u0026#34;.equals(username) || !\u0026#34;123\u0026#34;.equals(password)) { map.put(\u0026#34;msg\u0026#34;, \u0026#34;用户名密码错误\u0026#34;); return ResponseEntity.ok(map); } JwtUtil jwtUtil = new JwtUtil(\u0026#34;wdnmd\u0026#34;, SignatureAlgorithm.HS256); Map\u0026lt;String, Object\u0026gt; chaim = new HashMap\u0026lt;\u0026gt;(); chaim.put(\u0026#34;username\u0026#34;, username); // 生存时间在这里设置  String jwtToken = jwtUtil.encode(username, 20*1000, chaim); map.put(\u0026#34;msg\u0026#34;, \u0026#34;登录成功\u0026#34;); map.put(\u0026#34;token\u0026#34;, jwtToken); return ResponseEntity.ok(map); } @RequestMapping(\u0026#34;/testdemo\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; testdemo() { return ResponseEntity.ok(\u0026#34;我爱蛋炒饭\u0026#34;); } } 请求登录接口，密码正确后返回一个token，以后每次请求带上这个token以header里的Authorization字段的形式\n之后的页面都会经过拦截器分配到对应的过滤器进行验证token是否有效，实现了鉴权。\n","date":"2020-10-17T16:52:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_shiro_jwt/","title":"[SpringBoot]整合shiro+JWT做鉴权"},{"content":"开通服务 登录阿里云，开通OSS服务，默认按量计费，为了业务稳定可以购买包月包年的资源包。\n准备工作 创建Bucket，如果是为了作为网站的静态资源存储供用户访问的话把权限设为公共读，填写信息后创建成功，可以在Bucket下新建目录什么的。\n单独创建一个RAM子用户用来调用API，选择编程访问，创建成功后一定要把AccessKeyID和AccessKeySecret等重要信息记下来，后面配置文件要用到。\n然后要给这个子用户添加权限AliyunOSSFullAccess\nMaven依赖 \u0026lt;!-- OSS --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.oss\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-sdk-oss\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.2\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.httpcomponents\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;httpclient\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.4.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置文件 endpoint就是在存储桶的概览里地域节点，填外网访问那个就行\nurl填资源访问的URL的前面部分（填到.com/）\naccessKeyId和accessKeySecret就是创建子用户时那个\nbucketName就是存储桶的名字\n# 阿里云ossoss:endpoint:*url:*accessKeyId:*accessKeySecret:*bucketName:*配置类 项目的config目录下新建OSS的配置类\npackage com.ccqstark.springbootquick.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import java.io.Serializable; /** * @Description: 阿里云 OSS 配置信息 * @Author: ccq * @Date: 2020/10/16 */ @Component //注册bean @Data @Configuration @ConfigurationProperties(prefix = \u0026#34;oss\u0026#34;) public class OSSConfig implements Serializable { private String endpoint; private String url; private String accessKeyId; private String accessKeySecret; private String bucketName; } 上传文件工具类 项目的util目录下新建这上传工具类\npackage com.ccqstark.springbootquick.util; import com.aliyun.oss.ClientConfiguration; import com.aliyun.oss.OSSClient; import com.aliyun.oss.common.auth.DefaultCredentialProvider; import com.ccqstark.springbootquick.config.OSSConfig; import org.springframework.web.multipart.MultipartFile; import java.io.IOException; import java.util.UUID; /** * @Description: 阿里云 oss 上传工具类(高依赖版) * @Author: ccq * @Date: 2020/10/17 */ public class OSSBootUtil { private OSSBootUtil(){} /** * oss 工具客户端 */ private volatile static OSSClient ossClient = null; /** * 上传文件至阿里云 OSS * 文件上传成功,返回文件完整访问路径 * 文件上传失败,返回 null * * @param ossConfig oss 配置信息 * @param file 待上传文件 * @param fileDir 文件保存目录 * @return oss 中的相对文件路径 */ public static String upload(OSSConfig ossConfig, MultipartFile file, String fileDir){ // 初始化客户端  initOSS(ossConfig); // 文件URL  StringBuilder fileUrl = new StringBuilder(); try { String suffix = file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf(\u0026#39;.\u0026#39;)); String fileName = System.currentTimeMillis() + \u0026#34;-\u0026#34; + UUID.randomUUID().toString().substring(0,18) + suffix; if (!fileDir.endsWith(\u0026#34;/\u0026#34;)) { fileDir = fileDir.concat(\u0026#34;/\u0026#34;); } fileUrl = fileUrl.append(fileDir + fileName); // 上传文件到指定的存储空间，并将其保存为指定的文件名称  ossClient.putObject(ossConfig.getBucketName(), fileUrl.toString(), file.getInputStream()); } catch (IOException e) { e.printStackTrace(); return null; } fileUrl = fileUrl.insert(0,ossConfig.getUrl()); return fileUrl.toString(); } /** * 初始化 oss 客户端 * @param ossConfig * @return */ private static OSSClient initOSS(OSSConfig ossConfig) { if (ossClient == null ) { synchronized (OSSBootUtil.class) { if (ossClient == null) { ossClient = new OSSClient(ossConfig.getEndpoint(), new DefaultCredentialProvider(ossConfig.getAccessKeyId(), ossConfig.getAccessKeySecret()), new ClientConfiguration()); } } } return ossClient; } } 服务层 在项目的service目录下新建服务层接口\npackage com.ccqstark.springbootquick.service; import com.ccqstark.springbootquick.model.ApiResult; import org.springframework.web.multipart.MultipartFile; /** * @Description: 公共业务 * @Author: ccq * @Date: 2020/10/17 */ public interface CommonService { /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ ApiResult uploadOSS(MultipartFile file, String uploadKey) throws Exception; } 新建实现类\npackage com.ccqstark.springbootquick.service; import com.ccqstark.springbootquick.config.OSSConfig; import com.ccqstark.springbootquick.model.ApiResult; import com.ccqstark.springbootquick.util.OSSBootUtil; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.web.multipart.MultipartFile; import java.util.HashMap; import java.util.Map; /** * @Description: 公共业务具体实现类 * @Author: ccq * @Date: 2020/10/17 */ @Service(\u0026#34;commonService\u0026#34;) public class CommonServiceImpl implements CommonService { @Autowired private OSSConfig ossConfig; /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ @Override public ApiResult uploadOSS(MultipartFile file, String uploadKey) throws Exception { // 高依赖版本 oss 上传工具  String ossFileUrlBoot = null; ossFileUrlBoot = OSSBootUtil.upload(ossConfig, file, \u0026#34;image/\u0026#34;); // 注意这里填写的是存储桶中你要存放文件的目录  Map\u0026lt;String, Object\u0026gt; resultMap = new HashMap\u0026lt;\u0026gt;(16); resultMap.put(\u0026#34;ossFileUrlBoot\u0026#34;, ossFileUrlBoot); return new ApiResult(200, resultMap); } } Controller上传测试 package com.ccqstark.springbootquick.controller; import com.ccqstark.springbootquick.model.ApiResult; import com.ccqstark.springbootquick.service.CommonService; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.HttpHeaders; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.ResponseEntity; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.multipart.MultipartFile; /** * @Description: 上传文件 * @Author: ccq * @Date: 2020/10/17 */ @Slf4j @RestController @RequestMapping(\u0026#34;/upload\u0026#34;) public class UploadController { @Autowired private CommonService commonService; /** * 上传文件至阿里云 oss * * @param file * @param uploadKey * @return * @throws Exception */ @RequestMapping(value = \u0026#34;/oss\u0026#34;, method = {RequestMethod.POST}, produces = {MediaType.APPLICATION_JSON_VALUE}) public ResponseEntity\u0026lt;?\u0026gt; uploadOSS(@RequestParam(value = \u0026#34;file\u0026#34;) MultipartFile file, String uploadKey) throws Exception { ApiResult apiResult = commonService.uploadOSS(file, uploadKey); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return new ResponseEntity\u0026lt;\u0026gt;(apiResult, headers, HttpStatus.CREATED); } } Postman工具，用POST请求，在form-data中用file字段对应图片或其他类型的文件，然后请求接口\n返回的URL在浏览器中可以用公网访问说明成功了！\n","date":"2020-10-17T10:54:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_oss/","title":"[SpringBoot]使用阿里云OSS上传文件"},{"content":"添加依赖 \u0026lt;!-- druid数据库连接池 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.21\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- MySql数据库驱动 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--分页插件 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.pagehelper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pagehelper-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- log4j日志 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 添加配置 spring:datasource:username:rootpassword:root#serverTimezone=UTC解决时区的报错url:jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf-8driver-class-name:com.mysql.cj.jdbc.Drivertype:com.alibaba.druid.pool.DruidDataSource#Spring Boot 默认是不注入这些属性值的，需要自己绑定#druid 数据源专有配置initialSize:5minIdle:5maxActive:20maxWait:60000timeBetweenEvictionRunsMillis:60000minEvictableIdleTimeMillis:300000validationQuery:SELECT 1 FROM DUALtestWhileIdle:truetestOnBorrow:falsetestOnReturn:falsepoolPreparedStatements:true#配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入#如果允许时报错 java.lang.ClassNotFoundException: org.apache.log4j.Priority#则导入 log4j 依赖即可，Maven 地址：https://mvnrepository.com/artifact/log4j/log4jfilters:stat,wall,log4jmaxPoolPreparedStatementPerConnectionSize:20useGlobalDataSourceStat:trueconnectionProperties:druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500测试 编写测试类\n@SpringBootTest class SpringbootQuickApplicationTests { @Autowired DataSource dataSource; @Test void contextLoads() throws SQLException { System.out.println(dataSource.getClass()); Connection connection = dataSource.getConnection(); System.out.println(connection); connection.close(); } } 运行后控制台出现如下druid连接池相关字样说明成功\n2020-10-15 10:40:34.179 INFO 11352 --- [ main] com.alibaba.druid.pool.DruidDataSource : {dataSource-1} inited\rDEBUG [main] - {conn-10005} pool-connect\rcom.alibaba.druid.proxy.jdbc.ConnectionProxyImpl@31db34da\rDEBUG [main] - {conn-10005} pool-recycle\r添加后台监控 项目应用目录下的cofig目录添加\n@Configuration public class DruidConfig { @ConfigurationProperties(prefix = \u0026#34;spring.datasource\u0026#34;) @Bean public DataSource druidDataSource(){ return new DruidDataSource(); } @Bean // 后台监控  public ServletRegistrationBean statViewServlet(){ ServletRegistrationBean\u0026lt;StatViewServlet\u0026gt; bean = new ServletRegistrationBean\u0026lt;\u0026gt;(new StatViewServlet(),\u0026#34;/druid/*\u0026#34;); // 存储账号密码  HashMap\u0026lt;String,String\u0026gt; initParameters = new HashMap\u0026lt;\u0026gt;(); // 设置后台登录账号密码  initParameters.put(\u0026#34;loginUsername\u0026#34;,\u0026#34;admin\u0026#34;); initParameters.put(\u0026#34;loginPassword\u0026#34;,\u0026#34;123456\u0026#34;); // 谁都可以访问  initParameters.put(\u0026#34;allow\u0026#34;,\u0026#34;\u0026#34;); bean.setInitParameters(initParameters); // 设置初始化参数  return bean; } // filter  public FilterRegistrationBean webStatFilter(){ FilterRegistrationBean bean = new FilterRegistrationBean(); bean.setFilter(new WebStatFilter()); // 被过滤的请求  Map\u0026lt;String,String\u0026gt; initParameters = new HashMap\u0026lt;\u0026gt;(); initParameters.put(\u0026#34;exclusions\u0026#34;,\u0026#34;*.js,*.css,/druid/*\u0026#34;); bean.setInitParameters(initParameters); return bean; } } 运行项目后打开localhost:8080/druid/出现后台监控登录页面说明成功\n","date":"2020-10-17T10:54:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_druid/","title":"[SpringBoot]整合Druid数据源"},{"content":"以我的项目目录结构为例: com.ccqstark.springbootquick\n导入依赖 \u0026lt;!-- springboot的mybatis --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.mybatis.spring.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置 #整合mybatismybatis:type-aliases-package:com.ccqstark.springbootquick.pojomapper-locations:classpath:mybatis/mapper/*.xml编写POJO(用了Lombok) 在com.ccqstark.springbootquick下新建目录pojo，然后新建类User.java，用于存储数据的对象（与数据库中的表对应）\npackage com.ccqstark.springbootquick.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class User { private int id; private String name; private String pwd; } 编写Mapper 在com.ccqstark.springbootquick下新建目录mapper，然后新建UserMapper.java，用于写接口，CRUD函数\npackage com.ccqstark.springbootquick.mapper; import com.ccqstark.springbootquick.pojo.User; import org.apache.ibatis.annotations.Mapper; import org.springframework.stereotype.Repository; import java.util.List; // Mapper注解说明这是一个mybatis的mapper类 //@Mapper //如果有扫描的话这里可以不用写这个注解了 @Repository public interface UserMapper { List\u0026lt;User\u0026gt; queryUserList(); User queryByUserId(int id); int addUser(User user); int updateUser(User user); int deleteUser(int id); } 如果是以扫描的形式，就是在项目的app启动类加上注解**@MapperScan**\n@SpringBootApplication // 也可以用着方式扫描，就不用一个个写@Mapper了 @MapperScan(\u0026#34;com.ccqstark.springbootquick.mapper\u0026#34;) public class SpringbootQuickApplication { public static void main(String[] args) { SpringApplication.run(SpringbootQuickApplication.class, args); } } 在XML里编写SQL语句 在resources目录下新建mybatis/mapper目录，再在下面新建xml文件，如这里的UserMapper.xml，在里面记得配好namespace，然后就可以写自定义SQL语句啦\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE mapper PUBLIC \u0026#34;-//mybatis.org//DTD Mapper 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-mapper.dtd\u0026#34;\u0026gt; \u0026lt;mapper namespace=\u0026#34;com.ccqstark.springbootquick.mapper.UserMapper\u0026#34;\u0026gt; \u0026lt;!-- namespace要配好，如上面的格式，对应源码目录中的mapper接口 --\u0026gt; \u0026lt;!-- 下面就是CRUD的SQL语句 --\u0026gt; \u0026lt;!-- id对应的就是接口定义的函数名 --\u0026gt; \u0026lt;select id=\u0026#34;queryUserList\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; // id对现有 SELECT * FROM user \u0026lt;/select\u0026gt; \u0026lt;!-- #{id}就是模板待填空位--\u0026gt; \u0026lt;select id=\u0026#34;queryByUserId\u0026#34; resultType=\u0026#34;User\u0026#34;\u0026gt; SELECT * FROM user WHERE id = #{id} \u0026lt;/select\u0026gt; \u0026lt;insert id=\u0026#34;addUser\u0026#34; parameterType=\u0026#34;User\u0026#34;\u0026gt; INSERT into user (id,name,pwd) values (#{id},#{name},#{pwd}) \u0026lt;/insert\u0026gt; \u0026lt;update id=\u0026#34;updateUser\u0026#34; parameterType=\u0026#34;User\u0026#34;\u0026gt; UPDATE user SET name=#{name},pwd=#{pwd} where id = #{id} \u0026lt;/update\u0026gt; \u0026lt;delete id=\u0026#34;deleteUser\u0026#34; parameterType=\u0026#34;int\u0026#34;\u0026gt; DELETE FROM user WHERE id = #{id} \u0026lt;/delete\u0026gt; \u0026lt;/mapper\u0026gt; 调用来进行CRUD 在Controller或者Service里调用Mybatis进行CRUD，先@Autowired注入一个Mapper，然后利用这个接口类型指向的对象就可以调用接口里面的方法了。这些方法对应的sql语句操作就是在xml中定义的。\n@RestController @RequestMapping(\u0026#34;/mybatis\u0026#34;) public class UserController { @Autowired private UserMapper userMapper; @PostMapping(\u0026#34;/query\u0026#34;) public List\u0026lt;User\u0026gt; queryUserList(){ List\u0026lt;User\u0026gt; userList = userMapper.queryUserList(); return userList; } @PostMapping(\u0026#34;/create\u0026#34;) public String createUser(){ userMapper.addUser(new User(4,\u0026#34;wuhu\u0026#34;,\u0026#34;5555\u0026#34;)); return \u0026#34;ok\u0026#34;; } @PostMapping(\u0026#34;/update\u0026#34;) public String updateUser(){ userMapper.updateUser(new User(1,\u0026#34;qqq\u0026#34;,\u0026#34;33\u0026#34;)); return \u0026#34;ok\u0026#34;; } @PostMapping(\u0026#34;/delete\u0026#34;) public String deleteUser(){ userMapper.deleteUser(4); return \u0026#34;ok\u0026#34;; } } ","date":"2020-10-17T10:54:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_mybatis/","title":"[SpringBoot]整合Mybatis"},{"content":"导入依赖 \u0026lt;!-- SLF4j - log4j --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.8.0-alpha2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 然后要在IDEA下载插件Maven Helper中把logback相关的包给Exclude，否则会出现冲突\n配置 log4j.properties中配置\n# rootLogger参数分别为：根Logger级别，输出器stdout，输出器log\rlog4j.rootLogger = info,stdout,log\r# 输出信息到控制台\rlog4j.appender.stdout = org.apache.log4j.ConsoleAppender\rlog4j.appender.stdout.layout = org.apache.log4j.PatternLayout\rlog4j.appender.stdout.layout.ConversionPattern = %d [%-5p] %l %rms: %m%n\r# 输出DEBUG级别以上的日志到D://log/debug.log，这个是日志文件存放的路径，根据时间情况进行设置\rlog4j.appender.log = org.apache.log4j.DailyRollingFileAppender\rlog4j.appender.log.DatePattern = '.'yyyy-MM-dd\rlog4j.appender.log.File = D://log/debug.log\rlog4j.appender.log.Encoding = UTF-8\r#log4j.appender.log.Threshold = INFO\rlog4j.appender.log.layout = org.apache.log4j.PatternLayout\rlog4j.appender.log.layout.ConversionPattern = %d [%-5p] (%c.%t): %m%n\r测试 编写测试类，使用@Slf4j注解之前确保使用了lombok\npackage com.ccqstark.springbootquick; import lombok.extern.slf4j.Slf4j; import org.junit.Test; @Slf4j public class LoggerTest { // private static final Logger log = LoggerFactory.getLogger(LoggerTest.class);  @Test public void TestSLF4j(){ log.info(\u0026#34;Current Time: {}\u0026#34;, System.currentTimeMillis()); log.info(\u0026#34;Current Time: \u0026#34; + System.currentTimeMillis()); log.info(\u0026#34;Current Time: {}\u0026#34;, System.currentTimeMillis()); log.trace(\u0026#34;trace log\u0026#34;); log.warn(\u0026#34;warn log\u0026#34;); log.debug(\u0026#34;debug log\u0026#34;); log.info(\u0026#34;info log\u0026#34;); log.error(\u0026#34;error log\u0026#34;); } } 运行后输出以下说明成功\n2020-10-15 16:36:45,459 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:13) 0ms: Current Time: 1602751005450\r2020-10-15 16:36:45,464 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:14) 5ms: Current Time: 1602751005464\r2020-10-15 16:36:45,465 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:15) 6ms: Current Time: 1602751005465\r2020-10-15 16:36:45,466 [WARN ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:17) 7ms: warn log\r2020-10-15 16:36:45,466 [INFO ] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:19) 7ms: info log\r2020-10-15 16:36:45,468 [ERROR] com.ccqstark.springbootquick.LoggerTest.TestSLF4j(LoggerTest.java:20) 9ms: error log\r用法 添加注解@Slf4j（确保使用了lombok）\n然后如测试类中log.info或其他类型的日志便可以使用了\n","date":"2020-10-17T10:54:00+08:00","permalink":"https://ccqstark.github.io/p/springboot_slf4j-log4j/","title":"[SpringBoot]整合SLF4J-log4j"},{"content":"问题引入 学过线性代数都知道矩阵的乘法，比如说矩阵A×B，就是A的每一行上的元素分别和B的每一列上对应位置的元素相乘再总体相加，每次得到一个位置上的元素的值。\n假设A是p × q，B是q × r，那结果矩阵就是p × r，当然，能够相乘的条件是A的列数等于B的行数。\n而A×B总共需要做的乘法数是p × q × r，由矩阵乘法的过程可知。\n可以发现，当至少3个矩阵相乘时，比如ABC，(AB)C和(A)BC两种计算顺序所需做的乘法数是不同的。\n现在的问题是一个矩阵链，比如A × B × C × D × E × F × G，要以什么样的顺序相乘才能得使得所需做的乘法数最小呢？\n题目 输入格式: 每个输入文件为一个测试用例，每个测试用例的第一行给出一个正整数(1≤n≤100)，表示一共有n个矩阵A​1​​ ,A​2​​ ,…,A​n​​ ，第二行给出n+1个整数P​0​​ ,P​1​​ …P​n​​ ，以空格分隔，其中1≤P​i​​ ≤100(0≤i≤n)，第i个矩阵A​i​​ 是阶为P​i−1​​ ∗P​i​​ 的矩阵。\n输出格式: 获得上述矩阵的乘积，所需的最少乘法次数。\n输入样例: 在这里给出一组输入。例如：\n 5\n30 35 15 5 10 20\n 输出样例: 在这里给出相应的输出。例如：\n 11875\n 思路 可以先求2个2个相邻相乘的值，然后用他们求3个3个相乘的，再4个\u0026hellip;依照此规律直到n个\n当前个数阶段也需要把每种划分方案进行尝试，并得出最小的那种。比如我在算4个4个相乘的，那划分位置就有3个，每个都要遍历算一次，最后选最小那个，为下一阶段使用。\n我们利用二维数组m[i][j]表示第i个到第j个矩阵连乘的最优解，有如下公式。\n就是每次划分为2部分，整体最优解=左部分最优解+右部分的最优解+两者相乘所需乘法数\n矩阵i的行数为p[i-1]，列数为p[i]\n \n我们用一个二维矩阵来存储各阶段结果，数据就一步步往右上角填上去，最终答案就在最右上角。\n代码 // 矩阵链相乘问题 #include \u0026lt;iostream\u0026gt;#include \u0026lt;string.h\u0026gt;using namespace std; const int MAX = 1000; int p[MAX]; // 存放行列数，就是题目输入的序列 int m[MAX][MAX]; // 存放局部和最终结果的矩阵 int n; // 需要相乘的矩阵个数  void matrix() { memset(m, 0, sizeof(m)); // 初始化矩阵为0  // 同时连续相乘的个数  for (int r = 2; r \u0026lt;= n; r++) { // 从第几个开始(到第几组了)  for (int i = 1; i \u0026lt;= n - r + 1; i++) { // 相乘链的最后一个  int j = i + r - 1; // 为了通过比较从而得出最小的那个，要有一个比较的初值，这里是划分第一个和其余的为2组  m[i][j] = m[i + 1][j] + p[i - 1] * p[i] * p[j]; // 一步步移动划分点  for (int k = i + 1; k \u0026lt; j; k++) { // 以k位置为划分点，划分i到j的相乘链  int t = m[i][k] + m[k + 1][j] + p[i - 1] * p[k] * p[j]; // 比较找出最小的那个  if (t \u0026lt; m[i][j]) { m[i][j] = t; } } } } } int main() { cin \u0026gt;\u0026gt; n; // 输入的数字总数比矩阵个数多1  for (int i = 0; i \u0026lt; n + 1; i++) { cin \u0026gt;\u0026gt; p[i]; } matrix(); // 最后答案会在右上角出现  cout \u0026lt;\u0026lt; m[1][n]; } 参考博文\n","date":"2020-10-12T21:07:00+08:00","permalink":"https://ccqstark.github.io/p/dp_matrix/","title":"DP动态规划——矩阵链相乘问题"},{"content":"“工欲善其事，必先利其器”，作为后端搬砖工，我们敲代码之前需要给我们的电脑配上所需的软件环境，这样我们写的代码才能跑起来，原地起飞！\n下载集成环境工具 可以选择xampp或phpenv（二选一就行）\nxampp xampp = Apache + MySQL(MariaDB) + PHP + Perl，是一个集成环境软件，装了一个就可以轻松获得服务器，数据库和php语言的环境，轻松快捷而且免费，唯一的缺点可能是因为是外网所以速度稍慢或者可能需要科学上网\n官网下载：https://www.apachefriends.org/zh_cn/index.html\n选择自己的平台，然后点击下载，完成后运行exe\n按普通安装步骤来就好，下面这个界面也默认选择就好，有些环境之后会用到\n \n安装路径建议安装在D盘，然后等待安装完成就可以了，打开软件看到主面板\n \n点击Apache和start按钮，等待图标变绿后再点击admin按钮或者浏览器地址栏输入localhost进行访问\n如果可以看到服务器主页面说明成功\n然后点击MySQL的start和admin，或者地址栏输入localhost/phpmyadmin/\n出现一个登录界面，账号填写root，密码为空不用填，直接点击登录，出现下面画面说明成功\n \nphpEnv 如果xampp实在太慢或者根本无法下载，也可以用phpEnv\n官网下载：https://www.phpenv.cn/\n根据你电脑是64位或者32位进行选择对应版本下载，如果不知道自己电脑是几位的可以点击教程查看\n同样建议放在D盘，其它的默认就行，运行后出现下面界面\n \n点击启动服务上面的图标，再点击打开主页的图标，看到phpEnv的主页面就说明成功了\n页面拉到最下面如下\n \n数据库端口填3306\n用户名填root\n密码也填root（注意：这里和xampp不一样）\n点击连接按钮后再把页面拉到最下面显示连接成功就行啦\n点击顶部菜单栏的开始，再点击phpMyAdmin，然后按上面xampp的对应内容操作就行\n安装IDE IDE(Integrated Development Environment)，集成开发环境，为开发者提供了基本的代码编辑器的同时还提供了许多适用工具，功能强大，是码农开发的利器。\nphp语言我们使用的比较多的是JetBrains公司出的PhpStorm\n官网下载：https://www.jetbrains.com/phpstorm/\n软件体积较大，如果你不想装它的话可以自己下载VSCode然后下载相应插件（自己查）\n由于软件是收费的，但是我们是学生，可以用学校给的邮箱进行学生认证就可以在毕业前都免费使用\n学生认证地址：https://www.jetbrains.com/community/education/#students\n学校邮箱获取方法 进入学校官网，进入智慧广外，\t在个人事务中可以看到自己的邮箱地址，一般是学号@gdufs.edu.cn\n \n下载破解版也可以，但可能比较花时间\n按步骤完成后打开phpstorm，进行下面的配置流程\n1. 新建一个项目  \n2. 选择创建路径 建议把目录建在集成环境指定的网络根目录下，目录路径如下（以安装在D盘为例）：\nxampp：D:\\xampp\\htdocs\nphpEnv：D:\\phpEnv\\www\\localhost\n \n路径最后自定义一个项目名，比如我这里叫test，然后点击creat\n3. 修改运行目录  \n如图打开设置\n \n选择Deployment，点击顶部+号，选择Local or mounted folder\n \nFolder就填写自己安装的集成环境软件的网络根目录\nWeb server URL记得要在最后补上斜杆和当前项目名\n点击右下角的Apply和OK\n4. Hello World!  \n对项目文件夹右键新建一个php文件，自定义命名，然后开始写下第一行php代码吧：\n\u0026lt;?php echo \u0026#34;hello world!\u0026#34;; 鼠标移到右上角选择一个浏览器运行，或者右键并选择run，或者快捷键Ctrl+Shift+F10\n \n如果出现了提醒你选择php解释器的情况\n \n就选择一个已有的版本就行，在settings -\u0026gt; Languages\u0026amp;Frameworks -\u0026gt; PHP也可以设置\n点击运行后出现\n \n或者是\n \n大功告成！现在可以愉快地敲代码了！\n当然，这是为了方便本地开发而安装的集成环境，有兴趣的小朋友可以自己尝试分别安装每个环境或者在Linux上进行编译安装\nPHPer现在可以带着世界上最好的语言开冲了！\n \n","date":"2020-10-10T11:39:00+08:00","image":"https://ccqstark.github.io/p/php_env/php_hu30aa9710d612d752c63ae5cdcfcf5665_61468_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/php_env/","title":"php后台开发基础环境搭建教程"},{"content":"基本操作 下载hugo 首先要有Golang的环境\n然后在GitHub上选择对应平台下载\nhttps://github.com/gohugoio/hugo/releases\nWindows下载完要设置环境变量\n创建新的站点 hugo new site \u0026lt;path\u0026gt; \n在指定路径下创建博客站点目录，目录最后是博客站点名\n找到心仪主题 在下面这个网站上找到喜欢的主题，按照各自的文档进行设置\nhttps://themes.gohugo.io/\n本地预览 hugo server -t \u0026lt;theme\u0026gt; --buildDrafts\n\u0026lt;theme\u0026gt;的位置填写主题的名称\n创建博客 hugo new post/blog.md\n博客的markdown文件一开始都是放在\\content\\post目录下\n创建GitHub/Gitee仓库 Github把仓库命名为\u0026lt;name\u0026gt;.github.io即可开启博客托管服务\nGitee直接命名为自己的用户名，一字不差，同时需要手动开启Gitee Page服务\n部署到远端仓库  生成\\public目录  hugo --theme=hugo-theme-stack --baseUrl=\u0026quot;https://ccqstark.github.io/\u0026quot; --buildDrafts\n根据具体仓库修改，也可以是\u0026quot;https://ccqstark.gitee.io/\u0026quot; 然后cd进public目录 在这个目录下创建git仓库，部署也是部署这个目录中的内容\n 三部曲  git add . git commit -m \u0026#39;...\u0026#39; git push github master 更新博客 要新增一篇博客就继续按下面这个步骤走\nhugo new post/name.md hugo --theme=hugo-theme-stack --baseUrl=\u0026#34;https://ccqstark.github.io/\u0026#34; --buildDrafts cd public git add . git commit -m \u0026#39;...\u0026#39; git push github master 如果只是更新就重新运行生成\\public目录的命令，再重新部署即可\n主题Stack配置 此博客的主题用的是Stack，下面是主题地址，可以找到文档和Demo\nhttps://themes.gohugo.io/hugo-theme-stack/\nicon设置 使用.ico文件类型的图标，并将其放置在\\public目录下\n\\layouts\\partials\\head下新建一个custom.html，写上\n\u0026lt;link rel=\u0026#34;shortcut icon\u0026#34; href=\u0026#34;https://ccqstark.github.io/icon.ico\u0026#34;/\u0026gt; 为了访问稳定也可以改为gitee\n文章外部展示图 在\\content\\post目录下创建博客时，先创建博客标题命名的文件夹，再在其下创建md文件index.md\n图片也是放在其下，在md文件开头的设置中添加image: \u0026quot;image.jpg\u0026quot;即可\nTags和分类 文章开头设置\ntags: - Spring categories: - Tech 一个是打标签，一个是分类\nAbout和Archives 在\\content\\page目录下创建about.md和archives.md\nabout.md用于写个人信息页面，需要文章顶部的设置写法改为字段加冒号的形式，配置slug为about\narchives.md用于分类和归档页面，用exampleSite的就行，不用做任何修改\nCategories 在\\content\\categories目录下创建以各分类命名的文件夹\n各分类的文件夹下放置_index.md和分类的展示图\n_index.md中的内容就是普通文章顶部的配置项，注意图片名配置对了就行\n","date":"2020-10-04T02:44:33+08:00","image":"https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/hugo_hu8b6407a07803ab5ecf8133363f04b00e_28892_120x120_fill_box_smart1_2.png","permalink":"https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","title":"使用Hugo+github/gitee搭建个人博客"}]