<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on ccq&#39;s blog</title>
    <link>https://ccqstark.github.io/post/</link>
    <description>Recent content in Posts on ccq&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 15 Jan 2022 17:13:23 +0800</lastBuildDate><atom:link href="https://ccqstark.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[并发编程]AQS源码分析</title>
      <link>https://ccqstark.github.io/p/aqs/</link>
      <pubDate>Sat, 15 Jan 2022 17:13:23 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/aqs/</guid>
      <description>简介 AQS（Abstract Queue Synchronizer）在java.util.concurrent.locks包下面，是一个用来构建锁和同步器的框架，使用AQS可以简单高效地构造出大量应用广泛的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于 AQS 的。当然，我们自己也能利用 AQS 非常轻松容易地构造出符合我们自己需求的同步器。
基本原理   AQS内部维护了一个FIFO的CLH队列，用来对获取资源线程的阻塞和排队。 还使用一个 int 成员变量state来表示同步状态，AQS 使用 CAS 对该同步状态进行原子操作实现对其值的修改。
private volatile int state; // 共享变量，使用volatile修饰保证线程可见性 状态信息通过 protected 类型的getState()，setState()，compareAndSetState() 进行操作。 不同的自定义同步器争用共享资源的方式也不同，实际上就是对共享资源state的获取与释放方式进行不同的实现，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法：
  tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
  tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
  tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
  tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 AQS使用了模板方法的设计模式，用户实现自己的同步组件的时候只需要重写以上几个方法，实现自己对state操作的逻辑，然后这些子类重写的方法就会被AQS顶层的一些方法调用去实现线程排队阻塞唤醒等具体操作。
实现例子     ReentrantLock：state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。
  CountDownLatch：任务分为N个子线程去执行，state也初始化为N，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会唤醒主调用线程，然后主调用线程就会从await()函数返回，继续后续动作。
锁的分类    独占锁：也就是同一时刻只允许一个线程访问资源，类似写锁。 共享锁：允许多个线程同时访问一个资源，类似读锁。  Node节点状态  CANCELLED(1)：表示当前结点已取消调度。当timeout或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。 SIGNAL(-1)：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为SIGNAL。 CONDITION(-2)：表示结点等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。（使用到Condition时才有等待队列的概念，原本的CLH队列是同步队列） PROPAGATE(-3)：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。共享式同步状态获取将会无条件传播下去。 初始值(0)：新结点入队时的默认状态。   负值表示结点处于有效等待状态，而正值表示结点已被取消。所以源码中很多地方用&amp;gt;0、&amp;lt;0来判断结点的状态是否正常。</description>
    </item>
    
    <item>
      <title>ConcurrentHashMap源码分析</title>
      <link>https://ccqstark.github.io/p/concurrenthashmap/</link>
      <pubDate>Mon, 03 Jan 2022 02:15:23 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/concurrenthashmap/</guid>
      <description>前言 上篇分析完HashMap之后，这次来分析下ConcurrentHashMap这个并发条件下线程安全的HashMap又有哪些精妙绝伦、惊为天人的设计呢🤔
 本文同样主要分析JDK1.8版本的ConcurrentHashMap
 sizeCtl的作用 这个变量的作用比较复杂，起到标识位作用的同时也可以记录阈值等实际意义，主要有以下几种情况
   sizeCtl值的情况 意义     0 代表数组未初始化，且数组的初始容量为16   正数 如果数组未初始化，那么其记录的是数组的初始容量；如果数组已经初始化，那么其记录的就是i扩容阈值（数组的初始容量*0.75）   -1 表示数组正在进行初始化   负数且不是-1 表示数组正在扩容，高16位是扩容标识戳，低16位是扩容线程数+1    扰动函数 static final int spread(int h) { // HASH_BITS（01111111111111111111111111111111）保证hash值一定是为正数，因为符号位为0  // 高低位去异或运算，这里和HashMap的类似，让高位参与运算是为了哈希得更均匀  return (h ^ (h &amp;gt;&amp;gt;&amp;gt; 16)) &amp;amp; HASH_BITS; } table数组的初始化 private final Node&amp;lt;K,V&amp;gt;[] initTable() { Node&amp;lt;K,V&amp;gt;[] tab; int sc; while ((tab = table) == null || tab.</description>
    </item>
    
    <item>
      <title>HashMap源码与扩容机制分析</title>
      <link>https://ccqstark.github.io/p/hashmap/</link>
      <pubDate>Sat, 01 Jan 2022 13:58:40 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/hashmap/</guid>
      <description>本文主要针对JDK1.8进行分析
 四个构造方法 // 默认构造函数。 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // 其他字段都是默认值 } // 包含另一个“Map”的构造函数 public HashMap(Map&amp;lt;? extends K, ? extends V&amp;gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } // 指定“容量大小”的构造函数 public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } // 指定“容量大小”和“加载因子”的构造函数 public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &amp;lt; 0) throw new IllegalArgumentException(&amp;#34;Illegal initial capacity: &amp;#34; + initialCapacity); if (initialCapacity &amp;gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &amp;lt;= 0 || Float.</description>
    </item>
    
    <item>
      <title>红黑树，这次终于拿下了</title>
      <link>https://ccqstark.github.io/p/red_black_tree/</link>
      <pubDate>Thu, 30 Dec 2021 00:52:42 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/red_black_tree/</guid>
      <description>前言 由于最近在看Java的容器，看到HashMap，发现它底层有用到红黑树，想起了一些段子以及很久之前曾经挑战过学习它但是没有成功，于是这次打算再次挑战一波，并写成博客。
应用场景  JDK的HashMap、TreeMap和TreeSet Linux内核的虚拟内存管理 Nginx的Timer管理 C++的STL  可以看到在实际工程场景中还是用得很多的一种数据结构的。
五大基本性质 首先红黑树是一颗二叉搜索树，然后再加上下面五大性质：
 节点有红色和黑色两种 根节点一定是黑色的 叶子节点（nil节点）都是黑色的 不能有连续的红色节点 任意节点到叶子节点所经过的黑色节点数相同   第5点就是红黑树维持平衡的重要条件，我们常说的达到黑色平衡或者红黑树达到平衡主要说的就是达到这个条件。
 如果精力充足的话建议可以再去了解一下2-3-4树，红黑树就是对概念模型2-3-4树的一种实现，这里推荐我当时看的敖丙写的一篇文章，介绍了2-3-4树的概念及其与红黑树的转化，最后介绍了红黑树的简化版——左倾红黑树的插入与删除。
本质与意义 这一部分要说的就是面试经常问的：为什么有了二查找查找树/平衡树还需要红黑树？
二叉查找树的缺点 二叉查找树大家应该很熟悉，特点就是左子树的节点都比父节点小，而右子树的节点值都比父节点大。基于这个特点，我们在二叉查找树查找某一个值时，采用类似二分查找的思想，时间复杂度只用O(logn)。
但是这是正常情况下，因为二叉查找树有可能出现一种极端，就是所有节点都同一方向上（如下图），这个时候二叉搜索树以及近似退化为一条链表了，查找的时间复杂度也顿时变成了O(n) ，那这样的话二叉搜索树也就失去了原本的意义——让搜索变得更快。
 
为了解决这个问题，出现了平衡二叉搜索树（也就是我们常说的AVL树）。
AVL树 为了解决二叉搜索树可能退化为链表的问题而生，有以下特点：
 拥有二叉树的全部特性 每个节点的左子树和右子树的高度差不超过1  由于第二点的约束使得AVL树不会出现大量节点一边倒的情况，但是在AVL树构建的过程中就需要很多额外的操作来保证其符合这个特性，使得其最坏情况下查找的时间复杂度也还是为O(logn)
为什么有了AVL树还要红黑树？ 虽然AVL树解决了二叉搜索树退化了近似链表的缺点，但是由于每个节点的左子树和右子树的高度差不超过1这个要求实在是太严苛了，导致每次插入和删除节点的时候很容易就破坏了这条规则，之后就需要左大量的左旋和右旋来进行调整时期再次符合AVL树的要求。
所以如果在插入和删除很频繁的场景中，AVL树需要很频繁地进行调整，这样的话效率就大大降低了，为了解决这个问题所以出现了红黑树。（如果在面试中接下来这里就可以说出红黑树的那5个特点）。
正由于红黑树的这些特点，使其最坏情况下不仅还能维持用O(logn)的时间复杂度找到某个节点，而且与AVL树相比，优势就在于不会那么频繁地破坏红黑树的规则，从而不用那么频繁地进行调整，这就是我们大多数情况下使用红黑树的原因。
所以红黑树是一种相对AVL树来说不那么严格的平衡树，也就是一种折中的方案，介于普通的二叉搜索树和AVL树之间。极端情况下左右子树的节点数（也就是深度）相差一倍，也就是左边都有黑节点，右边都是红黑相间，右子树的节点数或者说深度就也是左子树的2倍，这个要求就比AVL树的相差最多只能为1宽松多了，因此调整也就更少，效率也就更高。
为什么红黑树查找的时间复杂度还能维持在O(logn)？ 我们对最坏情况下的时间复杂度进行计算。
最坏情况下就是上面说的红黑相间，总节点数=红节点数+黑节点数，红黑节点数一致。
$$n = n_r + n_b$$
所以时间复杂度就是
$$O(2* \log n_b ) = O(2 * \log \frac{n}{2})$$
常数2直接去掉
$$O(\log \frac{n}{2}) = O(\log n - 1)$$</description>
    </item>
    
    <item>
      <title>[并发编程]volatile篇</title>
      <link>https://ccqstark.github.io/p/concurrent_volatile/</link>
      <pubDate>Sun, 12 Dec 2021 22:38:19 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/concurrent_volatile/</guid>
      <description>volatile简介 synchronized在锁竞争激烈的情况下会升级为重量级锁，而volatile是Java虚拟机提供的另一种轻量的同步机制。它会将共享变量从主内存中拷贝到线程自己的工作内存中，然后基于工作内存中的数据进行操作处理。而被volatile修饰的变量经过Java虚拟机的特殊约定，使一个线程对其的修改会立刻被其他线程所感知，就不会出现脏读的现象，从而保证数据的“可见性”。
相关概念 内存可见性 由于JMM（Java内存模型）是让线程在工作时把共享变量的副本拷贝到线程的本地内存，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它自己的拷贝副本值，造成数据的不一致。
 
内存可见性，指的是线程之间的可见性，当一个线程修改了共享变量时，另一个线程可以读取到这个修改后的值。
重排序 为了优化程序的性能，对原有的指令顺序进行重新排序。也就是说在指令层面，执行不一定是按原本顺序一条条执行的。重排序可能发生在多个阶段，比如编译重排序、CPU重排序等。
happens-before规则 happens-before规则是JVM对程序员作出的一个承诺，它保证指令在多线程之间的顺序性符合程序员的预期，但是实际的代码执行顺序可能是经过重排序的，也就是说JVM保证结果的正确性，实际优化实现则对程序员透明。
volatile的两个主要功能  保证变量的内存可见性 禁止volatile变量与普通变量重排序  保证可见性的原理（内存语义） 上面说到线程会把共享变量复制一份到自己线程的工作内存进行计算操作，之后再在某个时机写回主内存中，而volatile保证的可见性就是通过通知另外的线程说它拷贝的值是旧的，需要去主内存中去重新读最新的，具体操作如下：
在生成汇编代码时会在volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令，这个Lock前缀的指令在多核处理器下主要有两方面影响：
 将当前处理器缓存（即CPU缓存，如L1，L2）的数据写回系统内存 这个写回内存的操作回使得其他CPU里缓存来该内存地址的数据无效  在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，之后需要对此变量进行操作的时候需要去主存中读取最新值。
所以volatile可以保证被修饰的变量可以让每个线程都获取它的最新值，也就是保证了可见性。
阻止重排序的原理 阻止重排序主要靠的是内存屏障 的策略：
 在每个volatile写操作前插入一个StoreStore屏障； 在每个volatile写操作后插入一个StoreLoad屏障； 在每个volatile读操作后插入一个LoadLoad屏障； 在每个volatile读操作后再插入一个LoadStore屏障。   
volatile与普通变量的重排序规则:
 如果第一个操作是volatile读，那无论第二个操作是什么，都不能重排序； 如果第二个操作是volatile写，那无论第一个操作是什么，都不能重排序； 如果第一个操作是volatile写，第二个操作是volatile读，那不能重排序。  理解：
 volatile读就是让当前缓存行的数据失效，重新去主存中读取变量 volatile写就是把当前线程缓存行的变量刷到主存中让别的线程可以读到这个最新的，保证可见性   如果第一个操作是volatile 读，第二个是另外一种操作还进行重排序的话，那肯定不行，因为先volatile读就是为了保证后面的操作拿到的数值是最新的。 如果第二个操作是volatile写，第一个是另外一种操作还进行重排序的话，那肯定也不行，因为我们要保证valatile写更新到主存中的数据是最新的。 第三个很好理解，先把最新数据更新到主存，再去主存中读才能读到最新的。  并发编程的三个重要特性  原子性 : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么都不执行。synchronized 可以保证代码片段的原子性。 可见性 ：当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。 有序性 ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。  </description>
    </item>
    
    <item>
      <title>[并发编程]Synchronized优化篇——Java中的各种锁</title>
      <link>https://ccqstark.github.io/p/concurrent_synchronized_optimization/</link>
      <pubDate>Sat, 11 Dec 2021 17:09:24 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/concurrent_synchronized_optimization/</guid>
      <description>synchronized在JDK1.6之后官方对其进行优化，先要了解CAS和Java对象头，再去学习锁的四种状态：无锁、偏向锁、轻量级锁、重量级锁。这篇文章参考了多方资料，算是总结得比较全面，希望可以帮到你。
CAS CAS操作（又称为无锁操作）是一种乐观锁策略，它假设所有线程访问共享资源的时候不会出现冲突。CAS就是compare and swap ，通过比较内存中当前的值等不等于预期值，如果等于就可以赋值成功，如果不等于说明这个值被修改过了不再是预期的旧值。
当多个线程使用CAS操作一个变量的时候，只有一个线程会成功，其他的会因为冲突失败，失败后一般就会自旋重试，多次失败后选择挂起线程。
CAS实现需要硬件指令集的支撑，在JDK1.5后虚拟机才可以使用处理器提供的CMPXCHG 指令实现。
synchronized和CAS的区别 未优化的Synchronized最主要的问题是：当存在线程竞争的情况下会出现线程阻塞和唤醒带来的开销问题，这是一种阻塞同步（互斥同步）。而CAS不是直接就把线程挂起，在CAS操作失败后会进行一定的重试，而非直接进行耗时的挂起和唤醒等操作，因此叫做非阻塞同步。
CAS存在的问题   ABA问题
因为CAS会检测旧的值有没有发生变化，但是假如一个值从A变成了B，然后又变成了A，刚好CAS在检查的时候发现旧值A没有发生变化，但是实际上是发生了变化的。解决办法是添加一个版本号，Java在1.5后的atomic包中提供了AtomicStampedReference来解决ABA问题，思路也是这样的。
  自旋时间过长
CAS是非阻塞同步，会自选（死循环）进行下一次尝试，如果自旋时间过长的话对性能又很大影响。
  只能保证一个共享变量的原子操作
当CAS对一个变量进行操作时可以保证其原子性，如果对多个变量进行操作就不能保证其原子性，解决办法就是利用对象去整合多个共享变量，然后对整个对象进行CAS操作就可以保证原子性来。atomic包提供来AtomicReference来保证引用对象之间的原子性。
  Java对象头 Java的锁是基于对象的，而不是基于线程的（所以wait、notify等方法是Object中的不是Thread中的），那锁的存放自然是在对象中，存储在Java的对象头中。
1字宽在32位处理器中是32位，64位中是64。每个对象都有对象头，非数组类型长度是2个字宽，数组是3个。
   长度 内容 说明     1字宽 Mark Word 存储对象的hashCode、分代信息、锁信息等   1字宽 Class Metadata Address 存储到对象类型数据的指针   1字宽 Array length 数组的长度（如果是数组）    Mark Word的格式：
   锁状态 29 bit 或 61 bit 1 bit 是否是偏向锁？ 2 bit 锁标志位     无锁  0 01   偏向锁 线程ID 1 01   轻量级锁 指向栈中锁记录的指针 此时这一位不用于标识偏向锁 00   重量级锁 指向互斥量（重量级锁）的指针 此时这一位不用于标识偏向锁 10   GC标记  此时这一位不用于标识偏向锁 11    当对象状态为偏向锁时，Mark Word存储的是偏向的线程ID；</description>
    </item>
    
    <item>
      <title>[并发编程]ReentrantLock篇</title>
      <link>https://ccqstark.github.io/p/concurrent_reentrantlock/</link>
      <pubDate>Sat, 11 Dec 2021 17:05:58 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/concurrent_reentrantlock/</guid>
      <description>基本介绍 对于ReentrantLock（重入锁），是常用的Lock接口的一个实现，最主要的是了解他的重入性和公平锁/非公平锁，还有用他于synchronized机械能对比，下面进行具体介绍。
重入性实现原理 重入性有2个基本特点：
 在线程获取锁的时候，如果锁已经存在且锁还是当前线程的，那可以直接再次获取成功 由于锁可以被同一线程获取n次，在释放时同样要释放n次才能把锁完全释放开。  许多同步组件都是通过重写AQS的方法来实现自己的同步功能的，下面以ReentrantLock的非公平锁的源码来解析其重入的实现。核心方法nonfairTryAcquire ：
final boolean nonfairTryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); //1. 如果该锁未被任何线程占有，该锁能被当前线程获取  if (c == 0) { if (compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } //2.若被占有，检查占有线程是否是当前线程  else if (current == getExclusiveOwnerThread()) { // 3. 再次获取，计数加一  int nextc = c + acquires; if (nextc &amp;lt; 0) // overflow  throw new Error(&amp;#34;Maximum lock count exceeded&amp;#34;); setState(nextc); return true; } return false; } 首先是判断当前是否存在锁，如果不存在，那自然可以获取。</description>
    </item>
    
    <item>
      <title>[并发编程]synchronized篇</title>
      <link>https://ccqstark.github.io/p/concurrent_synchronized/</link>
      <pubDate>Sat, 11 Dec 2021 16:56:15 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/concurrent_synchronized/</guid>
      <description>说一说你对synchronized的理解？ synchronized关键字用于解决多个线程访问临界资源的同步问题，它可以保证同一时刻只有一个线程在操作一个临界资源。
在Java的早期版本synchronized属于重量级锁，效率低下。因为监视器锁（monitor）是以来于操作系统底层的Mutex Lock来实现的，Java的线程映射到操作系统的原生线程上，要挂起或者唤醒一个线程实现线程的切换，都需要涉及到操作系统的用户态和内核态的转换，开销比较大。
但是在Java6之后，Java官方在JVM层面对synchronized进行来优化，JDK1.6实现来自旋锁、自适应自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等减少来锁的开销。
说说synchronized怎么使用的？  加在实例方法上，获取的是当前对象实例的锁 加在静态方法上，获取的是class的锁，不会与实例对象上的锁冲突 加载某一代码块上，可以this来表示要获得当前对象的锁，也可以写类.class表示获取类的锁  使用synchronized实现双重检验锁方法写的单例模式 保证了线程安全
// 单例：双重校验锁 public class Singleton { private volatile static Singleton instance; private Singleton() { } public static Singleton getUniqueInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } } 为什么要加双重锁呢，因为instance = new Singleton(); 这段代码其实是分三步执行的：
 为instance分配空间 初始化instance 将instance指向分配的内存地址  但是由于JVM有指令重排的特性，执行循序又可能变成1→3→2，多线程环境下有可能导致一个线程获得一个还没有初始化的实例。比如线程A执行了1和3，此时线程B调用getUniqueInstance()后发现instance不为空，但是得到的instance此时还未被初始化。
使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。</description>
    </item>
    
    <item>
      <title>[并发编程]基础篇</title>
      <link>https://ccqstark.github.io/p/concurrent_basic/</link>
      <pubDate>Sun, 05 Dec 2021 20:20:47 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/concurrent_basic/</guid>
      <description>什么是进程？什么是线程？ 进程是程序的一次执行过程，是系统运行程序的基本单位，进程是一个系统对一个程序从创建，运行到消亡的过程。
在Java中，我们启动main函数就是启动了一个JVM的进程，main函数所在线程就是这个进程中的主线程。
线程是程序的一个更小的执行单位，一个进程在执行过程中可以产生多个线程。不同在与，同类的多个线程可以共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，系统在线程之间切换的代价要比进程小得多。
请简要描述线程与进程的关系,区别及优缺点？ 从JVM的角度说明
 
一个进程中包括多个线程，线程可以共享进程的堆和方法区，但是每个线程都有自己的虚拟机栈，本地方法栈，程序计数器
线程是进程划分成的更小的运行单位，区别在与进程基本上是各自独立的，而同一进程的不同线程则可能会相互影响。线程开销更小，但是不利于资源的管理和保护；进程则相反。
程序计数器为什么是私有的？ 程序计数器主要作用：
 字节码解释器通过改变程序计数器的位置来读取指令，从而实现代码的流程控制。如：顺序执行、选择、循环、异常处理。 多线程环境下，程序计数器用于记录当前程序的运行到的位置，当从别的线程切换回来的时候才能从上次运行到的位置继续运行。  所以程序计数器私有主要是为了线程切换回来后，能从原来停止的位置正确恢复运行。
虚拟机栈和本地方法栈为什么是私有的?  虚拟机栈：每个Java方法在执行的同时会创建一个栈帧用于存储局部变量表、函数返回地址和参数、划定栈帧范围的ebp和esp指针等信息。一个方法从被调用到执行完成，就对应着一个栈帧在Java虚拟机中入栈和出栈的过程。 本地方法栈：和虚拟机栈作用差不多，区别在与虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为Native方法用的。在HotSpot虚拟机中两者合二为一。  所以为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈就是线程私有的。
简单介绍下堆和方法区 堆和方法区都是线程共享的资源。
堆是进程中最大的一块内存，主要用于存放新创建的对象，几乎所有的对象都在这里分配内存。
方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。
说说并发和并行的区别？  并行：在单位时间内多个任务同时进程，一般在是多核CPU上出现， 并发：在同一段时间内，多个任务由CPU切换着处理，在某一瞬间是不一定同时处理多个任务的。例外就是当我们CPU使用了因特尔的超线程技术，一个内核被虚拟成2个逻辑内核，当两个任务分别用到CPU的不同运算资源时，比如一个任务计算整数另一个计算浮点数，这个时候就又可能是真的同时进行的。  为什么要使用多线程？ 从总体上说：
 从计算机底层的角度，线程是轻量级的进程，是程序执行的最小单位，线程切换的开销要远小于进程的切换，另外多核CPU时代意味着多个线程可以同时运行，再次减少了开销。 从当代互联网的发展趋势角度：现在的系统基本上就动辄百万千万级的并发，多线程技术就是高并发系统的基础，可以大大提高系统整体的性能和并发能力。  从计算机底层来说：
 单核时代：如果我们只有一个线程，那请求进程IO就会阻塞我们整个进程，而CPU就会被闲置了，如果由多个线程，那我们可以在一个线程被IO阻塞的时候，用另一个线程继续使用CPU的运算能力，提高系统整体的资源利用效率。 多核时代：如果有多个核心，那多个线程可以映射不同核心上并行执行，在没发生资源争抢的情况下执行效率就会显著提高。  使用多线程可能会带来什么问题？  内存泄漏：ThreadLocal就可能会导致内存泄漏 死锁：两个线程互相占用对方需要的资源并互相等待其释放 线程不安全：多线程访问并修改临界资源  说说线程的生命周期和状态？    状态名称 说明     NEW 初始状态，线程被构建，但是还没有调用start()方法   RUNNABLE 运行状态，Java线程将操作系统中的就绪和运行   BLOCKED 阻塞状态，表示线程阻塞于锁   WAITING 等待状态，表示线程进入等待状态，进入该状态表示当前线程需要等待其它线程作出一些特定动作（通知或中断）   TIME_WAITING 超时等待状态，该状态不同于WAITING，它是可以在指定的时间自行返回的   TERMINATED 终止状态，表示当前线程已经执行完毕    线程随着代码的执行在不同状态之间切换，Java线程状态变迁如下所示：</description>
    </item>
    
    <item>
      <title>关于CORS的Access-Control-Allow-Credentials设置问题</title>
      <link>https://ccqstark.github.io/p/cors_credentials/</link>
      <pubDate>Thu, 02 Dec 2021 18:31:11 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/cors_credentials/</guid>
      <description>前言 众所周知，跨域设置CORS的话我们需要设置Access-Control-Allow-Origin、Access-Control-Allow-Methods 等header，但是我们的Access-Control-Allow-Origin 只能设置为三种情况：
 星号 * 单域名 none  同时还有一个限制就是设置为星号的时候，Access-Control-Allow-Credentials 不能设置为true，下面来自MDN：
 对于附带身份凭证的请求，服务器不得设置 Access-Control-Allow-Origin 的值为“*”。这是因为请求的首部中携带了 Cookie 信息，如果 Access-Control-Allow-Origin 的值为“*”，请求将会失败。
 而Access-Control-Allow-Credentials 则一般是服务器用来设置是否允许前端携带Cookies的标志位，withCredentials 是前端用来表示是否给服务器发请求的时候带上Cookies的标志位：
 将 [XMLHttpRequest](https://developer.mozilla.org/en-US/DOM/XMLHttpRequest)的 withCredentials 标志设置为 true，从而向服务器发送 Cookies。因为这是一个简单 GET 请求，所以浏览器不会对其发起“预检请求”。但是，如果服务器端的响应中未携带 Access-Control-Allow-Credentials: true ，浏览器将不会把响应内容返回给请求的发送者。
 基于以上的规则，如果我们需要发Cookies的话，前端withCredentials 和后端的Access-Control-Allow-Credentials 都要设置为true，同时Access-Control-Allow-Origin 不能设置为星号，只能设置为单域名。
问题 但是在我看一个开源项目源码的时候，看到它CORS的地方：
@Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&amp;#34;/**&amp;#34;).allowedOrigins(&amp;#34;*&amp;#34;) .allowedMethods(&amp;#34;GET&amp;#34;, &amp;#34;HEAD&amp;#34;, &amp;#34;POST&amp;#34;, &amp;#34;PUT&amp;#34;, &amp;#34;DELETE&amp;#34;, &amp;#34;OPTIONS&amp;#34;) .allowCredentials(true).maxAge(3600); } 出现了疑惑，为什么它同时设为星号同时设置了true但是仍然请求正常呢？
打开了F12看响应的header，发现Access-Control-Allow-Origin 是前端的地址，不是设置了星号吗，怎么变成单origin了？然后把allowCredentials方法里传个false，发现请求就异常了，开始搞不懂了，因为这个项目其实也没有用到cookies呀，只用了token，token也是放在header里的。
探究 然后只能猜测是Spring MVC帮我们做了这一切，就去扒源码了，果然扒到了！
在org.springframework.web.cors 下的CorsConfiguration 类，有这么一个checkOrigin方法：
@Nullable public String checkOrigin(@Nullable String requestOrigin) { if (!</description>
    </item>
    
    <item>
      <title>Java单元测试利器——Mockito</title>
      <link>https://ccqstark.github.io/p/mockito/</link>
      <pubDate>Mon, 30 Aug 2021 12:34:20 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/mockito/</guid>
      <description>Mock介绍 基本介绍 为了提高代码质量，除了做静态代码测试，动态的单元测试也少不了。而在单元测试过程中，Mock是少不了的技术。
Mock是允许用模拟对象替换测试中的系统部件，并断言它们是如何被使用的一项技术。
Mock的作用如下  解决依赖问题：当测试一个接口或者功能模块的时候，如果这个接口或者功能模块依赖其他接口或其他模块，那么如果所依赖的接口或功能模块未开发完毕，那么我们就可以使用Mock模拟被依赖接口，完成目标接口的测试。 单元测试：如果某个功能未开发完成，又要进行测试用例的代码编写，也可以先模拟这个功能进行测试。 模拟复杂业务的接口：实际工作中如果我们在测试一个接口功能时，如果这个接口依赖一个非常复杂的接口业务或者来源于第三方接口（如第三方支付接口），那么我们完全可以使用Mock来模拟这个复杂的业务接口，其实这个和解决接口依赖是一样的原理。 前后端联调：进行前后端分离编程时，如果进行一个前端页面开发，需要根据后合返回的状态展示不同的页面，那么就需要调用后合的接口，但是后合接口还未开发完成，完全可以借助mock来模拟后台这个接口返回想要的数据。  Mock与Stub(桩)  桩代码(Stub)：用来代替真实代码的临时代码，主要作用是使被测代码能够独立编译、 链接，并独立运行 Mock代码：也是用来代替真实代码的临时代码，起到隔离和补齐的作用，但是它还可深入的模拟对象之间的交互方式，可以对结果进行验证  Mockito测试框架 Mockito是Java单元测试中使用率最高的Mock框架之一，同时也是SpringBoot默认引入的mock框架(spring-boot-starter-test包括JUnit, Hamcrest 和 Mockito)
Maven依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.mockito&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mockito-core&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.12.4&amp;lt;/version&amp;gt; &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt; 验证某些行为是否被调用 Mockito可以验证某些行为：一旦mock对象被创建了，mock对象会记住所有的交互
使用方法verify() 判断方法是否被调用过
@Test void verifyTest(){ Person mockPerson = Mockito.mock(Person.class); mockPerson.setId(1); Mockito.verify(mockPerson).setId(1); Mockito.verify(mockPerson).setName(&amp;#34;cc&amp;#34;); // 此方法没有调用过，所以会报错 } 测试桩Stub Mockito可以做一些测试桩（Stub），做测试桩的目的是为了在某些方法还没有开发出来，但我们测试时却需要调用它的时候，给这个方法模拟一个假的返回值供我们测试用。
默认情况下，所有函数都有返回值。mock函数默认返回的是null，一个空的集合或者一个被对象类型包装的内置类型。
当我们要指定某的函数的返回值时，可以使用when() 和 ThenReturn() 、ThenThrow() 方法
之后调用这些函数时，就会返回我们上面指定的值（注意返回类型也要正确）
@Test void stubTest(){ Person mockPerson = Mockito.mock(Person.class); Mockito.when(mockPerson.getId()).thenReturn(1); Mockito.when(mockPerson.getName()).thenThrow(new NoSuchMethodError()); System.out.println(mockPerson.getId()); // 返回1  System.out.println(mockPerson.getName()); // 抛出异常NoSuchMethodError } 一个方法可能多次调用，想要每次调用都设置对应返回值也是可以的</description>
    </item>
    
    <item>
      <title>Redis布隆过滤器与点赞功能设计</title>
      <link>https://ccqstark.github.io/p/bloom_filter/</link>
      <pubDate>Thu, 26 Aug 2021 03:57:56 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/bloom_filter/</guid>
      <description>什么是布隆过滤器 简介 布隆过滤器（Bloom Filter）是 1970 年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。
具体实现原理  
如上图所示，布隆过滤器的原理就是通过几个哈希函数把要存储的数据映射到一个二进制的数组里，映射到的对应位标为1，如上图就为（2，5，9）。后续有元素加入时，若该位本就为1，则不对该位再做处理。
当要判断一个元素是否在过滤器中，也是先进行Hash计算出对应的位，判断二进制数组中所有对应的位是否都为1，是的话表示元素在其中；反之不在。
存在的问题 布隆过滤器存在误判率，也是可能会把一个不存在的元素判定为存在的。因为在加入大量元素后，二进制数组中可能大部分位都被置为1了，所以一个新的数据Hash出来对应的位就很可能也都置为1了。
解决办法就是增加二进制数组的长度，使得二进制数组不那么快饱和，就可以容纳更多的元素，降低误判概率；或者增加Hash次数，使得数据更加分散。
所以但布隆过滤器判断一个元素存在时，可能不一定真的存在；但假如它判断一个元素不存在，那这个元素一定不存在，这种情况不存在误判。
还有一个问题是删除困难，因为在元素较多的情况下它们对应的位总有交叉，如果你把其中一个元素对应的位都置0了，那很可能也会影响到其他的元素，很难仅仅删除一个元素。
应用场景  网页爬虫对 URL 去重，避免爬取相同的 URL 地址； 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱； Google Chrome 使用布隆过滤器识别恶意 URL； Medium 使用布隆过滤器避免推荐给用户已经读过的文章； Google BigTable，Apache HBbase 和 Apache Cassandra 使用布隆过滤器减少对不存在的行和列的查找。  除了上述的应用场景之外，布隆过滤器还有一个应用场景就是解决缓存穿透的问题。所谓的缓存穿透就是服务调用方每次都是查询不在缓存中的数据，这样每次服务调用都会到数据库中进行查询，如果这类请求比较多的话，就会导致数据库压力增大，这样缓存就失去了意义。
所以当有黑客生成大量随机的不存在的值请求服务器导致查询数据库，造成大量缓存穿透的情况时。我们可以用布隆过滤器进行拦截，被布隆过滤器判断为不存在的值就不需要查询数据库了，直接返回，大大减低了数据库压力。(少量判断为存在的值因为有误判率所以可以进行下一步查询)
在redis中安装布隆过滤器 redis本身是不自带布隆过滤器功能的，要么基于bitmap自己实现，要么安装插件
（布隆过滤器在guava包中也有实现）
安装redis插件 非docker安装的redis可以采用安装插件的方式来
# 去这个github仓库看看最新版本 wget https://github.com/RedisLabsModules/rebloom/archive/v2.2.4.tar.gz # 解压 tar zxvf v2.2.4.tar.gz # 编译 cd RedisBloom-2.2.4 make 以上执行完之后在目录下多了一个rebloom.so文件，将其移动到一个合适的位置
然后在redis的配置文件里增加以下一行（最好添加在MODULES区域，规范点，redis配置文件所在路径可以在redis-cli中用info 命令查看）
# 后面为rebloom.so文件所在的目录 loadmodule /xxx/xxx/xxx/rebloom.so 重启redis后进入redis-cli尝试以下命令
bf.add test 1 bf.</description>
    </item>
    
    <item>
      <title>Redis分布式缓存实现</title>
      <link>https://ccqstark.github.io/p/redis_mybatis_cache/</link>
      <pubDate>Wed, 25 Aug 2021 16:07:15 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/redis_mybatis_cache/</guid>
      <description>缓存的分类 本地缓存(local cache)：存在应用服务器内存中的数据称为本地缓存
分布式缓存(dustribute cache)：存储在当前应用服务器之外的数据称为分布式缓存
这里顺带提及集群和分布式的区别
集群(cluster)：将同一种服务的多个节点放在一起共同对系统提供服务，称为集群
分布式(distribute system)：有多个不同服务集群功能对系统提供服务，这个系统称之为分布式系统
所以两者虽然都是多个服务器节点，区别就在多个节点中，集群侧重的是同一种服务，而分布式侧重的是不同的服务，而且分布式还是建立在集群的基础之上的。
缓存发挥的作用  
由图中可以看出，缓存是作为存储层和客户端之间的中间层，当客户端的请求过来时，首先请求缓存中的内容，如果查到（hit）则直接返回，不再去查找存储层；如果没有（miss），则去存储层中查找并将结果写入缓存（write cache）再返回，以便之后相同的请求可以去缓存中获取。
之所以加入缓存层是因为存储层一般是需要读写磁盘的，而缓存层在内存中，两者的读写速度完全不是一个量级，内存快的多。而大部分应用的请求都有一个特点——读多写少，所以将总是需要查到的数据放在缓存层中可以大大提高应用的响应速度，减少存储层的压力。
一般Web应用中，存储层就是我们用的关系型数据库，MySQL、Oracle、SQLServer等，而缓存层分类上面已经提到，常用的有Redis，Memcached等。
MyBatis开启二级缓存 MyBatis一级缓存中，其最大的共享范围就是一个SqlSession内部，如果多个SqlSession之间需要共享缓存，则需要使用到二级缓存。
开启方法：
在业务的mapper.xml文件中添加
&amp;lt;cache/&amp;gt; 二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。
当开启缓存后，数据的查询执行的流程就是 二级缓存 -&amp;gt; 一级缓存 -&amp;gt; 数据库。
 
这样开启的是本地二级缓存，这样有个缺点就是应用重新启动后，JVM重新分配内存，这样的话之前的缓存就都没了，所以我们得用分布式缓存来解决。
使用Redis作为Mybatis的二级缓存 MyBatis的缓存实现类默认是PerpetualCache，它继承类Cache接口，除此之外还有其他实现类。
原理就是维护一个HashMap，将查询的SQL以及Mapper的namespace作为Key，然后查询的结果作为Value，通过键值对的方式来实现缓存查询过的sql语句的结果，所以要用redis替换也还是十分合适的。
Cache接口 public interface Cache { String getId(); void putObject(Object var1, Object var2); Object getObject(Object var1); Object removeObject(Object var1); void clear(); int getSize(); ReadWriteLock getReadWriteLock(); } 解析
getId ：这个方法其实是获取了执行的sql对应的namespace，可以用来组成缓存的key
putObject ：此方法就是用来将数据放入缓存的
getObject ：用以根据key获取缓存的值
removeObject ：删除某一缓存项目，MyBatis暂未实现与启用此方法，所以暂时无用
clear ：每次执行update/delete/insert语句都会调用此方法进行清除原有的缓存</description>
    </item>
    
    <item>
      <title>[实战]自己动手编译JDK实录</title>
      <link>https://ccqstark.github.io/p/compile_jdk/</link>
      <pubDate>Tue, 27 Jul 2021 03:44:28 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/compile_jdk/</guid>
      <description>前言 最近在看周志明老师的经典《深入理解Java虚拟机》，第1章最后是一个自己编译JDK的实战，想到羊哥之前也出过这样一期视频，觉得做一做也蛮有成就感的，还可以加深下对Java的理解，所以边做边写下此篇博文。
环境准备 系统环境 我的环境是macOS10.14.6(黑苹果)，问题相对Windows应该会少很多，推荐大家也是用Linux或者macOS来进行编译。
 
Xcode下载 一些C/C++相关的工具链一般是用Xcode带的，所以去官网下载就行。但是如果像我一样是黑苹果，系统不是最新的，官网的版本很可能不适配（目前最新Xcode 13要求macOS 11以上），所以只能翻到以前百度云里存的Xcode11.xip下载解压并安装就可以了。
xip文件在解压时需要用系统自带的解压工具，不要用第三方的，不然解压出来不是一个.app文件。
还有就是解压时可能会遇到系统验证问题，通过以下两步解决：
 运行以下命令行  # 最后是xip文件的位置 xattr -d com.apple.quarantine Xcode_11.xip 在系统设置中修改系统的时间约为2018年7月，然后允许任何来源的软件安装。  所有软件环境基础 以下都是编译中需要用到的软件环境，确保都已经安装
# 有一个已经可用的jdk，版本至少是要编译的版本-1 java -version # 输出 openjdk version &amp;#34;11.0.9&amp;#34; 2020-10-20 OpenJDK Runtime Environment (build 11.0.9+11) OpenJDK 64-Bit Server VM (build 11.0.9+11, mixed mode) # C的编译器 clang --version # 输出 Apple clang version 11.0.0 (clang-1100.0.33.8) Target: x86_64-apple-darwin18.7.0 Thread model: posix InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin # C++的编译器 clang++ --version # 输出 Apple clang version 11.</description>
    </item>
    
    <item>
      <title>[leetcode]15.三数之和</title>
      <link>https://ccqstark.github.io/p/three_sum/</link>
      <pubDate>Fri, 23 Jul 2021 16:55:26 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/three_sum/</guid>
      <description>题目 给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？请你找出所有和为 0 且不重复的三元组。
注意：答案中不可以包含重复的三元组。
示例 1： 输入：nums = [-1,0,1,2,-1,-4] 输出：[[-1,-1,2],[-1,0,1]] 示例 2： 输入：nums = [] 输出：[] 示例 3： 输入：nums = [0] 输出：[] 分析 这里本可以借鉴两数之和的哈希法，通过判断0-(a+b)是否存在数组中来解答，但是由于题目要求的不能包含重复的三元组用这个方法实在很难去处理，所以这里就不推荐用哈希法了。
这里推荐排序+双指针法 来解决。先对数组进行排序，然后用一个指针i对所有元素进行遍历，每一次遍历我们都有两个指针叫left和right，left一开始指向i+1，right一开始指向数组最后一位，然后开始判断此时三个指针之和sum是否为0。
如果不是又分为两种情况，sum大于0，则让right左移一位，让sum减小；如果sum小于0，则让left右移一位，让sum增加。如果是找到了的话，就两边同时收缩。整个过程就是通过调整left和right指针来毕竟让sum逼近0，再注意一下去除重复情况即可。
动画如下：
 
代码 // 排序+双指针法（较优） public List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; threeSum(int[] nums) { List&amp;lt;List&amp;lt;Integer&amp;gt;&amp;gt; result = new ArrayList&amp;lt;&amp;gt;(); // 排序  Arrays.sort(nums); for (int i = 0; i &amp;lt; nums.</description>
    </item>
    
    <item>
      <title>Java注解和反射</title>
      <link>https://ccqstark.github.io/p/java_annotaion_reflection/</link>
      <pubDate>Thu, 22 Jul 2021 23:43:42 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/java_annotaion_reflection/</guid>
      <description>注解 概述 不是程序本身，可以对程序作出解释，可以被其他程序（如编译器等）读取
可以附加在package、class、method、field等上面，可以通过反射机制编程实现对这些元数据对访问
内置注解 @Override
只用修饰方法，表示一个方法声明打算重写超类中的另一个方法声明
@Deprecated
可以用于修饰方法，属性，类，表示不鼓励程序猿使用，但是还是可以使用的，只是使用它可能有危险或者存在更好的选择。
@SuppressWarnings
用来抑制编译时的警告信息，需要添加一个参数
 
元注解 @Target
用于描述注解的使用范围
@Target(value = {ElementType.METHOD, ElementType.TYPE}) @Retention
表示需要在什么级别保存该注释信息（SOURCE &amp;gt; CLASS &amp;gt; RUNTIME）
@Retention(value = RetentionPolicy.RUNTIME) @Document 说明该注解将被包含在javadoc中
@Inherited
说明子类可以继承父类中的该注解
自定义注解 使用@interface自定义注解时,自动继承了java. lang.annotation Annotation接口
@interface用来声明一个注解，格式: public @interface 注解名 { 定义内容 }
其中的每一个方法实际上是声明了一个配置参数，方法的名称就是参数的名称 返回值类型就是参数的类型(返回值只能是基本类型, Class, String, enum)
可以通过 default来声明参数的默认值
如果只有一个参数成员,一般参数名为 value 注解元素必须要有值，我们定义注解元素时，经常使用空字符串和0作为默认值
@Target({ElementType.TYPE, ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) @interface MyAnnotation2 { // 方法名为参数名  String name() default &amp;#34;&amp;#34;; int age() default 0; int id() default -1; // 如果默认值为-1, 代表不存在  String[] schools() default {&amp;#34;西部开源&amp;#34;, &amp;#34;东部闭源&amp;#34;}; } 反射 概述 Java不是动态语言，但是可以通过反射机制获得类似动态语言的特性。</description>
    </item>
    
    <item>
      <title>Dubbo&#43;Nacos实现RPC</title>
      <link>https://ccqstark.github.io/p/dubbo_nacos_rpc/</link>
      <pubDate>Thu, 22 Jul 2021 02:26:29 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dubbo_nacos_rpc/</guid>
      <description>RESTful 与 RPC 的区别 在微服务定义中提道，每个小服务运行在自己的进程中，并以轻量级的机制进行通信。这里并没有明确给出具体的通信方式，只是要求以轻量级的机制进行通信，虽然作者推荐使用 RESTful 作为首选方案，但微服务间通信本身还有另一个轻量级的选择：以 Dubbo 为代表的 RPC通信方式。
RPC 是远程过程调用（Remote Procedure Call）的缩写形式，RPC 与 RESTful 最大的不同是，RPC 采用客户端（Client) - 服务端（Server） 的架构方式实现跨进程通信，实现的通信协议也没有统一的标准，具体实现依托于研发厂商的设计。
 
目前开源市场上 RPC 框架有很多，例如 GoogleRPC、Alibaba Dubbo、Facebook Thrift，每一种产品都有自己的设计与实现方案。
那 RESTful 与 RPC 有什么区别呢？通过一个表格进行说明：
 
Apache Dubbo Dubbo 是阿里巴巴开源的高性能、轻量级的开源 Java 框架，目前被 Apache收录，官网是： http://dubbo.apache.org/
 
Dubbo 是典型的 RPC 框架的代表，通过客户端/服务端结构实现跨进程应用的高效二进制通信。
Apache Dubbo 提供了六大核心能力：
面向接口代理的高性能 RPC 调用；
智能容错和负载均衡；
服务自动注册和发现；
高度可扩展能力；
运行期流量调度；
可视化的服务治理与运维。
下图引用 Dubbo 的官方架构图，讲解 ApacheDubbo 的组成。
 
Dubbo 架构中，包含 5 种角色。</description>
    </item>
    
    <item>
      <title>RocketMQ入门</title>
      <link>https://ccqstark.github.io/p/rocketmq_startup/</link>
      <pubDate>Thu, 22 Jul 2021 02:03:53 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/rocketmq_startup/</guid>
      <description>理论知识  
RocketMQ 天然采用集群模式，常见的 RocketMQ 集群有三种形式：多 Master 模式、多 Master 多 Slave- 异步复制模式、多 Master 多 Slave- 同步双写模式，这三种模式各自的优缺点如下。
 多 Master 模式是配置最简单的模式，同时也是使用最多的形式。优点是单个 Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复情况下，由于 RAID10 磁盘非常可靠，同步刷盘消息也不会丢失，性能也是最高的；缺点是单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。 多 Master 多 Slave 异步复制模式。每个 Master 配置一个 Slave，有多对 Master-Slave，HA 采用异步复制方式，主备有短暂消息毫秒级延迟，即使磁盘损坏只会丢失少量消息，且消息实时性不会受影响。同时 Master 宕机后，消费者仍然可以从 Slave 消费，而且此过程对应用透明，不需要人工干预，性能同多 Master 模式几乎一样；缺点是 Master 宕机，磁盘损坏情况下会丢失少量消息。 多 Master 多 Slave 同步双写模式，HA 采用同步双写方式，即只有主备都写成功，才向应用返回成功，该模式数据与服务都无单点故障，Master 宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；缺点是性能比异步复制模式低 10% 左右，发送单个消息的执行时间会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。   
部署 部署 NameServer 集群 直接wget下载
wget https://mirror-hk.koddos.net/apache/rocketmq/4.8.0/rocketmq-all-4.8.0-bin-release.zip unzip 解压后，我们进入bin目录修改runserver.sh文件的虚拟机内存配置（因为默认的太大了吃不消），根据自己服务器实际情况更改
JAVA_OPT=&amp;#34;${JAVA_OPT}-server -Xms128m -Xmx128m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&amp;#34; 后台启动一下NameServer服务</description>
    </item>
    
    <item>
      <title>Sleuth&#43;Zipkin链路跟踪入门</title>
      <link>https://ccqstark.github.io/p/zipkin_startup/</link>
      <pubDate>Thu, 22 Jul 2021 01:56:55 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/zipkin_startup/</guid>
      <description>依赖 &amp;lt;!-- sleuth --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-starter-sleuth&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;2.2.6.RELEASE&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- zipkin --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-starter-zipkin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;2.2.6.RELEASE&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 这里踩了大坑，不要用阿里的镜像，用Maven官方的，阿里的有问题！！
配置文件 spring:sleuth:sampler:#采样器probability:1.0#采样率，采样率是采集Trace的比率，默认0.1rate:10000#每秒数据采集量，最多n条/秒Tracezipkin:#设置zipkin服务端地址base-url:http://49.234.82.226:9411然后去服务端部署zipkin的可视化监控程序，参照官网：
https://zipkin.io/pages/quickstart.html
推荐使用docker
docker run -d -p 9411:9411 openzipkin/zipkin 使用 之后调用的链路就可以在下面链接看到了
http://49.234.82.226:9411/zipkin
需要刷新和筛选一下
 
点进去可以看到具体信息</description>
    </item>
    
    <item>
      <title>Nacos配置中心入门</title>
      <link>https://ccqstark.github.io/p/nacos_config_startup/</link>
      <pubDate>Thu, 22 Jul 2021 01:48:33 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/nacos_config_startup/</guid>
      <description>建立数据库 建立个用于存放配置的数据库名为nacos-config，nacos/conf下有一个nacos-mysql.sql，运行一下便可获得存放配置信息的表
 
配置数据源 修改nacos/conf/application.properties
### If use MySQL as datasource: spring.datasource.platform=mysql ### Count of DB: db.num=1 ### Connect URL of DB: db.url.0=jdbc:mysql://xxxxxxx:3306/nacos_config?characterEncoding=utf8&amp;amp;connectTimeout=1000&amp;amp;socketTimeout=3000&amp;amp;autoReconnect=true&amp;amp;useUnicode=true&amp;amp;useSSL=false&amp;amp;serverTimezone=UTC db.user=root db.password=xxxxxxx 记得重启
应用接入配置中心 依赖
&amp;lt;!-- Spring Boot Web模块 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- Nacos注册中心starter --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.alibaba.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-starter-alibaba-nacos-discovery&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- Nacos配置中心starter --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.alibaba.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-starter-alibaba-nacos-config&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; 配置文件，我们把原来的application.yml删除了，我们不再需要本地配置
然后创建文件bootstrap.yml，注意名字要一模一样
spring:application:name:order-service#微服务idprofiles:active:dev#环境名cloud:nacos:config:#Nacos配置中心配置file-extension:yml#文件扩展名server-addr:192.168.31.10:8848username:nacospassword:nacoslogging:#开启debug日志，仅为学习时使用level:root:debug定义一份配置文件是用微服务id-环境名.文件扩展名 三部分组合为有效的 data id，比如上面的就是order-service-dev.yml
然后去Nacos把原来的那些应用配置给存到云端
点击➕ 号新建配置
 
注意data id 就是上面说的微服务id-环境名.文件扩展名 ，然后选择yaml格式，把我们以前写在本地的配置文件写到下面的配置内容中
 
此时新建的配置信息其实就是用我们之前配置的MySQL存的，你会发现这些配置信息存在config-info表中了</description>
    </item>
    
    <item>
      <title>OpenFeign服务调用入门</title>
      <link>https://ccqstark.github.io/p/openfeign_startup/</link>
      <pubDate>Thu, 22 Jul 2021 01:43:44 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/openfeign_startup/</guid>
      <description>Feign 与 OpenFeign Spring Cloud OpenFeign 并不是独立的技术。它底层基于 Netflix Feign，Netflix Feign 是 Netflix 设计的开源的声明式 WebService 客户端，用于简化服务间通信。Netflix Feign 采用“接口+注解”的方式开发，通过模仿 RPC 的客户端与服务器模式（CS），采用接口方式开发来屏蔽网络通信的细节。OpenFeign 则是在 Netflix Feign 的基础上进行封装，结合原有 Spring MVC 的注解，对 Spring Cloud 微服务通信提供了良好的支持。使用 OpenFeign 开发的方式与开发 Spring MVC Controller 颇为相似。
下面讲OpenFeign的使用方法。
服务提供方 依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.alibaba.cloud&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-cloud-starter-alibaba-nacos-discovery&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; 配置 spring:application:name:warehouse-service#应用/微服务名字cloud:nacos:discovery:server-addr:192.168.31.102:8848#nacos服务器地址username:nacos#用户名密码password:nacosserver:port:80可被调用的服务 @RestController public class WarehouseController { @GetMapping(&amp;#34;/stock&amp;#34;) public Stock getStock(Long skuId){ /* code */ return stock; } } 服务调用方 依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.</description>
    </item>
    
    <item>
      <title>Ribbon负载均衡入门</title>
      <link>https://ccqstark.github.io/p/ribbon_startup/</link>
      <pubDate>Thu, 22 Jul 2021 01:38:45 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/ribbon_startup/</guid>
      <description>客户端负载均衡 负载均衡顾名思义，是指通过软件或者硬件措施。它将来自客户端的请求按照某种策略平均的分配到集群的每一个节点上，保证这些节点的 CPU、内存等设备负载情况大致在一条水平线，避免由于局部节点负载过高产生宕机，再将这些处理压力传递到其他节点上产生系统性崩溃。
负载均衡按实现方式分类可区分为：服务端负载均衡与客户端负载均衡。
服务端负载均衡顾名思义，在架构中会提供专用的负载均衡器，由负载均衡器持有后端节点的信息，服务消费者发来的请求经由专用的负载均衡器分发给服务提供者，进而实现负载均衡的作用。目前常用的负载均衡器软硬件有：F5、Nginx、HaProxy 等。
客户端负载均衡是指，在架构中不再部署额外的负载均衡器，在每个服务消费者内部持有客户端负载均衡器，由内置的负载均衡策略决定向哪个服务提供者发起请求。通俗来讲，就是客户端在发送请求之前就通过某种策略选定了要请求的服务提供者，而不是让一个中间件来帮忙决定。
Ribbon Netfilx Ribbon 是 Netflix 公司开源的一个负载均衡组件，是属于客户端负载均衡器。目前Ribbon 已被 Spring Cloud 官方技术生态整合，运行时以 SDK 形式内嵌到每一个微服务实例中，为微服务间通信提供负载均衡与高可用支持。
 
过程如下：
 订单服务（order-service）与商品服务（goods-service）实例在启动时向 Nacos 注册； 订单服务向商品服务发起通信前，Ribbon 向 Nacos 查询商品服务的可用实例列表； Ribbon 根据设置的负载策略从商品服务可用实例列表中选择实例； 订单服务实例向商品服务实例发起请求，完成 RESTful 通信；  下面用一个实例来演示：
创建服务生产者 创建springboot项目模块，引入web和nacos客户端依赖
配置文件 spring:application:name:provider-service#应用/微服务名字cloud:nacos:discovery:server-addr:49.234.82.226:8848#nacos服务器地址username:nacos#用户名密码password:nacosserver:port:8081创建示例服务 @RestController public class ProviderController { @GetMapping(&amp;#34;/provider/msg&amp;#34;) public String sendMessage(){ return &amp;#34;This is the message from provider service one!&amp;#34;; } } 连续创建3个provider，注意配置文件中的应用/微服务名要一致，代表同一种服务，为了直接了当地识别服务来自不同的微服务示例，可以在返回的字符串中添加自己的标示。启动后可以在nacos中看到健康示例数为3:
 
创建服务消费者 引入web和nacos客户端依赖之外，还要引入ribbon
&amp;lt;!-- Ribbon --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.</description>
    </item>
    
    <item>
      <title>Nacos服务注册与发现入门</title>
      <link>https://ccqstark.github.io/p/nacos_startup/</link>
      <pubDate>Thu, 22 Jul 2021 01:30:53 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/nacos_startup/</guid>
      <description>docker单点部署 clone项目 git clone https://github.com/nacos-group/nacos-docker.git cd nacos-docker 修改配置文件 如果单机主机内存较小，可以修改配置文件example/standalone-derby.yaml 修改JVM运行内存
在nacos的environment 那里添加- JVM_XMS=256m和 - JVM_XMX=256m
version: &amp;#34;2&amp;#34;services: nacos: image: nacos/nacos-server:latest container_name: nacos-standalone environment: - PREFER_HOST_MODE=hostname - MODE=standalone - JVM_XMS=256m - JVM_XMX=256m volumes: - ./standalone-logs/:/home/nacos/logs - ./init.d/custom.properties:/home/nacos/init.d/custom.properties ports: - &amp;#34;8848:8848&amp;#34; prometheus: container_name: prometheus image: prom/prometheus:latest volumes: - ./prometheus/prometheus-standalone.yaml:/etc/prometheus/prometheus.yml ports: - &amp;#34;9090:9090&amp;#34; depends_on: - nacos restart: on-failure grafana: container_name: grafana image: grafana/grafana:latest ports: - 3000:3000 restart: on-failuredocker-compose启动容器 最后加个-d后台运行
docker-compose -f example/standalone-derby.yaml up -d 访问 地址：http://[ip地址]:8848/nacos/</description>
    </item>
    
    <item>
      <title>MySQL主从复制搭建与原理</title>
      <link>https://ccqstark.github.io/p/mysql_master_slave_replic/</link>
      <pubDate>Thu, 22 Jul 2021 01:00:48 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/mysql_master_slave_replic/</guid>
      <description>主从复制搭建 拉取镜像 用docker，mysql5.7
docker pull mysql:5.7 启动 主节点
docker run -p 3306:3306 --name mysql_master -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 从节点
docker run -p 3306:3306 --name mysql——slave -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 Master配置 通过docker exec -it [容器名] bash 进入容器内部
安装vim
apt-get update apt-get install vim 编辑配置文件my.cnf
cd /etc/mysql vim my.cnf 添加以下内容
[mysqld] ## 同一局域网内注意要唯一 server-id=100 ## 开启二进制日志功能，可以随便取（关键） log-bin=mysql-bin 完成后重启服务，重启服务后需要重启容器
service mysql restart docker start mysql_master 再次进入容器，创建用于同步数据的用户
mysql -hlocalhost -uroot -p CREATE USER &amp;#39;slave&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;123456&amp;#39;; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.</description>
    </item>
    
    <item>
      <title>[leetcode]203.移除链表元素</title>
      <link>https://ccqstark.github.io/p/remove_elements/</link>
      <pubDate>Sun, 11 Apr 2021 00:00:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/remove_elements/</guid>
      <description>题目 给你一个链表的头节点 head 和一个整数 val ，请你删除链表中所有满足 Node.val == val 的节点，并返回 新的头节点 。
 
示例 1: 输入: head = [1,2,6,3,4,5,6], val = 6 输出: [1,2,3,4,5] 示例 2: 输入: head = [], val = 1 输出: [] 示例 3: 输入: head = [7,7,7,7], val = 7 输出: [] 分析 很普通的一道链表移除元素题目。这里我们主要考虑两种方式：
 直接在原链表上删除节点操作 增加一个虚拟节点（也叫哨兵节点）来操作  第二种方法主要是为了统一所有的删除节点操作，而不用在遇到要删除头节点情况时要单独写一段代码来处理。
而对于普通节点，删除这个节点的操作一般是把自己的前驱节点的next指针指向自己的后驱节点，如图：
  由于是单链表，我们不能获得一个被删节点的前驱节点，所以一般是判断一个节点的next的值是否为被删值。
 对于C/C++，不能自动释放内存我们就要手动释放被删除的节点的内存，但Java会帮我们做好这一切。
 代码 ListNode节点类的代码：
public class ListNode { int val; ListNode next; ListNode() {} ListNode(int val) { this.</description>
    </item>
    
    <item>
      <title>[leetcode]59.螺旋矩阵II</title>
      <link>https://ccqstark.github.io/p/generate_matrix/</link>
      <pubDate>Wed, 07 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/generate_matrix/</guid>
      <description>题目 给你一个正整数 n ，生成一个包含 1 到 n^2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵 matrix 。
 
示例1: 输入:n = 3 输出:[[1,2,3],[8,9,4],[7,6,5]] 示例2: 输入: n = 1 输出: [[1]] 分析 第一次看到这道题感觉很懵很难，其实这道题也不涉及什么经典算法，就是考验你用代码复现这个过程道能力。
我们可以把按照题目给的图的按顺序去填充矩阵中的值，从第一个位置开始先从左到右➡️ ，再从上到下⬇️ ，再从右到左⬅️ ，再从下到上⬆️ 。如此循环，直到填充完毕，当然如果n为奇数的话就要考虑中间那一格需要最后去单独填充，偶数的话就没有这个问题。
当然每次循环还需要注意，每行/列都遵循的是左闭右开的原则，也就是说从头填到倒数第二个，最后一个就是下一行/列的，才能保证行/列填充行为的统一性。
还有一点是每次循环之后，每行/列需要填充的个数就要少2，看下下面的图就可以很直观的理解了。
下面就是n=5和n=4的例子：
   
代码 class Solution { public int[][] generateMatrix(int n) { // 矩阵本体  int[][] matrix = new int[n][n]; // 横行和纵向开始填充的起始点  int startx = 0, starty = 0; // 循环次数  int loop = n / 2; // n为奇数时矩阵的中间格  int mid = n / 2; // 用来填充的数字，从1开始  int count = 1; // 每列或每行在循环一次后，下一次循环时要填充的元素个数会减少2，用这个变量来记录当前减少的大小  int offset = 1; // 填充时用的指针，i为行，j为列  int i, j; while (loop-- !</description>
    </item>
    
    <item>
      <title>一次理解String的不可变性</title>
      <link>https://ccqstark.github.io/p/string/</link>
      <pubDate>Tue, 06 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/string/</guid>
      <description>今天在看有关StringBuilder和StringBuffer的文章的时候看到里面提及了有关String中的final字段和不可变的性质，发现这个知识点不是很熟悉，去查了很多文章之后整理出这篇。
新建字符串与缓冲池 新建一个String我们一般有下面2种方式：
String a = &amp;#34;ok&amp;#34;; String b = new String(&amp;#34;ok&amp;#34;); 这两种写法都可以创建一个String对象。
第一种用赋值运算符进行字符串初始化时，JVM自动为每个字符串生成一个String类的实例。
第二种就是创建String类的对象，因为String本来就是一个类，而不是像int和double那样的基本数据类型。
Java的字符串采用了缓冲池的技术，我们新建一个字符串的时候会去缓冲池寻找是否有已经存在的相同的字符串，如果有的话直接指向它即可；没有的话再创建，缓冲池是在堆里面的。
如下图，是下面代码的结果：
// one和two内容相同，指向同一String对象 String one = &amp;#34;someString&amp;#34;; String two = &amp;#34;someString&amp;#34;;   关于更深入的创建对象和之间的比较可以看下面这篇：
java 字符串缓冲池 String缓冲池_天天的专栏-CSDN博客
哪里不可变？ 那为什么说String不可变呢？我们明明可以通过给字符串变量赋一个新值来改变它的内容。
String str = &amp;#34;aaaaaaa&amp;#34;; System.out.println(str); str = &amp;#34;bbbbbbbbb&amp;#34;; System.out.println(str); // 输出 //aaaaaaa //bbbbbbbbb 实际上，当我们给字符串重新赋值的时候，它并不是去改变这个String对象中的字符数组char[] value的值（下面会讲到），而是去缓冲池里寻找有没有已经存在这个值的String对象，有的话就直接指向它，没有的话创建一个对象再指向它。
  str只是一个引用，指向的String对象是在堆中的。改变字符串的值其实只是改变整个对象的引用。
而原来的String对象还是在那里没有被改变，之后要是有别的变量赋这个值可以继续指向它。
为什么不可变？ 我们看下String的部分源码：
public final class String implements java.io.Serializable, Comparable&amp;lt;String&amp;gt;, CharSequence { /** The value is used for character storage.</description>
    </item>
    
    <item>
      <title>[leetcode]209.长度最小的子数组</title>
      <link>https://ccqstark.github.io/p/min_sub_array_len/</link>
      <pubDate>Sun, 04 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/min_sub_array_len/</guid>
      <description>题目 给定一个含有 n 个正整数的数组和一个正整数 target 。
找出该数组中满足其和 ≥ target 的长度最小的 连续子数组 [numsl, numsl+1, &amp;hellip;, numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。
示例 1: 输入: target = 7, nums = [2,3,1,2,4,3] 输出: 2 解释: 子数组 [4,3] 是该条件下的长度最小的子数组. 示例 2: 输入: target = 4, nums = [1,4,4] 输出: 1 示例 3: 输入: target = 11, nums = [1,1,1,1,1,1,1,1] 输出: 0 提示：
 1 &amp;lt;= target &amp;lt;= 109 1 &amp;lt;= nums.length &amp;lt;= 105 1 &amp;lt;= nums[i] &amp;lt;= 105  分析 这道题一开始想到的是暴力解法，也就是把每种可能的子数组长度都试一遍，后来发现这是道典型的滑动窗口题目，用滑动窗口就解决了。之后看官方题解有前缀+二分搜索的方法作为扩展。</description>
    </item>
    
    <item>
      <title>[leetcode]27.移除元素</title>
      <link>https://ccqstark.github.io/p/remove_element/</link>
      <pubDate>Fri, 02 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/remove_element/</guid>
      <description>题目 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。
不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。
元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。
分析 对于数组而言，我们原地移除元素的话就肯定要把被移除的元素后面的全部元素都往前挪一个位，这是最基本的操作。所以最普通的暴力解法就是删除一个，整体挪动一个位。优化一点的话就是当有几个需要删除的数连在一起时，我们找到边界后一起挪动n个位，减少整体挪动的次数。
最优的是经常被用到的双指针法，下面再解释。
代码 混合暴力法 public int removeElement(int[] nums, int val) { int len = nums.length; for (int left = 0; left &amp;lt; len; left++) { if (nums[left] == val) { // left位于最后一个元素时  if (left == len - 1) { return len - 1; } int right = left + 1; while (right &amp;lt;= len - 1 &amp;amp;&amp;amp; nums[right] == val) right++; if (right == len - 1 &amp;amp;&amp;amp; nums[right] == val) { // right超过长度时  return len - (right - left); } // 把元素right处整体前移到left  moveUp(left, right, nums, len); len = len - (right - left); } } return len; } // 该函数用于将right及后面的元素完前移到left位置 public void moveUp(int left, int right, int[] nums, int len) { int step = len - 1 - right; for (int i = 0; i &amp;lt;= step; i++) { nums[left + i] = nums[right + i]; } }   此方法其实是初步优化的暴力法，假设我们要移除值为2的元素，left指针找到第一被删除的元素，right指向left后第一个不等于2的元素，然后把从right开始的后面全部元素都往前挪至left位置。</description>
    </item>
    
    <item>
      <title>[leetcode]35.搜索插入位置</title>
      <link>https://ccqstark.github.io/p/search_insert/</link>
      <pubDate>Thu, 01 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/search_insert/</guid>
      <description>题目 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。
你可以假设数组中无重复元素。
示例 1: 输入: [1,3,5,6], 5 输出: 2 示例 2: 输入: [1,3,5,6], 2 输出: 1 示例 3: 输入: [1,3,5,6], 7 输出: 4 示例 4: 输入: [1,3,5,6], 0 输出: 0 分析 这道题就是找到数组中的数，遍历就不说了， 我们首先想到的比较好的解法当然是二分搜索
需要注意的是当目标值不存在于数组中时，我们要如何去定位合适的插入点？先上代码再分析。
代码 public int searchInsert(int[] nums, int target) { return binSearch(0,nums.length-1,target,nums); } public int binSearch(int left, int right, int x, int[] nums) { if (left &amp;gt; right) return left; int mid = (left + right) / 2; if (x &amp;lt; nums[mid]) return binSearch(left, mid - 1, x, nums); if (x &amp;gt; nums[mid]) return binSearch(mid + 1, right, x, nums); if (x == nums[mid]) return mid; return -1; } 这里是采用传统的递归来写二分，但其实这里可以不用，直接一个while循环就行</description>
    </item>
    
    <item>
      <title>[leetcode]1.两数之和</title>
      <link>https://ccqstark.github.io/p/two_sum/</link>
      <pubDate>Wed, 31 Mar 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/two_sum/</guid>
      <description>题目 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数组下标。
你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。
你可以按任意顺序返回答案。
示例 1: 输入: nums = [2,7,11,15], target = 9 输出: [0,1] 解释: 因为 nums[0] + nums[1] == 9, 返回 [0, 1]. 示例 2: 输入: nums = [3,2,4], target = 6 输出: [1,2] 示例 3: 输入: nums = [3,3], target = 6 输出: [0,1] 提示：
 2 &amp;lt;= nums.length &amp;lt;= 103 -109 &amp;lt;= nums[i] &amp;lt;= 109 -109 &amp;lt;= target &amp;lt;= 109 只会存在一个有效答案  分析 这道题比较容易，就是在数组中找到数值x和target-x</description>
    </item>
    
    <item>
      <title>[SpringBoot]日志与异常捕获</title>
      <link>https://ccqstark.github.io/p/log_catch_error/</link>
      <pubDate>Thu, 18 Mar 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/log_catch_error/</guid>
      <description>项目中用到了之前说的日志门面slf4j+log4j，但是之后遇到了一些问题。比如程序报错没有记录在日志，记录的时间也和服务器的不一致（服务器是东八区时间），或者记录一些不需要的信息，此篇就来解决这些问题。
slf4j与log4j 之前有一篇文章介绍了slf4j怎么整合进Springboot，slf4j是一个日志门面，和我们所用的logback、log4j这些日志框架不同，它是为这些日志框架统一调用的API，通过api来调用具体的日志实现，简化了日志的配置与使用。slf4j要与具体的日志框架搭配，我用的是log4j。
&amp;lt;!-- SLF4j - log4j --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.8.0-alpha2&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 使用时只要用注解@Slf4j ，然后直接用log.info() 方法就可以记录日志了。
日志等级 日志分为以下几个等级：
OFF：最高等级的，用于关闭所有日志记录。
FATAL：会导致应用程序推出的严重错误。
ERROR：虽然发生错误事件，但仍然不影响系统的继续运行，一般也是程序的各种Exception，但要注意的是并不是所有异常都会导致Error，这就是下面的要说的异常捕获。打印错误和异常信息，如果不想输出太多的日志，可以使用这个级别。
WARN：警告，表明会出现潜在错误的情形，有些信息不是错误信息，只是一些提示。
INFO：消息在粗粒度级别上突出强调应用程序的运行过程。打印一些你感兴趣的或者重要的信息，这个可以用于生产环境中输出程序运行的一些重要信息，但是不能滥用，避免打印过多的日志。
DEBUG：主要用于开发过程中打印一些运行信息。但是打印但信息量过多，项目上线后不要用。
TRACE：跟踪日志，日志消息的粒度太细，很低的日志级别，一般不会使用。
ALL：最低等级的，用于打开所有日志记录。
通过修改日志配置文件log4j.properties来改变日志等级：
log4j.rootLogger = ERROR,stdout,log //第一个参数是日志等级 错误捕获 在SpringBoot我们希望有统一的操作来捕获系统运行过程中参数的所有错误，对未预测到对错误设置友好的返回值给用户，避免返回500状态码。甚至可以将系统产生的报错通过邮件发送给开发者，让生产环境中的错误能得到快速直接的监测和解决。
我们用到@RestControllerAdvice和@ExceptionHandler 这两个注解
@Slf4j @RestControllerAdvice // 用于拦截异常的注解 public class ExceptionProcesser extends ResponseEntityExceptionHandler { @Autowired private MailService mailService; /** * 全局异常捕获入日志 */ // 此注解用来标示处理哪个类的异常 	@ExceptionHandler(value = Exception.class) // 表示所有的异常都会处理 	public CommonResult&amp;lt;String&amp;gt; defaultErrorHandler(Exception e) { // slf4j下的日志用法，简洁易用 	log.</description>
    </item>
    
    <item>
      <title>[ElasticSearch]ElasticSearch入门与原理浅析</title>
      <link>https://ccqstark.github.io/p/es_principle/</link>
      <pubDate>Sat, 13 Mar 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/es_principle/</guid>
      <description>简介 引入 对于搜索功能，大家以前都是怎么做的呢？我相信很多人一开始也是用SQL的LIKE关键字加上%来匹配关键字的吧，为了实现更好的模糊效果就再加一个分词器来拆分关键词。但是，一旦被搜索的数据量一大，这种方式就显得效率低下。为了实现更好的效果，我们可以使用当前最流行的分布式搜索引擎——ElasticSearch 。
基本介绍 Elasticsearch 是一个分布式的免费开源搜索和分析引擎，适用于包括文本、数字、地理空间、结构化和非结构化数据等在内的所有类型的数据，基于著名的Lucene库进行开发，并以简单的RESTful风格的API进行调用，支持Java、JavaScript(Node)、Go、 C#(.NET)、PHP、Python、Ruby等多种语言。ElasticSearch已经成为非常流行的搜索引擎，一些著名厂商例如京东、滴滴、携程、Stack Overflow、GitHub等都在使用。
官网地址：https://www.elastic.co/cn/elasticsearch/
 
应用场景  应用程序搜索 网站搜索 企业搜索 日志处理和分析 基础设施指标和容器监测 应用程序性能监测 地理空间数据分析和可视化 安全分析 业务分析  ELK ELK，即ElasticSearch + logstash + Kibana ，是一套开源的日志收集与分析解决方案。利用ElasticSearch对数据进行快速的复杂条件检索，用logstash则作为数据管道从多个来源进行数据的采集、转换和传输，Kibana则通过生成多种可视化报表方便用户进行日志监控。
一般小型系统我们分析日志可以直接在用grep、awk等命令进行过滤与检索，或者拉到本地用LogViewer等专门的日志工具打开查看。但是当系统体量一大，采用的是分布式架构，集群中的日志管理就成为一个难题。ELK目的就是为了解决大型系统中的日志收集、存储与分析问题，方便将节点中的日志统一管理从而提高效率。
 
概念介绍 基本概念 ElasticSearch（简称es）搜索的时候不是去数据库里拿数据，它有自己的一套存储与索引体系。数据库中的数据需要同步到es中，通过索引的形式来存储数据才能实现高效检索。
es索引体系的基本概念和关系型数据库中的有些类似，我们可以对比着来看
   Index 索引 Database 数据库     Type 文档类型 Table 表   Document 文档 Row 记录   Field 字段 Column 属性   Mapping 映射 Schema 模型   Query DSL SQL    es的层次组织结构类似于MySQL这样的关系型数据库，index就像database那样存储着不同的type，也就是数据库中的table；再下一级就是document，类似于数据库中的一条条记录；每条记录的字段field就对应表中的column；mapping就如schema那样表示着库表的架构；es中的查询语言Query DSL则对标我们熟悉的SQL。通过类比可以更快地认识es的结构组成。</description>
    </item>
    
    <item>
      <title>Dubbo &#43; ZooKeeper 基础入门</title>
      <link>https://ccqstark.github.io/p/dubbo_zookeeper/</link>
      <pubDate>Wed, 24 Feb 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dubbo_zookeeper/</guid>
      <description>简介 Dubbo原本是阿里的开源框架，有很多著名厂商都在用。但在14年停更，之后Spring Cloud大红大紫，Dubbo终于在17年再度更新，并在18年合并当当网的基于它开发出的DubboX推出了2.6版本。之后在18年除夕夜，阿里正式将Dubbo捐献给了著名开源组织Apache，成为Apache众多开源项目之一。
Apache Dubbo
ZooKeeper 也是 Apache 软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。
ZooKeeper 的架构通过冗余服务实现高可用性。
Zookeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。
一个典型的分布式数据一致性的解决方案，分布式应用程序可以基于它实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。
Apache ZooKeeper
安装 使用Dubbo引入相关依赖即可，下面具体实践会涉及。
ZooKeeper可以去官网下载安装，这里我还是用docker在Linux服务器上安装。
# 拉取镜像 docker pull zookeeper # 启动 docker run -d \ -p 2181:2181 \ -v /home/zookeeper/data/:/data/ \ --name=zookeeper \ --privileged zookeeper # 如果想运行自带的客户端可以： docker exec -it zookeeper bash cd bin ./zkCli.sh # 之后就可以使用相关命令了 安装ZooInspector来可视化查看zookeeper

# 下载后进入build目录运行jar包，输入zookeeper的地址即可连接 java -jar zookeeper-dev-ZooInspector.jar  
使用dubbo-admin可视化监控服务 dubbo-admin是一个Springboot项目，可以监控我们注册到注册中心到服务。
到github上下载
apache/dubbo-admin
解压后在application.properties中修改zookeeper地址
dubbo.registry.address=zookeeper://[ip]:2181 之后用mvn命令打包再运行jar包即可，也可以直接在idea里打包
运行后浏览器 打开localhost:7001 ，输入账号密码默认都为root，来到主页</description>
    </item>
    
    <item>
      <title>浅谈分布式系统与RPC</title>
      <link>https://ccqstark.github.io/p/distributed_rpc/</link>
      <pubDate>Wed, 24 Feb 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/distributed_rpc/</guid>
      <description>随着互联网的发展，Web应用与服务的规模不断扩大，才能满足不断增加的用户和需求。而原来只用一台服务器来部署的单机应用的方式已经满足不了如此大的需求。为了提高性能，单机发展为分布式架构，简单来说就是通过增加服务器的数量来弥补性能上的不足，当然同时也带来了一些问题。
分布式系统 分布式系统（distributed system）是由一组网络进行通信，为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统是为了用单体性能普通的机器完成单个计算机无法完成的计算、存储任务，通过合理调度各台计算机共同合作来提高性能，完成数量更多、体量更大的任务。
  比如百度或淘宝这样体量规模都十分大的应用，为了满足如此大的用户数量和请求压力，背后肯定不止一台计算机在提供服务，而是部署了计算机集群，通过提升计算机的数量来提高处理数据的能力。在流量高峰时，大量的请求可以被均匀地分配给各台服务器去处理，从而避免其中一台服务器由于压力过大而宕机，这就是负载均衡，也就是nginx可以做的事情。
  同时应用的各个模块也可以分别部署在不同的服务器上，比如淘宝这样的电商项目可以把服务拆分成商品、支付、订单、物流等不同的模块，不同模块可以部署在不同的服务器上。当一个模块部署到多台服务器上时，其中一台崩了，还有其他的服务器可以提供服务，提高了服务的稳定性与高可用。
  而对于用户来说，他们都是访问一个域名来获取服务的，所以对于用户来说服务还是一个整体，而不需要知道是哪台服务器为他们提供了服务。
RPC 下图是Dubbo官方文档中的一张图，说明了网站应用的架构演变
  原来应用是单体应用，程序如果要调用一个函数或方法就直接调用就行了，因为都是在本地。
现在应用采用分布式架构，服务被分散到不同的服务器上，一台服务器上的程序就会遇到需要调用另一台服务器上的某个方法的情况，这个时候就叫RPC(远程过程调用)(Remote Procedure call)
RPC的调用过程如下图：
  通过网络发送调用消息就需要先序列化，到目标服务器后成功调用对应的服务后返回，反序列化得到结果。
Dubbo就是一个流行的RPC框架，提供面向接口代理的高性能RPC调用、智能负载均衡、服务自动注册与发现、高度可扩展能力、运行期流量调度（灰度发布）、可视化工具等功能。
流动计算架构 当服务增多时，服务的管理与资源的分配成为亟待解决的问题，此时，需要增加一个调度中心基于访问压力实时管理集群容量，提高集群的利用率。用于提高机器利用率的资源调度和治理中心(SOA)(Service Oriented Architecture)就十分重要。
服务通过在注册中心进行注册，被统一的管理起来并可被发现，并对用户开放。当用户需要用到某一服务时，就去注册中心拿，注册中心就会将对应的服务提供给他。
  注册中心用的比较多的是Zookeeper</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合ElasticSearch</title>
      <link>https://ccqstark.github.io/p/springboot_es/</link>
      <pubDate>Thu, 04 Feb 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_es/</guid>
      <description>导入依赖 我们使用springboot操作es要用到对应的data相关starter
&amp;lt;!-- elasticsearch的starter依赖 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-elasticsearch&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- 将对象转为json传入source时要用 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;fastjson&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.2.75&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  ⚠️ 各springboot的版本对应特定的elasticsearch版本，引入上面的依赖时会自动下载对应版本的rest-high-level-client，使用时尽量使得版本对应，避免潜在问题。
 版本对应表如下：
  我使用的这里用Springboot2.4.1，所以对应的elasticsearch是7.9.3版本
配置类 config目录下新建es的配置类ElasticSearchClientConfig.java
@Configuration public class ElasticSearchClientConfig { @Bean public RestHighLevelClient restHighLevelClient() { final CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(&amp;#34;elastic&amp;#34;, &amp;#34;[密码]&amp;#34;)); RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(&amp;#34;[ip]&amp;#34;, 9200, &amp;#34;http&amp;#34;)) .setHttpClientConfigCallback(httpClientBuilder -&amp;gt; { httpClientBuilder.disableAuthCaching(); return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); })); return client; } } 这里有用到x-pack基础安全功能，所以配置了用户和密码。如果没有用户和密码，参照官方文档连接代码如下：
RestHighLevelClient client = new RestHighLevelClient( RestClient.</description>
    </item>
    
    <item>
      <title>[ElasticSearch]REST风格操作</title>
      <link>https://ccqstark.github.io/p/es_rest/</link>
      <pubDate>Wed, 03 Feb 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/es_rest/</guid>
      <description>基本的rest命令    method url 功能     PUT localhost:9200/索引名称/类型名称/文档id 创建文档（指定文档id)   POST localhost:9200/索引名称/类型名称 创建文档（随机文档id）   POST localhost:9200/索引名称/类型名称/文档id/_update 修改文档   DELETE localhost:9200/索引名称/类型名称/文档id 删除文档   GET localhost:9200/索引名称/类型名称/文档id 查询文档，通过文档id   POST localhost:9200/索引名称/类型名称/_search 查询所有数据     ⚠️ 自定义类型将在以后的版本中弃用，规范起见一律使用_doc 类型
 文档字段的数据类型   字符串类型
text keyword
  数值类型
long integer short byte double float half float scaled float
  日期类型
date</description>
    </item>
    
    <item>
      <title>我的vim入门配置折腾</title>
      <link>https://ccqstark.github.io/p/vim/</link>
      <pubDate>Sun, 31 Jan 2021 21:26:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/vim/</guid>
      <description>由于这几天开始看《CS:APP》，我就开始寻求一款Mac上的轻量的C语言编辑器。找来找去，无非是VSCode、CLion和大名鼎鼎的Vim。
为了减少磁盘占用同时让自己更接近于底层，我还是硬着头皮折腾起了Vim，这个上古神器之前就一直让我望而却步，我对它的掌握程度也差不多是会退出的程度，这一次就打算好好来折腾下。
安装NeoVim Vim其实到目前为止，不同的分支版本还是很多的，比较流行的现代版本就要属NeoVim了，所以我在终端安装了它，用iTerm2运行着。
brew install neovim 安装完成后用nvim命令就可以打开
nvim 配置文件路径
传统的vim的配置配置文件为~/.vimrc
而nvim的配置文件为/.config/nvim/init.vim ，之后修改nvim配置文件就用这个，以下简称为init.vim
安装SpaceVim 作为小白，快速搭建一个好看实用的Vim开发环境那最好的选择就是SpaceVim 了，下面是官方的介绍：
 SpaceVim 是一个社区驱动的模块化的 Vim IDE，以模块的方式组织管理插件以及相关配置， 为不同的语言开发量身定制了相关的开发模块，该模块提供代码自动补全， 语法检查、格式化、调试、REPL 等特性。用户仅需载入相关语言的模块即可得到一个开箱即用的 Vim IDE。
 官网地址：
主页 | SpaceVim
官网的文档还是很全的，按官方文档就可以快速搭建出来了。以MacOS为例：
安装spacevim
curl -sLf https://spacevim.org/cn/install.sh | bash 完成后重新打开nvim就会自动下载相关插件。
然后就是主界面：
  主题的修改可以参考官方文档
SpaceVim colorscheme 模块 | SpaceVim
快捷键符号说明
SPC 代表空格
&amp;lt;Leader&amp;gt; 默认为\
以下一些功能需要对mac进行一定的设置才能正常使用。
打开系统偏好设置 → 键盘
勾选将F1、F2等键用作标准功能键
这同时也解决了Chrome的F12 不能打开控制台的问题
  文件目录树
按F3 可以打开或关闭
语法函数树
按F2可以打开或关闭
mac下可能会出现错误，解决方案：
brew install ctags-exuberant 然后init.</description>
    </item>
    
    <item>
      <title>[Elastic]ElasticSearch 安全</title>
      <link>https://ccqstark.github.io/p/x_pack/</link>
      <pubDate>Fri, 29 Jan 2021 21:26:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/x_pack/</guid>
      <description>ElacticSearch索引中有大量的数据，如果没有一些安全措施的话会让系统处于一个十分危险的处境，引发的相关安全事件可以看看这篇文章。
你的Elasticsearch在&amp;quot;裸奔&amp;quot;吗？
而ElaticSearch官方的高级安全服务是收费的，主要给企业提供。但是从6.8和7.1版本开始，基础安全功能就免费了，而且已经集成在里面不用额外安装。
除此之外诸如Search Guard、ReadonlyREST、Nginx 等开源免费等方法来达到安全的目的，这里介绍的是使用官方的x-pack的基础安全功能，对于小项目来说够用了。
本文版本为7.10.1
修改配置文件 在elasticsearch.yml里新增
xpack.security.enabled:truexpack.security.transport.ssl.enabled:true之后重启 es
在es目录下执行 elasticsearch-setup-passwords interactive 然后输入多个用户的密码
Initiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: Reenter password for [elastic]: Passwords do not match. Try again. Enter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana]: Reenter password for [kibana]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: Changed password for user [apm_system] Changed password for user [kibana] Changed password for user [logstash_system] Changed password for user [beats_system] Changed password for user [remote_monitoring_user] Changed password for user [elastic] 其中elastic用户相当与es的root用户，之后使用es和kibana需要这个用户的密码</description>
    </item>
    
    <item>
      <title>[Elastic]使用logstash同步MySQL数据</title>
      <link>https://ccqstark.github.io/p/logstash_mysql/</link>
      <pubDate>Thu, 28 Jan 2021 21:26:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/logstash_mysql/</guid>
      <description>安装logstash 在实际项目中使用es进行搜索，我们就要把mysql数据库中的数据同步到es索引库中。进行这项过程的工具很多，比如go-mysql-elasticsearch，canal等等，当然也可以使用ELK组合中的logsatsh 来完成。这里同样用docker来部署logstash容器。
拉取镜像 docker pull logstash:7.10.1 启动容器 启动后进入容器内，修改jvm启动的内存设置，地址为/usr/share/logstash/config/jvm.options
# 修改jvm内存分配 vi jvm.options # 修改下面的参数，单位可以为g和m -Xms256m -Xmx256m 修改后重启容器即可
下载插件与依赖包 docker exec -it logstash bash 安装logstash-input-jdbc插件
bin/logstash-plugin install logstash-input-jdbc 如果出现以下ERROR，说明logstash里本身已经包含有这个插件了，就无需安装。7.10.1的版本是已经自带了。
ERROR: Installation aborted, plugin &amp;#39;logstash-input-jdbc&amp;#39; is already provided by &amp;#39;logstash-integration-jdbc&amp;#39; 下载mysql-connector-java，也就是jdbc驱动
MySQL官方下载地址：https://downloads.mysql.com/archives/c-j/
下载对应版本后本地解压，上传到服务器，然后用docker cp命令复制到logstash容器中
只需要其中的jar包即可
# 把文件复制到容器内 docker cp [jar包路径] logstash:[容器内路径] 在/usr/share/logstash目录下新建mysql/目录，把jar包复制到这里
同步配置文件 在刚刚的mysql目录下新建jdbc.conf 文件，来配置同步操作
 单表同步  input { jdbc { # jar包的绝对路径 jdbc_driver_library =&amp;gt; &amp;#34;/usr/share/logstash/mysql/mysql-connector-java-5.1.48.jar&amp;#34; jdbc_driver_class =&amp;gt; &amp;#34;com.mysql.jdbc.Driver&amp;#34; # 数据库连接信息 jdbc_connection_string =&amp;gt; &amp;#34;jdbc:mysql://[ip]:3306/[库名]?</description>
    </item>
    
    <item>
      <title>[Elastic]使用docker安装ElasticSearch &#43; Kibana</title>
      <link>https://ccqstark.github.io/p/es_docker/</link>
      <pubDate>Wed, 27 Jan 2021 21:26:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/es_docker/</guid>
      <description>安装ElasticSearch 拉取镜像 docker pull elasticsearch:7.10.1 启动容器 同时挂载目录（包括配置文件和data）（挂载出来的位置自己定义）
docker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=&amp;#34;-Xms256m -Xmx256m&amp;#34; -d \ -v /home/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \ -v /home/es/data:/usr/share/elasticsearch/data elasticsearch:7.10.1 注意这里还设置了JVM的内存大小，默认为2G，有点大，很可能会因为内存不够而无法正常启动。可以像我这里改为256m或者其他值。
可能出现的错误 查看容器日志
docker logs elasticsearch 如果出现以下错误
max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 则要修改服务器配置
vim /etc/sysctl.conf 添加这行
vm.max_map_count=262144 立即生效, 执行：
/sbin/sysctl -p 对挂载的宿主机data目录可能出现权限不足问题
chmod 777 [宿主机data目录] 配置跨域 到挂载出来到位置编辑配置文件
vim elasticsearch.yml 添加以下几行
network.host:0.0.0.0discovery.type:single-nodehttp.cors.enabled:truehttp.cors.allow-origin:&amp;#34;*&amp;#34;同时安全组和防火墙记得打开对应端口
记得每次修改完配置都要重启 docker restart elasticsearch 浏览器访问测试 http://[IP]:9200 看到类似以下的json就成功了</description>
    </item>
    
    <item>
      <title>什么是CAP理论？</title>
      <link>https://ccqstark.github.io/p/cap/</link>
      <pubDate>Thu, 21 Jan 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/cap/</guid>
      <description>随着移动互联网发展，用户和数据量越来越多，对应用系统提出了更高的要求，系统必须支持高并发访问和海量数据处理。
分布式系统技术就是用来解决集中式架构的性能瓶颈问题。一般来说，分布式系统是建立在网络之上的硬件或者软件系统，彼此之间通过消息等方式进行通信和协调。
分布式系统的核心是可扩展性，通过对服务、存储的扩展，来提高系统的处理能力，通过对多台服务器协同工作，来完成单台服务器无法处理的任务，尤其是高并发或者大数据量的任务。
单点故障（Single Point Failure）是指在系统中某个组件一旦失效，这会让整个系统无法工作。而分布式系统的设计就是为了避免出现单点故障问题，为了实现一个节点的失效不影响整个系统的运行。
无状态，是因为无状态的服务才能满足部分机器宕机不影响全部，可以随时进行扩展的需求。
由于分布式系统的特点，在分布式环境中更容易出现问题，比如节点之间通信失败、网络分区故障、多个副本的数据不一致等，为了更好地在分布式系统下进行开发，学者们提出了一系列的理论，其中具有代表性的就是 CAP 理论。
  一致性是指“所有节点同时看到相同的数据”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，等同于所有节点拥有数据的最新版本。
可用性是指“任何时候，读写都是成功的”，即服务一直可用，而且是正常响应时间。平时会看到一些 IT 公司说系统稳定性已经做到 3 个 9、4 个 9，即 99.9%、99.99%，这里的 n 个 9 就是对可用性的一个描述，叫做 SLA，即服务水平协议。比如我们说月度 99.95% 的 SLA，则意味着每个月服务出现故障的时间只能占总时间的 0.05%，如果这个月是 30 天，那么就是 21.6 分钟。
分区容忍性具体是指“当部分节点出现消息丢失或者分区故障的时候，分布式系统仍然能够继续运行”，即系统容忍网络出现分区，并且在遇到某节点或网络分区之间网络不可达的情况下，仍然能够对外提供满足一致性和可用性的服务。
在分布式系统中，由于系统的各层拆分，P 是确定的，CAP 的应用模型就是 CP 架构和 AP 架构。分布式系统所关注的，就是在 Partition Tolerance 的前提下，如何实现更好的 A 和更稳定的 C。
CAP 理论说明在架构设计中，不要把精力浪费在如何设计能满足三者的完美分布式系统上，而要合理进行取舍，因为三者无法完全兼得。
不同业务对于一致性的要求是不同的。例如，在微博上发表评论和点赞，用户对不一致是不敏感的，可以容忍相对较长时间的不一致，只要做好本地的交互，并不会影响用户体验；而我们在电商购物时，产品价格数据则是要求强一致性的，如果商家更改价格不能实时生效，则会对交易成功率有非常大的影响。
需要注意的是，CAP 理论中是忽略网络延迟的，也就是当事务提交时，节点间的数据复制一定是需要花费时间的。即使是同一个机房，从节点 A 复制到节点 B，由于现实中网络请求总是需要一定时间的，所以总会有一段时间不一致。
 CP 架构：对于 CP 来说，放弃可用性，追求一致性和分区容错性。
🔧 ZooKeeper就是采用了 CP 一致性，ZooKeeper 是一个分布式的服务框架，主要用来解决分布式集群中应用系统的协调和一致性问题。其核心算法是 Zab，所有设计都是为了一致性。在 CAP 模型中，ZooKeeper 是 CP，这意味着面对网络分区时，为了保持一致性，它是不可用的。</description>
    </item>
    
    <item>
      <title>Alfred &#43; iTerm2 快速ssh连接服务器</title>
      <link>https://ccqstark.github.io/p/alfred_iterm/</link>
      <pubDate>Sun, 10 Jan 2021 16:35:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/alfred_iterm/</guid>
      <description>为了提高在mac下连接ssh的效率，我们可以用alfred和iTerm配合，达到只要在输入框中输入ssh [主机名] 就可以快速连上了，效果如下图：
 
使用ssh config 在~/.ssh/config文件里添加服务器信息，没有的话就新建一个
vim ~/.ssh/config然后在文件中输入主机的信息，有多个主机就追加在后面就行
Host [主机名] HostName [ip] User root Port [端口]使用密钥登陆 如果本地的~/.ssh 目录下没有id_rsa 私钥文件，可以是使用下面这个目录生成，一路回车即可，如果已经有了就可以跳过这步
ssh-keygen然后将私钥复制到远程服务器
ssh-copy-id -i -p[端口号] root@ip按提示输入一次密码，就会自动将刚才生成的公钥id_rsa.pub追加到远程主机的~/.ssh/authorized_keys后面了，这样以后的 ssh 连接都不用输入密码了
安装alfred-ssh插件 https://github.com/deanishe/alfred-ssh
到上面github链接下载最新版：Secure-SHell的alfredworkflow，双击自动添加到alfred的workflow
添加后打开alfred的偏好设置可以看到效果如下：
  测试用alfred输入ssh+主机名就可以连上服务器了，但是默认是用mac自带但终端，想用好看的iTrem2还需要进一步操作
安装alfred集成iTerm2配置 如下图，打开iTrem2的偏好设置，如下图设置默认方式为ssh
  进入下面github链接，按说明操作
https://github.com/vitorgalvao/custom-alfred-iterm-scripts
  按上面要求运行命令并粘贴到对应地方就完成了！
参考文章： 开发效率神器之alfred集成ssh+iTerm2实现一步登录服务器</description>
    </item>
    
    <item>
      <title>Jenkins &#43; docker &#43; springboot 完美配合全流程教程</title>
      <link>https://ccqstark.github.io/p/jenkins_docker_springboot/</link>
      <pubDate>Sat, 09 Jan 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/jenkins_docker_springboot/</guid>
      <description>DevOps现在非常流行，CI/CD持续集成、持续部署也大火，而Jenkins就是自动化部署主要的工具之一。
这篇博客就来详细介绍用jenkins来实现自动化部署springboot项目的docker容器，堪称保姆级教学了。
用docker拉取jenkins镜像，启动Jenkins容器 这里采用的jenkins本身也是用docker容器部署的，不得不说docker确实好用，当然也可以直接运行在主机上
首先拉取Jenkins镜像 docker pull jenkins/jenkins ⚠️注意：切勿docker pull jenkins，已经废弃
启动Jenkins容器 docker run -u root -itd --name jenkins \ -p 6001:8080 \ -v $(which docker):/usr/bin/docker \ -v /var/run/docker.sock:/var/run/docker.sock -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ -v /etc/localtime:/etc/localtime:ro \ -v /volume1/docker/jenkins:/var/jenkins_home \ jenkins/jenkins  -p 6001:8080Jenkins默认网页访问端口为8080，将端口映射到外部主机6001端口 -v $(which docker):/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock使Jenkins内部可以使用docker命令 -e TZ=&amp;quot;Asia/Shanghai&amp;quot; -v /etc/localtime:/etc/localtime:ro配置Jenkins容器的时区 -v /volume1/docker/jenkins:/var/jenkins_home 将Jenkins的配置映射到外部主机卷，容器删除仍可保留配置  测试Jenkins容器内部 # 进入Jenkins的容器内部 docker exec -it jenkins bash # 判断docker命令是否正常执行 docker info 访问Jenkins网页端 用http://主机IP:6001 就可以访问Jenkins的网页端了</description>
    </item>
    
    <item>
      <title>[docker]用docker部署nginx</title>
      <link>https://ccqstark.github.io/p/docker_nginx/</link>
      <pubDate>Fri, 08 Jan 2021 15:46:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/docker_nginx/</guid>
      <description>如果是单体应用的话nginx用docker部署其实是更麻烦的，不过既然操作过就记录一下。
拉取nginx镜像 docker pull nginx 还是一样，默认是拉取latest版本，也可以选择想要的特定版本
启动并挂载html目录 docker container run \  -d \  -p 80:80 \  --name mynginx \  --v [本机挂载目录]:/usr/share/nginx/html \  nginx 复制出配置文件 docker container cp mynginx:/etc/nginx . 将复制出来的文件夹改名并移动到你想要的目录下，然后把容器停止并删除
挂载配置文件目录 最后一步就是重新启动一个容器并把html和配置文件目录都挂载了
docker run \  --name test-nginx \  -v [本机挂载html目录]:/usr/share/nginx/html \  -v [本机挂载nginx目录]:/etc/nginx \  -p 80:80 \  -d \  nginx 访问一下试试就可以了！
参考：
Nginx 容器教程</description>
    </item>
    
    <item>
      <title>[docker]用docker部署SpringBoot项目</title>
      <link>https://ccqstark.github.io/p/docker_springboot/</link>
      <pubDate>Thu, 07 Jan 2021 21:39:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/docker_springboot/</guid>
      <description>这篇文章介绍的是把整个Springboot后端项目部署到docker容器中，当然包括mysql和redis
按下面步骤一步步来
本地打出jar包 以Maven的话直接就IDEA里打出jar包到target目录下，这一步和以前一样
编写Dockerfile 可以用IDEA里的插件来写，也可以自己写dockerfile
在项目文件夹下新建一个文件Dockerfile
FROMopenjdk:8MAINTAINERccqstarkADD /target/[项目jar包名].jar app.jarEXPOSE8080ENTRYPOINT [&amp;#34;java&amp;#34;,&amp;#34;-jar&amp;#34;,&amp;#34;/app.jar&amp;#34;]⚠️注意：ADD后两个参数，第一个是项目jar包的相对路径，第二是把jar包在容器内重新命的名
构建镜像 在Dockerfile所在文件夹下运行build 命令，注意最后有一个.
docker build -f Dockerfile -t [镜像名]:[版本tag] .构建之后用docker images 查看一下自己构架的镜像
构建完之后本地run一下容器测试下
push上传到镜像仓库 其实也可以把jar包上传服务器后用服务器的docker来构建和运行
但这里采用的是把本地构建的镜像上传到repository，相当于镜像仓库，其他人想用这个镜像就可以从那拉取下来使用。
repository可以是官方的Docker Hub，但是比较慢，也可以花钱上传到阿里云的容器镜像服务就会快很多
这里是上传到docker hub，首先要登陆自己到docker账号，没有的话可以去官网注册一个
docker login -u [账户名] 输入密码成功后登陆
在push之前要给镜像打个tag，这样才能上传到自己账号对应的仓库下
docker tag [镜像名] [账户名]/[镜像仓库名]:latest 之后就可以上传了
docker push [账户名]/[镜像仓库名]:latest pull拉取镜像 docker pull [账户名]/[镜像仓库名]:[tag] 在服务器上拉取到镜像后就可以启动容器了
docker run -it -d -p [对外暴露端口]:8080 app:[tag] 部署MySQL容器 # 拉取mysql镜像 docker pull mysql:5.7 # 跑起来 docker run \ -d \ -p 3306:3306 \ -v /home/mysql/conf:/etc/mysql/conf.</description>
    </item>
    
    <item>
      <title>[docker]初识Dockerfile</title>
      <link>https://ccqstark.github.io/p/dockerfile/</link>
      <pubDate>Wed, 06 Jan 2021 21:13:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dockerfile/</guid>
      <description>Dockerfile介绍 dockfile是用来构建docker镜像的文件，命令参数脚本
💡构建步骤：
 编写dockerfile脚本 用docker build命令构建一个镜像 用docker run运行镜像 用docker push发布镜像（DockerHub、阿里云仓库）  在官网点击镜像会跳转到github对应的dockerfile
可以发现这些镜像也是通过dockerfile来构建的
  上图是centos的dockerfile，其中scratch是最基本的，90%都是基于这个镜像。
然后ADD 就是添加来一层centos相关的镜像文件
官方很多镜像都是基础包，功能很少，很多我们需要的都没有，所以我们通常都会构建自己的镜像。
比如我们可以直接构建一个centos+jdk+tomcat+mysql的镜像，不就直接有来一个可以运行javaweb项目的环境镜像了吗？
Dockerfile构建过程 基本规则  每个关键字（保留字）都是大写的 执行顺序是从上到下的 &amp;ldquo;#&amp;rdquo; 表示注释 每一个指令都会创建一个新的镜像层，并提交    以前开发交付都是用jar包或war包，现在云原生时代交付的就是docker镜像，docker镜像也逐渐成为企业交付标准，而构建docker镜像就需要学会编写dockerfile
什么是云原生？聊聊云原生的今生_阿里云开发者-CSDN博客
Dockerfile常用指令    指令关键字 作用     FROM 构建镜像所用的基础镜像   MAINTAINER 镜像作者，一般是姓名+邮箱   RUN 镜像构建时运行的命令   ADD 为镜像添加内容   WORKDIR 镜像的工作目录   VOLUME 挂载目录   EXPOSE 暴露的端口   CMD 容器启动时需要运行的命令，只有最后一个会生效，可被替代   ENTRYPOINT 也是指定启动时需要运行的命令，但是可以追加   ONBUILD 构建一个被继承的dockerfile时会运行ONBUILD的指令。触发指令   COPY 类似ADD，将文件拷贝到镜像中   ENV 构建时设置的环境变量    实践：构建自己的centos 举个例子：</description>
    </item>
    
    <item>
      <title>[docker]容器数据卷</title>
      <link>https://ccqstark.github.io/p/docker_volumes/</link>
      <pubDate>Wed, 06 Jan 2021 16:51:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/docker_volumes/</guid>
      <description>把容器内的目录挂载到宿主机的某一个目录下，实现双向同步。
也就是说两者都指向了同一文件目录下，在其中一端所做的修改都会同步。
好处：
 MySQL数据持久化，不会因为删了容器就没了 方便修改文件，比如nginx的配置文件  基本使用 bind mounts 以启动一个centos容器为例
docker run -it -v [宿主机目录]:[容器内目录] centos /bin/bash -it ：-t选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开，通常写成-it
-v ：挂载卷所需参数，后面的映射是[宿主机目录]:[容器内目录]
用此命令查看容器参数
docker inspect [容器id]   如上图，在Mounts 字段中可以看到：
Source 表示宿主机中被映射的目录
Destination 表示容器内要映射的目录
这种挂载方式称为bind mounts
实践：MySQL挂载 拉取mysql镜像 docker search mysql docker pull mysql:5.7 启动容器 -d 后台运行
-p 端口映射
-v 数据卷挂载
—name 容器名字
docker run \ -d \ -p 3310:3306 \ -v /home/mysql/conf:/etc/mysql/conf.d \ -v /home/mysql/data:/var/lib/mysql \ -e MYSQL_ROOT_PASSWORD=[你配置的mysql密码] \ --name [容器名] \ mysql:5.</description>
    </item>
    
    <item>
      <title>macOS终端美化指北</title>
      <link>https://ccqstark.github.io/p/mac_terminal/</link>
      <pubDate>Wed, 06 Jan 2021 02:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/mac_terminal/</guid>
      <description>终于从Windows转到心心念念的macOS上进行开发，虽然是黑苹果但是软件层面上没有太大的区别，程序员还是得用mac啊这终端上真的比windows好用无数倍，那终端到手后还是要折腾美化的，那就开始吧。 先看下我，还可以吧？  1 
准备工作 先保证自己下载homebrew和wget，安装软件或下载包很多情况下要用到它们，特别homebrew是mac下最好用的包管理器一定要有。下载方法网上也很多的，建议先下homebrew再用它下wget。
iTerm2 首先是下载第三方终端iTerm2，mac自带的终端用的比较少，大家用的最多还是这个。 官网下载
zsh zsh是shell的一种，mac默认的shell是bash，一般来说我们也是用zsh比较多，因为命令更多更好用。
下载zsh brew install zsh 切换shell为zsh # 查看当前使用的shell echo $SHELL # 切换为zsh chsh -s /bin/zsh 运行完上面命令后重启一下即可
oh-my-zsh oh-my-zsh用于美化终端，可以让你拥有很多好看的主题。
安装 wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh sh install.sh运行上面的命令来下载安装脚本并运行脚本，成功后会有如下画面
 2 
更换主题 oh-my-zsh有很多默认的主题，可以在~/.zshrc中修改ZSH_THEME来切换不同主题。 这里我推荐powerlever10k，它集合了很多不同主题风格的样式，支持自定义，如果默认主题中没有你满意的那推荐就用它。下面就讲powerlevel10k的安装方法。
下载 git clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k安装所需字体 # 安装 nerd-font 字体 brew tap homebrew/cask-fonts # 其他所需字体 cd ~ git clone https://github.com/powerline/fonts.git --depth=1 # 到目录下执行安装脚本 cd fonts .</description>
    </item>
    
    <item>
      <title>记一次服务器被攻击</title>
      <link>https://ccqstark.github.io/p/first_attack/</link>
      <pubDate>Sun, 22 Nov 2020 22:10:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/first_attack/</guid>
      <description>事情经过 11月17号这天早上上着课，突然有用户反馈应用卡顿，使用不了。我感觉上去看了果然是这样，有时数据加载很慢甚至加载不出来，我感到焦虑与害怕，害怕数据库和别人一样被黑了然后删光要钱，课都没心情听了。然后手机下了个Termius，先把服务关了。
中午回到宿舍后看了数据库发现数据完好无损，赶紧备份了一波，然后寻找问题。
内存和CPU和磁盘都挺正常，看了服务器的安全日志，那登录记录刷刷的，有人在暴力破解我的root密码！
由于下午还有体育课，就先直接关了服务器，然后上课去了。
下午来到实验室，重新打开服务器，又开始攻击了，气死了。用脚本封了攻击者一百多个肉鸡ip，以为可以了之后，把服务开启，通知用户可以用了。
结果用户又说太卡了，我又检查了一波，CPU、内存、磁盘正常，然后这个带宽就不太正常了，我学生机的1M/s都超了，应该是这个原因导致卡的。
用命令找了进程发现好像也没哪个占用很多呀，弄了很久还是很迷惑，攻击者的ip也明明被我加入黑名单了呀，之后还开了腾讯云的专业机阻断，还是很卡，卡到我ssh都连不太上。然后有个办法叫我改ssh的22端口，我怕操作失误连自己都直接连不上就GG了，然后就算了不这样搞了。
最后只能屁颠屁颠去找客服，他跟我说也是其他正常带宽跑满，叫我看有没有什么进程占用很多，主要是建议我临时升级带宽。
我想着：啊好家伙，开始了。但是也没啥其他办法，就去买了3天升级到3M/s的带宽，不贵，结果也是真香。
后来最多手动在安全组加了几个奇怪ip封掉，服务就完成稳定下来了，看来没有什么是加钱不能解决的。
后来过了两天攻击者还在继续冲，除了影响我带宽之外其实也没太大问题反正他进不来的，问了师兄建议说改22端口，反正重要使用期也过了，我就试试改下，还真有用，安全日志也没攻击者那些破解记录了，带宽也占用也再降了，说明攻击者也是冲22，这下直接完全被挡住，带宽也不占了。
第一次与黑客对线还是学到了很多的，也加强了我的安全防范意识
查看系统状态命令 下面有些命令工具需要额外安装的，直接yum install xxx安装就行
查看服务器安全日志(动态实时)(CentOS) tail -f /var/log/secure 查看CPU等的使用情况(按进程) top 查看内存使用情况 free -h 查看磁盘使用情况 df -hl 查看网络带宽占用(按ip) iftop -i eth0 jnettop 按Q退出
查看网络带宽占用(按进程) nethogs 还有防火墙工具iptables和firewall-cmd
https://wangchujiang.com/linux-command/c/iptables.html
https://wangchujiang.com/linux-command/c/firewall-cmd.html
编写自动化脚本封禁暴力破解登录的ip 从安全日志中读取记录，把那些多次登录失败的ip写进请求黑名单中（hosts.deny），但是这种办法只是拒绝连接，如果黑客继续攻击还是会占用带宽
先找个目录，vim建立一个脚本文件
vim /usr/local/secure_ssh.sh 然后编写脚本
#! /bin/bash cat /var/log/secure|awk &amp;#39;/Failed/{print $(NF-3)}&amp;#39;|sort|uniq -c|awk &amp;#39;{print $2&amp;#34;=&amp;#34;$1;}&amp;#39; &amp;gt; /usr/local/bin/black.txt for i in `cat /usr/local/bin/black.txt` do IP=`echo $i |awk -F= &amp;#39;{print $1}&amp;#39;` NUM=`echo $i|awk -F= &amp;#39;{print $2}&amp;#39;` result=$(cat /etc/hosts.</description>
    </item>
    
    <item>
      <title>[机器学习论文]Domain Adaptive Faster R-CNN for Object Detection in the Wild</title>
      <link>https://ccqstark.github.io/p/ml_domain_adaptation/</link>
      <pubDate>Sun, 22 Nov 2020 22:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/ml_domain_adaptation/</guid>
      <description>问题引入与研究目标 目标检测的数据集的收集往往是在现实场景中进行的，因此数据中目标的外观、背景、光照、图像质量等方面的巨大差异会导致训练数据和测试数据之间出现巨大的领域偏移。比如汽车在不同天气条件下驾驶收集到的数据，或者是相机的类型和设置的不同也会导致数据的领域偏移。这样的偏移会导致性能显著下降，尽管收集尽可能多的数据集可以降低这种影响，但是注释边界框也是一个费时费力的过程，因此开发一个新的算法来应对跨领域目标检测问题就尤为重要。
论文中方法适用于无监督场景，在源域有完整的监督，而在目标域没有监督。这样就可以不增加人工标注成本的前提下减少跨域对目标检测效率的影响。
关键术语介绍 目标检测 Object Detection 目标检测，也叫目标提取，是一种基于目标几何和统计特征的图像分割，它将目标的分割和识别合二为一，其准确性和实时性是整个系统的一项重要能力。尤其是在复杂场景中，需要对多个目标进行实时处理时，目标自动提取和识别就显得特别重要。目标检测主要有三个层次：
一是分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其他任务提供了基础。在应用领域，人脸、场景的识别等都可以归为分类任务。
二是检测（Detection）。分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置），因而，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。
三是分割（Segmentation）。分割包括语义分割（semantic segmentation）和实例分割（instance segmentation），前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。
领域自适应 Domain Adaptation 领域自适应（Domain Adaptation）是迁移学习中的一种代表性方法，指的是利用信息丰富的源域样本来提升目标域模型的性能。 领域自适应问题中两个至关重要的概念：
源域（source domain）表示与测试样本不同的领域，但是有丰富的监督信息
目标域（target domain）表示测试样本所在的领域，无标签或者只有少量标签。源域和目标域往往属于同一类任务，但是分布不同
根据目标域和源域的不同类型，领域自适应问题有四类不同的场景：无监督的，有监督的，异构分布和多个源域问题。 通过在不同阶段进行领域自适应，研究者提出了三种不同的领域自适应方法：
1）样本自适应，对源域样本进行加权重采样，从而逼近目标域的分布。
2）特征层面自适应，将源域和目标域投影到公共特征子空间。
3）模型层面自适应，对源域误差函数进行修改，考虑目标域的误差。
散度 Divergence 在机器学习中，我们常常需要用一个分布Q去逼近一个目标分布P，我们希望能够找到一个目标函数D ( Q , P ) D( Q,P)D(Q,P)，计算Q到P的距离。而这一个目标函数，正是Divergence(散度)，比如常见的KL-Divergence，JS-Divergence等等。通过这个散度的计算我们就能不断地去优化我们的Q，寻找一个最优的参数去逼近真实的分布P。
Faster R-CNN Faster R-CNN是何凯明等大神在2015年提出目标检测算法，该算法在2015年的ILSVRV和COCO竞赛中获得多项第一。该算法在Fast R-CNN基础上提出了RPN候选框生成算法，使得目标检测速度大大提高。
 
 
Faster-RCNN由下面几部分组成：
  数据集，image input
  卷积层CNN等基础网络，提取特征得到feature map
  RPN层，再在经过卷积层提取到的feature map上用一个3x3的slide window，去遍历整个feature map,在遍历过程中每个window中心按rate，scale（1:2,1:1,2:1）生成9个anchors，然后再利用全连接对每个anchors做二分类（是前景还是背景）和初步bbox regression，最后输出比较精确的300个ROIs。 把经过卷积层feature map用ROI pooling固定全连接层的输入维度。
  然后把经过RPN输出的rois映射到ROIpooling的feature map上进行bbox回归和分类。</description>
    </item>
    
    <item>
      <title>DP动态规划——编辑距离问题</title>
      <link>https://ccqstark.github.io/p/dp_edit_distance/</link>
      <pubDate>Sat, 31 Oct 2020 17:03:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dp_edit_distance/</guid>
      <description>问题 设A和B是2个字符串。要用最少的字符操作将字符串A转换为字符串B。这里所说的字符操作包括 (1)删除一个字符； (2)插入一个字符； (3)将一个字符改为另一个字符。 将字符串A变换为字符串B所用的最少字符操作数称为字符串A到 B的编辑距离，记为d(A,B)。 对于给定的字符串A和字符串B，计算其编辑距离 d(A,B)。
输入格式: 第一行是字符串A，文件的第二行是字符串B。
提示：字符串长度不超过2000个字符。
输出格式: 输出编辑距离d(A,B)
输入样例: 在这里给出一组输入。例如：
fxpimuxwrs 输出样例: 在这里给出相应的输出。例如：
5思路 用动态规划算法可以将问题分解出最优子结构。
设dp[i][j]表示把A字符串前i个字符组成的字符串转变为B字符串前j个字符组成的字符串所需的最少的字符操作数
如果A字符串的第i个字符与B字符串的第j个字符串相同，则这个位置不需要操作，所需的操作等于dp[i-1][j-1]，否则需要进行修改，操作数就要+1
由于每个位置都可以进行修改、删除、插入三种操作，因此需要把这三种操作中编辑距离最小的作为dp[i][j]的值
递推公式(代码表示)：
if (A[i - 1] == B[j - 1]) // dp矩阵以1开始，字符数组是0开始，因此对应的话要-1 	dp[i][j] = dp[i - 1][j - 1]; // 如果对应的位置相同就不用操作，否则要修改所以要+1 else dp[i][j] = dp[i - 1][j - 1] + 1; // 修改 删除 插入 dp[i][j] = min(dp[i][j], min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); 表的维度：二维</description>
    </item>
    
    <item>
      <title>贪心算法——会场安排问题</title>
      <link>https://ccqstark.github.io/p/greedy_activity/</link>
      <pubDate>Sat, 31 Oct 2020 09:45:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/greedy_activity/</guid>
      <description>题目 假设要在足够多的会场里安排一批活动，并希望使用尽可能少的会场。设计一个有效的 贪心算法进行安排。（这个问题实际上是著名的图着色问题。若将每一个活动作为图的一个 顶点，不相容活动间用边相连。使相邻顶点着有不同颜色的最小着色数，相应于要找的最小 会场数。）
输入格式: 第一行有 1 个正整数k，表示有 k个待安排的活动。 接下来的 k行中，每行有 2个正整数，分别表示 k个待安排的活动开始时间和结束时间。时间 以 0 点开始的分钟计。
输出格式: 输出最少会场数。
输入样例: 51 2312 2825 3527 8036 50 输出样例: 在这里给出相应的输出。例如：
3思路 首先这道题就很像书中那道在一个会场中安排尽可能多的活动，但是，不能完全按之前那个思路来做！
这里是要用尽可能少的会场，而且从题中可以看出会场的结束时间没有限制，只要活动的开始时间比上一场要晚就行。如果我们按书中的办法把活动先按结束时间从小到大排序，然后对当前未安排的活动用一个会场进行尽可能多的安排，之后若还每安排完在开辟一个新的会场继续之前的操作。这样的算法是有问题的，因为这样的在一个会场中尽可能多的安排活动，而从全局来看（还有这道题的特点：会场结束时间无限制），这种策略并不能保证把所有活动安排在最少的会场，所以两个问题并不能完全等同，这就是我一开始犯的错误。
其实原因就在于：会场结束时间无限制，要用最少的会场。
正确解法有2种：
 把活动按开始时间从小到大排，当开始时间相同则结束时间早的优先。遍历活动再用之前的那种在一个会场安排尽可能多的活动，完了之后开辟一个新的会场继续安排，直到全部活动安排完毕。 把活动按结束时间从小到大排，当结束时间相同则开始时间早的优先。遍历活动，每次再遍历一次所有会场看结束时间是否满足可以安排下，都不能安排下就新开一个会场，然后每次还要对所有已经开辟的会场按结束时间进行从大到小再次排序，这样直到所有活动遍历安排完毕。  所以这道题是要把有限的活动尽量塞在最少的会场中，要从所有会场全局去考虑，而且这道题的特点是单个会场的结束时间没有限制，所以第一种解法是按开始时间排的而不用按结束时间。第二种按结束时间的话就需要每次重新遍历所有会场，每次还重排，保证从全局去考虑。
代码 解法1： // 按开始时间排序 #include &amp;lt;iostream&amp;gt;#include &amp;lt;algorithm&amp;gt;using namespace std; #define MAX 666  struct activity { int start; int end; int arrage; } activities[MAX]; int n; bool struct_compare(activity a, activity b) { if (a.</description>
    </item>
    
    <item>
      <title>DP动态规划——挖地雷</title>
      <link>https://ccqstark.github.io/p/dp_digmines/</link>
      <pubDate>Thu, 22 Oct 2020 01:05:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dp_digmines/</guid>
      <description>题目 在一个地图上有n个地窖（n≤200）,每个地窖中埋有一定数量的地雷。同时，给出地窖之间的连接路径，并规定路径都是单向的,且保证都是小序号地窖指向大序号地窖，也不存在可以从一个地窖出发经过若干地窖后又回到原来地窖的路径。某人可以从任意一处开始挖地雷，然后沿着指出的连接往下挖（仅能选择一条路径），当无连接时挖地雷工作结束。设计一个挖地雷的方案，使他能挖到最多的地雷。
输入格式: 第一行：地窖的个数；
第二行：为依次每个地窖地雷的个数；
下面若干行：
xi yi //表示从xi可到yi，xi&amp;lt;yi。
最后一行为&amp;quot;0 0&amp;quot;表示结束。
输出格式: k1-k2−…−kv //挖地雷的顺序 挖到最多的雷。
输入样例: 65 10 20 5 4 51 21 42 43 44 54 65 60 0输出样例: 3-4-5-634代码 #include &amp;lt;iostream&amp;gt;using namespace std; #define MAX 203 int matrix[MAX][MAX]; // 存放通路情况 int mines[MAX]; // 存放各坑地雷数 int dp_mat[MAX][MAX]; // 存放子问题最优解 int path[MAX]; // 存放路径 int n, ans, last_update; // last_update是最后一个更新最大值的点  void dig() { // 一行行扫  for (int i = 1; i &amp;lt;= n; i++) { // max_last是此点之前所有点可以挖到的最大地雷数  int max_last = 0; for (int k = 1; k &amp;lt;= i - 1; k++) { // 判断之前所有可以通向现在的点中，可以挖到最大的地雷数的路径的最后一点  if (matrix[k][i] == 1) { // 按列方向扫，可以通向本点的点  if (dp_mat[k][i] &amp;gt; max_last) { max_last = dp_mat[k][i]; path[i] = k; // 路径是所连接的上一点  } } } for (int j = i; j &amp;lt;= n; j++) { // max_last + 本点地雷数 = 以本点作为路径末点可以挖到的最大地雷数  dp_mat[i][j] = max_last + mines[i]; if (dp_mat[i][j] &amp;gt; ans) { // 更新最终答案的最大地雷数  ans = dp_mat[i][j]; // 记录最后更新最终答案的那个点，作为答案路径的末尾点，用数组回溯可以打印出完整路径  last_update = i; } } } } // 递归回溯打印完整路径 void print_path(int point) { if (point == 0) return; print_path(path[point]); if (point == last_update) { cout &amp;lt;&amp;lt; point &amp;lt;&amp;lt; endl; } else { cout &amp;lt;&amp;lt; point &amp;lt;&amp;lt; &amp;#34;-&amp;#34;; } } int main() { cin &amp;gt;&amp;gt; n; for (int i = 1; i &amp;lt;= n; i++) { cin &amp;gt;&amp;gt; mines[i]; } int a, b; while (cin &amp;gt;&amp;gt; a &amp;gt;&amp;gt; b) { if (a == 0 &amp;amp;&amp;amp; b == 0) break; matrix[a][b] = 1; } dig(); print_path(last_update); cout &amp;lt;&amp;lt; ans; } </description>
    </item>
    
    <item>
      <title>DP动态规划——单调递增最长子序列</title>
      <link>https://ccqstark.github.io/p/dp_increasing/</link>
      <pubDate>Wed, 21 Oct 2020 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dp_increasing/</guid>
      <description>题目 设计一个O(n2)时间的算法，找出由n个数组成的序列的最长单调递增子序列。
输入格式: 输入有两行： 第一行：n，代表要输入的数列的个数 第二行：n个数，数字之间用空格格开
输出格式: 最长单调递增子序列的长度
输入样例: 在这里给出一组输入。例如：
51 3 5 2 9输出样例: 在这里给出相应的输出。例如：
4思路 用动态规划的思想，利用子问题的最优解求更大一点的子问题。
设一个数组dp[i]用于存放数组中从0到i下标的序列中，最长的递增子序列的长度
双重遍历，如果arr[j]小于arr[i]，则dp[i]为dp[j]+1和dp[i]中较大的那个。即
dp[i] = max{ dp[j]+1, dp[i] }
由于每次重头又遍历了一次，并每次都分析最优解，避免了1 2 3 9 6 7 这样在最大数后面还有2个较小的数可以产生更长递增子序列的情况可能犯的错误。
这也说明这个算法的时间复杂度只能是O(n2)
代码 // 单调递增最长子序列 #include &amp;lt;iostream&amp;gt;using namespace std; #define MAX 666 int arr[MAX]; int dp[MAX]; int n; int longest_increasing(){ // 初始化第一个  dp[0] = 1; // 双重遍历  for (int i = 0;i&amp;lt;n;i++){ for (int j = 0;j&amp;lt;i;j++){ // 利用子问题最优解  if(arr[i]&amp;gt;arr[j]){ dp[i] = (dp[j]+1&amp;gt;dp[i])?</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合shiro&#43;JWT做鉴权</title>
      <link>https://ccqstark.github.io/p/springboot_shiro_jwt/</link>
      <pubDate>Sat, 17 Oct 2020 16:52:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_shiro_jwt/</guid>
      <description>添加依赖 &amp;lt;!-- shiro --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shiro&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;shiro-spring&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.4.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- JWT --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.auth0&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;java-jwt&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.11.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.jsonwebtoken&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;jjwt&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;0.9.1&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; JWT加密解密验证工具类 package com.ccqstark.springbootquick.util; import com.auth0.jwt.JWT; import com.auth0.jwt.JWTVerifier; import com.auth0.jwt.algorithms.Algorithm; import io.jsonwebtoken.Claims; import io.jsonwebtoken.JwtBuilder; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import org.apache.commons.codec.binary.Base64; import java.util.Date; import java.util.HashMap; import java.util.Map; import java.util.UUID; /* * 总的来说，工具类中有三个方法 * 获取JwtToken，获取JwtToken中封装的信息，判断JwtToken是否存在 * 1. encode()，参数是=签发人，存在时间，一些其他的信息=。返回值是JwtToken对应的字符串 * 2. decode()，参数是=JwtToken=。返回值是荷载部分的键值对 * 3. isVerify()，参数是=JwtToken=。返回值是这个JwtToken是否存在 * */ public class JwtUtil { // 创建默认的秘钥和算法，供无参的构造方法使用  private static final String defaultbase64EncodedSecretKey = &amp;#34;wdnmd&amp;#34;; private static final SignatureAlgorithm defaultsignatureAlgorithm = SignatureAlgorithm.</description>
    </item>
    
    <item>
      <title>[SpringBoot]使用阿里云OSS上传文件</title>
      <link>https://ccqstark.github.io/p/springboot_oss/</link>
      <pubDate>Sat, 17 Oct 2020 10:54:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_oss/</guid>
      <description>开通服务 登录阿里云，开通OSS服务，默认按量计费，为了业务稳定可以购买包月包年的资源包。
准备工作 创建Bucket，如果是为了作为网站的静态资源存储供用户访问的话把权限设为公共读，填写信息后创建成功，可以在Bucket下新建目录什么的。
单独创建一个RAM子用户用来调用API，选择编程访问，创建成功后一定要把AccessKeyID和AccessKeySecret等重要信息记下来，后面配置文件要用到。
然后要给这个子用户添加权限AliyunOSSFullAccess
Maven依赖 &amp;lt;!-- OSS --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.aliyun.oss&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;aliyun-sdk-oss&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.4.2&amp;lt;/version&amp;gt; &amp;lt;exclusions&amp;gt; &amp;lt;exclusion&amp;gt; &amp;lt;groupId&amp;gt;org.apache.httpcomponents&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;httpclient&amp;lt;/artifactId&amp;gt; &amp;lt;/exclusion&amp;gt; &amp;lt;/exclusions&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.httpcomponents&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;httpclient&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;4.4.1&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 配置文件 endpoint就是在存储桶的概览里地域节点，填外网访问那个就行
url填资源访问的URL的前面部分（填到.com/）
accessKeyId和accessKeySecret就是创建子用户时那个
bucketName就是存储桶的名字
# 阿里云ossoss:endpoint:*url:*accessKeyId:*accessKeySecret:*bucketName:*配置类 项目的config目录下新建OSS的配置类
package com.ccqstark.springbootquick.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import java.io.Serializable; /** * @Description: 阿里云 OSS 配置信息 * @Author: ccq * @Date: 2020/10/16 */ @Component //注册bean @Data @Configuration @ConfigurationProperties(prefix = &amp;#34;oss&amp;#34;) public class OSSConfig implements Serializable { private String endpoint; private String url; private String accessKeyId; private String accessKeySecret; private String bucketName; } 上传文件工具类 项目的util目录下新建这上传工具类</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合Druid数据源</title>
      <link>https://ccqstark.github.io/p/springboot_druid/</link>
      <pubDate>Sat, 17 Oct 2020 10:54:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_druid/</guid>
      <description>添加依赖 &amp;lt;!-- druid数据库连接池 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;druid&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.1.21&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- MySql数据库驱动 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!--分页插件 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.github.pagehelper&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;pagehelper-spring-boot-starter&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.0.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- log4j日志 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;log4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;log4j&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.2.17&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 添加配置 spring:datasource:username:rootpassword:root#serverTimezone=UTC解决时区的报错url:jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8driver-class-name:com.mysql.cj.jdbc.Drivertype:com.alibaba.druid.pool.DruidDataSource#Spring Boot 默认是不注入这些属性值的，需要自己绑定#druid 数据源专有配置initialSize:5minIdle:5maxActive:20maxWait:60000timeBetweenEvictionRunsMillis:60000minEvictableIdleTimeMillis:300000validationQuery:SELECT 1 FROM DUALtestWhileIdle:truetestOnBorrow:falsetestOnReturn:falsepoolPreparedStatements:true#配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入#如果允许时报错 java.lang.ClassNotFoundException: org.apache.log4j.Priority#则导入 log4j 依赖即可，Maven 地址：https://mvnrepository.com/artifact/log4j/log4jfilters:stat,wall,log4jmaxPoolPreparedStatementPerConnectionSize:20useGlobalDataSourceStat:trueconnectionProperties:druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500测试 编写测试类
@SpringBootTest class SpringbootQuickApplicationTests { @Autowired DataSource dataSource; @Test void contextLoads() throws SQLException { System.out.println(dataSource.getClass()); Connection connection = dataSource.getConnection(); System.out.println(connection); connection.close(); } } 运行后控制台出现如下druid连接池相关字样说明成功
2020-10-15 10:40:34.179 INFO 11352 --- [ main] com.</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合Mybatis</title>
      <link>https://ccqstark.github.io/p/springboot_mybatis/</link>
      <pubDate>Sat, 17 Oct 2020 10:54:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_mybatis/</guid>
      <description>以我的项目目录结构为例: com.ccqstark.springbootquick
导入依赖 &amp;lt;!-- springboot的mybatis --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.mybatis.spring.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mybatis-spring-boot-starter&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;2.1.1&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 配置 #整合mybatismybatis:type-aliases-package:com.ccqstark.springbootquick.pojomapper-locations:classpath:mybatis/mapper/*.xml编写POJO(用了Lombok) 在com.ccqstark.springbootquick下新建目录pojo，然后新建类User.java，用于存储数据的对象（与数据库中的表对应）
package com.ccqstark.springbootquick.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class User { private int id; private String name; private String pwd; } 编写Mapper 在com.ccqstark.springbootquick下新建目录mapper，然后新建UserMapper.java，用于写接口，CRUD函数
package com.ccqstark.springbootquick.mapper; import com.ccqstark.springbootquick.pojo.User; import org.apache.ibatis.annotations.Mapper; import org.springframework.stereotype.Repository; import java.util.List; // Mapper注解说明这是一个mybatis的mapper类 //@Mapper //如果有扫描的话这里可以不用写这个注解了 @Repository public interface UserMapper { List&amp;lt;User&amp;gt; queryUserList(); User queryByUserId(int id); int addUser(User user); int updateUser(User user); int deleteUser(int id); } 如果是以扫描的形式，就是在项目的app启动类加上注解**@MapperScan**</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合SLF4J-log4j</title>
      <link>https://ccqstark.github.io/p/springboot_slf4j-log4j/</link>
      <pubDate>Sat, 17 Oct 2020 10:54:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_slf4j-log4j/</guid>
      <description>导入依赖 &amp;lt;!-- SLF4j - log4j --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.8.0-alpha2&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 然后要在IDEA下载插件Maven Helper中把logback相关的包给Exclude，否则会出现冲突
配置 log4j.properties中配置
# rootLogger参数分别为：根Logger级别，输出器stdout，输出器loglog4j.rootLogger = info,stdout,log# 输出信息到控制台log4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = %d [%-5p] %l %rms: %m%n# 输出DEBUG级别以上的日志到D://log/debug.log，这个是日志文件存放的路径，根据时间情况进行设置log4j.appender.log = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.log.DatePattern = &#39;.&#39;yyyy-MM-ddlog4j.appender.log.File = D://log/debug.loglog4j.appender.log.Encoding = UTF-8#log4j.appender.log.Threshold = INFOlog4j.appender.log.layout = org.apache.log4j.PatternLayoutlog4j.appender.log.layout.ConversionPattern = %d [%-5p] (%c.%t): %m%n测试 编写测试类，使用@Slf4j注解之前确保使用了lombok
package com.ccqstark.springbootquick; import lombok.extern.slf4j.Slf4j; import org.junit.Test; @Slf4j public class LoggerTest { // private static final Logger log = LoggerFactory.</description>
    </item>
    
    <item>
      <title>DP动态规划——矩阵链相乘问题</title>
      <link>https://ccqstark.github.io/p/dp_matrix/</link>
      <pubDate>Mon, 12 Oct 2020 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dp_matrix/</guid>
      <description>问题引入 学过线性代数都知道矩阵的乘法，比如说矩阵A×B，就是A的每一行上的元素分别和B的每一列上对应位置的元素相乘再总体相加，每次得到一个位置上的元素的值。
假设A是p × q，B是q × r，那结果矩阵就是p × r，当然，能够相乘的条件是A的列数等于B的行数。
而A×B总共需要做的乘法数是p × q × r，由矩阵乘法的过程可知。
可以发现，当至少3个矩阵相乘时，比如ABC，(AB)C和(A)BC两种计算顺序所需做的乘法数是不同的。
现在的问题是一个矩阵链，比如A × B × C × D × E × F × G，要以什么样的顺序相乘才能得使得所需做的乘法数最小呢？
题目 输入格式: 每个输入文件为一个测试用例，每个测试用例的第一行给出一个正整数(1≤n≤100)，表示一共有n个矩阵A​1​​ ,A​2​​ ,…,A​n​​ ，第二行给出n+1个整数P​0​​ ,P​1​​ …P​n​​ ，以空格分隔，其中1≤P​i​​ ≤100(0≤i≤n)，第i个矩阵A​i​​ 是阶为P​i−1​​ ∗P​i​​ 的矩阵。
输出格式: 获得上述矩阵的乘积，所需的最少乘法次数。
输入样例: 在这里给出一组输入。例如：
 5
30 35 15 5 10 20
 输出样例: 在这里给出相应的输出。例如：
 11875
 思路 可以先求2个2个相邻相乘的值，然后用他们求3个3个相乘的，再4个&amp;hellip;依照此规律直到n个
当前个数阶段也需要把每种划分方案进行尝试，并得出最小的那种。比如我在算4个4个相乘的，那划分位置就有3个，每个都要遍历算一次，最后选最小那个，为下一阶段使用。
我们利用二维数组m[i][j]表示第i个到第j个矩阵连乘的最优解，有如下公式。
就是每次划分为2部分，整体最优解=左部分最优解+右部分的最优解+两者相乘所需乘法数
矩阵i的行数为p[i-1]，列数为p[i]
 
我们用一个二维矩阵来存储各阶段结果，数据就一步步往右上角填上去，最终答案就在最右上角。</description>
    </item>
    
    <item>
      <title>php后台开发基础环境搭建教程</title>
      <link>https://ccqstark.github.io/p/php_env/</link>
      <pubDate>Sat, 10 Oct 2020 11:39:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/php_env/</guid>
      <description>“工欲善其事，必先利其器”，作为后端搬砖工，我们敲代码之前需要给我们的电脑配上所需的软件环境，这样我们写的代码才能跑起来，原地起飞！
下载集成环境工具 可以选择xampp或phpenv（二选一就行）
xampp xampp = Apache + MySQL(MariaDB) + PHP + Perl，是一个集成环境软件，装了一个就可以轻松获得服务器，数据库和php语言的环境，轻松快捷而且免费，唯一的缺点可能是因为是外网所以速度稍慢或者可能需要科学上网
官网下载：https://www.apachefriends.org/zh_cn/index.html
选择自己的平台，然后点击下载，完成后运行exe
按普通安装步骤来就好，下面这个界面也默认选择就好，有些环境之后会用到
 
安装路径建议安装在D盘，然后等待安装完成就可以了，打开软件看到主面板
 
点击Apache和start按钮，等待图标变绿后再点击admin按钮或者浏览器地址栏输入localhost进行访问
如果可以看到服务器主页面说明成功
然后点击MySQL的start和admin，或者地址栏输入localhost/phpmyadmin/
出现一个登录界面，账号填写root，密码为空不用填，直接点击登录，出现下面画面说明成功
 
phpEnv 如果xampp实在太慢或者根本无法下载，也可以用phpEnv
官网下载：https://www.phpenv.cn/
根据你电脑是64位或者32位进行选择对应版本下载，如果不知道自己电脑是几位的可以点击教程查看
同样建议放在D盘，其它的默认就行，运行后出现下面界面
 
点击启动服务上面的图标，再点击打开主页的图标，看到phpEnv的主页面就说明成功了
页面拉到最下面如下
 
数据库端口填3306
用户名填root
密码也填root（注意：这里和xampp不一样）
点击连接按钮后再把页面拉到最下面显示连接成功就行啦
点击顶部菜单栏的开始，再点击phpMyAdmin，然后按上面xampp的对应内容操作就行
安装IDE IDE(Integrated Development Environment)，集成开发环境，为开发者提供了基本的代码编辑器的同时还提供了许多适用工具，功能强大，是码农开发的利器。
php语言我们使用的比较多的是JetBrains公司出的PhpStorm
官网下载：https://www.jetbrains.com/phpstorm/
软件体积较大，如果你不想装它的话可以自己下载VSCode然后下载相应插件（自己查）
由于软件是收费的，但是我们是学生，可以用学校给的邮箱进行学生认证就可以在毕业前都免费使用
学生认证地址：https://www.jetbrains.com/community/education/#students
学校邮箱获取方法 进入学校官网，进入智慧广外，	在个人事务中可以看到自己的邮箱地址，一般是学号@gdufs.edu.cn
 
下载破解版也可以，但可能比较花时间
按步骤完成后打开phpstorm，进行下面的配置流程
1. 新建一个项目  
2. 选择创建路径 建议把目录建在集成环境指定的网络根目录下，目录路径如下（以安装在D盘为例）：
xampp：D:\xampp\htdocs
phpEnv：D:\phpEnv\www\localhost</description>
    </item>
    
    <item>
      <title>使用Hugo&#43;github/gitee搭建个人博客</title>
      <link>https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Sun, 04 Oct 2020 02:44:33 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</guid>
      <description>基本操作 下载hugo 首先要有Golang的环境
然后在GitHub上选择对应平台下载
https://github.com/gohugoio/hugo/releases
Windows下载完要设置环境变量
创建新的站点 hugo new site &amp;lt;path&amp;gt; 
在指定路径下创建博客站点目录，目录最后是博客站点名
找到心仪主题 在下面这个网站上找到喜欢的主题，按照各自的文档进行设置
https://themes.gohugo.io/
本地预览 hugo server -t hugo-theme-stack --buildDrafts &amp;lt;theme&amp;gt;的位置填写主题的名称
创建博客 hugo new post/blog.md 博客的markdown文件一开始都是放在\content\post目录下
创建GitHub/Gitee仓库 Github把仓库命名为&amp;lt;name&amp;gt;.github.io即可开启博客托管服务
Gitee直接命名为自己的用户名，一字不差，同时需要手动开启Gitee Page服务
部署到远端仓库  生成\public目录  hugo --theme=hugo-theme-stack --baseUrl=&amp;#34;https://ccqstark.github.io/&amp;#34; --buildDrafts 根据具体仓库修改，也可以是&amp;quot;https://ccqstark.gitee.io/&amp;quot; 然后cd进public目录 在这个目录下创建git仓库，部署也是部署这个目录中的内容
 三部曲  git add . git commit -m &amp;#39;...&amp;#39; git push github master 更新博客 要新增一篇博客就继续按下面这个步骤走
hugo new post/name.md hugo --theme=hugo-theme-stack --baseUrl=&amp;#34;https://ccqstark.github.io/&amp;#34; --buildDrafts cd public git add .</description>
    </item>
    
  </channel>
</rss>
