<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on ccq&#39;s blog</title>
    <link>https://ccqstark.github.io/post/</link>
    <description>Recent content in Posts on ccq&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Apr 2021 00:00:00 +0800</lastBuildDate><atom:link href="https://ccqstark.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[leetcode]203.移除链表元素</title>
      <link>https://ccqstark.github.io/p/remove_elements/</link>
      <pubDate>Sun, 11 Apr 2021 00:00:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/remove_elements/</guid>
      <description>题目 给你一个链表的头节点 head 和一个整数 val ，请你删除链表中所有满足 Node.val == val 的节点，并返回 新的头节点 。
示例 1: 输入: head = [1,2,6,3,4,5,6], val = 6 输出: [1,2,3,4,5] 示例 2: 输入: head = [], val = 1 输出: [] 示例 3: 输入: head = [7,7,7,7], val = 7 输出: [] 分析 很普通的一道链表移除元素题目。这里我们主要考虑两种方式：
 直接在原链表上删除节点操作 增加一个虚拟节点（也叫哨兵节点）来操作  第二种方法主要是为了统一所有的删除节点操作，而不用在遇到要删除头节点情况时要单独写一段代码来处理。
而对于普通节点，删除这个节点的操作一般是把自己的前驱节点的next指针指向自己的后驱节点，如图：
由于是单链表，我们不能获得一个被删节点的前驱节点，所以一般是判断一个节点的next的值是否为被删值。
 对于C/C++，不能自动释放内存我们就要手动释放被删除的节点的内存，但Java会帮我们做好这一切。
 代码 ListNode节点类的代码：
public class ListNode { int val; ListNode next; ListNode() {} ListNode(int val) { this.</description>
    </item>
    
    <item>
      <title>[leetcode]59.螺旋矩阵II</title>
      <link>https://ccqstark.github.io/p/generate_matrix/</link>
      <pubDate>Wed, 07 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/generate_matrix/</guid>
      <description>题目 给你一个正整数 n ，生成一个包含 1 到 n^2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵 matrix 。
示例1: 输入:n = 3 输出:[[1,2,3],[8,9,4],[7,6,5]] 示例2: 输入: n = 1 输出: [[1]] 分析 第一次看到这道题感觉很懵很难，其实这道题也不涉及什么经典算法，就是考验你用代码复现这个过程道能力。
我们可以把按照题目给的图的按顺序去填充矩阵中的值，从第一个位置开始先从左到右➡️ ，再从上到下⬇️ ，再从右到左⬅️ ，再从下到上⬆️ 。如此循环，直到填充完毕，当然如果n为奇数的话就要考虑中间那一格需要最后去单独填充，偶数的话就没有这个问题。
当然每次循环还需要注意，每行/列都遵循的是左闭右开的原则，也就是说从头填到倒数第二个，最后一个就是下一行/列的，才能保证行/列填充行为的统一性。
还有一点是每次循环之后，每行/列需要填充的个数就要少2，看下下面的图就可以很直观的理解了。
下面就是n=5和n=4的例子：
代码 class Solution { public int[][] generateMatrix(int n) { // 矩阵本体  int[][] matrix = new int[n][n]; // 横行和纵向开始填充的起始点  int startx = 0, starty = 0; // 循环次数  int loop = n / 2; // n为奇数时矩阵的中间格  int mid = n / 2; // 用来填充的数字，从1开始  int count = 1; // 每列或每行在循环一次后，下一次循环时要填充的元素个数会减少2，用这个变量来记录当前减少的大小  int offset = 1; // 填充时用的指针，i为行，j为列  int i, j; while (loop-- !</description>
    </item>
    
    <item>
      <title>一次理解String的不可变性</title>
      <link>https://ccqstark.github.io/p/string/</link>
      <pubDate>Tue, 06 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/string/</guid>
      <description>今天在看有关StringBuilder和StringBuffer的文章的时候看到里面提及了有关String中的final字段和不可变的性质，发现这个知识点不是很熟悉，去查了很多文章之后整理出这篇。
新建字符串与缓冲池 新建一个String我们一般有下面2种方式：
String a = &amp;#34;ok&amp;#34;; String b = new String(&amp;#34;ok&amp;#34;); 这两种写法都可以创建一个String对象。
第一种用赋值运算符进行字符串初始化时，JVM自动为每个字符串生成一个String类的实例。
第二种就是创建String类的对象，因为String本来就是一个类，而不是像int和double那样的基本数据类型。
Java的字符串采用了缓冲池的技术，我们新建一个字符串的时候会去缓冲池寻找是否有已经存在的相同的字符串，如果有的话直接指向它即可；没有的话再创建，缓冲池是在堆里面的。
如下图，是下面代码的结果：
// one和two内容相同，指向同一String对象 String one = &amp;#34;someString&amp;#34;; String two = &amp;#34;someString&amp;#34;; 关于更深入的创建对象和之间的比较可以看下面这篇：
java 字符串缓冲池 String缓冲池_天天的专栏-CSDN博客
哪里不可变？ 那为什么说String不可变呢？我们明明可以通过给字符串变量赋一个新值来改变它的内容。
String str = &amp;#34;aaaaaaa&amp;#34;; System.out.println(str); str = &amp;#34;bbbbbbbbb&amp;#34;; System.out.println(str); // 输出 //aaaaaaa //bbbbbbbbb 实际上，当我们给字符串重新赋值的时候，它并不是去改变这个String对象中的字符数组char[] value的值（下面会讲到），而是去缓冲池里寻找有没有已经存在这个值的String对象，有的话就直接指向它，没有的话创建一个对象再指向它。
str只是一个引用，指向的String对象是在堆中的。改变字符串的值其实只是改变整个对象的引用。
而原来的String对象还是在那里没有被改变，之后要是有别的变量赋这个值可以继续指向它。
为什么不可变？ 我们看下String的部分源码：
public final class String implements java.io.Serializable, Comparable&amp;lt;String&amp;gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 } 重点在这个字符数组value就是存放字符串内容的地方，注意它是被final 修饰的，也就是一旦初始化之后它的值就不能改变。</description>
    </item>
    
    <item>
      <title>[leetcode]209.长度最小的子数组</title>
      <link>https://ccqstark.github.io/p/min_sub_array_len/</link>
      <pubDate>Sun, 04 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/min_sub_array_len/</guid>
      <description>题目 给定一个含有 n 个正整数的数组和一个正整数 target 。
找出该数组中满足其和 ≥ target 的长度最小的 连续子数组 [numsl, numsl+1, &amp;hellip;, numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。
示例 1: 输入: target = 7, nums = [2,3,1,2,4,3] 输出: 2 解释: 子数组 [4,3] 是该条件下的长度最小的子数组. 示例 2: 输入: target = 4, nums = [1,4,4] 输出: 1 示例 3: 输入: target = 11, nums = [1,1,1,1,1,1,1,1] 输出: 0 提示：
 1 &amp;lt;= target &amp;lt;= 109 1 &amp;lt;= nums.length &amp;lt;= 105 1 &amp;lt;= nums[i] &amp;lt;= 105  分析 这道题一开始想到的是暴力解法，也就是把每种可能的子数组长度都试一遍，后来发现这是道典型的滑动窗口题目，用滑动窗口就解决了。之后看官方题解有前缀+二分搜索的方法作为扩展。</description>
    </item>
    
    <item>
      <title>[leetcode]27.移除元素</title>
      <link>https://ccqstark.github.io/p/remove_element/</link>
      <pubDate>Fri, 02 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/remove_element/</guid>
      <description>题目 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。
不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。
元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。
分析 对于数组而言，我们原地移除元素的话就肯定要把被移除的元素后面的全部元素都往前挪一个位，这是最基本的操作。所以最普通的暴力解法就是删除一个，整体挪动一个位。优化一点的话就是当有几个需要删除的数连在一起时，我们找到边界后一起挪动n个位，减少整体挪动的次数。
最优的是经常被用到的双指针法，下面再解释。
代码 混合暴力法 public int removeElement(int[] nums, int val) { int len = nums.length; for (int left = 0; left &amp;lt; len; left++) { if (nums[left] == val) { // left位于最后一个元素时  if (left == len - 1) { return len - 1; } int right = left + 1; while (right &amp;lt;= len - 1 &amp;amp;&amp;amp; nums[right] == val) right++; if (right == len - 1 &amp;amp;&amp;amp; nums[right] == val) { // right超过长度时  return len - (right - left); } // 把元素right处整体前移到left  moveUp(left, right, nums, len); len = len - (right - left); } } return len; } // 该函数用于将right及后面的元素完前移到left位置 public void moveUp(int left, int right, int[] nums, int len) { int step = len - 1 - right; for (int i = 0; i &amp;lt;= step; i++) { nums[left + i] = nums[right + i]; } } 此方法其实是初步优化的暴力法，假设我们要移除值为2的元素，left指针找到第一被删除的元素，right指向left后第一个不等于2的元素，然后把从right开始的后面全部元素都往前挪至left位置。</description>
    </item>
    
    <item>
      <title>[leetcode]35.搜索插入位置</title>
      <link>https://ccqstark.github.io/p/search_insert/</link>
      <pubDate>Thu, 01 Apr 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/search_insert/</guid>
      <description>题目 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。
你可以假设数组中无重复元素。
示例 1: 输入: [1,3,5,6], 5 输出: 2 示例 2: 输入: [1,3,5,6], 2 输出: 1 示例 3: 输入: [1,3,5,6], 7 输出: 4 示例 4: 输入: [1,3,5,6], 0 输出: 0 分析 这道题就是找到数组中的数，遍历就不说了， 我们首先想到的比较好的解法当然是二分搜索
需要注意的是当目标值不存在于数组中时，我们要如何去定位合适的插入点？先上代码再分析。
代码 public int searchInsert(int[] nums, int target) { return binSearch(0,nums.length-1,target,nums); } public int binSearch(int left, int right, int x, int[] nums) { if (left &amp;gt; right) return left; int mid = (left + right) / 2; if (x &amp;lt; nums[mid]) return binSearch(left, mid - 1, x, nums); if (x &amp;gt; nums[mid]) return binSearch(mid + 1, right, x, nums); if (x == nums[mid]) return mid; return -1; } 这里是采用传统的递归来写二分，但其实这里可以不用，直接一个while循环就行</description>
    </item>
    
    <item>
      <title>[leetcode]1.两数之和</title>
      <link>https://ccqstark.github.io/p/two_sum/</link>
      <pubDate>Wed, 31 Mar 2021 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/two_sum/</guid>
      <description>题目 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数组下标。
你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。
你可以按任意顺序返回答案。
示例 1: 输入: nums = [2,7,11,15], target = 9 输出: [0,1] 解释: 因为 nums[0] + nums[1] == 9, 返回 [0, 1]. 示例 2: 输入: nums = [3,2,4], target = 6 输出: [1,2] 示例 3: 输入: nums = [3,3], target = 6 输出: [0,1] 提示：
 2 &amp;lt;= nums.length &amp;lt;= 103 -109 &amp;lt;= nums[i] &amp;lt;= 109 -109 &amp;lt;= target &amp;lt;= 109 只会存在一个有效答案  分析 这道题比较容易，就是在数组中找到数值x和target-x</description>
    </item>
    
    <item>
      <title>[SpringBoot]日志与异常捕获</title>
      <link>https://ccqstark.github.io/p/log_catch_error/</link>
      <pubDate>Thu, 18 Mar 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/log_catch_error/</guid>
      <description>项目中用到了之前说的日志门面slf4j+log4j，但是之后遇到了一些问题。比如程序报错没有记录在日志，记录的时间也和服务器的不一致（服务器是东八区时间），或者记录一些不需要的信息，此篇就来解决这些问题。
slf4j与log4j 之前有一篇文章介绍了slf4j怎么整合进Springboot，slf4j是一个日志门面，和我们所用的logback、log4j这些日志框架不同，它是为这些日志框架统一调用的API，通过api来调用具体的日志实现，简化了日志的配置与使用。slf4j要与具体的日志框架搭配，我用的是log4j。
&amp;lt;!-- SLF4j - log4j --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.8.0-alpha2&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 使用时只要用注解@Slf4j ，然后直接用log.info() 方法就可以记录日志了。
日志等级 日志分为以下几个等级：
OFF：最高等级的，用于关闭所有日志记录。
FATAL：会导致应用程序推出的严重错误。
ERROR：虽然发生错误事件，但仍然不影响系统的继续运行，一般也是程序的各种Exception，但要注意的是并不是所有异常都会导致Error，这就是下面的要说的异常捕获。打印错误和异常信息，如果不想输出太多的日志，可以使用这个级别。
WARN：警告，表明会出现潜在错误的情形，有些信息不是错误信息，只是一些提示。
INFO：消息在粗粒度级别上突出强调应用程序的运行过程。打印一些你感兴趣的或者重要的信息，这个可以用于生产环境中输出程序运行的一些重要信息，但是不能滥用，避免打印过多的日志。
DEBUG：主要用于开发过程中打印一些运行信息。但是打印但信息量过多，项目上线后不要用。
TRACE：跟踪日志，日志消息的粒度太细，很低的日志级别，一般不会使用。
ALL：最低等级的，用于打开所有日志记录。
通过修改日志配置文件log4j.properties来改变日志等级：
log4j.rootLogger = ERROR,stdout,log //第一个参数是日志等级 错误捕获 在SpringBoot我们希望有统一的操作来捕获系统运行过程中参数的所有错误，对未预测到对错误设置友好的返回值给用户，避免返回500状态码。甚至可以将系统产生的报错通过邮件发送给开发者，让生产环境中的错误能得到快速直接的监测和解决。
我们用到@RestControllerAdvice和@ExceptionHandler 这两个注解
@Slf4j @RestControllerAdvice // 用于拦截异常的注解 public class ExceptionProcesser extends ResponseEntityExceptionHandler { @Autowired private MailService mailService; /** * 全局异常捕获入日志 */ // 此注解用来标示处理哪个类的异常 	@ExceptionHandler(value = Exception.class) // 表示所有的异常都会处理 	public CommonResult&amp;lt;String&amp;gt; defaultErrorHandler(Exception e) { // slf4j下的日志用法，简洁易用 	log.</description>
    </item>
    
    <item>
      <title>[ElasticSearch]ElasticSearch入门与原理浅析</title>
      <link>https://ccqstark.github.io/p/es_principle/</link>
      <pubDate>Sat, 13 Mar 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/es_principle/</guid>
      <description>简介 引入 对于搜索功能，大家以前都是怎么做的呢？我相信很多人一开始也是用SQL的LIKE关键字加上%来匹配关键字的吧，为了实现更好的模糊效果就再加一个分词器来拆分关键词。但是，一旦被搜索的数据量一大，这种方式就显得效率低下。为了实现更好的效果，我们可以使用当前最流行的分布式搜索引擎——ElasticSearch 。
基本介绍 Elasticsearch 是一个分布式的免费开源搜索和分析引擎，适用于包括文本、数字、地理空间、结构化和非结构化数据等在内的所有类型的数据，基于著名的Lucene库进行开发，并以简单的RESTful风格的API进行调用，支持Java、JavaScript(Node)、Go、 C#(.NET)、PHP、Python、Ruby等多种语言。ElasticSearch已经成为非常流行的搜索引擎，一些著名厂商例如京东、滴滴、携程、Stack Overflow、GitHub等都在使用。
官网地址：https://www.elastic.co/cn/elasticsearch/
应用场景  应用程序搜索 网站搜索 企业搜索 日志处理和分析 基础设施指标和容器监测 应用程序性能监测 地理空间数据分析和可视化 安全分析 业务分析  ELK ELK，即ElasticSearch + logstash + Kibana ，是一套开源的日志收集与分析解决方案。利用ElasticSearch对数据进行快速的复杂条件检索，用logstash则作为数据管道从多个来源进行数据的采集、转换和传输，Kibana则通过生成多种可视化报表方便用户进行日志监控。
一般小型系统我们分析日志可以直接在用grep、awk等命令进行过滤与检索，或者拉到本地用LogViewer等专门的日志工具打开查看。但是当系统体量一大，采用的是分布式架构，集群中的日志管理就成为一个难题。ELK目的就是为了解决大型系统中的日志收集、存储与分析问题，方便将节点中的日志统一管理从而提高效率。
概念介绍 基本概念 ElasticSearch（简称es）搜索的时候不是去数据库里拿数据，它有自己的一套存储与索引体系。数据库中的数据需要同步到es中，通过索引的形式来存储数据才能实现高效检索。
es索引体系的基本概念和关系型数据库中的有些类似，我们可以对比着来看
   Index 索引 Database 数据库     Type 文档类型 Table 表   Document 文档 Row 记录   Field 字段 Column 属性   Mapping 映射 Schema 模型   Query DSL SQL    es的层次组织结构类似于MySQL这样的关系型数据库，index就像database那样存储着不同的type，也就是数据库中的table；再下一级就是document，类似于数据库中的一条条记录；每条记录的字段field就对应表中的column；mapping就如schema那样表示着库表的架构；es中的查询语言Query DSL则对标我们熟悉的SQL。通过类比可以更快地认识es的结构组成。</description>
    </item>
    
    <item>
      <title>Dubbo &#43; ZooKeeper 基础入门</title>
      <link>https://ccqstark.github.io/p/dubbo_zookeeper/</link>
      <pubDate>Wed, 24 Feb 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dubbo_zookeeper/</guid>
      <description>简介 Dubbo原本是阿里的开源框架，有很多著名厂商都在用。但在14年停更，之后Spring Cloud大红大紫，Dubbo终于在17年再度更新，并在18年合并当当网的基于它开发出的DubboX推出了2.6版本。之后在18年除夕夜，阿里正式将Dubbo捐献给了著名开源组织Apache，成为Apache众多开源项目之一。
Apache Dubbo
ZooKeeper 也是 Apache 软件基金会的一个软件项目，它为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。
ZooKeeper 的架构通过冗余服务实现高可用性。
Zookeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。
一个典型的分布式数据一致性的解决方案，分布式应用程序可以基于它实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。
Apache ZooKeeper
安装 使用Dubbo引入相关依赖即可，下面具体实践会涉及。
ZooKeeper可以去官网下载安装，这里我还是用docker在Linux服务器上安装。
# 拉取镜像 docker pull zookeeper # 启动 docker run -d \ -p 2181:2181 \ -v /home/zookeeper/data/:/data/ \ --name=zookeeper \ --privileged zookeeper # 如果想运行自带的客户端可以： docker exec -it zookeeper bash cd bin ./zkCli.sh # 之后就可以使用相关命令了 安装ZooInspector来可视化查看zookeeper

# 下载后进入build目录运行jar包，输入zookeeper的地址即可连接 java -jar zookeeper-dev-ZooInspector.jar 使用dubbo-admin可视化监控服务 dubbo-admin是一个Springboot项目，可以监控我们注册到注册中心到服务。
到github上下载
apache/dubbo-admin
解压后在application.properties中修改zookeeper地址
dubbo.registry.address=zookeeper://[ip]:2181 之后用mvn命令打包再运行jar包即可，也可以直接在idea里打包
运行后浏览器 打开localhost:7001 ，输入账号密码默认都为root，来到主页</description>
    </item>
    
    <item>
      <title>浅谈分布式系统与RPC</title>
      <link>https://ccqstark.github.io/p/distributed_rpc/</link>
      <pubDate>Wed, 24 Feb 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/distributed_rpc/</guid>
      <description>随着互联网的发展，Web应用与服务的规模不断扩大，才能满足不断增加的用户和需求。而原来只用一台服务器来部署的单机应用的方式已经满足不了如此大的需求。为了提高性能，单机发展为分布式架构，简单来说就是通过增加服务器的数量来弥补性能上的不足，当然同时也带来了一些问题。
分布式系统 分布式系统（distributed system）是由一组网络进行通信，为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统是为了用单体性能普通的机器完成单个计算机无法完成的计算、存储任务，通过合理调度各台计算机共同合作来提高性能，完成数量更多、体量更大的任务。
比如百度或淘宝这样体量规模都十分大的应用，为了满足如此大的用户数量和请求压力，背后肯定不止一台计算机在提供服务，而是部署了计算机集群，通过提升计算机的数量来提高处理数据的能力。在流量高峰时，大量的请求可以被均匀地分配给各台服务器去处理，从而避免其中一台服务器由于压力过大而宕机，这就是负载均衡，也就是nginx可以做的事情。
同时应用的各个模块也可以分别部署在不同的服务器上，比如淘宝这样的电商项目可以把服务拆分成商品、支付、订单、物流等不同的模块，不同模块可以部署在不同的服务器上。当一个模块部署到多台服务器上时，其中一台崩了，还有其他的服务器可以提供服务，提高了服务的稳定性与高可用。
而对于用户来说，他们都是访问一个域名来获取服务的，所以对于用户来说服务还是一个整体，而不需要知道是哪台服务器为他们提供了服务。
RPC 下图是Dubbo官方文档中的一张图，说明了网站应用的架构演变
原来应用是单体应用，程序如果要调用一个函数或方法就直接调用就行了，因为都是在本地。
现在应用采用分布式架构，服务被分散到不同的服务器上，一台服务器上的程序就会遇到需要调用另一台服务器上的某个方法的情况，这个时候就叫RPC(远程过程调用)(Remote Procedure call)
RPC的调用过程如下图：
通过网络发送调用消息就需要先序列化，到目标服务器后成功调用对应的服务后返回，反序列化得到结果。
Dubbo就是一个流行的RPC框架，提供面向接口代理的高性能RPC调用、智能负载均衡、服务自动注册与发现、高度可扩展能力、运行期流量调度（灰度发布）、可视化工具等功能。
流动计算架构 当服务增多时，服务的管理与资源的分配成为亟待解决的问题，此时，需要增加一个调度中心基于访问压力实时管理集群容量，提高集群的利用率。用于提高机器利用率的资源调度和治理中心(SOA)(Service Oriented Architecture)就十分重要。
服务通过在注册中心进行注册，被统一的管理起来并可被发现，并对用户开放。当用户需要用到某一服务时，就去注册中心拿，注册中心就会将对应的服务提供给他。
注册中心用的比较多的是Zookeeper</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合ElasticSearch</title>
      <link>https://ccqstark.github.io/p/springboot_es/</link>
      <pubDate>Thu, 04 Feb 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_es/</guid>
      <description>导入依赖 我们使用springboot操作es要用到对应的data相关starter
&amp;lt;!-- elasticsearch的starter依赖 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-elasticsearch&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- 将对象转为json传入source时要用 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;fastjson&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.2.75&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt;  ⚠️ 各springboot的版本对应特定的elasticsearch版本，引入上面的依赖时会自动下载对应版本的rest-high-level-client，使用时尽量使得版本对应，避免潜在问题。
 版本对应表如下：
我使用的这里用Springboot2.4.1，所以对应的elasticsearch是7.9.3版本
配置类 config目录下新建es的配置类ElasticSearchClientConfig.java
@Configuration public class ElasticSearchClientConfig { @Bean public RestHighLevelClient restHighLevelClient() { final CredentialsProvider credentialsProvider = new BasicCredentialsProvider(); credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(&amp;#34;elastic&amp;#34;, &amp;#34;[密码]&amp;#34;)); RestHighLevelClient client = new RestHighLevelClient( RestClient.builder( new HttpHost(&amp;#34;[ip]&amp;#34;, 9200, &amp;#34;http&amp;#34;)) .setHttpClientConfigCallback(httpClientBuilder -&amp;gt; { httpClientBuilder.disableAuthCaching(); return httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider); })); return client; } } 这里有用到x-pack基础安全功能，所以配置了用户和密码。如果没有用户和密码，参照官方文档连接代码如下：
RestHighLevelClient client = new RestHighLevelClient( RestClient.</description>
    </item>
    
    <item>
      <title>[ElasticSearch]REST风格操作</title>
      <link>https://ccqstark.github.io/p/es_rest/</link>
      <pubDate>Wed, 03 Feb 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/es_rest/</guid>
      <description>基本的rest命令    method url 功能     PUT localhost:9200/索引名称/类型名称/文档id 创建文档（指定文档id)   POST localhost:9200/索引名称/类型名称 创建文档（随机文档id）   POST localhost:9200/索引名称/类型名称/文档id/_update 修改文档   DELETE localhost:9200/索引名称/类型名称/文档id 删除文档   GET localhost:9200/索引名称/类型名称/文档id 查询文档，通过文档id   POST localhost:9200/索引名称/类型名称/_search 查询所有数据     ⚠️ 自定义类型将在以后的版本中弃用，规范起见一律使用_doc 类型
 文档字段的数据类型   字符串类型
text keyword
  数值类型
long integer short byte double float half float scaled float
  日期类型
date</description>
    </item>
    
    <item>
      <title>我的vim入门配置折腾</title>
      <link>https://ccqstark.github.io/p/vim/</link>
      <pubDate>Sun, 31 Jan 2021 21:26:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/vim/</guid>
      <description>由于这几天开始看《CS:APP》，我就开始寻求一款Mac上的轻量的C语言编辑器。找来找去，无非是VSCode、CLion和大名鼎鼎的Vim。
为了减少磁盘占用同时让自己更接近于底层，我还是硬着头皮折腾起了Vim，这个上古神器之前就一直让我望而却步，我对它的掌握程度也差不多是会退出的程度，这一次就打算好好来折腾下。
安装NeoVim Vim其实到目前为止，不同的分支版本还是很多的，比较流行的现代版本就要属NeoVim了，所以我在终端安装了它，用iTerm2运行着。
brew install neovim 安装完成后用nvim命令就可以打开
nvim 配置文件路径
传统的vim的配置配置文件为~/.vimrc
而nvim的配置文件为/.config/nvim/init.vim ，之后修改nvim配置文件就用这个，以下简称为init.vim
安装SpaceVim 作为小白，快速搭建一个好看实用的Vim开发环境那最好的选择就是SpaceVim 了，下面是官方的介绍：
 SpaceVim 是一个社区驱动的模块化的 Vim IDE，以模块的方式组织管理插件以及相关配置， 为不同的语言开发量身定制了相关的开发模块，该模块提供代码自动补全， 语法检查、格式化、调试、REPL 等特性。用户仅需载入相关语言的模块即可得到一个开箱即用的 Vim IDE。
 官网地址：
主页 | SpaceVim
官网的文档还是很全的，按官方文档就可以快速搭建出来了。以MacOS为例：
安装spacevim
curl -sLf https://spacevim.org/cn/install.sh | bash 完成后重新打开nvim就会自动下载相关插件。
然后就是主界面：
主题的修改可以参考官方文档
SpaceVim colorscheme 模块 | SpaceVim
快捷键符号说明
SPC 代表空格
&amp;lt;Leader&amp;gt; 默认为\
以下一些功能需要对mac进行一定的设置才能正常使用。
打开系统偏好设置 → 键盘
勾选将F1、F2等键用作标准功能键
这同时也解决了Chrome的F12 不能打开控制台的问题
文件目录树
按F3 可以打开或关闭
语法函数树
按F2可以打开或关闭
mac下可能会出现错误，解决方案：
brew install ctags-exuberant 然后init.vim里添加下面这行即可
let g:Tlist_Ctags_Cmd=&amp;#39;/usr/local/Cellar/ctags/5.8_1/bin/ctags&amp;#39; shell终端</description>
    </item>
    
    <item>
      <title>[Elastic]ElasticSearch 安全</title>
      <link>https://ccqstark.github.io/p/x_pack/</link>
      <pubDate>Fri, 29 Jan 2021 21:26:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/x_pack/</guid>
      <description>ElacticSearch索引中有大量的数据，如果没有一些安全措施的话会让系统处于一个十分危险的处境，引发的相关安全事件可以看看这篇文章。
你的Elasticsearch在&amp;quot;裸奔&amp;quot;吗？
而ElaticSearch官方的高级安全服务是收费的，主要给企业提供。但是从6.8和7.1版本开始，基础安全功能就免费了，而且已经集成在里面不用额外安装。
除此之外诸如Search Guard、ReadonlyREST、Nginx 等开源免费等方法来达到安全的目的，这里介绍的是使用官方的x-pack的基础安全功能，对于小项目来说够用了。
本文版本为7.10.1
修改配置文件 在elasticsearch.yml里新增
xpack.security.enabled:truexpack.security.transport.ssl.enabled:true之后重启 es
在es目录下执行 elasticsearch-setup-passwords interactive 然后输入多个用户的密码
Initiating the setup of passwords for reserved users elastic,apm_system,kibana,logstash_system,beats_system,remote_monitoring_user. You will be prompted to enter passwords as the process progresses. Please confirm that you would like to continue [y/N]y Enter password for [elastic]: Reenter password for [elastic]: Passwords do not match. Try again. Enter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana]: Reenter password for [kibana]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: Changed password for user [apm_system] Changed password for user [kibana] Changed password for user [logstash_system] Changed password for user [beats_system] Changed password for user [remote_monitoring_user] Changed password for user [elastic] 其中elastic用户相当与es的root用户，之后使用es和kibana需要这个用户的密码</description>
    </item>
    
    <item>
      <title>[Elastic]使用logstash同步MySQL数据</title>
      <link>https://ccqstark.github.io/p/logstash_mysql/</link>
      <pubDate>Thu, 28 Jan 2021 21:26:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/logstash_mysql/</guid>
      <description>安装logstash 在实际项目中使用es进行搜索，我们就要把mysql数据库中的数据同步到es索引库中。进行这项过程的工具很多，比如go-mysql-elasticsearch，canal等等，当然也可以使用ELK组合中的logsatsh 来完成。这里同样用docker来部署logstash容器。
拉取镜像 docker pull logstash:7.10.1 启动容器 启动后进入容器内，修改jvm启动的内存设置，地址为/usr/share/logstash/config/jvm.options
# 修改jvm内存分配 vi jvm.options # 修改下面的参数，单位可以为g和m -Xms256m -Xmx256m 修改后重启容器即可
下载插件与依赖包 docker exec -it logstash bash 安装logstash-input-jdbc插件
bin/logstash-plugin install logstash-input-jdbc 如果出现以下ERROR，说明logstash里本身已经包含有这个插件了，就无需安装。7.10.1的版本是已经自带了。
ERROR: Installation aborted, plugin &amp;#39;logstash-input-jdbc&amp;#39; is already provided by &amp;#39;logstash-integration-jdbc&amp;#39; 下载mysql-connector-java，也就是jdbc驱动
MySQL官方下载地址：https://downloads.mysql.com/archives/c-j/
下载对应版本后本地解压，上传到服务器，然后用docker cp命令复制到logstash容器中
只需要其中的jar包即可
# 把文件复制到容器内 docker cp [jar包路径] logstash:[容器内路径] 在/usr/share/logstash目录下新建mysql/目录，把jar包复制到这里
同步配置文件 在刚刚的mysql目录下新建jdbc.conf 文件，来配置同步操作
 单表同步  input { jdbc { # jar包的绝对路径 jdbc_driver_library =&amp;gt; &amp;#34;/usr/share/logstash/mysql/mysql-connector-java-5.1.48.jar&amp;#34; jdbc_driver_class =&amp;gt; &amp;#34;com.mysql.jdbc.Driver&amp;#34; # 数据库连接信息 jdbc_connection_string =&amp;gt; &amp;#34;jdbc:mysql://[ip]:3306/[库名]?</description>
    </item>
    
    <item>
      <title>[Elastic]使用docker安装ElasticSearch &#43; Kibana</title>
      <link>https://ccqstark.github.io/p/es_docker/</link>
      <pubDate>Wed, 27 Jan 2021 21:26:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/es_docker/</guid>
      <description>安装ElasticSearch 拉取镜像 docker pull elasticsearch:7.10.1 启动容器 同时挂载目录（包括配置文件和data）（挂载出来的位置自己定义）
docker run --name elasticsearch -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=&amp;#34;-Xms256m -Xmx256m&amp;#34; -d \ -v /home/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \ -v /home/es/data:/usr/share/elasticsearch/data elasticsearch:7.10.1 注意这里还设置了JVM的内存大小，默认为2G，有点大，很可能会因为内存不够而无法正常启动。可以像我这里改为256m或者其他值。
可能出现的错误 查看容器日志
docker logs elasticsearch 如果出现以下错误
max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] 则要修改服务器配置
vim /etc/sysctl.conf 添加这行
vm.max_map_count=262144 立即生效, 执行：
/sbin/sysctl -p 对挂载的宿主机data目录可能出现权限不足问题
chmod 777 [宿主机data目录] 配置跨域 到挂载出来到位置编辑配置文件
vim elasticsearch.yml 添加以下几行
network.host:0.0.0.0discovery.type:single-nodehttp.cors.enabled:truehttp.cors.allow-origin:&amp;#34;*&amp;#34;同时安全组和防火墙记得打开对应端口
记得每次修改完配置都要重启 docker restart elasticsearch 浏览器访问测试 http://[IP]:9200 看到类似以下的json就成功了</description>
    </item>
    
    <item>
      <title>什么是CAP理论？</title>
      <link>https://ccqstark.github.io/p/cap/</link>
      <pubDate>Thu, 21 Jan 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/cap/</guid>
      <description>随着移动互联网发展，用户和数据量越来越多，对应用系统提出了更高的要求，系统必须支持高并发访问和海量数据处理。
分布式系统技术就是用来解决集中式架构的性能瓶颈问题。一般来说，分布式系统是建立在网络之上的硬件或者软件系统，彼此之间通过消息等方式进行通信和协调。
分布式系统的核心是可扩展性，通过对服务、存储的扩展，来提高系统的处理能力，通过对多台服务器协同工作，来完成单台服务器无法处理的任务，尤其是高并发或者大数据量的任务。
单点故障（Single Point Failure）是指在系统中某个组件一旦失效，这会让整个系统无法工作。而分布式系统的设计就是为了避免出现单点故障问题，为了实现一个节点的失效不影响整个系统的运行。
无状态，是因为无状态的服务才能满足部分机器宕机不影响全部，可以随时进行扩展的需求。
由于分布式系统的特点，在分布式环境中更容易出现问题，比如节点之间通信失败、网络分区故障、多个副本的数据不一致等，为了更好地在分布式系统下进行开发，学者们提出了一系列的理论，其中具有代表性的就是 CAP 理论。
一致性是指“所有节点同时看到相同的数据”，即更新操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，等同于所有节点拥有数据的最新版本。
可用性是指“任何时候，读写都是成功的”，即服务一直可用，而且是正常响应时间。平时会看到一些 IT 公司说系统稳定性已经做到 3 个 9、4 个 9，即 99.9%、99.99%，这里的 n 个 9 就是对可用性的一个描述，叫做 SLA，即服务水平协议。比如我们说月度 99.95% 的 SLA，则意味着每个月服务出现故障的时间只能占总时间的 0.05%，如果这个月是 30 天，那么就是 21.6 分钟。
分区容忍性具体是指“当部分节点出现消息丢失或者分区故障的时候，分布式系统仍然能够继续运行”，即系统容忍网络出现分区，并且在遇到某节点或网络分区之间网络不可达的情况下，仍然能够对外提供满足一致性和可用性的服务。
在分布式系统中，由于系统的各层拆分，P 是确定的，CAP 的应用模型就是 CP 架构和 AP 架构。分布式系统所关注的，就是在 Partition Tolerance 的前提下，如何实现更好的 A 和更稳定的 C。
CAP 理论说明在架构设计中，不要把精力浪费在如何设计能满足三者的完美分布式系统上，而要合理进行取舍，因为三者无法完全兼得。
不同业务对于一致性的要求是不同的。例如，在微博上发表评论和点赞，用户对不一致是不敏感的，可以容忍相对较长时间的不一致，只要做好本地的交互，并不会影响用户体验；而我们在电商购物时，产品价格数据则是要求强一致性的，如果商家更改价格不能实时生效，则会对交易成功率有非常大的影响。
需要注意的是，CAP 理论中是忽略网络延迟的，也就是当事务提交时，节点间的数据复制一定是需要花费时间的。即使是同一个机房，从节点 A 复制到节点 B，由于现实中网络请求总是需要一定时间的，所以总会有一段时间不一致。
 CP 架构：对于 CP 来说，放弃可用性，追求一致性和分区容错性。
🔧 ZooKeeper就是采用了 CP 一致性，ZooKeeper 是一个分布式的服务框架，主要用来解决分布式集群中应用系统的协调和一致性问题。其核心算法是 Zab，所有设计都是为了一致性。在 CAP 模型中，ZooKeeper 是 CP，这意味着面对网络分区时，为了保持一致性，它是不可用的。</description>
    </item>
    
    <item>
      <title>Alfred &#43; iTerm2 快速ssh连接服务器</title>
      <link>https://ccqstark.github.io/p/alfred_iterm/</link>
      <pubDate>Sun, 10 Jan 2021 16:35:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/alfred_iterm/</guid>
      <description>为了提高在mac下连接ssh的效率，我们可以用alfred和iTerm配合，达到只要在输入框中输入ssh [主机名] 就可以快速连上了，效果如下图：
使用ssh config 在~/.ssh/config文件里添加服务器信息，没有的话就新建一个
vim ~/.ssh/config然后在文件中输入主机的信息，有多个主机就追加在后面就行
Host [主机名] HostName [ip] User root Port [端口]使用密钥登陆 如果本地的~/.ssh 目录下没有id_rsa 私钥文件，可以是使用下面这个目录生成，一路回车即可，如果已经有了就可以跳过这步
ssh-keygen然后将私钥复制到远程服务器
ssh-copy-id -i -p[端口号] root@ip按提示输入一次密码，就会自动将刚才生成的公钥id_rsa.pub追加到远程主机的~/.ssh/authorized_keys后面了，这样以后的 ssh 连接都不用输入密码了
安装alfred-ssh插件 https://github.com/deanishe/alfred-ssh
到上面github链接下载最新版：Secure-SHell的alfredworkflow，双击自动添加到alfred的workflow
添加后打开alfred的偏好设置可以看到效果如下：
测试用alfred输入ssh+主机名就可以连上服务器了，但是默认是用mac自带但终端，想用好看的iTrem2还需要进一步操作
安装alfred集成iTerm2配置 如下图，打开iTrem2的偏好设置，如下图设置默认方式为ssh
进入下面github链接，按说明操作
https://github.com/vitorgalvao/custom-alfred-iterm-scripts
按上面要求运行命令并粘贴到对应地方就完成了！
参考文章： 开发效率神器之alfred集成ssh+iTerm2实现一步登录服务器</description>
    </item>
    
    <item>
      <title>Jenkins &#43; docker &#43; springboot 完美配合全流程教程</title>
      <link>https://ccqstark.github.io/p/jenkins_docker_springboot/</link>
      <pubDate>Sat, 09 Jan 2021 23:01:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/jenkins_docker_springboot/</guid>
      <description>DevOps现在非常流行，CI/CD持续集成、持续部署也大火，而Jenkins就是自动化部署主要的工具之一。
这篇博客就来详细介绍用jenkins来实现自动化部署springboot项目的docker容器，堪称保姆级教学了。
用docker拉取jenkins镜像，启动Jenkins容器 这里采用的jenkins本身也是用docker容器部署的，不得不说docker确实好用，当然也可以直接运行在主机上
首先拉取Jenkins镜像 docker pull jenkins/jenkins ⚠️注意：切勿docker pull jenkins，已经废弃
启动Jenkins容器 docker run -u root -itd --name jenkins \ -p 6001:8080 \ -v $(which docker):/usr/bin/docker \ -v /var/run/docker.sock:/var/run/docker.sock -e TZ=&amp;#34;Asia/Shanghai&amp;#34; \ -v /etc/localtime:/etc/localtime:ro \ -v /volume1/docker/jenkins:/var/jenkins_home \ jenkins/jenkins  -p 6001:8080Jenkins默认网页访问端口为8080，将端口映射到外部主机6001端口 -v $(which docker):/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock使Jenkins内部可以使用docker命令 -e TZ=&amp;quot;Asia/Shanghai&amp;quot; -v /etc/localtime:/etc/localtime:ro配置Jenkins容器的时区 -v /volume1/docker/jenkins:/var/jenkins_home 将Jenkins的配置映射到外部主机卷，容器删除仍可保留配置  测试Jenkins容器内部 # 进入Jenkins的容器内部 docker exec -it jenkins bash # 判断docker命令是否正常执行 docker info 访问Jenkins网页端 用http://主机IP:6001 就可以访问Jenkins的网页端了</description>
    </item>
    
    <item>
      <title>[docker]用docker部署nginx</title>
      <link>https://ccqstark.github.io/p/docker_nginx/</link>
      <pubDate>Fri, 08 Jan 2021 15:46:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/docker_nginx/</guid>
      <description>如果是单体应用的话nginx用docker部署其实是更麻烦的，不过既然操作过就记录一下。
拉取nginx镜像 docker pull nginx 还是一样，默认是拉取latest版本，也可以选择想要的特定版本
启动并挂载html目录 docker container run \  -d \  -p 80:80 \  --name mynginx \  --v [本机挂载目录]:/usr/share/nginx/html \  nginx 复制出配置文件 docker container cp mynginx:/etc/nginx . 将复制出来的文件夹改名并移动到你想要的目录下，然后把容器停止并删除
挂载配置文件目录 最后一步就是重新启动一个容器并把html和配置文件目录都挂载了
docker run \  --name test-nginx \  -v [本机挂载html目录]:/usr/share/nginx/html \  -v [本机挂载nginx目录]:/etc/nginx \  -p 80:80 \  -d \  nginx 访问一下试试就可以了！
参考：
Nginx 容器教程</description>
    </item>
    
    <item>
      <title>[docker]用docker部署SpringBoot项目</title>
      <link>https://ccqstark.github.io/p/docker_springboot/</link>
      <pubDate>Thu, 07 Jan 2021 21:39:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/docker_springboot/</guid>
      <description>这篇文章介绍的是把整个Springboot后端项目部署到docker容器中，当然包括mysql和redis
按下面步骤一步步来
本地打出jar包 以Maven的话直接就IDEA里打出jar包到target目录下，这一步和以前一样
编写Dockerfile 可以用IDEA里的插件来写，也可以自己写dockerfile
在项目文件夹下新建一个文件Dockerfile
FROMopenjdk:8MAINTAINERccqstarkADD /target/[项目jar包名].jar app.jarEXPOSE8080ENTRYPOINT [&amp;#34;java&amp;#34;,&amp;#34;-jar&amp;#34;,&amp;#34;/app.jar&amp;#34;]⚠️注意：ADD后两个参数，第一个是项目jar包的相对路径，第二是把jar包在容器内重新命的名
构建镜像 在Dockerfile所在文件夹下运行build 命令，注意最后有一个.
docker build -f Dockerfile -t [镜像名]:[版本tag] .构建之后用docker images 查看一下自己构架的镜像
构建完之后本地run一下容器测试下
push上传到镜像仓库 其实也可以把jar包上传服务器后用服务器的docker来构建和运行
但这里采用的是把本地构建的镜像上传到repository，相当于镜像仓库，其他人想用这个镜像就可以从那拉取下来使用。
repository可以是官方的Docker Hub，但是比较慢，也可以花钱上传到阿里云的容器镜像服务就会快很多
这里是上传到docker hub，首先要登陆自己到docker账号，没有的话可以去官网注册一个
docker login -u [账户名] 输入密码成功后登陆
在push之前要给镜像打个tag，这样才能上传到自己账号对应的仓库下
docker tag [镜像名] [账户名]/[镜像仓库名]:latest 之后就可以上传了
docker push [账户名]/[镜像仓库名]:latest pull拉取镜像 docker pull [账户名]/[镜像仓库名]:[tag] 在服务器上拉取到镜像后就可以启动容器了
docker run -it -d -p [对外暴露端口]:8080 app:[tag] 部署MySQL容器 # 拉取mysql镜像 docker pull mysql:5.7 # 跑起来 docker run \ -d \ -p 3306:3306 \ -v /home/mysql/conf:/etc/mysql/conf.</description>
    </item>
    
    <item>
      <title>[docker]初识Dockerfile</title>
      <link>https://ccqstark.github.io/p/dockerfile/</link>
      <pubDate>Wed, 06 Jan 2021 21:13:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dockerfile/</guid>
      <description>Dockerfile介绍 dockfile是用来构建docker镜像的文件，命令参数脚本
💡构建步骤：
 编写dockerfile脚本 用docker build命令构建一个镜像 用docker run运行镜像 用docker push发布镜像（DockerHub、阿里云仓库）  在官网点击镜像会跳转到github对应的dockerfile
可以发现这些镜像也是通过dockerfile来构建的
上图是centos的dockerfile，其中scratch是最基本的，90%都是基于这个镜像。
然后ADD 就是添加来一层centos相关的镜像文件
官方很多镜像都是基础包，功能很少，很多我们需要的都没有，所以我们通常都会构建自己的镜像。
比如我们可以直接构建一个centos+jdk+tomcat+mysql的镜像，不就直接有来一个可以运行javaweb项目的环境镜像了吗？
Dockerfile构建过程 基本规则  每个关键字（保留字）都是大写的 执行顺序是从上到下的 &amp;ldquo;#&amp;rdquo; 表示注释 每一个指令都会创建一个新的镜像层，并提交  以前开发交付都是用jar包或war包，现在云原生时代交付的就是docker镜像，docker镜像也逐渐成为企业交付标准，而构建docker镜像就需要学会编写dockerfile
什么是云原生？聊聊云原生的今生_阿里云开发者-CSDN博客
Dockerfile常用指令    指令关键字 作用     FROM 构建镜像所用的基础镜像   MAINTAINER 镜像作者，一般是姓名+邮箱   RUN 镜像构建时运行的命令   ADD 为镜像添加内容   WORKDIR 镜像的工作目录   VOLUME 挂载目录   EXPOSE 暴露的端口   CMD 容器启动时需要运行的命令，只有最后一个会生效，可被替代   ENTRYPOINT 也是指定启动时需要运行的命令，但是可以追加   ONBUILD 构建一个被继承的dockerfile时会运行ONBUILD的指令。触发指令   COPY 类似ADD，将文件拷贝到镜像中   ENV 构建时设置的环境变量    实践：构建自己的centos 举个例子：</description>
    </item>
    
    <item>
      <title>[docker]容器数据卷</title>
      <link>https://ccqstark.github.io/p/docker_volumes/</link>
      <pubDate>Wed, 06 Jan 2021 16:51:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/docker_volumes/</guid>
      <description>把容器内的目录挂载到宿主机的某一个目录下，实现双向同步。
也就是说两者都指向了同一文件目录下，在其中一端所做的修改都会同步。
好处：
 MySQL数据持久化，不会因为删了容器就没了 方便修改文件，比如nginx的配置文件  基本使用 bind mounts 以启动一个centos容器为例
docker run -it -v [宿主机目录]:[容器内目录] centos /bin/bash -it ：-t选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开，通常写成-it
-v ：挂载卷所需参数，后面的映射是[宿主机目录]:[容器内目录]
用此命令查看容器参数
docker inspect [容器id] 如上图，在Mounts 字段中可以看到：
Source 表示宿主机中被映射的目录
Destination 表示容器内要映射的目录
这种挂载方式称为bind mounts
实践：MySQL挂载 拉取mysql镜像 docker search mysql docker pull mysql:5.7 启动容器 -d 后台运行
-p 端口映射
-v 数据卷挂载
—name 容器名字
docker run \ -d \ -p 3310:3306 \ -v /home/mysql/conf:/etc/mysql/conf.d \ -v /home/mysql/data:/var/lib/mysql \ -e MYSQL_ROOT_PASSWORD=[你配置的mysql密码] \ --name [容器名] \ mysql:5.</description>
    </item>
    
    <item>
      <title>MacOS终端美化指北</title>
      <link>https://ccqstark.github.io/p/mac_terminal/</link>
      <pubDate>Wed, 06 Jan 2021 02:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/mac_terminal/</guid>
      <description>终于从Windows转到心心念念的MacOS上进行开发，虽然是黑苹果但是软件层面上没有太大的区别，程序员还是得用mac啊这终端上真的比windows好用无数倍，那终端到手后还是要折腾美化的，那就开始吧。 先看下我，还可以吧？ 准备工作 先保证自己下载homebrew和wget，安装软件或下载包很多情况下要用到它们，特别homebrew是mac下最好用的包管理器一定要有。下载方法网上也很多的，建议先下homebrew再用它下wget。
iTerm2 首先是下载第三方终端iTerm2，mac自带的终端用的比较少，大家用的最多还是这个。 官网下载
zsh zsh是shell的一种，mac默认的shell是bash，一般来说我们也是用zsh比较多，因为命令更多更好用。
下载zsh brew install zsh 切换shell为zsh # 查看当前使用的shell echo $SHELL # 切换为zsh chsh -s /bin/zsh 运行完上面命令后重启一下即可
oh-my-zsh oh-my-zsh用于美化终端，可以让你拥有很多好看的主题。
安装 wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh sh install.sh 运行上面的命令来下载安装脚本并运行脚本，成功后会有如下画面
更换主题 oh-my-zsh有很多默认的主题，可以在~/.zshrc中修改ZSH_THEME来切换不同主题。 这里我推荐powerlever10k，它集合了很多不同主题风格的样式，支持自定义，如果默认主题中没有你满意的那推荐就用它。下面就讲powerlevel10k的安装方法。
下载 git clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 安装所需字体 # 安装 nerd-font 字体 brew tap homebrew/cask-fonts # 其他所需字体 cd ~ git clone https://github.com/powerline/fonts.git --depth=1 # 到目录下执行安装脚本 cd fonts ./install.sh # 删除刚刚下载的 cd .. rm -rf fonts 配置 vim ~/.</description>
    </item>
    
    <item>
      <title>记一次服务器被攻击</title>
      <link>https://ccqstark.github.io/p/first_attack/</link>
      <pubDate>Sun, 22 Nov 2020 22:10:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/first_attack/</guid>
      <description>事情经过 11月17号这天早上上着课，突然有用户反馈应用卡顿，使用不了。我感觉上去看了果然是这样，有时数据加载很慢甚至加载不出来，我感到焦虑与害怕，害怕数据库和别人一样被黑了然后删光要钱，课都没心情听了。然后手机下了个Termius，先把服务关了。
中午回到宿舍后看了数据库发现数据完好无损，赶紧备份了一波，然后寻找问题。
内存和CPU和磁盘都挺正常，看了服务器的安全日志，那登录记录刷刷的，有人在暴力破解我的root密码！
由于下午还有体育课，就先直接关了服务器，然后上课去了。
下午来到实验室，重新打开服务器，又开始攻击了，气死了。用脚本封了攻击者一百多个肉鸡ip，以为可以了之后，把服务开启，通知用户可以用了。
结果用户又说太卡了，我又检查了一波，CPU、内存、磁盘正常，然后这个带宽就不太正常了，我学生机的1M/s都超了，应该是这个原因导致卡的。
用命令找了进程发现好像也没哪个占用很多呀，弄了很久还是很迷惑，攻击者的ip也明明被我加入黑名单了呀，之后还开了腾讯云的专业机阻断，还是很卡，卡到我ssh都连不太上。然后有个办法叫我改ssh的22端口，我怕操作失误连自己都直接连不上就GG了，然后就算了不这样搞了。
最后只能屁颠屁颠去找客服，他跟我说也是其他正常带宽跑满，叫我看有没有什么进程占用很多，主要是建议我临时升级带宽。
我想着：啊好家伙，开始了。但是也没啥其他办法，就去买了3天升级到3M/s的带宽，不贵，结果也是真香。
后来最多手动在安全组加了几个奇怪ip封掉，服务就完成稳定下来了，看来没有什么是加钱不能解决的。
后来过了两天攻击者还在继续冲，除了影响我带宽之外其实也没太大问题反正他进不来的，问了师兄建议说改22端口，反正重要使用期也过了，我就试试改下，还真有用，安全日志也没攻击者那些破解记录了，带宽也占用也再降了，说明攻击者也是冲22，这下直接完全被挡住，带宽也不占了。
第一次与黑客对线还是学到了很多的，也加强了我的安全防范意识
查看系统状态命令 下面有些命令工具需要额外安装的，直接yum install xxx安装就行
查看服务器安全日志(动态实时)(CentOS) tail -f /var/log/secure 查看CPU等的使用情况(按进程) top 查看内存使用情况 free -h 查看磁盘使用情况 df -hl 查看网络带宽占用(按ip) iftop -i eth0 jnettop 按Q退出
查看网络带宽占用(按进程) nethogs 还有防火墙工具iptables和firewall-cmd
https://wangchujiang.com/linux-command/c/iptables.html
https://wangchujiang.com/linux-command/c/firewall-cmd.html
编写自动化脚本封禁暴力破解登录的ip 从安全日志中读取记录，把那些多次登录失败的ip写进请求黑名单中（hosts.deny），但是这种办法只是拒绝连接，如果黑客继续攻击还是会占用带宽
先找个目录，vim建立一个脚本文件
vim /usr/local/secure_ssh.sh 然后编写脚本
#! /bin/bash cat /var/log/secure|awk &amp;#39;/Failed/{print $(NF-3)}&amp;#39;|sort|uniq -c|awk &amp;#39;{print $2&amp;#34;=&amp;#34;$1;}&amp;#39; &amp;gt; /usr/local/bin/black.txt for i in `cat /usr/local/bin/black.txt` do IP=`echo $i |awk -F= &amp;#39;{print $1}&amp;#39;` NUM=`echo $i|awk -F= &amp;#39;{print $2}&amp;#39;` result=$(cat /etc/hosts.</description>
    </item>
    
    <item>
      <title>[机器学习论文]Domain Adaptive Faster R-CNN for Object Detection in the Wild</title>
      <link>https://ccqstark.github.io/p/ml_domain_adaptation/</link>
      <pubDate>Sun, 22 Nov 2020 22:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/ml_domain_adaptation/</guid>
      <description>问题引入与研究目标 目标检测的数据集的收集往往是在现实场景中进行的，因此数据中目标的外观、背景、光照、图像质量等方面的巨大差异会导致训练数据和测试数据之间出现巨大的领域偏移。比如汽车在不同天气条件下驾驶收集到的数据，或者是相机的类型和设置的不同也会导致数据的领域偏移。这样的偏移会导致性能显著下降，尽管收集尽可能多的数据集可以降低这种影响，但是注释边界框也是一个费时费力的过程，因此开发一个新的算法来应对跨领域目标检测问题就尤为重要。
论文中方法适用于无监督场景，在源域有完整的监督，而在目标域没有监督。这样就可以不增加人工标注成本的前提下减少跨域对目标检测效率的影响。
关键术语介绍 目标检测 Object Detection 目标检测，也叫目标提取，是一种基于目标几何和统计特征的图像分割，它将目标的分割和识别合二为一，其准确性和实时性是整个系统的一项重要能力。尤其是在复杂场景中，需要对多个目标进行实时处理时，目标自动提取和识别就显得特别重要。目标检测主要有三个层次：
一是分类（Classification），即是将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。这一任务是最简单、最基础的图像理解任务，也是深度学习模型最先取得突破和实现大规模应用的任务。其中，ImageNet是最权威的评测集，每年的ILSVRC催生了大量的优秀深度网络结构，为其他任务提供了基础。在应用领域，人脸、场景的识别等都可以归为分类任务。
二是检测（Detection）。分类任务关心整体，给出的是整张图片的内容描述，而检测则关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。相比分类，检测给出的是对图片前景和背景的理解，我们需要从背景中分离出感兴趣的目标，并确定这一目标的描述（类别和位置），因而，检测模型的输出是一个列表，列表的每一项使用一个数据组给出检出目标的类别和位置（常用矩形检测框的坐标表示）。
三是分割（Segmentation）。分割包括语义分割（semantic segmentation）和实例分割（instance segmentation），前者是对前背景分离的拓展，要求分离开具有不同语义的图像部分，而后者是检测任务的拓展，要求描述出目标的轮廓（相比检测框更为精细）。分割是对图像的像素级描述，它赋予每个像素类别（实例）意义，适用于理解要求较高的场景，如无人驾驶中对道路和非道路的分割。
领域自适应 Domain Adaptation 领域自适应（Domain Adaptation）是迁移学习中的一种代表性方法，指的是利用信息丰富的源域样本来提升目标域模型的性能。 领域自适应问题中两个至关重要的概念：
源域（source domain）表示与测试样本不同的领域，但是有丰富的监督信息
目标域（target domain）表示测试样本所在的领域，无标签或者只有少量标签。源域和目标域往往属于同一类任务，但是分布不同
根据目标域和源域的不同类型，领域自适应问题有四类不同的场景：无监督的，有监督的，异构分布和多个源域问题。 通过在不同阶段进行领域自适应，研究者提出了三种不同的领域自适应方法：
1）样本自适应，对源域样本进行加权重采样，从而逼近目标域的分布。
2）特征层面自适应，将源域和目标域投影到公共特征子空间。
3）模型层面自适应，对源域误差函数进行修改，考虑目标域的误差。
散度 Divergence 在机器学习中，我们常常需要用一个分布Q去逼近一个目标分布P，我们希望能够找到一个目标函数D ( Q , P ) D( Q,P)D(Q,P)，计算Q到P的距离。而这一个目标函数，正是Divergence(散度)，比如常见的KL-Divergence，JS-Divergence等等。通过这个散度的计算我们就能不断地去优化我们的Q，寻找一个最优的参数去逼近真实的分布P。
Faster R-CNN Faster R-CNN是何凯明等大神在2015年提出目标检测算法，该算法在2015年的ILSVRV和COCO竞赛中获得多项第一。该算法在Fast R-CNN基础上提出了RPN候选框生成算法，使得目标检测速度大大提高。
 
 
Faster-RCNN由下面几部分组成：
  数据集，image input
  卷积层CNN等基础网络，提取特征得到feature map
  RPN层，再在经过卷积层提取到的feature map上用一个3x3的slide window，去遍历整个feature map,在遍历过程中每个window中心按rate，scale（1:2,1:1,2:1）生成9个anchors，然后再利用全连接对每个anchors做二分类（是前景还是背景）和初步bbox regression，最后输出比较精确的300个ROIs。 把经过卷积层feature map用ROI pooling固定全连接层的输入维度。
  然后把经过RPN输出的rois映射到ROIpooling的feature map上进行bbox回归和分类。</description>
    </item>
    
    <item>
      <title>DP动态规划——编辑距离问题</title>
      <link>https://ccqstark.github.io/p/dp_edit_distance/</link>
      <pubDate>Sat, 31 Oct 2020 17:03:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dp_edit_distance/</guid>
      <description>问题 设A和B是2个字符串。要用最少的字符操作将字符串A转换为字符串B。这里所说的字符操作包括 (1)删除一个字符； (2)插入一个字符； (3)将一个字符改为另一个字符。 将字符串A变换为字符串B所用的最少字符操作数称为字符串A到 B的编辑距离，记为d(A,B)。 对于给定的字符串A和字符串B，计算其编辑距离 d(A,B)。
输入格式: 第一行是字符串A，文件的第二行是字符串B。
提示：字符串长度不超过2000个字符。
输出格式: 输出编辑距离d(A,B)
输入样例: 在这里给出一组输入。例如：
fxpimuxwrs 输出样例: 在这里给出相应的输出。例如：
5思路 用动态规划算法可以将问题分解出最优子结构。
设dp[i][j]表示把A字符串前i个字符组成的字符串转变为B字符串前j个字符组成的字符串所需的最少的字符操作数
如果A字符串的第i个字符与B字符串的第j个字符串相同，则这个位置不需要操作，所需的操作等于dp[i-1][j-1]，否则需要进行修改，操作数就要+1
由于每个位置都可以进行修改、删除、插入三种操作，因此需要把这三种操作中编辑距离最小的作为dp[i][j]的值
递推公式(代码表示)：
if (A[i - 1] == B[j - 1]) // dp矩阵以1开始，字符数组是0开始，因此对应的话要-1 	dp[i][j] = dp[i - 1][j - 1]; // 如果对应的位置相同就不用操作，否则要修改所以要+1 else dp[i][j] = dp[i - 1][j - 1] + 1; // 修改 删除 插入 dp[i][j] = min(dp[i][j], min(dp[i - 1][j] + 1, dp[i][j - 1] + 1)); 表的维度：二维</description>
    </item>
    
    <item>
      <title>贪心算法——会场安排问题</title>
      <link>https://ccqstark.github.io/p/greedy_activity/</link>
      <pubDate>Sat, 31 Oct 2020 09:45:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/greedy_activity/</guid>
      <description>题目 假设要在足够多的会场里安排一批活动，并希望使用尽可能少的会场。设计一个有效的 贪心算法进行安排。（这个问题实际上是著名的图着色问题。若将每一个活动作为图的一个 顶点，不相容活动间用边相连。使相邻顶点着有不同颜色的最小着色数，相应于要找的最小 会场数。）
输入格式: 第一行有 1 个正整数k，表示有 k个待安排的活动。 接下来的 k行中，每行有 2个正整数，分别表示 k个待安排的活动开始时间和结束时间。时间 以 0 点开始的分钟计。
输出格式: 输出最少会场数。
输入样例: 51 2312 2825 3527 8036 50 输出样例: 在这里给出相应的输出。例如：
3思路 首先这道题就很像书中那道在一个会场中安排尽可能多的活动，但是，不能完全按之前那个思路来做！
这里是要用尽可能少的会场，而且从题中可以看出会场的结束时间没有限制，只要活动的开始时间比上一场要晚就行。如果我们按书中的办法把活动先按结束时间从小到大排序，然后对当前未安排的活动用一个会场进行尽可能多的安排，之后若还每安排完在开辟一个新的会场继续之前的操作。这样的算法是有问题的，因为这样的在一个会场中尽可能多的安排活动，而从全局来看（还有这道题的特点：会场结束时间无限制），这种策略并不能保证把所有活动安排在最少的会场，所以两个问题并不能完全等同，这就是我一开始犯的错误。
其实原因就在于：会场结束时间无限制，要用最少的会场。
正确解法有2种：
 把活动按开始时间从小到大排，当开始时间相同则结束时间早的优先。遍历活动再用之前的那种在一个会场安排尽可能多的活动，完了之后开辟一个新的会场继续安排，直到全部活动安排完毕。 把活动按结束时间从小到大排，当结束时间相同则开始时间早的优先。遍历活动，每次再遍历一次所有会场看结束时间是否满足可以安排下，都不能安排下就新开一个会场，然后每次还要对所有已经开辟的会场按结束时间进行从大到小再次排序，这样直到所有活动遍历安排完毕。  所以这道题是要把有限的活动尽量塞在最少的会场中，要从所有会场全局去考虑，而且这道题的特点是单个会场的结束时间没有限制，所以第一种解法是按开始时间排的而不用按结束时间。第二种按结束时间的话就需要每次重新遍历所有会场，每次还重排，保证从全局去考虑。
代码 解法1： // 按开始时间排序 #include &amp;lt;iostream&amp;gt;#include &amp;lt;algorithm&amp;gt;using namespace std; #define MAX 666  struct activity { int start; int end; int arrage; } activities[MAX]; int n; bool struct_compare(activity a, activity b) { if (a.</description>
    </item>
    
    <item>
      <title>DP动态规划——挖地雷</title>
      <link>https://ccqstark.github.io/p/dp_digmines/</link>
      <pubDate>Thu, 22 Oct 2020 01:05:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dp_digmines/</guid>
      <description>题目 在一个地图上有n个地窖（n≤200）,每个地窖中埋有一定数量的地雷。同时，给出地窖之间的连接路径，并规定路径都是单向的,且保证都是小序号地窖指向大序号地窖，也不存在可以从一个地窖出发经过若干地窖后又回到原来地窖的路径。某人可以从任意一处开始挖地雷，然后沿着指出的连接往下挖（仅能选择一条路径），当无连接时挖地雷工作结束。设计一个挖地雷的方案，使他能挖到最多的地雷。
输入格式: 第一行：地窖的个数；
第二行：为依次每个地窖地雷的个数；
下面若干行：
xi yi //表示从xi可到yi，xi&amp;lt;yi。
最后一行为&amp;quot;0 0&amp;quot;表示结束。
输出格式: k1-k2−…−kv //挖地雷的顺序 挖到最多的雷。
输入样例: 65 10 20 5 4 51 21 42 43 44 54 65 60 0输出样例: 3-4-5-634代码 #include &amp;lt;iostream&amp;gt;using namespace std; #define MAX 203 int matrix[MAX][MAX]; // 存放通路情况 int mines[MAX]; // 存放各坑地雷数 int dp_mat[MAX][MAX]; // 存放子问题最优解 int path[MAX]; // 存放路径 int n, ans, last_update; // last_update是最后一个更新最大值的点  void dig() { // 一行行扫  for (int i = 1; i &amp;lt;= n; i++) { // max_last是此点之前所有点可以挖到的最大地雷数  int max_last = 0; for (int k = 1; k &amp;lt;= i - 1; k++) { // 判断之前所有可以通向现在的点中，可以挖到最大的地雷数的路径的最后一点  if (matrix[k][i] == 1) { // 按列方向扫，可以通向本点的点  if (dp_mat[k][i] &amp;gt; max_last) { max_last = dp_mat[k][i]; path[i] = k; // 路径是所连接的上一点  } } } for (int j = i; j &amp;lt;= n; j++) { // max_last + 本点地雷数 = 以本点作为路径末点可以挖到的最大地雷数  dp_mat[i][j] = max_last + mines[i]; if (dp_mat[i][j] &amp;gt; ans) { // 更新最终答案的最大地雷数  ans = dp_mat[i][j]; // 记录最后更新最终答案的那个点，作为答案路径的末尾点，用数组回溯可以打印出完整路径  last_update = i; } } } } // 递归回溯打印完整路径 void print_path(int point) { if (point == 0) return; print_path(path[point]); if (point == last_update) { cout &amp;lt;&amp;lt; point &amp;lt;&amp;lt; endl; } else { cout &amp;lt;&amp;lt; point &amp;lt;&amp;lt; &amp;#34;-&amp;#34;; } } int main() { cin &amp;gt;&amp;gt; n; for (int i = 1; i &amp;lt;= n; i++) { cin &amp;gt;&amp;gt; mines[i]; } int a, b; while (cin &amp;gt;&amp;gt; a &amp;gt;&amp;gt; b) { if (a == 0 &amp;amp;&amp;amp; b == 0) break; matrix[a][b] = 1; } dig(); print_path(last_update); cout &amp;lt;&amp;lt; ans; } </description>
    </item>
    
    <item>
      <title>DP动态规划——单调递增最长子序列</title>
      <link>https://ccqstark.github.io/p/dp_increasing/</link>
      <pubDate>Wed, 21 Oct 2020 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dp_increasing/</guid>
      <description>题目 设计一个O(n2)时间的算法，找出由n个数组成的序列的最长单调递增子序列。
输入格式: 输入有两行： 第一行：n，代表要输入的数列的个数 第二行：n个数，数字之间用空格格开
输出格式: 最长单调递增子序列的长度
输入样例: 在这里给出一组输入。例如：
51 3 5 2 9输出样例: 在这里给出相应的输出。例如：
4思路 用动态规划的思想，利用子问题的最优解求更大一点的子问题。
设一个数组dp[i]用于存放数组中从0到i下标的序列中，最长的递增子序列的长度
双重遍历，如果arr[j]小于arr[i]，则dp[i]为dp[j]+1和dp[i]中较大的那个。即
dp[i] = max{ dp[j]+1, dp[i] }
由于每次重头又遍历了一次，并每次都分析最优解，避免了1 2 3 9 6 7 这样在最大数后面还有2个较小的数可以产生更长递增子序列的情况可能犯的错误。
这也说明这个算法的时间复杂度只能是O(n2)
代码 // 单调递增最长子序列 #include &amp;lt;iostream&amp;gt;using namespace std; #define MAX 666 int arr[MAX]; int dp[MAX]; int n; int longest_increasing(){ // 初始化第一个  dp[0] = 1; // 双重遍历  for (int i = 0;i&amp;lt;n;i++){ for (int j = 0;j&amp;lt;i;j++){ // 利用子问题最优解  if(arr[i]&amp;gt;arr[j]){ dp[i] = (dp[j]+1&amp;gt;dp[i])?</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合shiro&#43;JWT做鉴权</title>
      <link>https://ccqstark.github.io/p/springboot_shiro_jwt/</link>
      <pubDate>Sat, 17 Oct 2020 16:52:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_shiro_jwt/</guid>
      <description>添加依赖 &amp;lt;!-- shiro --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.shiro&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;shiro-spring&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.4.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- JWT --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.auth0&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;java-jwt&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.11.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.jsonwebtoken&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;jjwt&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;0.9.1&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; JWT加密解密验证工具类 package com.ccqstark.springbootquick.util; import com.auth0.jwt.JWT; import com.auth0.jwt.JWTVerifier; import com.auth0.jwt.algorithms.Algorithm; import io.jsonwebtoken.Claims; import io.jsonwebtoken.JwtBuilder; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; import org.apache.commons.codec.binary.Base64; import java.util.Date; import java.util.HashMap; import java.util.Map; import java.util.UUID; /* * 总的来说，工具类中有三个方法 * 获取JwtToken，获取JwtToken中封装的信息，判断JwtToken是否存在 * 1. encode()，参数是=签发人，存在时间，一些其他的信息=。返回值是JwtToken对应的字符串 * 2. decode()，参数是=JwtToken=。返回值是荷载部分的键值对 * 3. isVerify()，参数是=JwtToken=。返回值是这个JwtToken是否存在 * */ public class JwtUtil { // 创建默认的秘钥和算法，供无参的构造方法使用  private static final String defaultbase64EncodedSecretKey = &amp;#34;wdnmd&amp;#34;; private static final SignatureAlgorithm defaultsignatureAlgorithm = SignatureAlgorithm.</description>
    </item>
    
    <item>
      <title>[SpringBoot]使用阿里云OSS上传文件</title>
      <link>https://ccqstark.github.io/p/springboot_oss/</link>
      <pubDate>Sat, 17 Oct 2020 10:54:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_oss/</guid>
      <description>开通服务 登录阿里云，开通OSS服务，默认按量计费，为了业务稳定可以购买包月包年的资源包。
准备工作 创建Bucket，如果是为了作为网站的静态资源存储供用户访问的话把权限设为公共读，填写信息后创建成功，可以在Bucket下新建目录什么的。
单独创建一个RAM子用户用来调用API，选择编程访问，创建成功后一定要把AccessKeyID和AccessKeySecret等重要信息记下来，后面配置文件要用到。
然后要给这个子用户添加权限AliyunOSSFullAccess
Maven依赖 &amp;lt;!-- OSS --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.aliyun.oss&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;aliyun-sdk-oss&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.4.2&amp;lt;/version&amp;gt; &amp;lt;exclusions&amp;gt; &amp;lt;exclusion&amp;gt; &amp;lt;groupId&amp;gt;org.apache.httpcomponents&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;httpclient&amp;lt;/artifactId&amp;gt; &amp;lt;/exclusion&amp;gt; &amp;lt;/exclusions&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.apache.httpcomponents&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;httpclient&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;4.4.1&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 配置文件 endpoint就是在存储桶的概览里地域节点，填外网访问那个就行
url填资源访问的URL的前面部分（填到.com/）
accessKeyId和accessKeySecret就是创建子用户时那个
bucketName就是存储桶的名字
# 阿里云ossoss:endpoint:*url:*accessKeyId:*accessKeySecret:*bucketName:*配置类 项目的config目录下新建OSS的配置类
package com.ccqstark.springbootquick.config; import lombok.Data; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import java.io.Serializable; /** * @Description: 阿里云 OSS 配置信息 * @Author: ccq * @Date: 2020/10/16 */ @Component //注册bean @Data @Configuration @ConfigurationProperties(prefix = &amp;#34;oss&amp;#34;) public class OSSConfig implements Serializable { private String endpoint; private String url; private String accessKeyId; private String accessKeySecret; private String bucketName; } 上传文件工具类 项目的util目录下新建这上传工具类</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合Druid数据源</title>
      <link>https://ccqstark.github.io/p/springboot_druid/</link>
      <pubDate>Sat, 17 Oct 2020 10:54:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_druid/</guid>
      <description>添加依赖 &amp;lt;!-- druid数据库连接池 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.alibaba&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;druid&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.1.21&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- MySql数据库驱动 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!--分页插件 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.github.pagehelper&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;pagehelper-spring-boot-starter&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.0.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- log4j日志 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;log4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;log4j&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.2.17&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 添加配置 spring:datasource:username:rootpassword:root#serverTimezone=UTC解决时区的报错url:jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC&amp;amp;useUnicode=true&amp;amp;characterEncoding=utf-8driver-class-name:com.mysql.cj.jdbc.Drivertype:com.alibaba.druid.pool.DruidDataSource#Spring Boot 默认是不注入这些属性值的，需要自己绑定#druid 数据源专有配置initialSize:5minIdle:5maxActive:20maxWait:60000timeBetweenEvictionRunsMillis:60000minEvictableIdleTimeMillis:300000validationQuery:SELECT 1 FROM DUALtestWhileIdle:truetestOnBorrow:falsetestOnReturn:falsepoolPreparedStatements:true#配置监控统计拦截的filters，stat:监控统计、log4j：日志记录、wall：防御sql注入#如果允许时报错 java.lang.ClassNotFoundException: org.apache.log4j.Priority#则导入 log4j 依赖即可，Maven 地址：https://mvnrepository.com/artifact/log4j/log4jfilters:stat,wall,log4jmaxPoolPreparedStatementPerConnectionSize:20useGlobalDataSourceStat:trueconnectionProperties:druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500测试 编写测试类
@SpringBootTest class SpringbootQuickApplicationTests { @Autowired DataSource dataSource; @Test void contextLoads() throws SQLException { System.out.println(dataSource.getClass()); Connection connection = dataSource.getConnection(); System.out.println(connection); connection.close(); } } 运行后控制台出现如下druid连接池相关字样说明成功
2020-10-15 10:40:34.179 INFO 11352 --- [ main] com.</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合Mybatis</title>
      <link>https://ccqstark.github.io/p/springboot_mybatis/</link>
      <pubDate>Sat, 17 Oct 2020 10:54:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_mybatis/</guid>
      <description>以我的项目目录结构为例: com.ccqstark.springbootquick
导入依赖 &amp;lt;!-- springboot的mybatis --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.mybatis.spring.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mybatis-spring-boot-starter&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;2.1.1&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 配置 #整合mybatismybatis:type-aliases-package:com.ccqstark.springbootquick.pojomapper-locations:classpath:mybatis/mapper/*.xml编写POJO(用了Lombok) 在com.ccqstark.springbootquick下新建目录pojo，然后新建类User.java，用于存储数据的对象（与数据库中的表对应）
package com.ccqstark.springbootquick.pojo; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class User { private int id; private String name; private String pwd; } 编写Mapper 在com.ccqstark.springbootquick下新建目录mapper，然后新建UserMapper.java，用于写接口，CRUD函数
package com.ccqstark.springbootquick.mapper; import com.ccqstark.springbootquick.pojo.User; import org.apache.ibatis.annotations.Mapper; import org.springframework.stereotype.Repository; import java.util.List; // Mapper注解说明这是一个mybatis的mapper类 //@Mapper //如果有扫描的话这里可以不用写这个注解了 @Repository public interface UserMapper { List&amp;lt;User&amp;gt; queryUserList(); User queryByUserId(int id); int addUser(User user); int updateUser(User user); int deleteUser(int id); } 如果是以扫描的形式，就是在项目的app启动类加上注解**@MapperScan**</description>
    </item>
    
    <item>
      <title>[SpringBoot]整合SLF4J-log4j</title>
      <link>https://ccqstark.github.io/p/springboot_slf4j-log4j/</link>
      <pubDate>Sat, 17 Oct 2020 10:54:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/springboot_slf4j-log4j/</guid>
      <description>导入依赖 &amp;lt;!-- SLF4j - log4j --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.8.0-alpha2&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; 然后要在IDEA下载插件Maven Helper中把logback相关的包给Exclude，否则会出现冲突
配置 log4j.properties中配置
# rootLogger参数分别为：根Logger级别，输出器stdout，输出器loglog4j.rootLogger = info,stdout,log# 输出信息到控制台log4j.appender.stdout = org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout = org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern = %d [%-5p] %l %rms: %m%n# 输出DEBUG级别以上的日志到D://log/debug.log，这个是日志文件存放的路径，根据时间情况进行设置log4j.appender.log = org.apache.log4j.DailyRollingFileAppenderlog4j.appender.log.DatePattern = &#39;.&#39;yyyy-MM-ddlog4j.appender.log.File = D://log/debug.loglog4j.appender.log.Encoding = UTF-8#log4j.appender.log.Threshold = INFOlog4j.appender.log.layout = org.apache.log4j.PatternLayoutlog4j.appender.log.layout.ConversionPattern = %d [%-5p] (%c.%t): %m%n测试 编写测试类，使用@Slf4j注解之前确保使用了lombok
package com.ccqstark.springbootquick; import lombok.extern.slf4j.Slf4j; import org.junit.Test; @Slf4j public class LoggerTest { // private static final Logger log = LoggerFactory.</description>
    </item>
    
    <item>
      <title>DP动态规划——矩阵链相乘问题</title>
      <link>https://ccqstark.github.io/p/dp_matrix/</link>
      <pubDate>Mon, 12 Oct 2020 21:07:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/dp_matrix/</guid>
      <description>问题引入 学过线性代数都知道矩阵的乘法，比如说矩阵A×B，就是A的每一行上的元素分别和B的每一列上对应位置的元素相乘再总体相加，每次得到一个位置上的元素的值。
假设A是p × q，B是q × r，那结果矩阵就是p × r，当然，能够相乘的条件是A的列数等于B的行数。
而A×B总共需要做的乘法数是p × q × r，由矩阵乘法的过程可知。
可以发现，当至少3个矩阵相乘时，比如ABC，(AB)C和(A)BC两种计算顺序所需做的乘法数是不同的。
现在的问题是一个矩阵链，比如A × B × C × D × E × F × G，要以什么样的顺序相乘才能得使得所需做的乘法数最小呢？
题目 输入格式: 每个输入文件为一个测试用例，每个测试用例的第一行给出一个正整数(1≤n≤100)，表示一共有n个矩阵A​1​​ ,A​2​​ ,…,A​n​​ ，第二行给出n+1个整数P​0​​ ,P​1​​ …P​n​​ ，以空格分隔，其中1≤P​i​​ ≤100(0≤i≤n)，第i个矩阵A​i​​ 是阶为P​i−1​​ ∗P​i​​ 的矩阵。
输出格式: 获得上述矩阵的乘积，所需的最少乘法次数。
输入样例: 在这里给出一组输入。例如：
 5
30 35 15 5 10 20
 输出样例: 在这里给出相应的输出。例如：
 11875
 思路 可以先求2个2个相邻相乘的值，然后用他们求3个3个相乘的，再4个&amp;hellip;依照此规律直到n个
当前个数阶段也需要把每种划分方案进行尝试，并得出最小的那种。比如我在算4个4个相乘的，那划分位置就有3个，每个都要遍历算一次，最后选最小那个，为下一阶段使用。
我们利用二维数组m[i][j]表示第i个到第j个矩阵连乘的最优解，有如下公式。
就是每次划分为2部分，整体最优解=左部分最优解+右部分的最优解+两者相乘所需乘法数
矩阵i的行数为p[i-1]，列数为p[i]
 
我们用一个二维矩阵来存储各阶段结果，数据就一步步往右上角填上去，最终答案就在最右上角。
代码 // 矩阵链相乘问题 #include &amp;lt;iostream&amp;gt;#include &amp;lt;string.</description>
    </item>
    
    <item>
      <title>php后台开发基础环境搭建教程</title>
      <link>https://ccqstark.github.io/p/php_env/</link>
      <pubDate>Sat, 10 Oct 2020 11:39:00 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/php_env/</guid>
      <description>“工欲善其事，必先利其器”，作为后端搬砖工，我们敲代码之前需要给我们的电脑配上所需的软件环境，这样我们写的代码才能跑起来，原地起飞！
下载集成环境工具 可以选择xampp或phpenv（二选一就行）
xampp xampp = Apache + MySQL(MariaDB) + PHP + Perl，是一个集成环境软件，装了一个就可以轻松获得服务器，数据库和php语言的环境，轻松快捷而且免费，唯一的缺点可能是因为是外网所以速度稍慢或者可能需要科学上网
官网下载：https://www.apachefriends.org/zh_cn/index.html
选择自己的平台，然后点击下载，完成后运行exe
按普通安装步骤来就好，下面这个界面也默认选择就好，有些环境之后会用到
 
安装路径建议安装在D盘，然后等待安装完成就可以了，打开软件看到主面板
 
点击Apache和start按钮，等待图标变绿后再点击admin按钮或者浏览器地址栏输入localhost进行访问
如果可以看到服务器主页面说明成功
然后点击MySQL的start和admin，或者地址栏输入localhost/phpmyadmin/
出现一个登录界面，账号填写root，密码为空不用填，直接点击登录，出现下面画面说明成功
 
phpEnv 如果xampp实在太慢或者根本无法下载，也可以用phpEnv
官网下载：https://www.phpenv.cn/
根据你电脑是64位或者32位进行选择对应版本下载，如果不知道自己电脑是几位的可以点击教程查看
同样建议放在D盘，其它的默认就行，运行后出现下面界面
 
点击启动服务上面的图标，再点击打开主页的图标，看到phpEnv的主页面就说明成功了
页面拉到最下面如下
 
数据库端口填3306
用户名填root
密码也填root（注意：这里和xampp不一样）
点击连接按钮后再把页面拉到最下面显示连接成功就行啦
点击顶部菜单栏的开始，再点击phpMyAdmin，然后按上面xampp的对应内容操作就行
安装IDE IDE(Integrated Development Environment)，集成开发环境，为开发者提供了基本的代码编辑器的同时还提供了许多适用工具，功能强大，是码农开发的利器。
php语言我们使用的比较多的是JetBrains公司出的PhpStorm
官网下载：https://www.jetbrains.com/phpstorm/
软件体积较大，如果你不想装它的话可以自己下载VSCode然后下载相应插件（自己查）
由于软件是收费的，但是我们是学生，可以用学校给的邮箱进行学生认证就可以在毕业前都免费使用
学生认证地址：https://www.jetbrains.com/community/education/#students
学校邮箱获取方法 进入学校官网，进入智慧广外，	在个人事务中可以看到自己的邮箱地址，一般是学号@gdufs.edu.cn
 
下载破解版也可以，但可能比较花时间
按步骤完成后打开phpstorm，进行下面的配置流程
1. 新建一个项目  
2. 选择创建路径 建议把目录建在集成环境指定的网络根目录下，目录路径如下（以安装在D盘为例）：
xampp：D:\xampp\htdocs
phpEnv：D:\phpEnv\www\localhost</description>
    </item>
    
    <item>
      <title>使用Hugo&#43;github/gitee搭建个人博客</title>
      <link>https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Sun, 04 Oct 2020 02:44:33 +0800</pubDate>
      
      <guid>https://ccqstark.github.io/p/%E4%BD%BF%E7%94%A8hugo-github/gitee%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</guid>
      <description>基本操作 下载hugo 首先要有Golang的环境
然后在GitHub上选择对应平台下载
https://github.com/gohugoio/hugo/releases
Windows下载完要设置环境变量
创建新的站点 hugo new site &amp;lt;path&amp;gt; 
在指定路径下创建博客站点目录，目录最后是博客站点名
找到心仪主题 在下面这个网站上找到喜欢的主题，按照各自的文档进行设置
https://themes.gohugo.io/
本地预览 hugo server -t &amp;lt;theme&amp;gt; --buildDrafts &amp;lt;theme&amp;gt;的位置填写主题的名称
创建博客 hugo new post/blog.md 博客的markdown文件一开始都是放在\content\post目录下
创建GitHub/Gitee仓库 Github把仓库命名为&amp;lt;name&amp;gt;.github.io即可开启博客托管服务
Gitee直接命名为自己的用户名，一字不差，同时需要手动开启Gitee Page服务
部署到远端仓库  生成\public目录  hugo --theme=hugo-theme-stack --baseUrl=&amp;#34;https://ccqstark.github.io/&amp;#34; --buildDrafts 根据具体仓库修改，也可以是&amp;quot;https://ccqstark.gitee.io/&amp;quot; 然后cd进public目录 在这个目录下创建git仓库，部署也是部署这个目录中的内容
 三部曲  git add . git commit -m &amp;#39;...&amp;#39; git push github master 更新博客 要新增一篇博客就继续按下面这个步骤走
hugo new post/name.md hugo --theme=hugo-theme-stack --baseUrl=&amp;#34;https://ccqstark.github.io/&amp;#34; --buildDrafts cd public git add .</description>
    </item>
    
  </channel>
</rss>
